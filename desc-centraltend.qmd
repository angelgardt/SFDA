# Меры центральной тенденции

```{r opts, echo=FALSE, eval=TRUE}
knitr::opts_chunk$set(echo = FALSE, eval = TRUE, warning = FALSE, message = FALSE, error = FALSE)
```

```{r pkgs}
library(tidyverse)
theme_set(theme_bw())
```

Мы знаем, что наши переменные-признаки могут быть некоторым образом распределены --- как в генеральной совокупности, так и в выборке. Как именно они распределены, описывается распределением случайной величины.

Вот мы собрали некоторые данные и получили какое-то эмпирическое распределение наших переменных. Нам бы, конечно, хотелось понять, что там такое за распределение. И первым шагом к пониманию этого будет *описание* распределения.


## Виды статистики

Вообще статистика [как набор методов и инструментов] делится на два вида:

- **Описательная статистика (descriptive statistics[^desc-stats1])** занимается обработкой статистических данных, их наглядным представлением, и собственно описанием через некоторые характеристики.
    - Эти характеристики, количественно описывающие особенности имеющихся данных, называются **описательными статистиками (descriptive statistics[^desc-stats2]).**
    - Задача описательной статистики --- ёмко описать имеющиеся данные и составить на основе этих описаний общее представление о них, а также обнаружить особенности, которые могут повлиять на дальнейший анализ.
- **Статистика вывода (inferential statistics)** занимается поиском ответов на содержательные вопросы, которые мы задаем данным в ходе их анализа в рамках научных и практических исследований.
    - Состоит из двух компонентов --- **тестирования статистических гипотез** и **статистических методов**.

[^desc-stats1]: Mass (uncountable) noun.
[^desc-stats2]: Countable noun, plural in this case.

:::{.callout-note}
### Замечание о машинном обучении

Вы наверняка не раз слышали словосочетание «машинное обучение». Это что-то, что время от времени становится то менее, то более хайпово. На самом деле, статистические методы лежат где-то между статистикой вывода и машинным обучением.

Почему?

Дело в том, что на статистические методы можно смотреть по-разному.

- Если нашей задачей является *поиск ответов на исследовательские вопросы* о закономерностях, о связи каких-либо факторов или влиянии переменных друг на друга, то мы будем смотреть на статистические модели с точки зрения *статистики вывода*. Это позволит нам находить ответы на интересующие нас вопросы --- причем не важно, говорим мы о научных исследованиях или об исследованиях в индустрии.
- Если перед нами стоит задача хорошо *предсказывать одни переменные на основании значений других* --- например, выдавать рекомендации на Яндекс Музыке или в Яндекс Лавке --- то мы будем смотреть на те же статистические модели с точки зрения *машинного обучения*.

То есть, модели абсолютно одни и те же, но то, какую модель мы назовем хорошей и как мы эту «хорошесть» определим, будет различаться в зависимости от задачи --- исследовательская или предиктивная --- которая перед нами стоит.
:::

Мы начнем знакомиться со статистикой с описательной статистики, а именно с мер центральной тенденции.



## Меры центральной тенденции

Итак, мы хотим описать наши данные. Точнее, распределения переменных, которые у нас в данных есть. Хотим мы сделать это просто и ёмко. Насколько просто и ёмко? Ну, допустим максимально --- одним числом. Кажется, значение переменной, которое лежит в центре распределения, неплохо для этого подойдет.

Как мы будем искать, что там в центре распределения? Зависит от шкалы, в которой измерена конкретная переменная.

| Шкала | Мера центральной тенденции |
|:---|:---|
| Номинальная |	Мода |
| Порядковая | Медиана |
| Интервальная | Среднее арифметическое |
| Абсолютная | Среднее арифметическое, геометрическое и др. |

Однако есть некоторые нюансы.


### Мода

:::{#def-mode}
**Мода (mode)** --- наиболее часто встречающееся значение данной переменной.
:::

Тут все достаточно просто и интуитивно понятно. Пусть у нас есть следующий ряд наблюдений:

```{r}
x <- c(1, 3, 4, 6, 4, 2, 4, 3, 2, 4, 1)
x
```

Если мы составим *таблицу частот*, то получим следующее:

```{r}
table(x)
```

Очевидно, что $4$ встречается чаще других значений --- это и есть мода.

Понятно, что если на нашей шкале нет чисел, а есть текстовые лейблы, это ничего не меняет:

```{r}
y <- c("Москва", "Казань", "Кёнигсберг", "Барнаул (Алтайский край)", "Москва", "Санкт-Петербург", "Санкт-Петербург", "Москва", "Санкт-Петербург", "Москва", "Кёнигсберг", "Санкт-Петербург", "Москва", "Казань", "Санкт-Петербург", "Санкт-Петербург", "Казань", "Казань", "Санкт-Петербург", "Москва", "Москва", "Санкт-Петербург", "Санкт-Петербург", "Санкт-Петербург", "Санкт-Петербург", "Москва", "Кёнигсберг", "Санкт-Петербург", "Казань")
y
```

```{r}
table(y)
```

Мода, получается, Санкт-Петербург.

Так мы поступаем с эмпирическим распределением. Если мы имеем дело с генеральной совокупностью, то можем формально определить моду через функцию вероятности (probability mass function, PMF). Модой будет являться значение случайной величины, при котором PMF принимает своё максимальное значение.

$$
\text{mode}(X) = \arg \max \big( \text{PMF}(X) \big)
$$

```{r}
tibble(x = 1:10,
       y = c(.01, .03, .07, .1, .1, .15, .2, .1, .09, .15)) |> 
  ggplot(aes(x, y)) +
  annotate(geom = "point", x = 7, y = 0.2, size = 7, shape = 21, color = "darkred", fill = "red", alpha = .5) +
  geom_point() +
  geom_vline(xintercept = 7, color = "darkred", linetype = "dashed") +
  annotate(geom = "text", label = "это максимум функции", 
           x = 8.5, y = 0.2, color = "darkred") +
  annotate(geom = "text", label = "это мода", 
           x = 7, y = 0, color = "darkred") +
  scale_x_continuous(breaks = 1:10) +
  labs(x = "Значение", y = "Вероятность")
```

Мода — 7.



### Медиана

:::{#def-median}
Медиана (median) --- значение переменной, которые располагается на середине отсортированного ряда значений.
:::

То есть, она делит все наблюдения переменной ровно пополам, и половина наблюдений оказывается по одну сторону от медианы, а половина --- по другую.

Если у нас нечетное число наблюдений, то всё ясно. Пусть есть такой ряд наблюдений:

```{r}
v1 <- c(2, 3, 14, 9, 16, 19, 28, 7, 26, 18, 1)
v1
```

Отсортируем его:

```{r}
sort(v1)
```

Посмотрим в середину --- найдем медиану:

```{r}
median(v1)
```

А что делать, если число наблюдений чётное? Ведь тогда середина ряда будет между двух чисел. Ну, возьмем их среднее арифметическое --- это и будет медиана.

Возьмём такой ряд наблюдений:

```{r}
v2 <- c(14, 10, 9, 16, 30, 3, 25, 8, 18, 7)
v2
```

Отсортируем:

```{r}
sort(v2)
```

Найдём медиану как $(10 + 14) / 2$:

```{r}
median(v2)
```

Формально это можно написать так:

$$
\text{median}(X) = \cases{
X_{\frac{n+1}{2}}, \quad \text{if} \, n \, \text{is odd} \\
\frac{X_{\frac{n}{2}} + X_{\frac{n}{2}+1}}{2}, \quad \text{otherwise}
}
$$

где $X$ --- ряд наблюдений данной переменной, $n$ --- число наблюдений, $X_i$ --- наблюдение с индексом $i$ в сортированном векторе $X$.



### Среднее арифметическое

С этим существом все знакомы еще со школы.

:::{#def-mean}
**Арифметическое среднее (arithmetic mean, mean, average)** --- сумма всех значений переменной, делёная на их количество.
:::

Иначе говоря:

$$
M(X) = \overline{X} = \frac{1}{n} \sum_{i=1}^n x_i
$$

где $\overline X$ --- среднее арифметическое, $x_i$ --- наблюдение в векторе $X$, $n$ --- количество наблюдений.

Ну, то есть всё сложить и поделить на количество того, чего сложили. Изи.

Вот, скажем, средние по двум рядам наблюдений, которые мы встречали в разделе про медиану:

```{r}
v1
mean(v1)
```

```{r}
v2
mean(v2)
```


### Среднее взвешенное

Часто возникает такая ситуация, когда нам нужно посчитать среднее по каким-либо имеющимся характеристикам, но одни характеристики для нас важнее, чем другие. Например, мы хотим вычислить суммарный балл обучающегося за курс на основе ряда работ, выполненных в течение курса. Мы могли бы взять оценки за все работы и усреднить их. Однако мы понимаем, что, скажем, тест из десяти вопросов с множественным выбором явно менее показателен, чем, например, аналитическое эссе или экзаменационная оценка. Что делать? Взвесить параметры!

Что значит *взвесить*? Умножить на некоторое число. На самом деле, любое. Пусть мы посчитали, что написать эссе в три абстрактных раза тяжелее, чем написать тест, а сдать экзамен в два раза тяжелее, чем написать эссе. Тогда мы можем присвоить баллу за тест вес $1$, баллу за аналитическое эссе вес $3$, а экзамену --- вес $6$. Тогда итоговая оценка за курс будет рассчитываться следующим образом:

$$
\text{final score} = 1 \cdot \text{test} + 3 \cdot \text{essay} + 6 \cdot \text{exam}
$$

Суперкласс. Однако! Весьма вероятно, что в учебном заведении принята единая система оценивания для всех видов работ --- ну, скажем, некая абстрактная десятибалльная система в сферическом вакууме. Получается, если и за тест, и за эссе, и за экзамен у студента по 10 баллов, то суммарный балл 100, что, кажется, больше, чем 10. Чтобы вернуться к изначальным границам баллов, нужно поделить суммарный балл на сумму весов параметров:

$$
\text{final score} = 
\frac{1 \cdot \text{test} + 3 \cdot \text{essay} + 6 \cdot \text{exam}}
{1 + 3 + 6}
$$

Кайф! Собственно, это и есть взвешенное среднее. Коэффициенты, на которые мы умножаем значения переменных, называются *весами*. В общем виде формула принимает следующий вид:

$$
\overline X = \frac{\sum_{i=1}^n w_i \cdot x_i}{\sum_{i=1}^n w_i},
$$

где $x_i$ --- значения переменной, $w_i$ --- веса для этих значений.

Взвешенное среднее часто применяется именно во всякого рода ассессментах, и не только образовательных. Например, вы HR-аналитик и оцениваете персонал. Вы аналитически вычисляете веса коэффициентов (допустим, с помощью линейной регрессии), а далее на их основе высчитываете интегральный балл, по которому будете оценивать сотрудников. Это как один из индустриальных примеров.



### Другие средние

Среднее бывает не только арифметическое. Правда встретятся вам другие его виды примерно нигде --- то есть о-о-о-очень редко и, скорее всего, в каких-то узкоспециализированных статьях. Но упомянуть их, пожалуй, стоит как минимум ради того, чтобы вы не перепугались излишне, ежели вдруг с ними столкнётесь.


#### Квадратичное среднее

Это весьма полезная вещь.

:::{#def-quadmean}
**Квадратичное среднее (quadratic mean, root mean square, RMS)** --- это квадратный корень из среднего квадрата наблюдений.
:::

Ничего не понятно, поэтому по порядку:

- есть наблюдение $x_i$
- значит есть и его квадрат $x_i^2$
- мы умеем считать обычно среднее арифметическое
    - но ведь $x_i^2$ --- это тоже наблюдение (число), просто в квадрате
- значит можем посчитать среднее арифметическое квадратов наблюдений --- средний квадрат (mean square) --- $\displaystyle \frac{1}{n} \sum_{i=1}^n x_i^2$
- теперь извлечём из этого дела корень, чтобы вернуться к исходным единицам измерения --- получим то, что нам надо

$$
\text{RMS}(X) = \sqrt{\frac{1}{n} \sum_{i=1}^n x_i^2}
$$

Per se[^per-se] мы его вряд ли ещё когда-то увидим, но пару раз оно внезапно всплывет.

[^per-se]: Per se (*лат.*) --- в чистом виде.



#### Геометрическое среднее

В психологии и социальных науках встречается редко. Применяется там, где необходимо изучать средние скорости изменения --- например, в экономике и финансах при изучении доходности, прибыли и выручки; в демографии при расчете индекса человеческого потенциала и др.

$$
G(X) = \sqrt[n]{\prod_{i=1}^n x_i}
$$



#### Гармоническое

Весьма экзотическая конструкция, используемая при работе с величинами, заданными через обратные значения. Встречается в финансах и экономике, страховании, физике.

$$
H(X) = \frac{n}{\displaystyle \sum_{i=1}^n \frac{1}{x_i}}
$$




## Сравнение мер центральной тенденции

Сравнивать будем моду, медиану и среднее [арифметическое].

Все три статистики --- мода, медиана и среднее --- описывают **центральную тенденцию** --- значение изучаемой нами переменной, вокруг которого собираются другие значения. Но если их три и все они используются, значит между ними должны быть какие-то различия. Посмотрим, какие.


### Меры центральной тенденции и типы переменных

- Во-первых, очевидно, что **моду невозможно посчитать для непрерывной переменной**.

:::{.callout-note appearance="minimal" collapse="true"}
### Нет, не очевидно

Так как вероятность того, что непрерывная случайная величина принимает своё конкретное значение, равна нулю, каждое наблюдение в нашей выборке будет уникально --- встретится ровно один раз. Вспомните пример из предыдущей главы (@fig-unif-10000), где мы набирали числа из отрезка. Получается, что мода теряет свой смысл.
:::

- Во-вторых, **медиану нельзя посчитать на номинальной шкале**. Кстати, почему?

:::{.callout-note appearance="minimal" collapse="true"}
### Потому что

на номинальной шкале нет отношения порядка между элементами --- на ней нельзя сравнивать на больше-меньше. Следовательно, невозможно отсортировать наблюдения, а значит, и найти медиану.
:::

- В-третьих, **среднее тоже нельзя посчитать на номинальной шкале**.

:::{.callout-note appearance="minimal" collapse="true"}
### Можно, но осторожно

Вообще, конечно, да --- нельзя, потому что на номинальной шкале не определена операция сложения, входящая в вычисление среднего. Однако если на номинальной шкале есть только две категории, которые закодированы `0` и `1`, то посчитать среднее можно. Но что оно будет значить?

Исходный математический смысл среднего явно утерян. Посмотрим на это по-другому: посчитать сумму единиц это всё равно, что посчитать количество единиц. То есть, если мы сложим все нули и единицы, то получим количество единиц среди всех наших наблюдений. А разделив количество единиц на количество наблюдений, мы получим долю единиц --- то есть долю наблюдений с лейблом `1`.

окак
:::

- В-четвертых, **для дискретной переменной значение среднего арифметического будет не особо осмысленно**. Ну, скажем, странно сказать, что в аудитории в среднем стоят 15.86 столов или в российских семьях в среднем 1.5 ребенка. Конечно, в ряде случаев можно это как-то более-менее содержательно интерпретировать, но это требует усилий, а мы ленивые, поэтому лучше использовать медиану.


:::{.callout-warning}
### Итого, делаем следующие выводы

- для номинальной шкалы пригодна только мода
- для дискретных переменных подходят мода и медиана
- мода иногда лучше, так как точно всегда будет целым числом
- для непрерывных переменных подходят медиана и среднее
:::



### Меры центральной тенденции и форма распределения

Помимо того, что среднее, мода и медиана информативны сами по себе, полезно смотреть на их взаимное расположение.

```{r central_tendency_sampling, include=FALSE}
set.seed(108)
symm <- sample(
  x = seq(1, 10, 0.5),
  size = 600,
  replace = TRUE,
  prob = c(
    .05,
    .05,
    .07,
    .1,
    .1,
    .15,
    .20,
    .30,
    .35,
    .5,
    .35,
    .30,
    .20,
    .15,
    .1,
    .1,
    .07,
    .05,
    .05
  )
)
asymm_right <- sample(
  x = seq(1, 10, 0.5),
  size = 600,
  replace = TRUE,
  prob = c(
    .1,
    .2,
    .25,
    .4,
    .5,
    .5,
    .4,
    .35,
    .3,
    .25,
    .2,
    .25,
    .2,
    .15,
    .1,
    .1,
    .07,
    .05,
    .05
  )
)
asymm_left <- sample(
  x = seq(1, 10, 0.5),
  size = 600,
  replace = TRUE,
  prob = c(
    .03,
    .05,
    .07,
    .1,
    .15,
    .15,
    .2,
    .2,
    .25,
    .25,
    .3,
    .35,
    .5,
    .5,
    .4,
    .4,
    .25,
    .2,
    .2
  )
)
bimodal <- sample(
  x = seq(1, 10, 0.5),
  size = 600,
  replace = TRUE,
  prob = c(
    .05,
    .05,
    .07,
    .1,
    .1,
    .2,
    .3,
    .35,
    .3,
    .15,
    .1,
    .15,
    .20,
    .40,
    .50,
    .25,
    .1,
    .05,
    .05
  )
)
colors <- c("Mean" = "red4", "Median" = "blue4", "Mode" = "green4")
```

На симметричном распределении мода, медиана и среднее совпадают [или, по крайней мере, находятся очень близко друг к другу]. Здесь и далее: красная линия — среднее, синяя — медиана, зелёная — мода.

```{r central_tendency_symm, echo=FALSE}
ggplot(NULL, aes(symm)) +
  geom_histogram(aes(y = ..density..), alpha =.5, binwidth = .5) +
  geom_density() +
  geom_vline(xintercept = mean(symm), color = colors['Mean']) +
  geom_vline(xintercept = median(symm), color = colors['Median']) +
  # geom_vline(xintercept = mode(symm)-0.04, color = colors['Mode']) +
  labs(x = 'Value',
       y = 'Density')
```


На асимметричном распределении мода [практически] в пике. Практически, потому что функция плотности вероятности [черная линия на графике] на всегда точно аппроксимирует (в данном случае то же, что и сглаживает) эмпирическое распределение. На картинке ниже мы видим, что на гистограмме мода — самый высокий столбик, что и показывает нам зелёная линия, которой обозначена мода. Однако при сглаживании гистограммы пик немного съехал, и мода оказалась не совсем в вершине графика функции плотности вероятности.

```{r central_tendency_asymm_right, echo=FALSE}
ggplot(NULL, aes(asymm_right)) +
  geom_histogram(aes(y = ..density..), alpha =.5, binwidth = .5) +
  geom_density() +
  geom_vline(xintercept = mean(asymm_right), color = colors['Mean']) +
  geom_vline(xintercept = median(asymm_right), color = colors['Median']) +
  # geom_vline(xintercept = mode(asymm_right), color = colors['Mode']) +
  labs(x = 'Value',
       y = 'Density')
```

```{r central_tendency_asymm_left, echo=FALSE}
ggplot(NULL, aes(asymm_left)) +
  geom_histogram(aes(y = ..density..), alpha =.5, binwidth = .5) +
  geom_density() +
  geom_vline(xintercept = mean(asymm_left), color = colors['Mean']) +
  geom_vline(xintercept = median(asymm_left), color = colors['Median']) +
  # geom_vline(xintercept = mode(asymm_left), color = colors['Mode']) +
  labs(x = 'Value',
       y = 'Density')
```

Вообще-то это нормально, потому что мода для непрерывной величины, которую мы и визуализируем с помощью графика плотности, либо не может быть посчитана вовсе, либо — если так получилось, и у нас все же есть повторяющиеся значения — не слишком хорошая мера центральной тенденции. В целом, и на симметричном распределении мода тоже может находиться немного в стороне от пика.

На асимметричном распределении медиана и среднее смещены в сторону хвоста. Среднее смещено сильнее медианы. Это связано с тем, что медиана зависит только от количества наблюдений, а среднее ещё и от самих значений. На картинке ниже пример для распределения с правосторонней асимметрии (потому что хвост справа) — среднее (красная линия) правее медианы (синяя линия).



А это пример для распределения с левосторонней асимметрией (так как хвост слева) — среднее (красная линия) левее медианы (синяя линия).



Для того, чтобы лучше разобраться с тем, как большие и малые значения влияют на моду и медиану посмотрим такой пример. Пусть у нас есть оценки за выпускную квалификационную работу. Например, такие:

marks
 [1] 6 7 7 8 8
Посчитаем медиану и среднее:

median(marks)
 [1] 7
mean(marks)
 [1] 7.2

Среднее  
7.2
  округлиться до  
7
 , то есть можно считать, что среднее и медиана совпали. Ну, ок.

Но в комиссии сидят два требовательных доктора наук, которые поставили оценки, сильно отличающиеся от остальных:

marks
 [1] 6 7 7 8 8 3 4
Посчитаем медиану и среднее теперь:

median(marks)
 [1] 7
mean(marks)
 [1] 6.142857
Медиана осталась на месте — всё ещё  
7
 . А вот среднее  
6.1
  округлится до  
6
 . Казалось бы, это немного, но в смысле оценок — это прилично, и может сильно повлиять на GPA.

Итого, среднее более чувствительно к нетипичным значениям (очень большим или очень малым).

Есть ещё один интересный вариант распределений — бимодальные. Значит ли, что у этого распределения две моды? Не всегда. Посмотрим пример ниже:

```{r central_tendency_bimodal, echo=FALSE}
ggplot(NULL, aes(bimodal)) +
  geom_histogram(aes(y = ..density..), alpha =.5, binwidth = .5) +
  geom_density() +
  geom_vline(xintercept = mean(bimodal), color = 'red4') +
  geom_vline(xintercept = median(bimodal), color = 'blue4') +
  # geom_vline(xintercept = mode(bimodal), color = 'green4') +
  labs(x = 'Value',
       y = 'Density')
```

Мы видим, что на графике есть два пика, однако строго математически мода одна (зеленая линия) — и она в более высоком пике. Это логично, ибо там самые часто встречающиеся значения.

И все жё содержательно мы не можем пренебречь вторым пиком. Почему нам он важен? Обычно бимодальное распределение — это повод задуматься о том, что наша выборка неоднородна. Бимодальное распределение как бы сложено из двух с центрами в двух пиках. То есть в нашей выборке как будто бы две подвыборки, которые обладают разными распределениями интересующего нам признака.

Что с этим делать? Хорошо всегда иметь в данным какие-либо дополнительные переменные — как минимум соцдем — чтобы мы могли по данным попытаться предположить, какую группировку мы могли забыть учесть при планировании исследования.

Со средним и медианой происходит примерно то же, что и в случае асимметричного распределения. Второй пик смещает к себе обе меры центральной тенденции, причем среднее вновь сильнее, чем медиану.


## Свойства среднего арифметического

Если к каждому значению распределения прибавить некоторое число (константу), то среднее увеличится на это же константу.
M
x
+
c
=
M
x
+
c
 

Вот почему:

M
x
+
c
=
∑
n
i
=
1
(
x
i
+
c
)
n
=
∑
n
i
=
1
x
i
+
n
c
n
=
∑
n
i
=
1
x
i
n
+
c
=
M
x
+
c
 

Иначе говоря, распределение просто сдвинется. Например, если к каждому значению синего распределения прибавить  
2
 , получится красное:



Если каждое значение распределение умножить на некоторое число (константу), то среднее увеличится во столько же раз.
M
x
×
c
=
M
x
×
c
 

Вот почему:

M
x
×
c
=
∑
n
i
=
1
(
x
i
×
c
)
n
=
c
×
∑
n
i
=
1
x
i
n
=
∑
n
i
=
1
x
i
n
×
c
=
M
x
×
c
 

Например, здесь каждое значение синего распределения умножили на  
3
  и получили красное:



Тут, правда, явно что-то ещё произошло, но мы пока этого не знаем. Однако, отметит этот факт.

Сумма отклонений от среднего значения равна нулю.
n
∑
i
=
1
 
(
x
i
−
M
x
)
=
0
 

Элегантное доказательство:

n
∑
i
=
1
 
(
x
i
−
M
x
)
=
n
∑
i
=
1
 
x
i
−
n
∑
i
=
1
 
M
x
=
n
∑
i
=
1
 
x
i
−
n
M
x
=
=
n
∑
i
=
1
 
x
i
−
n
×
1
n
n
∑
i
=
1
 
x
i
=
n
∑
i
=
1
 
x
i
−
n
∑
i
=
1
 
x
i
=
0

Но можно это осмыслить и более просто графически.

Отклонение — это разность между средним и конкретным значением переменной. И, действительно, так как среднее находится в центре распределения, то часть значений лежит справа, а часть слева. Значит, будут как положительные, так и отрицательные отклонения — и их сумма в итоге будет равна нулю.
