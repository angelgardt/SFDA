# Доверительные интервалы

```{r opts, echo=FALSE, eval=TRUE}
knitr::opts_chunk$set(echo = FALSE, eval = TRUE, warning = FALSE, message = FALSE, error = FALSE)
```

```{r}
library(tidyverse)
theme_set(theme_bw())
theme_update(legend.position = "bottom")
```

## Точечные и интервальные оценки

До этого момента мы работали только с **точечными оценками** --- это оценки, представляющие собой одно число. Например, таковы меры центральной тенденции --- медиана, среднее арифметическое --- или меры разброса --- межквартильный размах, дисперсия, стандартное отклонение. Когда мы рассчитываем каждый из этих показателей мы получаем только одно число.

Однако поскольку мы имеет дело со статистическими данными, основные свойства которых это *неопределенность* и *вариативность*, нам необходимы, помимо точечных оценок, ещё и интервальные оценки.

Напомним кратко себе, что

- **Неопределенность** статистических данных означает, что мы никогда не знаем, что мы получим в результате данного конкретного измерения.
    - во-первых, потому что мы работаем со случайными величинами,
    - во-вторых, потому что наши измерительные инструменты не идеальны и всегда содержат ошибку измерения.
- **Вариативность** статистических данных говорит нам о том, что наши измерения всегда обладают некоторым разбросом.
    - во-первых, потому что объекты нашего изучения --- люди --- разные,
    - во-вторых, потому наши измерительные инструменты всё ещё не идеальны и всегда содержат ошибку измерения.


Таким образом, мы не можем быть до конца уверены, что мы получили суперточную оценку изучаемых нами параметров. Даже если мы пользуемся достаточно точными измерительными инструментами, собираем большие выборки и вообще делаем всё, чтобы быть максимально точными и объективными. Возникает необходимость найти какие-то способы выражения нашей неуверенности в точечной оценки параметра генеральной совокупности. Это и есть интервальные оценки --- по сути, меры нашей неуверенности.

Чтобы к ним подойти, нам придется познакомиться с одной важной статистической теоремой.


## Центральная предельная теорема {#ci-clt}

Для построения интервальных оценок параметров используют центральную предельную теорему. Сформулировать её можно так.

:::{#thm-clt}
**Центральная предельная теорема (ЦПТ).** Cумма достаточно большого количества слабо зависимых одинаково распределенных случайных величин имеет распределение, близкое к нормальному.
:::

Однако нас будет интересовать не столько сама теорема, сколько одно из её следствий.

:::{#cor-clt-mean}
Если $X_1, \, X_2, \, \ldots, X_n$ --- независимые одинаково распределённые случайные величины со средним $\mu$ и дисперсией $\sigma^2$, то при увеличении их числа распределение средних этих случайных величин имеет распределение, близкое к нормальному со средним $\mu$ и дисперсией $\dfrac{\sigma^2}{n}$ (стандартным отклонением $\dfrac{\sigma}{\sqrt{n}}$):

$$
X_i \overset{\text{i.i.d}}{\thicksim} (\mu, \sigma^2) \Rightarrow \overline X_i \overset{d}{\to} \mathcal{N} \bigg( \mu, \frac{\sigma^2}{n} \bigg)
$$
:::

Формулировка следствия довольно сложна. Давайте подумаем, чем она соответствует в области исследовательской практики.

- Когда мы проводим исследование, мы извлекаем выборку из генеральной совокупности.
- На этой выборке мы измеряем какую-либо переменную $X$.
- Пусть на этой выборке мы получили случайную величину $X_1$, измерив интересующая нас переменную.
- Повторив исследование несколько раз --- допустим, $n$ --- на других выборках из той же генеральной совокупности, мы получим случайные величины $X_2,\, X_3,\, \ldots X_n$.
- Поскольку все выборки приходили из одной и той же генеральной совокупности, распределения всех случайных величин будут иметь одни и те же параметры --- то есть наши случайные величины будут одинаково распределены.
- Так как выборки извлекались отдельно для каждого исследования, получившиеся случайные величины оказываются независимы.

Таким образом, [следствие] **ЦПТ рассматривает поведение распределения выборочных средних при многократном повторении исследования**. По сути, это та же ситуация, которую мы рассматривали при обсуждении [несмещённости точечных оценок](desc-variation.qmd#variation-estim-features).


Итак, пусть есть некоторая случайная величина $X$, распределение которой в генеральной совокупности асимметрично. Случай асимметричного распределения удобен для рассмотрения, поскольку эффект, описываемый ЦПТ можно увидеть более наглядно. Допустим, выглядит это как-то так:

```{r}
N <- 1000 # количество выборок
n <- 50 # объем выборки
shape1 <- 2
shape2 <- 3
set.seed(29)
rbeta(n = n * N, shape1 = 2, shape2 = 3) %>% 
  matrix(ncol = 1000) %>% 
  as_tibble() -> clt_smpls
```

:::{#fig-pop-dist}
```{r}
clt_smpls %>% 
  pivot_longer(cols = everything()) %>% 
  ggplot(aes(value)) +
  geom_histogram(aes(y = after_stat(density)), binwidth = .05) +
  geom_function(fun = dbeta, args = list(shape1 = 2, shape2 = 3),
                linewidth = 1)
```

Распределение случайной величины в генеральной совокупности
:::

Откуда мы знаем, что случайная величина распределена так? Ниоткуда. В рамках симуляции, которой мы сейчас будем заниматься мы просто рассматриваем такой случай. Разумеется, в реальной ситуации мы может сделать только *допущение* о распределении величины генеральной совокупности --- как она распределена на самом деле мы никогда не узнаем.

Понятно, что это распределение будет обладать неким средним и некоторым стандартным отклонением --- в нашем случае значения будут такими:

:::{#tbl-pop-params}

|Параметр распределения|Значение|
|:---|---:|
|Среднее|`r shape1 / (shape1 + shape2)`|
|Стандартное отклонение|`r sqrt((shape1 * shape2) / ((shape1 + shape2)^2 * (shape1 + shape2 + 1)))`|

Параметры распределения случайной величины в генеральной совокупности
:::

Чтобы максимально точно приблизиться к оценке нашего параметра --- будем оценивать среднее генеральной совокупности --- нам надо извлечь много больших выборок из нашей генеральной совокупности. Ну, допустим мы извлекаем 1000 выборок по 50 наблюдений. Можно и больше, но давайте посмотрим пока, что будет на таких значениях.

Посмотрим на распределения нашей переменной в нескольких из выборок:

:::{#fig-pop-samples}
```{r}
clt_smpls %>%
  select(1:20) %>% 
  pivot_longer(cols = everything()) %>% 
  mutate(name = factor(name, ordered = TRUE, levels = paste0("V", 1:20))) %>% 
  ggplot(aes(value)) +
  geom_histogram() +
  facet_wrap(~ name, ncol = 4) +
  labs(x = "Значение", y = "Количество")
```

Распределения случайной величины в первых двадцати выборках
:::

Вот распределения в первых двадцати выборках. На что здесь стоит обратить внимание?

От выборки к выборки распределения, безусловно, отличаются. Причем достаточно сильно --- где-то распределение больше похоже на нормальное, где-то оно более асимметричное, где-то менее, где-то вообще напоминает равномерное. Это мы в живую увидели вариативность и неопределенность.

Каждая из выборок характеризуется каким-то своим средним и каким-то своим разбросом (@tbl-sample-desc).

:::{#tbl-sample-desc}
```{r}
clt_smpls %>% 
  select(1:20) %>% 
  pivot_longer(cols = everything()) %>% 
  summarise(mean = mean(value),
            sd = sd(value),
            .by = name) %>% 
  knitr::kable(digits = 2, col.names = c(name = "Sample", mean = "Mean", sd = "SD"))
```

Выборочные средние и стандарные отклонения первых двадцати выборок
:::


Видим, что есть некоторая вариативность выборочных средних. Но раз у нас есть 1000 выборок --- а значит и 1000 средних --- мы можем построить распределение выборочных средних (@fig-samplemean-dist).

:::{#fig-samplemean-dist}
```{r}
clt_smpls %>% 
  pivot_longer(cols = everything()) %>% 
  summarise(mean = mean(value),
            .by = name) %>% 
  ggplot(aes(mean)) +
  geom_histogram(aes(y = after_stat(density))) +
  geom_function(fun = dnorm, args = list(mean = 0.4, sd = sqrt(0.04/50)),
                linewidth = 1) +
  labs(x = "Выборочные средние", y = "Плотность")
```

Распределение выборочных средних
:::

Мы получили распределение выборочных средних значений, которое очень похоже на нормальное --- эмпирическое распределение отображено с помощью гистограммы, а ожидаемое теоретическое с помощью чёрной линии. Вот об этом и говорит центральная предельная теорема.

Более того, если мы посчитаем среднее и стандартное отклонение данного распределения, мы получим следующее (@tbl-means-params).

:::{#tbl-means-params}

|Параметры|Значение|
|:---|---:|
|Среднее (M)|`r clt_smpls %>% sapply(mean) %>% mean() %>% round(2)`|
|Стандартное отклонение (SD)|`r clt_smpls %>% sapply(mean) %>% sd() %>% round(2)`|

Параметры распределения выборочных средних
:::

Также нужно обратить внимание еще на две важные детали:

- чем большее количество выборок мы наберем, тем ближе распределение будет к нормальному и тем более точную оценку среднего мы получим
- чем большее количество наблюдений будет в отдельной выборке, тем ближе распределение будет к нормальному и тем более точную оценку среднего мы получим

[Здесь](https://gallery.shinyapps.io/CLT_mean/) можно посмотреть динамическую симуляцию, изучить роль количества выборок и количества наблюдений в формировании итогового распределения средних.

:::{.callout-note appearance="minimal"}
Итак, независимо от того, какое распределение переменной есть в генеральной совокупности, при извлечении достаточно большого количества выборок достаточно большого объема мы можем получить очень точную оценку среднего генеральной совокупности, а распределение выборочных средних будет стремиться к нормальному.
:::



## Стандартная ошибка среднего {#ci-se}

Собственно, а зачем нам это надо было?

Посмотрим на стандартное отклонение выборочных средних (@fig-se).

:::{#fig-se}
```{r}
m <- clt_smpls %>% sapply(mean) %>% mean()
se <- clt_smpls %>% sapply(mean) %>% sd()

clt_smpls %>% 
  pivot_longer(cols = everything()) %>% 
  summarise(mean = mean(value),
            .by = name) %>% 
  ggplot(aes(mean)) +
  geom_histogram(aes(y = after_stat(density)), fill = "gray70") +
  geom_function(fun = dnorm, args = list(mean = 0.4, sd = sqrt(0.04/50)),
                linewidth = 1) +
  geom_vline(xintercept = m, linetype = "dotted") +
  geom_vline(xintercept = m+se, linetype = "dashed") +
  geom_vline(xintercept = m-se, linetype = "dashed") +
  labs(x = "Выборочные средние", y = "Плотность")
```

Стандартная ошибка среднего. Точечная линия --- среднее выборочных средних, пунктирные линии --- плюс-минус одно стандартное отклонение.
:::

Поскольку ЦПТ обеспечила нам возможность пользоваться свойствами нормального распределения, то в пределах одного стандартного отклонения от среднего средних будет лежать 68.2% выборочных средних (@fig-normdist-probs и @eq-normdist-probs). Таким образом, мы получаем диапазон, в пределах которого лежат наиболее часто встречающиеся выборочные средние, а значит это может служить интервальной оценкой нашего параметра --- он называется *стандартной ошибкой среднего*.

:::{#def-se}
**Стандартная ошибка среднего** ($\text{se}$) --- стандартное отклонение распределения выборочных средних.
:::

Теперь задумаемся о следующем: чтобы получить стандартную ошибку, мы сгенерировали 1000 выборок, однако в рамках отдельного исследования мы работаем только с одной выборкой --- значит ли это, что мы не сможем посчитать стандартную ошибку, чтобы получить интервальную оценку среднего?

Нет. Рассчитать стандартную ошибку среднего можно и по одной выборке вот так:

$$
\text{se}_X = \frac{s_X}{\sqrt{n}},
$${#eq-se}

где $s_X$ --- это выборочное стандартное отклонение, а $n$ --- количество наблюдений в данной выборке.

Формула, прямо скажем, не то чтобы очень интуитивна, однако вам придется мне поверить, что она верна.

:::{.callout-note appearance="simple" collapse="true"}
### Я недоверчив(а)

Для того, чтобы доказать формулу, нам понадобятся два утверждения. С одним мы хорошо знакомы (@prp-var2):

$$
D_{X \times c} = D_X \times c^2
$$

Второе утверждение говорит нам, чему равна дисперсия суммы случайных величин --- тут вам точно придется мне просто поверить, иначе эта глава никогда не закончится:

$$
D_{X + Y} = D_X + D_Y + 2 \text{cov}_{X,Y},
$$

$\text{cov}_{X,Y}$ --- это ковариация двух случайных величин, мера их взаимной изменчивости. Мы будем обсуждать её в курсе позже, сейчас она для нас не столь существенна.

Так как мы предполагает, что выборки мы набирали независимо и из одной и той же генеральной совокупности, то величины в каждой из выборок независимы и [теоретически] одинаково распределены (independent identically distributed, i.i.d.) (для упрощения жизни здесь рассмотрено нормальное распределение):

$$
X_i \overset{\text{i.i.d.}}{\thicksim} \mathcal{N} (\mu, \sigma^2)
$$

В частности, в силу независимости случайный величин их ковариация равна нулю. Поэтому дисперсия распределения выборочных средних --- то есть суммы средних наших исходных случайных величин $X_i$ --- будет определяться так:

$$
\begin{split}
D \big( \sum_{i=1}^n \frac{1}{n} X_i \big) &= 
D \big( \frac{1}{n} \sum_{i=1}^n X_i \big) = \\
&= \frac{1}{n^2} \sum_{i=1}^n D(X_i) = \\
&= \frac{1}{n^2} \sum_{i=1}^n \sigma^2 = \frac{1}{n^2} \cdot n \sigma^2 = \\
& = \frac{n}{n^2} \sigma^2 = \frac{\sigma^2}{n}
\end{split}
$$

А значит, стандартное отклонение этого распределения --- оно же стандартная ошибка среднего --- будет таким:

$$
\text{se}_X = \sqrt{\frac{\sigma^2}{n}} = \frac{\sigma}{\sqrt{n}}
$$

Магия статистических допущений.

:::

Стандартная ошибка используется и сама по себе как одна из описательных статистик. Однако также на её основе рассчитывается другая интервальная оценка.



## Доверительные интервалы {#ci-ci}

Еще раз вспомним о том, что стандартная ошибка --- это не что иное как стандартное отклонение [выборочных средних]. Также вспомним, что главой ранее мы определяли, с какой вероятностью лежит значение нашей случайной величины в пределах скольких-либо стандартных отклонений (@fig-normdist-probs).

Можем ли мы через стандартное отклонение выразить такой интервал, в котором будет лежать, скажем, 95% значений величины? Для определенности возьмем стандартное нормальное распределение, и выделим на нём диапазон, в пределах которого лежит 95% значений.

:::{#fig-stnorm-95}
```{r}
ggplot() +
  geom_function(fun = dnorm) +
  stat_function(fun = dnorm, geom = "area", xlim = c(-1.96, 1.96),
                fill = "royalblue", alpha = .5) +
  geom_vline(xintercept = c(-1.96, 1.96), linetype = "dashed") +
  annotate(geom = "text", label = "95%", x = 0, y = .1) +
  annotate(geom = "text", label = "−1.96", x = -2.3, y = 0) +
  annotate(geom = "text", label = "1.96", x = 2.2, y = 0) +
  xlim(-4, 4) +
  labs(x = "Значения", y = "Плотность")
```
Стандартное нормальное распределение. Диапазон, в пределах которого лежит 95% значений.

:::

Математически вычислимо, что границы этого интервала будут такими --- $[-1.96, 1.96]$.

Окей, но это не совсем то, что нас интересовало. Мы хотели узнать, в каких пределах лежит 95% выборочных средних, если мы знаем их распределение. Воспользуемся известной нам стандартизацией (@eq-standartization) --- вернее, её обратным преобразованием --- и перейдем от z-значений к значениям произвольного распределения:

$$
x_i = z_i \cdot s_x + \overline X,
$$

где $z_i$ --- значения стандартного нормального распределения, $x_i$ --- значение нового распределения, $\overline X$ --- среднее нового распределения, $s_x$ --- стандартное отклонение нового распределения.

:::{#fig-ci}
```{r}
clt_smpls %>% 
  pivot_longer(cols = everything()) %>% 
  summarise(mean = mean(value),
            .by = name) %>% 
  ggplot(aes(mean)) +
  geom_histogram(aes(y = after_stat(density)), fill = "gray70") +
  geom_function(fun = dnorm, args = list(mean = 0.4, sd = sqrt(0.04/50)),
                linewidth = 1) +
  stat_function(fun = dnorm, args = list(mean = 0.4, sd = sqrt(0.04/50)),
                geom = "area", fill = "royalblue", alpha = .5,
                xlim = c(m-1.96*se, m+1.96*se)) +
  geom_vline(xintercept = m, linetype = "dotted") +
  geom_vline(xintercept = m+1.96*se, linetype = "dashed") +
  geom_vline(xintercept = m-1.96*se, linetype = "dashed") +
  labs(x = "Выборочные средние", y = "Плотность")
```

Доверительный интервал. Точечная линия --- среднее выборочных средних, пунктирные линии --- доверительный интервал для среднего.
:::

Таким образом, мы можем перевести границы $[-1.96, 1.96]$ в границы на распределении выборочных средних следующим образом:

$$
[\overline X - 1.96 \cdot \text{se}_x, \, \overline X + 1.96 \cdot \text{se}_x]
$${#eq-ci}

В пределах такого интервала будет лежать 95% выборочных средних.

Однако на практике мы имеет дело только с одной выборкой, поэтому и интервал будет рассчитываться на основании одного выборочного среднего и стандартного отклонения по выборке. Например, если мы возьмем первую выборку из сгенерированных (@tbl-sample-desc) и рассчитаем такой интервал для её среднего, получится:

$$
\begin{split}
&[\overline X - 1.96 \cdot \text{se}_X, \, \overline X + 1.96 \cdot \text{se}_X] = \Big[ \overline X - 1.96 \cdot \frac{s_X}{\sqrt{n}}, \, \overline X + 1.96 \cdot \frac{s_X}{\sqrt{n}} \Big] = \\
&= \Big[0.37 - 1.96 \cdot \frac{0.18}{\sqrt{50}}, \, 0.37 + 1.96 \cdot \frac{0.18}{\sqrt{50}} \Big] = 
[0.32, \, 0.42]
\end{split}
$$

Этот интервал называется **95%-ным доверительным интервалом (95% confidence interval, 95% CI)**. Он является второй интервальной оценкой среднего и мерой нашей неуверенности относительно точности оценки среднего генеральной совокупности.

Вообще можно рассчитать любой доверительный интервал, который вам захочется, однако самые популярные варианты --- это 90%, 95% и 99%. Выражаются через стандартную ошибку они так:

$$
\begin{split}
90\%: &\quad \overline X \pm 1.645 \cdot \text{se}_x \\
95\%: &\quad \overline X \pm 1.96 \cdot \text{se}_x \\
99\%: &\quad \overline X \pm 2.576 \cdot \text{se}_x
\end{split}
$$

Наиболее широко в социальных науках используется 95%-ный. С ним и будем работать.



### Интерпретация границ доверительного интервала {#ci-interp}

Теперь еще одна непростая задача --- понять, что значит этот интервал.

Глядя на график распределения выборочных средних (@fig-ci) и исходя из того, как интервал был получен, хочется сказать, что *генеральное среднее лежит в границах 95%-ного доверительного интервала с вероятностью 0.95.*

**Но это не верно!!!** Вновь необходимо вспомнить, что в рамках отдельного исследования мы имеем дело только с одной выборкой, и доверительный интервал, рассчитанный на одной выборке, это совершенно не то, что отображает вышеупомянутый график (@fig-ci). Он показывает логику, положенную в механизм расчёта интервала, однако не пригоден для его интерпретации.

:::{.callout-important}
### Статистика в отдельном исследовании

Отметим, что та статистика, которую мы изучаем --- **фреквентистская статистика** --- рассматривает любые результаты с точки зрения *принципиальной возможности бесконечно повторять проведённое исследование*. Соответственно, корректная интерпретация получаемых статистических штук будет строиться в долгосрочной перспективе повторения исследований.

Такое положение дел затрудняет интерпретацию результатов отдельного исследования и часто приводит к некорректным выводам, поэтому необходимо уделить вопросу интерпретации отдельное серьезное внимание.
:::

Давайте на примере самого доверительного интервала. Корректная статистическая интерпретация звучит так:

:::{.callout-important appearance="simple"}
Если мы будет бесконечно извлекать новые выборки из генеральной совокупности, рассчитывать на них средние и 95% доверительные интервалы к ним, то генеральное среднее попадёт в границы 95% таких доверительных интервалов.
:::

То есть, если мы извлечем 100 выборок, посчитаем на каждой из них среднее и построим 95% доверительный интервал к каждому из 100 средних, то 95 доверительных интервалов из 100 будут содержать генеральное среднее, а 5 интервалов содержать его не будут.

В частности, если мы посмотрим, что происходит на сгенерированных ранее выборках (@fig-pop-samples), мы получим следующую картину (@fig-ci-coverage).

:::{#fig-ci-coverage}
```{r}
clt_smpls %>% 
  pivot_longer(cols = everything()) %>% 
  summarise(ci = mean_cl_normal(value),
            .by = name) %>% 
  unnest(cols = ci) %>% 
  mutate(cover = ymin < shape1 / (shape1 + shape2) & 
           ymax > shape1 / (shape1 + shape2),
         n = str_extract(name, "\\d+") %>% as.numeric()) %>% # pull(cover) %>% sum()
  ggplot() +
  geom_pointrange(aes(x = y, xmin = ymin, xmax = ymax, y = n, color = cover),
                  alpha = .5) +
  geom_vline(xintercept = shape1 / (shape1 + shape2)) +
  scale_color_discrete(labels = c(`TRUE` = "да", `FALSE` = "нет")) +
  labs(x = "Значение", y = "Номер выборки", color = "Содержит генеральное среднее")
```

Покрытие генерального среднего доверительными интервалами. Из 1000 доверительных интервалов 966 содержат генеральной среднее, 34 --- не содержат.
:::

Динамическую визуализацию этого можно наблюдать [здесь](https://rpsychologist.com/d3/ci/).

Корректная статистическая интерпретация, конечно, корректная, однако трудноусваемая и сложноприменяемая в практике Попробуем сделать её более осязаемой. Есть три путя.

:::{.callout-important}
#### Самый простой, но крайне некорректный

Если, ну, прям ваще никак не получается уложить статистическую интерпретацию, то можно думать о доверительном интервале так: «генеральное среднее, скорее всего, лежит где-то в этих пределах».

Однако в приличных местах об этом говорить никому не стоит. И даже когда соберетесь прибегнуть к такой интерпретации, **обязательно сначала вспомните, что она некорректная!**
::::

:::{.callout-important}
#### Скорректированный вариант

К подобной интерпретации также есть некоторые вопросы, однако, по крайней мере, она обоснована симуляциями. Задаваться вопросом о вероятности попадания генерального среднего в конкретный рассчитанный нами здесь и сейчас доверительный интервал всё же можно. Симуляции показывают, что эта вероятность приблизительно равна **84.3%**. Эту величину назвали **capture percentage** --- то есть отдельный 95% доверительный интервал «ловит» генеральное среднее 843 раза из 1000.
:::


:::{.callout-important}
#### Практически применимый вариант

Ежели мы всё же посмотрим на @fig-ci и попробуем вытащить практически пригодную интерпретацию, то мы можем заметить, что в границы доверительного интервала попадают наиболее частотные, типичные значения среднего. Также необходимо вспомнить, что мы работаем с конкретными данными в рамках одного исследования. Исходя из этих двух пунктов, можно сказать, что границы доверительного интервала задают диапазон значений, которые *не противоречат* имеющимся у нас данным.

Эта интерпретация хорошо согласуется с NHST-подходом к тестированию статистических гипотез, о котором мы будем говорить далее.
:::


### Доверительный интервал и сравнение средних {#ci-meancomp}

Чем нам может помочь интервальная оценка при поиске различий между группами? Посмотрим на возможные ситуации. Пусть у нас есть средние и доверительные интервалы к ним в двух группах наблюдений --- например, балл по шкале депрессии HADS у жителей Москвы и Петербурга.

Первоначально попробуем выяснить, справедливо ли утверждение «у жителей столиц нет клинически выраженной депрессии». Для этого необходимо, чтобы средний балл был меньше 11. Рассмотрим картину.

:::{#fig-ci-value}
```{r}
tibble(
  a = c("y", "ymin", "ymax"),
  `Москва` = c(6, 4, 8),
  `Санкт-Петербург` = c(8.5, 5, 12)
) %>% 
  pivot_longer(cols = -a) %>% 
  pivot_wider(names_from = a, values_from = value) %>% 
  ggplot(aes(x = name)) +
  geom_point(aes(y = y), size = 4) +
  geom_errorbar(aes(ymin = ymin, ymax = ymax), width = .2, linewidth = 1) +
  geom_hline(yintercept = 11, linetype = "dashed") +
  scale_y_continuous(breaks = 4:12) +
  labs(x = "Город", y = "HADS", caption = "отображён 95% доверительный интервал")
```

Сравнение выборочного среднего с данным значением через доверительный интервал
:::

Мы наблюдаем, что в случае Москвы интересующее нас значение 11 не попадает в доверительный интервал, в то время как в случае Петербурга --- попадает. Поскольку доверительный интервал отображает нашу неуверенность в том, что наше выборочное среднее отражает генеральное среднее, для нас все значения в пределах доверительного интервала *статистически равны* между собой. Или же можем сказать, что границы доверительного интервала обозначают значения, не противоречащие данным. Таким образом, так как 11 не попадает в 95%-ный доверительный интервал для Москвы, мы можем сказать, что средний уровень депрессии жителей Москвы ниже порога клинически выраженной депрессии. Про петербуржцев такого сказать не получится, так как 11 попало в доверительный интервал для Петербурга --- а значит, средний уровень депрессии 8.5 статистически равен 11, хотя по абсолютному значению ниже. Иначе говоря, значение 11 не противоречит имеющимся данным, хотя выборочное среднее и не совпадает с ним.

:::{.callout-note appearance="minimal"}
- если некоторое число попадает в доверительный интервал для выборочного среднего, то мы говорим, что среднее статистически не отличается от этого числа --- даже если по абсолютным значениям разница существенна
- если некоторое число не попадает в доверительный интервал для выборочного среднего, то мы говорим, что среднее статистически отличается от этого числа --- и больше или меньше в зависимости от абсолютных значений
:::

Однако чаще мы сравниваем две группы между собой. Посмотрим на ситуации, которые принципиально возможны при сравнении средних в двух группах.

:::{#fig-ci-groups}
```{r}
tibble(
  a = c("y", "ymin", "ymax"),
  A_1 = c(8, 6, 10),
  A_2 = c(8.5, 5, 12),
  B_1 = c(4, 1, 7),
  B_2 = c(1.5, 0, 3),
  C_1 = c(5, 2, 8),
  C_2 = c(1, -2, 4),
  D_1 = c(5.5, 3, 8),
  D_2 = c(0, -2, 2)
) %>% pivot_longer(cols = -a) %>% 
  pivot_wider(names_from = a, values_from = value) %>% 
  separate(name, into = c("group1", "group2")) %>% 
  ggplot(aes(x = group2, y = y, ymin = ymin, ymax = ymax)) +
  geom_hline(aes(yintercept = ymin), linetype = "dashed", color = "gray70", alpha = .5) +
  geom_hline(aes(yintercept = ymax), linetype = "dashed", color = "gray70", alpha = .5) +
  geom_point(size = 4) +
  geom_errorbar(width = .2, linewidth = 1) +
  facet_wrap(~ group1) +
  labs(x = "Group", y = "Value")
```
Сравнение выборочных средних в двух группах

:::


По оси $x$ --- группы наблюдений, по оси $y$ --- значение интересующей нас переменной. Видим четыре возможные ситуации:

- А --- каждое среднее попадает в доверительный интервал другого среднего
- B — одно среднее попадает в доверительный интервал другого среднего, а второе — не попадает
    - в данном случае, среднее второй группы попало в доверительный интервал среднего первой группы, в то время как среднее первой группы лежит за границами доверительного интервала среднего второй группы
- С --- ни одно из средних не попало в доверительный интервал другого среднего
    - но есть пересечение доверительных интервалов
- D --- доверительные интервалы не пересекаются, следовательно, ни одно из средних не попало в доверительный интервал другого среднего

Исходя из рассуждений выше, можно отметить, что если хотя бы одно среднее попало в доверительный интервал другого --- случаи A и B --- то различий между группами нет. А вот если средние не попадают в доверительные интервалы друг друга --- случаи C и D --- то различия между группами есть.



### Связь доверительного интервала с разбросом и объемом выборки {#ci-sd-n}

Так как доверительный интервал рассчитывается на основе стандартной ошибки (@eq-ci), которая в свою очередь рассчитывается на основе стандартного отклонения и числа наблюдений (@eq-se), нетрудно заметить, что:

:::{.callout-tip appearance="simple"}
- чем **выше разброс** в данных, тем будет **шире доверительный интервал**, так как больше стандартная ошибка
- чем **больше наблюдений** в нашей выборке, тем будет **у́же доверительный интервал**,[так как меньше стандартная ошибка
:::
