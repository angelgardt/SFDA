# Меры разброса

```{r opts, echo=FALSE, eval=TRUE}
knitr::opts_chunk$set(echo = FALSE, eval = TRUE, warning = FALSE, message = FALSE, error = FALSE)
```

```{r pkgs}
library(tidyverse)
theme_set(theme_bw())
```

Итак, мы разобрались с мерами центральной тенденции. Однако для описания распределения их оказывается недостаточно. Почему?

## Зачем нужны меры разброса {#variation-why}

Посмотрим на несколько распределений:

```{r}
set.seed(123)
tibble(`Var 1` = rnorm(100, 2, 1),
       `Var 2` = rnorm(100, 2, 0.5),
       `Var 3` = rnorm(100, 2, 5)) %>% 
  pivot_longer(cols = everything()) %>% 
  ggplot(aes(value)) +
  geom_histogram() +
  facet_wrap(~ name) +
  labs(x = "Значение", y = "Количество")
```


Методом пристального взгляда можно установить, что у всех распределений одинаковые средние:

```{r}
set.seed(123)
tibble(`Var 1` = rnorm(100, 2, 1),
       `Var 2` = rnorm(100, 2, 0.5),
       `Var 3` = rnorm(100, 2, 5)) %>% 
  pivot_longer(cols = everything()) %>% 
  ggplot(aes(value)) +
  geom_histogram() +
  geom_vline(aes(xintercept = mean(value)), linetype = "dashed") +
  facet_wrap(~ name) +
  labs(x = "Значение", y = "Количество")
```

Однако мы видим, что значения по-разному группируются вокруг среднего. Как они группируются --- плотно, как на втором рисунке, или не особо, как на третьем --- можно описать с помощью мер разброса, или мер вариативности.


## Основные характеристики статистических данных {#variation-data-features}

Вообще если посмотреть на это более свысока, то необходимость описания разброса определяется тем, что статистические данные обладают **двумя ключевыми особенностями --- неопределенностью и вариативностью**.

- **Неопределённость** нам говорит о том, что мы не знаем, что именно мы получим в результате наших измерений для конкретной выборки. В том числе потому, что мы работаем на просторах случайных величин.
- **Вариативность** означает, что наши данные будут различаться ещё и от респондента к респонденту. И между выборками тоже. Здесь и ошибка измерения, и различные смешения и ещё куча всего.

Более того, вариативность есть главное условие применения статики, поскольку она входит в расчёт любого статистического критерия. Если у переменной отсутствует вариативность, статистика на ней работать не будет.


## Минимум, максимум, размах {#variation-min-max}

Начнем с самого простого. Как наиболее просто описать вариативность? Мы работаем с выборкой, а в выборке, как известно, ограниченное число наблюдений. А если оно ограниченное, значит среди них точно есть наибольшее --- **максимум (max)** --- и наименьшее --- **минимум (min)**.

Допустим, мы открыли ведомость по «Анатомии и физиологии ЦНС» некоторой академической группы и пронаблюдали следующее:

```{r}
anat_marks <- c(7, 4, 6, 9, 10, 5, 6, 9, 6, 6, 3, 6, 8, 8, 5, 10, 7, 5, 7, 3, 9, 4, 8, 3, 8, 4, 6, 8, 7, 5)
anat_marks
```

Мы можем посчитать минимальное и максимальное значение по этому ряду наблюдений --- они окажутся равны соответственно `r min(anat_marks)` и `r max(anat_marks)`. То есть оценки по этой дисциплине варьируются от `r min(anat_marks)` до `r max(anat_marks)`. Ну, чу́дно. 

Разница между максимальным и минимальным значением называется **размах (range)**:

$$
\text{range}(X) = \max(X) - \min(X)
$$
 
В примере выше он будет равен `r max(anat_marks) - min(anat_marks)`.

И вот мы преисполнившиеся сим знанием идёт описывать вариативность переменной с помощью размаха, но обнаруживаем в другой ведомости этой же группы (по «Введению в психологию») вот что:

```{r}
intro_psy_marks <- c(6, 8, 4, 6, 7, 5, 7, 10, 4, 6, 7, 8, 7, 6, 8, 10, 8, 7, 7, 6, 8, 7, 6, 8, 6, 3, 8, 6, 6, 4)
intro_psy_marks
```

Минимум, максимум и размах вроде как такие же: `r min(anat_marks)`, `r max(anat_marks)` и `r max(anat_marks) - min(anat_marks)` соответственно.

Значит ли это, что вариативность одинаковая? Нарисуем.

```{r}
tibble(`Anatomy and Physiology` = anat_marks,
       `Introduction to Psychology` = intro_psy_marks) %>% 
  pivot_longer(cols = everything()) %>% 
  ggplot(aes(value)) +
  geom_bar() +
  facet_wrap(~ name, ncol = 1) +
  labs(x = "Оценка", y = "Количество")
```

Кажется, что вариативность различна. Распределение оценок по «Анатомии и физиологии ЦНС» более равномерное, в то время как оценки по «Введению в психологию» активнее группируются где-то в середине.

Штош, размах хоть и дает нам некоторую информацию о вариативности, нам этого маловато. Будем искать другие меры разброса.


## Квантили {#variation-quatile}

Возьмем распределение суммарного балла по шкале толерантности к неопределенности. Выглядит оно как-то так:

```{r, eval=FALSE, include=FALSE}
read_csv2("data/tolerance_uncertainty.csv") %>% 
  mutate(id = 1:405) %>% 
  select(id, starts_with("tu")) %>% 
  pivot_longer(cols = -id) %>% 
  summarise(score = sum(value),
            .by = id) %>% 
  write_csv("data/tol-uncert-score.csv")
```

```{r}
tu <- read_csv("data/tol-uncert-score.csv")
tu %>% 
  ggplot(aes(score)) +
  geom_histogram(binwidth = 1) +
  labs(x = "Балл", y = "Количество")
```


Теперь нам понадобится определение квантиля распределения.

:::{#def-quantile}
**Квантиль (quantile)** --- это значение переменной, которое не превышается с определенной вероятностью.
:::

Обозначим эту вероятность $p$. Тогда можно сказать, что квантиль уровня $p$ --- это такое значение переменной, слева от которого лежит $p\%$ наблюдений.

Посмотрим на картинки.

Слева относительно квантиля-0.05 ($x_{0.05}$) лежит 5% наблюдений:

```{r}
qtu <- quantile(tu$score, c(.05, .68, .99, .25, .5, .75))

tu %>% 
  mutate(
    qtu5 = ifelse(score < qtu["5%"], TRUE, FALSE),
    qtu68 = ifelse(score < qtu["68%"], TRUE, FALSE),
    qtu99 = ifelse(score < qtu["99%"], TRUE, FALSE),
    # qrtu1 = ifelse(score < qtu["25%"], TRUE, FALSE),
    # qrtu2 = ifelse(score < qtu["50%"], TRUE, FALSE),
    # qrtu3 = ifelse(score < qtu["75%"], TRUE, FALSE),
    qrtu = case_when(score < qtu["25%"] ~ 1,
                     score < qtu["50%"] ~ 2,
                     score < qtu["75%"] ~ 3,
                     .default = 4)
    ) -> tu

tu %>% 
  ggplot(aes(score, fill = qtu5)) +
  geom_histogram(binwidth = 1) +
  geom_vline(xintercept = qtu["5%"]) +
  labs(x = "Балл", y = "Количество") +
  guides(fill = FALSE) +
  scale_fill_manual(values = c("FALSE" = "gray", "TRUE" = "royalblue"))
```



Слева относительно квантиля-0.68 ($x_{0.68}$) лежит 68% наблюдений:

```{r}
tu %>% 
  ggplot(aes(score, fill = qtu68)) +
  geom_histogram(binwidth = 1) +
  geom_vline(xintercept = qtu["68%"]) +
  labs(x = "Балл", y = "Количество") +
  guides(fill = FALSE) +
  scale_fill_manual(values = c("FALSE" = "gray", "TRUE" = "royalblue"))
```

Слева относительно квантиля-0.99 ($x_{0.99}$) лежит 99% наблюдений:

```{r}
tu %>% 
  ggplot(aes(score, fill = qtu99)) +
  geom_histogram(binwidth = 1) +
  geom_vline(xintercept = qtu["99%"]) +
  labs(x = "Балл", y = "Количество") +
  guides(fill = FALSE) +
  scale_fill_manual(values = c("FALSE" = "gray", "TRUE" = "royalblue"))
```

Итак, мы поняли, а также приняли и осознали, что такое квантиль. Неясно только, как он нам поможет описать вариативность данных.

### Квартили {#variation-quartile}

Для этого нам пригодятся специально обученные квантили. Оказалось достаточно удобно поделить все наблюдение на *четыре равные части* --- вот так:

```{r}
tu %>% 
  ggplot(aes(score, fill = as_factor(qrtu))) +
  geom_histogram(binwidth = 1) +
  geom_vline(xintercept = qtu[c("25%", "50%", "75%")]) +
  annotate(geom = "text", label = "25%", x = 75, y = 2) +
  annotate(geom = "text", label = "25%", x = 85, y = 2) +
  annotate(geom = "text", label = "25%", x = 95, y = 2) +
  annotate(geom = "text", label = "25%", x = 110, y = 2) +
  annotate(geom = "text", label = "Q1", x = 77, y = 17.5) +
  annotate(geom = "text", label = "Q2", x = 87, y = 17.5) +
  annotate(geom = "text", label = "Q3", x = 101, y = 17.5) +
  labs(x = "Балл", y = "Количество") +
  guides(fill = FALSE)
```

Значения переменной, которые делят выборку на четыре равные части называются **квартили (quartile)**. Получается, что

- слева от первого (нижнего) квартиля ($\text{Q1}, x_{0.25}$) лежит 25% наблюдений
- слева от второго (среднего) квартиля ($\text{Q2}, x_{0.50}$) лежит 50% наблюдений
    - а значит и справа 50%: получается второй квартиль делит выборку пополам --- это медиана
- слева от третьего (верхнего) квартиля ($\text{Q3}, x_{0.75}$) лежит 75% наблюдений

Четвертый квартиль не используется, потому что является максимальным значением --- слева от него лежит 100% наблюдений.

Кстати, можно также отметить, что первый квартиль --- это медиана нижней (меньшей) половины наблюдений, а третий --- медиана верней (большей) половины наблюдений.

Вот такая вот прикольная история.


### Децили {#variation-decile}

К слову, делить выборку можно не только на четверти --- можно поделить, скажем, на 10 частей и получить **децили**. Так, слева от первого дециля ($x_{0.10}$) лежит 10% наблюдений, а слева от третьего ($x_{0.30}$) --- 30%.

Децили встречаются редко (в основном в психометрике), но знать о них полезно.


### Перцентили {#variation-percentile}

Гораздо чаще встречаются **перцентили** --- значения переменной, которые делят выборку на 100 равных частей. Например, так устроен ваш рейтинг. Только стоит помнить, что в рейтинге отсчет ведется от максимального GPA, поэтому если у вас нулевой перцентиль ($x_{0.00}$) по программе, значит выше вас в рейтинге никого нет. А если ваш перцентиль, скажем, 36-ой ($x_{0.36}$), то выше вас в рейтинге 36% ваших однокурсников, то есть вы все ещё в первой половине рейтинга, что очень неплохо!


## Интерквартильный размах {#variation-iqr}

И --- о, ура! --- мы наконец-то добрались до того, ради чего тут собрались! Зная первый и третий квартили распределения, можно рассчитать **интерквартильный (межквартильный) размах (interquartile range, IQR)** как разницу между третьим и первым квартилями.

$$
\text{IQR}(X) = \text{Q3}(X) - \text{Q1}(X)
$$
 
Эта величина описывает интервал значений признака, в котором лежит 50% наблюдений. В случае с баллами по шкале толерантности к неопределенности он равен `r IQR(tu$score)`, то есть 50% срединных наблюдений лежит в пределах `r IQR(tu$score)` единиц шкалы.



### Визуализация квартилей. Боксплот {#variation-boxplot}

Отображать квартили на гистограмме, во-первых, совершенно неудобно, а во-вторых, не то чтобы график получается информативный. Для визуализации квартилей придумали специальный тип графика --- **ящик с усами, или боксплот (boxplot)**.

```{r}
tu %>% 
  ggplot(aes(y = score)) +
  geom_boxplot() +
  labs(y = "Балл") +
  theme(axis.text.x = element_text(size = 0))
```


Прикольная ерунда. Научимся его читать.

- Значения переменной идут по вертикальной оси (оси ординат)[^horizontal-boxplot]
- По горизонтальной оси (оси абсцисс) здесь ничего не идёт[^x-boxplot]
- Жирная линия посередине ящика --- медиана (второй квартиль)
- Нижняя граница ящика --- первый квартиль, верхняя --- третий
- Границы ящика показывают нам межквартильный размах
- Нижний ус --- первый квартиль минус полтора межквартильных размаха
- Верхний ус --- третий квартиль плюс полтора межквартильных размаха

[^horizontal-boxplot]: Обычно это так, хотя не обязательно --- иногда боксплоты рисуют горизонтально, если это лучше отображает закономерности.

[^x-boxplot]: Но если мы рисуем несколько боксплотов рядом, то на оси $x$ будет категориальная переменная.

```{r}
tu %>% 
  ggplot(aes(y = score)) +
  geom_boxplot() +
  annotate(geom = "text", label = "Q1", x = -.4, y = 80) +
  annotate(geom = "text", label = "Q2", x = -.4, y = 90) +
  annotate(geom = "text", label = "Q3", x = -.4, y = 104) +
  annotate(geom = "text", label = "Q1−1.5IQR", x = -.06, y = 50) +
  annotate(geom = "text", label = "Q3+1.5IQR", x = -.06, y = 140) +
  labs(x = "", y = "Балл") +
  theme(axis.text.x = element_text(size = 0))
```

:::{.callout-warning}
#### Кривой ящик

Ящик может быть асимметричным --- то есть верхняя его часть (расстояние между медианой и третьим квартилем) и нижняя его часть (расстояние между медианой и первым квартилем) могут быть разными. Это нам говорит об асимметричности распределения. Усы также могут быть неравными, если один из них упирается в максимум / минимум --- тоже по причине асимметричности распределения.
:::

Ну, допустим. А что тогда точки?



### Выбросы {#variation-outliers}

Вообще справедливо было бы задаться вопросом, а зачем нам вообще усы на этом графике? И почему мы прибавляем полтора межквартильных размаха?

Это один из подходов к определению нехарактерных значений --- **выбросов (outliers)**. При исследовании данных мы часто задаемся вопросом, есть ли в наших данных такие значения, которые сильно отличаются от распределения той или иной переменной. Но как определить это самое «сильно»?

Вот один из подходов. Будем считать, что значения, которые укладываются в интервал $(\text{Q1} - 1.5 \times \text{IQR}, \text{Q3} + 1.5 \times \text{IQR})$, нас устраивают. Всё что попадает в этот интервал --- это «нормальные», типичные значения нашей переменной. Те же, которые будут находиться за пределами этого интервала, мы назовём нетипичными, аномальными значениями, или выбросами. Эти значения и будут отмечены точками на графике.

:::{.callout-tip}
#### Что делать с выбросами?

Во-первых, содержательно анализировать. Выбросы могут возникнуть по разным причинам. Может быть испытуемый отвлекся на прилетевшего в окно голубя, и у нас в данных появилось время реакции 200 секунд. Такие выбросы мы можем исключить из данных.

А возможно в нашу выборку попали какие-то люди, которые, скажем, очень сильно или очень слабо толерантны к неопределенности. Эти наблюдения не являются «ошибками», и их необходимо дополнительно проанализировать --- возможно, это представители каких-либо специфических групп нашей генеральной совокупности. Анализ принесет нам дополнительную информацию, которую мы могли не учесть при планировании исследования. Крч, думать надо. И собирать побольше данных, чтобы можно было найти содержательную интерпретацию происходящему.
:::



## Дисперсия {#variation-disp}

Хотя описание разброса переменных с помощью квантилей (в частности, квартилей) может дать нам много полезной информации, все же у них есть существенный недостаток: *они никак не взаимодействуют с самими значениями нашей переменной*.

Действительно, мы делим нашу отсортированную выборку на равные части, и смотрим, что в эти части попало. Но хотелось бы как-то учесть ещё и сами значения переменной в некоторой числовой мере разброса.

Ну, хорошо. Поступим следующим образом. Мы все ещё хотим узнать, как наши значения группируются вокруг среднего. В предыдущей главе мы уже видели, что наши наблюдения отклоняются от среднего значения --- значит мы можем посчитать отклонение для каждого наблюдения ($d$ --- от лат. *вумшфешщт* или англ. *deviation*):

$$
d_i = \overline X - x_i
$$

Окей. Если мы сложим все отклонения и поделим получившуюся сумму на их количество, равное количеству наблюдений ($n$), то получим среднее отклонение, да?

В принципе, да:

$$
\overline d = 
\frac{1}{n} \sum_{i=1}^n d_i = 
\frac{1}{n} \sum_{i=1}^n (\overline X - x_i)
$$
 
Однако есть одна проблема. В прошлой главе мы выяснили, что сумма отклонений от среднего равна нулю (@prp-mean3), а значит и cреднее отклонение также будет равно нулю.

Хорошо. Но отрицательные значения ведь можно победить! Есть два пути:

- **Модуль.** Преимущество первого в том, что размерность величины разброса остается той же, что и у измеряемой переменной.
- **Квадрат.** Преимущество второго в том, что квадрат обладает более хорошими аналитическими свойствами, чем модуль, а ещё сильные отклонения будут оказывать более сильное влияние на окончательное значение статистики (см. заметку [-@nte-abs-sq]).

Второй путь на практике оказывается полезнее, так как мы хотим, чтобы сильно отличающиеся наблюдения вносили больший вклад в меру разброса.

Возведя отклонения в квадрат, получим формулу **дисперсии (вариации, variation)**:

$$
D(X) = \text{var}(X) = \sigma^2_X =
\frac{1}{n} \sum_{i=1}^n d_i^2 = 
\frac{1}{n} \sum_{i=1}^n (\overline X - x_i)^2
$${#eq-pop-var}

Гениально.

:::{.callout-note collapse="true"}
### Почему квадрат лучше модуля?

Рассмотрим два простейших примера. Пусть у нас есть два нехитрых ряда наблюдений:

```{r}
v1 <- 1:6
v2 <- c(1:5, 20)
v1
v2
```

Как несложно заметить, они отличаются друг от друга всего лишь одним наблюдением --- в первом случае существенных отклонений нет, а во втором есть одно наблюдений, значительно отклоняющееся от всех остальных.

Попробуем посчитать разброс, используя модуль --- формула будет такова:

$$
\text{MAD} = \frac{1}{n} \sum_{i=1}^n |d| = \frac{1}{n} \sum_{i=1}^n |\overline X - x_i|
$$

Эта статистика называется *среднее абсолютное отклонение (mean absolute deviation, MAD)*.

Для первого ряда наблюдений получим **`r mean(abs(v1 - mean(v1))) %>% round(2)`**, для второго --- **`r mean(abs(v2 - mean(v2))) %>% round(2)`**.

Значения разброса, безусловно, различаются, однако не то чтобы очень значительно.

Теперь воспользуется формулой дисперсии:

$$
\text{var}(X) = \frac{1}{n} \sum_{i=1}^n d^2 = \frac{1}{n} \sum_{i=1}^n (\overline X - x_i)^2
$$

Для первого ряда наблюдений получим **`r mean((v1 - mean(v1))^2) %>% round(2)`**, для второго --- **`r mean((v2 - mean(v2))^2) %>% round(2)`**.

В этой случае значения различаются уже гораздо сильнее --- на целый порядок.

Отметим, что и в случае отклонений в меньшую от среднего сторону формулы не перестают работать. Возьмём такие ряды наблюдений:

```{r}
v3 <- 15:20
v4 <- c(5, 16:20)
v3
v4
```

Расчёты мер разброса для них представлены ниже.

||MAD (модуль)|Дисперсия (квадрат)|
|:---:|:---:|:---:|
|Первый ряд|`r mean(abs(v3 - mean(v3))) %>% round(2)`|`r mean((v3 - mean(v3))^2) %>% round(2)`|
|Второй ряд|`r mean(abs(v4 - mean(v4))) %>% round(2)`|`r mean((v4 - mean(v4))^2) %>% round(2)`|

:::

Но не совсем. Формула, которую мы получили, пригодна для расчета *дисперсии генеральной совокупности* --- на выборке же она будет давать неточную оценку.

Чтобы получить точную (несмещенную) *оценку дисперсии по выборке*, нам нужно исправить знаменатель дроби --- вместо $n$ использовать $n - 1$:

$$
s^2_X = \hat \sigma^2_X = 
\frac{1}{n-1} \sum_{i=1}^n d^2 = 
\frac{1}{n-1} \sum_{i=1}^n (\overline X - x_i)^2
$${#eq-sample-var}

Но почему?

:::{.callout-tip}
### Обозначения параметров и их выборочных оценок

Обратим внимание на используемые обозначения.

- Для обозначения **параметров генеральной совокупности** используются греческие буквы, поэтому *дисперсия генеральной совокупности* обозначена как $\sigma^2$.
- Для обозначения **оценок параметров, полученных на выборке** используются соответствующие греческим латинские буквы, поэтому *выборочная дисперсия* обозначена как $s^2$.

Также для обозначения выборочных оценок может быть использована «шляпка», которая надевается на обозначение параметра --- в случае дисперсии это выглядит как $\hat \sigma^2$.

:::

### Свойства выборочных оценок {#variation-estim-features}

Во всём виновата выборка. В первой главе мы говорили, что в ходе исследования мы собираем выборку, чтобы по результатам её изучения сделать вывод о генеральной совокупности (см. [@fig-sampling-inference]). Иначе говоря, мы заинтересованы в получение максимально точных выборочных оценок параметров генеральной совокупности.

Однако ввиду *неопределенности и вариативности* данных мы неизбежно будем ошибаться, то есть значение любой выборочной оценки будет отличаться от значения параметра генеральной совокупности. Что же делать?

Необходимо предъявить определённые требования к оценке параметра, для того чтобы она считалась «хорошей», «правильной», «корректной». Таких требований всего существует три --- *несмещённость*, *состоятельность* и *эффективность* --- из которых мы познакомимся только с первым, так как оно имеет непосредственное отношение к оценке дисперсии.

**Несмещённость** выражает следующую идею:

> пусть мы будем ошибаться в оценке параметра на отдельной выборке, <br>
> однако мы не должны ошибаться *в среднем*, постоянно используя один и тот же способ оценки.

Иначе говоря, да, мы ошибёмся на конкретной выборке, но если выборок будет много, то, усреднив оценки по всем выборкам, мы будем попадать ровно в значение параметра генеральной совокупности.

Под эту идею существует математические обоснование, которое мы не будем рассматривать --- лучше поглядим на картинки. Начнём с чего-то хорошо нам знакомого --- например, среднего. Ведь у среднего была только одна формула, как мы помним. Почему?

Сделаем симуляцию. Пусть известно, что среднее некоторой переменной в генеральной совокупности равно $10$, а дисперсия --- $25$. Для определенности можете считать, допустим, что это время реакции на некоторым тип стимулов, хотя это не важно --- излагаемая логика будет работать для любых переменных.

Извлечём из этой генеральной совокупности 1000 выборок по 50 наблюдений. На каждой из выборок мы посчитаем среднее и получим что-то такое:
  
```{r}
set.seed(123)

replicate(1000, rnorm(50, 10, 5)) %>% 
  apply(2, mean) -> means
means[1:100]
```

Здесь представлено только 100 первых значений выборочных средних, так как выводить все довольно громоздко. Наблюдаем, что от выборки к выборки среднее меняется, но все они плюс-минус находятся около 10 --- значения параметра генеральной совокупности.

Мы можем усреднить полученные значения, то есть посчитать *среднее средних*. Отобразим его на *распределении выборочных средних*, добавив на график значение параметра генеральной совокупности:

:::{#fig-unbias-mean}
```{r}
ggplot(NULL) +
  geom_histogram(aes(means), fill = "gray70") +
  geom_vline(xintercept = mean(means), linetype = "dashed") +
  geom_vline(xintercept = 10, color = "red") +
  labs(x = "Выборочные средние", y = "Количество")
```

Несмещённость среднего арифметического как оценки среднего генеральной совокупности
:::

На рисунке красная сплошная линия --- значение параметра генеральной совокупности, черная пунктирная --- среднее выборочных средних. Видно, что линии [практически] совпадают. Значит, при использовании среднего арифметического в качестве выборочной оценки генерального среднего мы *в среднем* не ошибаемся. Это и есть несмещённость.

Теперь рассмотрим ситуацию с дисперсией. Итак, у нас есть два способа оценки дисперсии по выборке --- @eq-pop-var и @eq-sample-var. Возьмём те же 1000 выборок по 50 наблюдений и посчитаем для каждой выборке её дисперси двумя способами --- по формуле выборочной дисперсии и по формуле дисперсии генеральной совокупности. Получим такие значения:

```{r}
set.seed(123)

replicate(1000, rnorm(50, 10, 5)) %>% 
  apply(2, function(x) {return(c(var(x), mean((mean(x) - x)^2)))}) -> vars
vars[, 1:100]
```

Вновь взглянем на первую сотню пар значений: в первой строке расчёты по формуле выборочной дисперсии, во второй --- по формуле дисперсии генеральной совокупности. Заметим, что значения в первой строке всегда больше, чем значения во второй. Оно и понятно --- так устроены формулы. При этом числа в обеих строках вновь плюс-минус собираются около 25 --- значения параметра генеральной совокупности.

Изобразим картину для большей наглядности:

```{r}
vars %>% t() %>% 
  as_tibble() %>% 
  pivot_longer(cols = everything()) %>%
  ggplot(aes(value, color = name)) +
  geom_density() +
  geom_vline(xintercept = mean(vars[1, ]), linetype = "dashed", color = "black") +
  geom_vline(xintercept = mean(vars[2, ]), linetype = "dashed", color = "blue") +
  geom_vline(xintercept = 25, color = "red") +
  scale_color_manual(values = c("black", "blue"),
                     labels = c("V1" = "По формуле для выборки",
                                "V2" = "По формуле для генеральной совокупности")) +
  labs(x = "Выборочные дисперсии", y = "Количество",
       color = "Оценка дисперсии") +
  theme(legend.position = "bottom")
```

Красной сплошной линией здесь вновь отображен параметр генеральной совокупности. Несложно пронаблюдать, что среднее выборочных дисперсий --- чёрная пунктирная линия --- [практически] совпадает с красной. Следовательно, *формула дисперсии для выборки действительно даёт несмещённую оценку*. Теперь обратим внимание на синюю пунктирную линию --- среднее оценок дисперсии по формуле для генеральной совокупности. Она *не совпадает с красной*. Более того, если мы посмотрим на распределение --- синяя сплошная линия --- то заметим, что оно сдвинуто в сторону относительно чёрного распределения. Это нам говорит о том, что формула для генерального среднего систематически промахивается, что и является выражением смещённости оценки.

Таким образом, при оценке дисперсии по выборке используется @eq-sample-var, поскольку именно оно даёт несмещённую оценку параметра генеральной совокупности.


### Степени свободы {#variation-df}

Число $n-1$ в [-@eq-sample-var] называется *количеством степеней свободы*. Это довольно мутное понятие, которое при этом непозволительно часто встречается в статистике. Попытаемся к нему хотя бы интуитивно подойти.

Сразу возникает разумный вопрос: почему $n-1$? Почему не $n-2$ или $n+6$?

Это число с неизбежностью появляется в расчетах при математическом способе исследования несмещённости оценки дисперсии. Как говорилось выше, в математику мы здесь нырять не будем, однако можно помыслить обоснование следующим образом.

Взглянем на формулу дисперсии: в неё входит среднее арифметическое. То есть для того, чтобы рассчитать дисперсию на выборке, сначала нам необходимо на этой же выборке рассчитать среднее. Мы получаем часть информации о выборке, тем самым как бы «фиксируя» её этим средним значением.

В каком смысле «фиксируя»? Рассчитанное среднее могло получиться многими способами --- разные значения наблюдений могли сложиться в одно и то же среднее. До расчета среднего число свободно варьирующихся наблюдений в выборке было $n$, то есть все имеющиеся значения. Однако когда среднее стало известно, возможность варьирования уменьшилась. Теперь свободно варьирующихся наблюдений стало $n-1$, так как при известном среднем произвольно могут измениться все наблюдения, кроме одного --- всегда можно будет его вычислить, зная выборочное среднее и все предыдущие.

Иначе говоря, теперь одно из наблюдений не является случайным, а значит не участвует в формировании дисперсии выборки. По этой причине оно исключается из расчетов, и в формуле дисперсии появляется $n-1$.

О степенях свободы можно думать ещё и так: для расчета дисперсии мы посчитали одну статистику --- среднее арифметическое, значит из числа наблюдений надо вычесть единицу. В общем-то это то же, что и излагалось выше, только в предельно укороченном варианте. 

Впрочем, это не так далеко от истины --- позже мы стокнемся со случаями, когда для расчета мер изменчивости необходимо будет рассчитывать две, три и более статистик, и тогда количество степеней свободы будет соответственно $n-2$, $n-3$ и $n-p$.


## Стандартное отклонение {#variation-sd}

И вот мы получили невероятное! У нас есть формула расчета меры разброса, которая позволяет учесть каждое значение переменной! Ну, не чудо ли!

Чудо, конечно. Однако есть некоторая проблема. Мы возводили отклонения в квадрат. Представим, что мы хотим посчитать дисперсию роста студентов психфака. Пусть мы измеряли рост в метрах. Отклонения тоже будут в метрах, так как среднее --- это тоже метры, а если из метров вычитать метры, то мы получим метры. При возведении же метров в квадрат получаются метры в квадрате. Очевидно, что если мы поделим квадратные метры на некоторое число, они все еще останутся метрами в квадрате.

Мы знаем, что в квадратных метрах измеряется, например, площадь, однако едва ли можно говорить о разбросе роста как о площади. Что-то тут нелогичное получается. К тому же, если мы возьмем не рост, а скажем, время реакции, то его дисперсия будет измеряться в квадратных секундах. Это уже вовсе за рамками всевозможных приличий…

А счастье было так близко, так возможно! Неужели мы не сможем интерпретировать эту меру разброса? Не сможем даже нарисовать?

Да, но это не очень большая беда. Для того, чтобы вернуться к исходным единицам измерения нашей переменной, нам всего лишь нужно извлечь корень из дисперсии:

$$
\sigma_X = \sqrt{\sigma^2_X} = 
\sqrt{\frac{1}{n} \sum_{i=1}^n d^2} = 
\sqrt{\frac{1}{n} \sum_{i=1}^n (\overline X - x_i)^2}
$$

Мы получили величину, называемую **стандартным (средним квадратичным[^sd_rms]) отклонением (standard deviation)**.

Чем она хороша? Тем, что её размерность совпадает с размерностью нашей переменной. Стандартное отклонение уже может быть достаточно интерпретабельно и хорошо визуализируемо.

[^sd_rms]: Взгляните [в предыдущую главу](desc-centraltend.qmd#centraltend-rms). Как и было обещано, мы увиделись с одним из других средних.

Кстати, формула выше --- это *стандартное отклонение генеральной совокупности*, потому что под корнем стоит дисперсия генеральной совокупности.

Чтобы посчитать **стандартное отклонение по выборке**, нам надо извлечь корень из выборочной дисперсии:

$$
s_X = \sqrt{s^2_X} = \sqrt{\frac{1}{n-1} \sum_{i=1}^n d^2} = \sqrt{\frac{1}{n-1} \sum_{i=1}^n(\overline X - x_i)^2}
$$



## Сравнение мер разброса {#variation-comparison}

Как и разные меры центральной тенденции, разные меры разброса по-своему хороши. Более того, они «дружат» с мерами центральной тенденции. Так, *с медианой обычно используется межквартильный размах*, а *со средним арифметическим --- стандартное отклонение*.

Размах подходит для всего сразу. Его стоит рассчитать, чтобы составить самое первое представление о разбросе, о границах изменения изучаемого признака [на нашей выборке].

Стоит также отметить, что все, что мы тут обсуждали, совершенно не годится для номинативных переменных. Однако у них тоже есть вариативность. Согласитесь, что выборка из Питера, Москвы, и Казани более вариативна, чем выборка из Москвы. Аналогом меры разброса для номинальной переменной можно назвать количество уникальных значений этой переменной.

## Свойства дисперсии и стандартного отклонения {#variation-disp-features}

Мы рассмотрим два свойства дисперсии и два свойства стандартного отклонения, непосредственно следующих из свойств дисперсии.

:::{#prp-var1}
Если к каждому значению распределения прибавить некоторое число (константу), то дисперсия распределения не изменится.

$$
D_{X+c} = D_X
$$
:::

:::{.proof}

$$
\begin{split}
D_{X+c} &=\frac{1}{n} \sum_{i=1}^n \big( (\overline X + c) - (x_i + c) \big)^2 = \\
&= \frac{1}{n} \sum_{i=1}^n (\overline X + c - x_i - c)^2 = \\
&= \frac{1}{n} \sum_{i=1}^n (\overline X - x_i)^2 = D_X
\end{split}
$$
:::

:::{#cor-sd1}
Если к каждому значению распределения прибавить некоторое число (константу), то стандартное отклонение не изменится.

$$
\sigma_{X+c} = \sigma_X
$$

:::

:::{.proof}
$$
\sigma_{X+c} = \sqrt{\sigma^2_{X+c}} = \sqrt{D_{X+c}} = \sqrt{D_X} = \sqrt{\sigma^2_X} = \sigma_X
$$
:::


:::{#prp-var2}
Если каждое значение распределения умножить на некоторое число (константу), то дисперсия изменится в $c^2$ раз.

$$
D_{X \times c} = D_X \times c^2
$$
:::

:::{.proof}

$$
\begin{split}
D_{X \times c} &=\frac{1}{n} \sum_{i=1}^n \big( (\overline X \times c) - (x_i \times c) \big)^2 = \\
&= \frac{1}{n} \sum_{i=1}^n c^2 \times (\overline X - x_i)^2 = \\
&= c^2 \times \frac{1}{n} \sum_{i=1}^n (\overline X - x_i)^2 = \\
&= c^2 \times D_X
\end{split}
$$

:::

:::{#cor-sd2}
Если каждое значение распределения умножить на некоторое число (константу), то стандартное отклонение изменится во столько же раз.

$$
\sigma_{X \times c} = \sigma_X \times c
$$

:::

:::{.proof}

$$
\sigma_{X \times c} = \sqrt{\sigma^2_{X \times c}} = \sqrt{D_{X \times c}} = \sqrt{c^2 \times D_X} = c \times \sqrt{D_X} = c \times \sqrt{\sigma^2_X} = c \times \sigma_X
$$

:::

Проиллюстрировать свойства дисперсии довольно трудно, поскольку на графиках её отобразить весьма проблематично, однако для стандартного отклонения картинки нарисовать можно. Собственно, мы их уже видели, когда обсуждали свойства среднего арифметического (см. @prp-mean1 и @prp-mean2).

Для следствия [-@cor-sd1] визуализация будет такой:

```{r tibble_for_feature_vis_1, include=FALSE}
smpl1 <- tibble(x1 = seq(-3, 3, by = .001),
               y1 = dnorm(x1),
               x2 = x1 + 2,
               y2 = dnorm(x2, mean = 2))
```

```{r sd_feature_1, echo=FALSE}
smpl1 %>% 
  ggplot() +
  geom_line(aes(x1, y1), color = "blue4") +
  geom_line(aes(x2, y2), color = "red4") +
  geom_vline(xintercept = 0, linetype = "dashed", color = "blue4") +
  geom_vline(xintercept = 2, linetype = "dashed", color = "red4") +
  labs(x = "Value", y = "Density")
```

Как мы уже видели, распределение просто сдвигается на константу. Если к каждому значению синего распределения прибавить $2$, получится красное --- разброс у обоих распределений одинаковый.

Для следствия [-@cor-sd2] визуализация выглядит так:

```{r tibble_for_feature_vis_2, include=FALSE}
smpl2 <- tibble(x1 = seq(-2, 4, by = .001),
               y1 = dnorm(x1, mean = 1),
               x2 = x1 * 3,
               y2 = dnorm(x2, mean = 3, sd = 3))
```

```{r sd_feature_2, echo=FALSE}
smpl2 %>% 
  ggplot() +
  geom_line(aes(x1, y1), color = "blue4") +
  geom_line(aes(x2, y2), color = "red4") +
  geom_vline(xintercept = 1, linetype = "dashed", color = "blue4") +
  geom_vline(xintercept = 3, linetype = "dashed", color = "red4") +
  labs(x = "Value", y = "Density")
```

Здесь каждое значение синего распределения умножили на $3$ и получили красное --- разброс также увеличился в три раза, поэтому распределение более плоское.
