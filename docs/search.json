[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "SFDA | PSY HSE",
    "section": "",
    "text": "Начало",
    "crumbs": [
      "Начало"
    ]
  },
  {
    "objectID": "index.html#врубаем-тэхно-для-рабочего-настроения",
    "href": "index.html#врубаем-тэхно-для-рабочего-настроения",
    "title": "SFDA | PSY HSE",
    "section": "Врубаем тэхно для рабочего настроения",
    "text": "Врубаем тэхно для рабочего настроения\n\nПрежде всего, разумно будет попытаться разобраться в том, заради чего мы тут собрались. Ну, попробуем…\n\nВот, скажем, решили мы замерить уровень счастья российского населения — задача, прямо скажем, не суперпростая. Дать опросник 144 миллионам людей весьма энергозатратно, и хотелось бы как-то упростить себе задачу. Сколько нам надо опросить людей, чтобы наш замер отражал реальность? Как нам их выбрать? Как потом обсчитать цифры, которые мы получим? И вообще, наш опросник — он точный? Надежный? Им вообще законно что-либо измерять?\nИли вот мы — учёный. Решили провести некоторый суровый когнитивный эксперимент, чтобы узнать, как пользователи Android и iOS ищут иконки разных приложений. Скачали статей, выдвинули гипотезы, придумали дизайн, запрогали эксп, нашли несчастных, которые прошли этот эксп — по итогу получили какие-то цифири. Возникает справедливый вопрос: и чё? Как нам сказать, что данные подтвердили или опровергли наши гипотезы? Можем ли мы вообще по этим данным что-то сказать? Ну, допустим, мы ленивые и вообще программировать это для умных — отдадим специально обученным аналитикам посчитать это всё. И получим цифири. О, нет — опять! Возникает ещё один справедливый вопрос: и чё? Как нам сказать, что эти цифры подтверждают или опровергают наши гипотезы? Можем ли мы вообще по этим цифрам что-либо сказать осмысленное? А содержательно как это интерпретировать? Иконки-то как пользователи ищут?\nНу, или мы — HR в компании на 100500 тыщ человек сотрудников. Пришел гендир, сказал «уволить нельзя премировать, только непонятно кого». Дал нам экселевскую таблицу со всякими показателями эффективности и сказал «завтра к вечеру должна быть система грейдов, по которой будем оценить сотрудников». И что делать? Придется всю ночь ворочать цифры и статистически моделировать.\nА вот, скажем, залезли мы в ковидные новости очередной волны — там что-то страшное, да в графиках, да снова цифры какие-то ужасные. Хлебнули чаю, включили статистический взгляд — а, ну так все норм же. Оценили риски для себя, друзей, родных, убедились в том, что журналисты снова навели излишней суеты, восхитились собой, пошли инвестировать в крипту.\nОпять какие-то графики увидели, тренды, прогнозы и всё такое. Как понять? Как прочитать это всё? Как оценить, куда надо стипуху вкласть? Вспомнили статистику, навели шороху, собрали достойный инвестиционный портфельчик — хлебнули кофе, пошли покупать билеты на Бали.\nДальше можно расписывать огромное количество подобных случаев. Приходится признать, что сегодня мы живем в окружении огромного количества алгоритмов, основанных на статистическом анализе. Всё то, что называется модным словосочетанием «машинное обучение» базируется на тех статистических методах, которые мы будем с вами изучать.\nМожно ли жить без этого знания? В принципе, да. Однако\n\nкогнитивщикам и нейроисследователям необходимо анализировать свои данные своих экспериментов и — что значительное более важно — корректно интерпретировать результаты статистического анализа, что невозможно без понимания того, как используемые статистические методы работают\nсоциальщикам и личностникам-исследователям также необходимо анализировать данные своих исследований — и используемые ими модели даже сложнее, чем у когнитивщиков и нейроученых\nорганизационщикам придется также работать с данными, потому что HR-аналитика на хайпе и экспертный подход к оценке персонала постепенно теряет актуальность [а ещё айтишников нанимать придётся]\nличностникам-консультантам надо быть в теме того, что творят личностники-исследователи, а значит придется читать статьи и оценивать их адекватность, в том числе, в аспекте анализа данных\nвсем [даже некоторым когнитивщикам] придется работать с опросниками — а вся психометрика строится на статистике\nвсем придется в жизни анализировать потоки информации, возрастающие с невероятной скоростью, данные и графики, критически и оценивать, выявлять неочевидные закономерности, чтобы понимать, что происходит — и статистика в этом сильно поможет\nвсе мы продолжаем жить в мире гаджетов и технологий, и понимание того, какие модели лежат в их основе, очень прилично апгрейдит наше понимание того, что восстание машин будет о-о-о-очень не скоро.\n\nКонечно, мы не можем обсудить всё. Мы находимся в рамках суровых институциональных ограничений. Но мы постараемся заложить достаточно прочный фундамент, который при правильном применении и должном уходе поможет вам преуспеть и в жизни, и в работе и вообще.",
    "crumbs": [
      "Начало"
    ]
  },
  {
    "objectID": "index.html#зачем-изучать-анализ-данных-в-эпоху-нейросетей",
    "href": "index.html#зачем-изучать-анализ-данных-в-эпоху-нейросетей",
    "title": "SFDA | PSY HSE",
    "section": "Зачем изучать анализ данных в эпоху нейросетей?",
    "text": "Зачем изучать анализ данных в эпоху нейросетей?\nА действительно? Можно же просто закинуть промпт, и всё готово…\nНу, закинем промпт.\n\nЗачем изучать анализ данных, если существуют нейросети, которые могут проанализировать данные за меня?\n\n\n\n\n\n\n\nОтвет ChatGPT-4 (30 мая 2024)\n\n\n\nЭто отличный вопрос! Действительно, нейросети и другие методы машинного обучения становятся все более мощными инструментами для анализа данных. Однако есть несколько причин, почему важно изучать анализ данных, даже если существуют такие технологии:\n\nПонимание процесса: Понимание основ анализа данных позволяет лучше понять, как работают нейросети и другие алгоритмы машинного обучения. Это помогает в настройке, интерпретации и улучшении моделей.\nВыбор методов: Анализ данных помогает выбирать подходящие методы и инструменты для конкретной задачи. Нейросети — не всегда лучший выбор, особенно для небольших наборов данных или когда требуется интерпретируемость результатов.\nКачество данных: Анализ данных включает в себя предварительную обработку данных — очистку, нормализацию, выявление и исправление ошибок. Без этого этапа нейросеть может обучиться на “грязных” данных и выдавать неправильные результаты.\nИнтерпретируемость моделей: Многие модели машинного обучения (включая нейросети) сложны для интерпретации. Традиционные методы анализа данных, такие как регрессия или дерево решений, могут предложить более простые и интерпретируемые модели, что важно в некоторых приложениях, например, в медицине или финансах.\nОбоснование результатов: В некоторых ситуациях требуется не только предсказать результат, но и объяснить, почему модель приняла то или иное решение. Это особенно важно в регулируемых отраслях, таких как банковское дело или страхование.\nКомбинаторика методов: Возможно объединение различных методов анализа данных и машинного обучения для достижения лучших результатов. Глубокое понимание как статистических методов, так и нейросетей позволяет строить гибридные модели.\nИнновации и новые подходы: Знания в области анализа данных способствуют разработке новых алгоритмов и подходов, что может привести к появлению более эффективных способов решения задач.\n\nВ целом, изучение анализа данных дает фундаментальные знания, которые помогут лучше использовать и усовершенствовать нейросетевые модели и другие инструменты машинного обучения.\n\n\n\nЗачем мне как аналитику уметь писать код, если можно попросить нейросеть написать код под конкретную задачу по анализу данных?\n\n\n\n\n\n\n\nОтвет ChatGPT-4 (30 мая 2024)\n\n\n\nИспользование нейросетей для генерации кода под задачи анализа данных может быть полезным, но есть несколько причин, по которым важно уметь писать код самостоятельно, даже если вы аналитик:\n\nПонимание данных и процессов: Знание программирования помогает лучше понять структуру данных и методы, которые вы используете для их анализа. Это особенно важно для интерпретации результатов и их корректного применения.\nОтладка и валидность результатов: Автоматически сгенерированный код может привести к ошибкам или неправильным выводам. Умение самостоятельно писать и проверять код позволяет убедиться, что все работает корректно.\nГибкость и адаптация: Ваши задачи могут изменяться, требуя новой логики анализа или дополнительных шагов обработки данных. Умение писать код позволяет легче адаптироваться к новым требованиям и быстро вносить изменения.\nКачество данных: Предварительная обработка данных — ключевой этап анализа. Знание программирования помогает эффективно очистить, нормализовать и обработать данные перед анализом.\nОптимизация: Автоматически сгенерированный код может быть неоптимальным. Умение писать собственный код позволяет вам сделать анализ данных более эффективным и производительным.\nИнтерпретируемость: Полное понимание кода делает результаты вашего анализа более понятными и объяснимыми для заинтересованных сторон.\nКомандная работа и документация: В команде аналитиков важно уметь читать и писать структурированный код, чтобы эффективно сотрудничать с коллегами и поддерживать документацию проекта.\nНавык решения уникальных задач: Задачи анализа данных могут быть очень разнообразными и требовать индивидуального подхода. Нейросеть может не всегда справиться с уникальными или нестандартными задачами без надлежащего контекста.\nПрофессиональный рост: Знание программирования является важным навыком для роста и развития в карьере аналитика. Это открывает двери к более сложным и интересным проектам.\nБезопасность и конфиденциальность: Используя нейросеть, вы можете столкнуться с проблемами, связанными с конфиденциальностью данных. Самостоятельная работа с кодом помогает лучше контролировать безопасность и защиту данных.\n\nХотя нейросети могут быть полезным инструментом, знание программирования остается важным навыком для аналитиков, обеспечивая гибкость, контроль и качество работы.\n\n\nВ общем-то, автор согласен с мнением большой языковой модели. Пусть и не все обозначенные ею пункты в полной мере актуальны для психологов, так или иначе каждый тезис находит своё отражение в исследовательской работе психолога.\nКроме того, если мы уж и решили использовать нейросеть для генерации кода или подбора статистического метода под имеющуюся у вас задачу, надо каким-то образом надо сформулировать промпт. А как его сформулировать, если не знать хотя бы на концептуальном уровне, что должно получиться в результате анализа данных?\nПолучается, что всё-таки имеет смысл разобраться в статистике и анализе данных хотя бы на некотором базовом уровне, чтобы использоваться нейросетки с умом.",
    "crumbs": [
      "Начало"
    ]
  },
  {
    "objectID": "intro-intro.html",
    "href": "intro-intro.html",
    "title": "1  Основания статистики",
    "section": "",
    "text": "1.1 Выборка и генеральная совокупность\nЗвучит красиво. Осталось понять, что это значит.\nМассовые явления затрагивают огромные массы людей. Огромность масс, конечно, различна. Скажем, базовые перцептивные закономерности, связанные с тем, как устроена зрительная система, охватывают всех людей. Уровень удовлетворенности жизнью россиян охватывает только население России. Городские блага москвичей — только для жителей Москвы. Учебная мотивация студентов департамента психологии НИУ ВШЭ — это только про людей с психологических бакалавриата и магистратур НИУ ВШЭ.\nКороче, надо исследовать много людей, а времени и денег нет, поэтому мы никогда не сможем полностью изучить всю интересующая нас генеральную совокупность. Однако исследования всё же проводить нужно, поэтому приходится из генеральной совокупности извлекать выборку (sample) — некоторую часть нашей генеральной совокупности (объемом \\(n\\)). При этом \\(n \\ll N\\) (много меньше).\nНас, конечно же, интересуют какие-то признаки, которыми обладают объекты нашей генеральной совокупности. Эти признаки могут быть выражены количественно в определенных показателях (Таблица 1.1).\nПризнаки могут быть очень разными, как и показатели, которыми мы их пытаемся измерить. Не будем сильно в это углубляться, ибо подробнее об этом будет рассказано в других курсах. Мы же остановимся\nЧто нам важно сейчас: генеральная совокупность характеризуется параметром.\nНу, то есть в принципе существует средний уровень нейротизма студентов-психологов, или средняя удовлетворенность условиями труда сотрудниками IT-компаний, или средний уровень академической мотивации выпускников бакалавриата. Проблема в том, что величина параметра, который мы изучаем, неизвестна. И никогда не будет известна.\nНо почему?\nПоэтому величину параметра мы можем только предсказать с определённой статистической точностью. Измеряя что-либо на выборке, мы получаем выборочную характеристику, или оценку.\nТак, оценкой для среднего уровня нейротизма студентов-психологов может служить средний балл нескольких тысяч студентов-психологов по соответствующей шкале опросника BFI (Big Five Inventory), а оценкой для средней академической мотивации выпускников бакалавриата будет, например, средний балл нескольких тысяч выпускников по опроснику академической мотивации.",
    "crumbs": [
      "Введение в статистику",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Основания статистики</span>"
    ]
  },
  {
    "objectID": "intro-intro.html#выборка-и-генеральная-совокупность",
    "href": "intro-intro.html#выборка-и-генеральная-совокупность",
    "title": "1  Основания статистики",
    "section": "",
    "text": "Определение 1.1 Статистика (statistics) — это междисциплинарная область знаний, а также практической деятельности, изучающая массовые явления, а также принципы и методы работы с данными, характеризующими эти явления.\n\n\n\n\nОпределение 1.2 Генеральная совокупность (population) — множество всех [существующих] исследуемых объектов, а также сведения о них.\n\n\nОпределение 1.3 Объем совокупности (\\(N\\)) — число единиц, образующих совокупность.\n\n\n\n\n\n\nТаблица 1.1: Примеры признаков и показателей\n\n\n\n\n\n\n\n\n\nПризнак\nПоказатель\n\n\n\n\nРабочая память\nОбъем рабочей памяти\n\n\nНейротизм\nУровень нейротизма по BFI\n\n\nЗаработная плата\nСредняя заработная плата\n\n\nКогнитивная нагрузка\nУровень когнитивной нагрузки по ЭЭГ-коррелятам\n\n\nДоверие к ИИ\nУровень доверия к ИИ по опроснику TAIA\n\n\nИндивидуализм/коллективизм\nИндекс индивидуализма/коллективизма по модели Хофстеде\n\n\n\n\n\n\n\n\n\nОпределение 1.4 Параметр (statistical parameter) (\\(\\theta\\)) — относительно постоянная [от одной совокупности к другой] величина, характеризующая генеральную совокупность по некоторому показателю.\n\n\n\n\nМы не можем изучить всю генеральную совокупность — в ней слишком много объектов\nНаши измерения всегда содержат ошибку — мы даже длину линейкой точно не можем измерить, что уж о психологических измерениях говорить\n\n\n\nОпределение 1.5 Выборочная оценка (estimation) (\\(\\hat \\theta\\)) — эмпирический (измеримый) аналог параметра.\n\n\n\nВыше приводились примеры, где в качестве параметров и их оценок выступали средние. Чаще всего мы в психологии действительно работаем со средними [арифметическими], однако в других науных областях могут встречаться и более хитрые параметры и оценки.",
    "crumbs": [
      "Введение в статистику",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Основания статистики</span>"
    ]
  },
  {
    "objectID": "intro-intro.html#основная-задача-статистики",
    "href": "intro-intro.html#основная-задача-статистики",
    "title": "1  Основания статистики",
    "section": "1.2 Основная задача статистики",
    "text": "1.2 Основная задача статистики\nМы в какой-то малоприятной ситуации… Мы пытаемся измерить то, что в определенном смысле невозможно измерить, при этом достаточно точно, чтобы потом это можно было сравнивать или строить какие-то модели. Задача выглядит заведомо провальной…\nОднако именно в этот момент на помощь нам приходит статистика. Не в гордом одиночестве, конечно. Она приводит с собой теорию вероятности, теорию измерений, психометрику, теорию обнаружения сигнала и др. Всё это работает в нашей психологической науке в комплексе. Мы же в данном курсе сосредотачиваемся на статистической части этого салата.\nСтатистика даёт нам теоретический и математический инструментарий, чтобы мы могли делать какие-либо выводы о генеральной совокупности по собранным на выборке данным. К сожалению, как бы нам не хотелось, мы не можем делать выводы по сырым данным, потому что измерения по выборке не отражают вот прям ровно то, что есть в генеральной совокупности. Нам их надо определенным образом обсчитать, чтобы наши выводы были корректными. Этим и занимается статистика.\nЕсли мы попытаемся нарисовать какую-то концептуальную схему работы с выборкой в ходе исследования, то получится нечто такое (Рисунок 1.1).\n\n\n\n\n\n\nРисунок 1.1: Схема работы с выборкой в ходе исследования\n\n\n\nМы желаем изучить некую генеральную совокупность (population), которая недоступна нам в полном объёме. По этой причине мы извлекаем (sampling) из неё выборку (sample). На выборке мы собираем данные (data), по которым хотим делать вывод (inference) о генеральной совокупности. Как именно нам сделать такой вывод и рассказывает статистика.\nВероятно, сейчас это звучит достаточно абстрактно, но на данном этапе будет достаточно некоторого интуитивного понимания того, зачем нужна статистика. Далее интуиция обрастёт содержанием и уложится, хотелось бы надеяться, в достаточно стройную систему.\n\n\n\n\n\n\nИтог\n\n\n\nCтатистика помогает нам делать выводы об изучаемой генеральной совокупности по выборке.",
    "crumbs": [
      "Введение в статистику",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Основания статистики</span>"
    ]
  },
  {
    "objectID": "intro-intro.html#основная-характеристика-выборки",
    "href": "intro-intro.html#основная-характеристика-выборки",
    "title": "1  Основания статистики",
    "section": "1.3 Основная характеристика выборки",
    "text": "1.3 Основная характеристика выборки\nОкей, статистика даёт нам теоретический и математический аппарат, который позволяет делать выводы о генеральной совокупности по выборке. Однако если мы криво собрали данные, то никакая математика нас не спасет от некорректных выводов.\n\nОдин из принципов машинного обучения, актуальный и для нас, гласит: garbage in, garbage out, что значит «плохие данные на входе — бессмысленные результаты на выходе».\n\nТогда возникает вопрос: как собрать хорошие данные? Аспектов в этом вопросе много, и все они решаются при разработке дизайна исследования. Мы не будем здесь подробно разбирать, как корректно разрабатывать дизайн исследования, ибо это не является задачей курса статистики. Однако одни из ключевых элементов дизайна любого исследования — его выборка и способ её формирования.\nСреди характеристик выборки можно назвать много чего — например, объём и сбалансированность — но в целом все отдельные характеристики обобщаются в понятие репрезентативности.\nРепрезентативность выборки — это степень соответствия характеристик выборки характеристикам генеральной совокупности.\nНапример, мы хотим исследовать связь учебной мотивации и академической успеваемости бакалавров психологии. Если мы соберем данные только со своих однокурсников, будет нехорошо, так как в нашу выборку не попали (1) другие курсы психологического бакалавриата нашего вуза, (2) бакалавры-психологи других вузов Москвы и (3) бакалавры-психологи вузов других городов России.\nИ так работает всегда.\n\nНу, почти. Есть соблазн проводить исследования на студентах-психологах, потому что они достаточно близко и их можно загнать на эксперименты за баллы. Более-менее сносно это может работать на каких-то базовых когнитивных феноменах из восприятия и памяти. Обычно у нас нет оснований предполагать, что восприятие и память работают принципиально по-разному у людей разного возраста и разных социальных страт. Хотя, например, относительно памяти уже надо разбираться в том, что мы конкретно хотим про память изучать. Всё становится сложнее, если мы собираемся изучать что-то более высокоуровневое — например, мышление — или феномены личностной или социальной психологии.\n\nПочему выборка должна быть репрезентативной?\nПотому что если мы делаем нормально, то хотим обобщать результаты нашего исследования, полученные на выборке, на генеральную совокупность. Если выборка нерепрезентативна, то мы не можем этого сделать. Зачем в таком случае проводить исследование — решительно неясно.\nТогда возникает вопрос: как собрать репрезентативную выборку? Можно предложить следующий общий алгоритм.\n\nОсознать, кто наша генеральная совокупность.\n\nВ самом начале этой страницы приводились примеры разных генеральных совокупностей, и для каждой генеральной совокупности репрезентативная выборка будет своя.\n\nПонять, есть ли какая-то группировка, важная для нашего исследования, в нашей генеральной совокупности.\n\nСоциальная страта, специальность образования, сфера работы, пол или гендер, возрастные группы, регион проживания, семейное положение, что-либо ещё.\n\nРассчитать достаточный объём выборки\n\nэто не самая простая задача, и о ней мы будем говорить отдельно\nпока отметим в назывном порядке, что на объем выборки будут влиять дизайн исследования, изменчивость признака, уровень значимости и размер эффекта [что бы это ни значило]\n\nОбеспечить случайное попадание респондентов в выборку.\n\nНа последнем пункте стоит остановиться подробнее. Если у нас есть ресурсы набрать много людей в выборку — скажем, раза в 2–3 больше, чем достаточный объем выборки — то можно просто случайным образом откуда-то доставать людей, и всё будет хорошо. Некоторые статистические теоремы говорят, что такой вариант вполне пригоден для обеспечения репрезентативности выборки.\nЕсли мы всё же не можем набрать много людей, то надо набрать выборку достаточного объема и проверить репрезентативна ли она — отражает ли выборка те группировки изучаемых объектов, которые есть в генеральной совокупности.\nИдеальная выборка — это когда каждый человек имеет равную вероятность попасть в число респондентов (или испытуемых). Такая выборка называется вероятностной (probability sampling). Полностью случайный отбор трудно достижим — это очень дорого — но к нему нужно стремиться. Кроме того, сам метод сбора данных может деформировать выборку (например, онлайн-опросы отсекают пенсионеров), поэтому думать о сборе данных необходимо уже на этапе планирования исследования.",
    "crumbs": [
      "Введение в статистику",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Основания статистики</span>"
    ]
  },
  {
    "objectID": "intro-intro.html#способы-формирования-выборки",
    "href": "intro-intro.html#способы-формирования-выборки",
    "title": "1  Основания статистики",
    "section": "1.4 Способы формирования выборки",
    "text": "1.4 Способы формирования выборки\nСпособов формирования выборки существует много. Для каждого отдельного исследования существующие способы можно модифицировать, что даст нам ещё кучу новых способов. Однако в рамках курса мы рассмотрим три основные способа формирования вероятностной выборки.\n\n1.4.1 Простая случайная выборка\nВ случае простой случайной выборки (simple random sample) элементы генеральной совокупности случайным образом попадают в выборку. Представим, что на этой картинке изображена вся генеральная совокупность:\n\n\n\n\n\n\n\n\n\nЕсли мы наберем простую случайную выборку из этой генеральной совокупности, она будет выглядеть так:\n\n\n\n\n\n\n\n\n\nКак можно заметить, в выборку попали объекты из всех частей нашей генеральной совокупности — это говорит о том, что выборка репрезентативна.\nПростая случайная выборка, конечно, хороша своей простотой, однако у неё есть два существенных недостатка. Во-первых, действительно случайное попадание респондентов (или испытуемых) в выборку обеспечить практически невозможно — всегда будут ограничение на доступ к каким-либо частям генеральной совокупности. Во-вторых, простая случайная выборка будет репрезентативной только при большом объёме. Так, если мы посмотрим на простую случайную выборку малого объёма для той жё генеральной совокупности, что была выше, то получим следующее:\n\n\n\n\n\n\n\n\n\nНа рисунке видно, что многие части генеральной совокупности не представлены в выборке, что свидетельсвует о нерепрезентативности выборки.\n\n\n1.4.2 Стратифицированная выборка\nВ случае стратифицированной выборки (stratified sample) генеральная совокупность разбивается на несколько обособленных и различных по своей природе групп (страт). В каком смысле обособленных? В том, что каждый объект (респондент, испытуемый) может принадлежать только к одной страте. Например, возрастная группа (дети, подростки, молодежь, взрослые, пожилые), пол, среднемесячный доход семьи и др. Важно отметить, что страта — это характеристика изучаемых объектов, важная с точки зрения дизайна исследования. Ровно поэтому мы хотим учесть её при формировании выборки, обеспечив её репрезентативность по данной характеристике.\nПусть наша генеральная совокупность выглядит как-то так и состоит из четырёх страт:\n\n\n\n\n\n\n\n\n\nЕсли мы поделим это месиво точек по стратам, то получим следующее:\n\n\n\n\n\n\n\n\n\nТеперь из каждой страты случайным образом выберем несколько объектов, которые и попадут в выборку.\n\n\n\n\n\n\n\n\n\nОтносительно количества объектов, извлекаемых из каждой страты, существуют разные варианты. Дизайн исследования может предполагать, что количество респондентов из каждой страты должно быть одинаковым — тогда мы будем набирать равное количество респондентов из каждой страты. Или же нам может быть важно обеспечить в выборке такое же соотношение между стратами по количеству респондентов, какое существует в генеральной совокупности — тогда необходимо, зная общий объём выборки, рассчитать количества респондентов из каждой страты, зная пропорции в генеральной совокупности, например, из данных государственной статистики или других источников.\n\n\n1.4.3 Групповая выборка\nВ случае групповой выборки (cluster sample) мы разбиваем генеральную совокупность на несколько обособленных, но одинаковых групп (кластеров). Обособленный в том же смысле, что и в случае стратифицированной выборки — один респондент может принадлежать только к одной группе наблюдений. В каком смысле группы тогда должны быть одинаковыми? Они должны быть одинаковыми с точки зрения дизайна исследования. Пусть мы изучаем удовлетворенность городскими благами жителей некоторого города. Группой (cluster) в этом случае может выступить район города, в котором проживает респондент, если у нас нет оснований предполагать, что районы города различаются по характеристике «городские блага». Зачем нам такое разделение может пригодится? Возможно, у нас доступ к организациям городского района, которые могут помочь нам распространить опрос, что снизит затраты на проведение исследования.\nПусть мы разделили нашу генеральную совокупность на шесть кластеров:\n\n\n\n\n\n\n\n\n\nКластеры мы считаем примерно одинаковыми по характеристикам между собой — по крайне мере, мы так предполагаем с точки зрения дизайна исследования. Выберем случайно три кластера, которые примут участие в исследовании:\n\n\n\n\n\n\n\n\n\nТеперь из этих кластеров наберем выборку случайным образом:\n\n\n\n\n\n\n\n\n\nХотя такой подход к формированию выборки позволяет экономить драгоценные временные и денежные ресурсы, он имеет свои недостатки. В частности, мы должны быть уверенны, что выделенные нами группы действительно одинаковы с точки зрения исследования — это можно утверждать далеко не всегда.\n\nПока что остановимся на этом — для первого знакомства со статистикой будет достаточно. Мы еще не раз будем возвращаться к этим вопросам, и на других курсах вы тоже будете говорить о репрезентативности выборки.",
    "crumbs": [
      "Введение в статистику",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Основания статистики</span>"
    ]
  },
  {
    "objectID": "part-r.html",
    "href": "part-r.html",
    "title": "Анализ данных в R",
    "section": "",
    "text": "Вырубаем тэхно — врубаем дипхаус",
    "crumbs": [
      "Анализ данных в R"
    ]
  },
  {
    "objectID": "intro-randvals.html",
    "href": "intro-randvals.html",
    "title": "2  Шкалы и случайные величины",
    "section": "",
    "text": "2.1 Измерение в социальных науках\nВспомним, что\nТеперь бы понять, что такое измерение…\nИзмерение мы будем определять так:\nЕще раз:\nТакое определение нам позволяет измерить практически всё, что угодно:\nСейчас нас не интересует, как именно «внутри себя» происходит процесс измерения, какие предположения стоят за различными измерениями и как сделать измерение качественным. Об этом подробно рассказывается в курсах когнитивной и экспериментальной психологии, психодиагностики и психометрики и других. Отметим только, что, конечно же, нам как исследователям надо следить за тем, насколько адекватные измерения мы имеем, насколько приписанные значения отражают выраженность, например, психологических черт, или насколько измеряемые (зависимые) экспериментальные переменные адекватны исследовательским задачам.\nИтак, у нас есть интересующие нас признаки генеральной совокупности выборки, которые мы измерили, то есть приклеили на них некоторые значения из определенных шкал. Успех!\nНо тут, пожалуй, разумно задуматься про шкалы. Ведь очевидно, что возраст и пол будут измеряться по-разному, также как и нарциссизм и время реакции.",
    "crumbs": [
      "Введение в статистику",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Шкалы и случайные величины</span>"
    ]
  },
  {
    "objectID": "intro-randvals.html#признаки-и-переменные",
    "href": "intro-randvals.html#признаки-и-переменные",
    "title": "2  Шкалы и случайные величины",
    "section": "2.2 Признаки и переменные",
    "text": "2.2 Признаки и переменные\nМы уже упомянули выше, что мы можем измерять различные признаки. Попытаемся как-то эту кучу систематизировать. В терминах данных признаки — это переменные, поэтому далее мы будем чаще употребляться именно этот термин — переменная — имея в виду то, что мы намерили, изучая признак. Во многом признак и переменная — это синонимы, только первый термин больше из теории измерений, а второй — из статистики и анализа данных. Измерение же от отдельного человека (объекта выборки) называется наблюдение.\n\n\n\n\n\n\nТипы переменных\n\n\n\n\nКоличественные переменные — те, которые принимают числовые значения\n\nнепрерывные — принимают любые значения (рост, возраст, время реакции и др.)\nдискретные — могут принимать только определенные значения (количество детей в семье, число отчисленных студентов, количество стаканов кофе, выпитых в ночь перед экзаменом и др.)\n\n\nЧисло, приписываемое количественному признаку (переменной) ведёт себя как привычное нам математическое число в том смысле, что выражает некоторое количество — сантиметров, лет, секунд, детей, студентов, стаканов кофе…\n\nНоминальные (категориальные) переменные — используются для разделения наших наблюдений на группы (пол, национальность, курс обучения, используемая операционная система компьютера и др.).\n\nЗаписаны эти переменные обычно текстом (скажем, как в примерах выше, пол — male и female — или операционная система — Win, macOS, Linux).\nОднако, например, курс обучения можно записать по-разному: текстом — freshman, sophomore, junior, senior — или числом — 1, 2, 3, 4. Однако в данном случае числа не несут никакого математического смысла — это просто лейблы, с помощью которых мы различаем группы наблюдений. Ведь и пол мы можем записать с помощью чисел — пусть male = 0, female = 1. Ведь не будем же мы складывать-вычитать девушек и парней?\n\n\n\n\nВнимательный читатель мог заметить, что курс обучения — это не совсем категориальная переменная, ведь «второкурсник» в каком-то смысле «больше», чем «первокурсник». Но мы не можем сказать «на сколько» или «во сколько» больше! Что же делать?\n\n\n\n\n\n\nРанговые переменные\n\n\n\n\nНельзя сказать, что «второкурсник» выражает бо́льшую выраженность признака «год обучения», чем «первокурсник».\nВместе с тем «второкурсник» дольше учился и освоил больше дисциплин, чем «первокурсник». При этом «третьекурсник» учился дольше «второкурсника» — то есть существует порядок категорий.\nТакая переменная называется ранговой.\n\n\n\nДругой пример ранговой переменной — это студенческий рейтинг. Что делает рейтинг? Упорядочивает студентов. Можно ли сказать, что четвертый в рейтинге студент в два раза менее успешен, чем второй? Нет — тот же GPA может отличаться на десятые или сотые доли.\nИтого, классификацию переменных можно представить так (Рисунок 2.1):\n\n\n\n\n\n\nflowchart TD\n  vars(\"Переменные\")\n  quantitative(\"Количественные\")\n  discrete(\"Дискретные\")\n  continuous(\"Непрерывные\")\n  rank(\"Ранговые\")\n  nominal(\"Номинальные\")\n  \n  vars --&gt; quantitative\n  vars --&gt; rank\n  vars --&gt; nominal\n  quantitative --&gt; discrete\n  quantitative --&gt; continuous\n\n\n\n\nРисунок 2.1: Классификация переменных",
    "crumbs": [
      "Введение в статистику",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Шкалы и случайные величины</span>"
    ]
  },
  {
    "objectID": "intro-randvals.html#шкалы",
    "href": "intro-randvals.html#шкалы",
    "title": "2  Шкалы и случайные величины",
    "section": "2.3 Шкалы",
    "text": "2.3 Шкалы\n\n2.3.1 Зачем нам знать виды шкал?\nОт того, в какой шкале измерена переменная, которую мы исследуем, будет зависеть:\n\nкакие графики мы сможем нарисовать\nкакие статистики на ней имеют смысл\nкакие статистические модели дадут адекватный результат\n\nВ общем, почти весь анализ определяется1 тем, с какой шкалой мы работаем.\nЧто же такое шкала?\n\nОпределение 2.2 Шкала (scale) — это набор допустимых значений переменной с ограничениями на допустимые операции над этими значениями.\n\nВновь посмотрим на признаки, которые мы можем измерять. Пол имеет два допустимых значения — male и female — и мы можем лишь сравнить значения, проверив, совпадают они или нет. В то же время, рассматривая переменную «время», которая может принимать значения от \\(0\\) до \\(+\\infty\\), мы уверенно можем утверждать, что если одна пара длится 120 минут, то две будут длиться 240 минут — мы можем считать сумму значений по этой переменной.\nМожно ли как-то систематизировать все возможные варианты допустимых значений и операций?\n\n\n2.3.2 Типы и виды шкал\nВсего выделяют четыре вида шкал (Таблица 2.1).\n\n\n\nТаблица 2.1: Виды шкал изменения\n\n\n\n\n\n\n\n\n\n\n\n\n\nШкала\nТип шкалы\nТип данных\nДопустимые операции\nНоль\nДопустимые преобразования\n\n\n\n\nНоминальная (номинативная, nominal scale)\nНеметрическая\nКачественные Категориальные\n\\(=\\), \\(\\neq\\)\nОтсутствует\n—\n\n\nПорядковая (ранговая, ordinal scale)\nНеметрическая\nКачественные Категориальные (?) Ранговые\n\\(=\\), \\(\\neq\\), \\(&gt;\\), \\(&lt;\\)\nОтсутствует\nМонотонное преобразование\n\n\nИнтервальная (шкала разностей, interval scale)\nМетрическая\nКоличественные\n\\(=\\), \\(\\neq\\), \\(&gt;\\), \\(&lt;\\), \\(+\\), \\(-\\)\nОтносительный\nЛинейное преобразование\n\n\nАбсолютная (шкала отношений, ratio scale)\nМетрическая\nКоличественные\n\\(=\\), \\(\\neq\\), \\(&gt;\\), \\(&lt;\\), \\(+\\), \\(-\\), \\(\\times\\), \\(\\div\\)\nАбсолютный\nПреобразование подобия\n\n\n\n\n\n\nПройдёмся по колонкам этой таблицы.\n\nТип шкалы — метрическая или неметрическая — определяется тем, одинаково расстояние между делениями шкалы или же нет. Иначе, есть ли на шкале цена деления.\n\nТак, понятно, что на шкале времени реакции все секунды одинакового размера — метрическая шкала.\nА на шкале «используемая операционная система» вообще нет делений, не то что расстояний.\nОбратите внимание, что на ранговой шкале хотя и есть деления (например, шкала Ликерта), их размер неодинаковый: нельзя сказать2, что \\(6\\) на шкале Ликерта в два раза или на три больше, чем \\(3\\). Поэтому ранговая шкала — неметрическая.\n\nТип данных — количественные или категориальные — определяется тем, какие свойства чисел работают на этой шкале.\n\nЧтобы не утонуть в математической части этого всего, соотнесём это с колонкой допустимые операции.\n\nНа количественных шкалах допустимы операции сложения, вычитания, умножения и деления.\nНа категориальных шкалах шкалах допустимы только операции сравнения.\n\n\nНоль\n\nНа номинальной и порядковой шкалах нуля в математическом смысле нет вовсе.\n\nДля номинальной шкалы это очевидно, потому что там вообще нет «чисел» — там только лейблы.\nДля порядковой шкалы, в определенной мере, тоже, потому что \\(0\\) на ней будет обозначать только то, что ранг у этого наблюдения ниже, чем ранг у наблюдения с \\(1\\). Ничего другого этот ноль не обозначает.\n\nНа интервальной и абсолютной шкалах ноль есть.\n\nКлассический пример интервальной шкалы — это температура в градусах Цельсия. Ноль на этой шкале — температуре замерзания воды — выбран произвольно. Ну, потому что это было достаточно удобно. Больше этот ноль ничем не обоснован.\n\nПоскольку ноль относительный, на такой шкале могут быть отрицательные значения — с температурой по Цельсию нас это совершенно не удивляет.\n\nКлассический пример абсолютной шкалы — это температура по Кельвину. Известно, что на этой шкале не бывает отрицательных значений, так как минимум этой шкалы — это минимально возможная температура во Вселенной. Ниже не бывает. Поэтому это абсолютный ноль.\n\n\nДопустимые операции\n\nНаличие относительного нуля даёт возможность складывать и вычитать.\nНаличие абсолютного нуля даёт возможность складывать, вычитать, делить и умножать.\nНа номинальной и порядковой шкалах нуля нет, поэтому арифметические действия на них невозможны.\nНа номинальной шкале допустимо только сравнение на [не]равенство — мы можем только проверить, одинаковы ли наблюдения [по этой переменной] или не одинаковые.\nНа порядковой шкале, помимо сравнения на [не]равенство, допустимо также сравнение на больше-меньше, так как задан порядок.\n\nДопустимые преобразования\n\nОтсюда нам нужно попытаться понять, что такое монотонное преобразование. Это любое преобразование, сохраняющее порядок элементов.\n\nНапример, у нас есть шкала Ликерта от 1 до 5 — [1, 2, 3, 4, 5]. Шкала Ликерта — порядковая, поэтому мы можем утверждать, что 1 &lt; 2 &lt; 3 &lt; 4 &lt; 5.\nПусть мы психометрик и собираемся вычислять психометрические штуки на таких данных. Для удобства нам надо сделать так, чтобы шкала начиналась с нуля.\n\nКажется, надо просто вычесть единицу из всех наблюдений — но законно ли это? Не сломаются ли закономерности наших данных?\n\nДа, законно, потому что вычитание единицы — это монотонное преобразование. И хотя значения переменной изменятся — [0, 1, 2, 3, 4] — порядок значений сохранится — 0 &lt; 1 &lt; 2 &lt; 3 &lt; 4.\n\n\n\n\n\n\n\n\n\nО термине «качественные данные»\n\n\n\nПочему-то номинальную и ранговую шкалы в литературе часто называют «качественными». Видимо, потому что качественные данные обычно рассматриваются как оппозиция количественным.\nЭто в некоторой мере справедливо, поскольку есть два типа исследований — качественные и количественные. Они различаются методологией и используемыми методиками и, как следствие, собираемыми данными.\nВ рамках качественных исследований чаще всего собираются тексты, поэтому во многом качественные данные обычно текстовые. Количественные данные — это, как правило, таблицы с цифрами из любой из четырёх шкал. Безусловно, анализ качественных и количественных данных также существенно различается.\nИтого, кажется, что называть «качественными» номинальную и ранговые шкалы — странно, потому что качественные данные — это неструктурированный текст. Лучше их именовать категориальными. Правда, например, рейтинг студентов (ранговая шкала) тоже не совсем категориальные данные. Такая переменная, конечно, делит наших респондентов на категории (группы), однако между этими группами определён порядок — больше-меньше — поэтому такие переменные называются ранговыми.\n\n\n\n\n2.3.3 Порядок шкал по мощности\nЕсли взять за основу допустимые операции, можно упорядочить шкалы по мощности — более мощной является та шкала, на которой допустимо больше операций. Тогда шкалы можно упорядочить так:\n\\[\n\\text{номинальная} &lt; \\text{порядковая} &lt; \\text{интервальная} &lt; \\text{абсолютная}\n\\]\nНаименее мощная — номинальная, наиболее мощная — абсолютная. Что нам надо вынести из этой иерархии? То, что мы можем по ней двигаться только влево. Если переменная измерена в абсолютной шкале, то мы можем сделать её порядковой или номинальной. Если же переменная изначально номинальная, то перейти в порядковую или интервальную шкалу невозможно.\nНапример, вот такой нехитрый пример (Таблица 2.2):\n\n\n\nТаблица 2.2: Одна и та же переменная, измеренная в разных шкалах\n\n\n\n\n\nВозраст [абсолютная]\nВозраст [ранговая]\nВозраст [номинальная]\n\n\n\n\n86\nпенсионер\nсовершеннолетний\n\n\n43\nвзрослый\nсовершеннолетний\n\n\n38\nвзрослый\nсовершеннолетний\n\n\n22\nмолодой\nсовершеннолетний\n\n\n16\nподросток\nнесовершеннолетний\n\n\n10\nребёнок\nнесовершеннолетний\n\n\n8\nребёнок\nнесовершеннолетний\n\n\n\n\n\n\nВ психологии чаще всего мы сталкиваемся с порядковыми шкалами. Это просто факт. Надо его принять.",
    "crumbs": [
      "Введение в статистику",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Шкалы и случайные величины</span>"
    ]
  },
  {
    "objectID": "intro-randvals.html#случайные-величины",
    "href": "intro-randvals.html#случайные-величины",
    "title": "2  Шкалы и случайные величины",
    "section": "2.4 Случайные величины",
    "text": "2.4 Случайные величины\nЕщё раз:\n\nИзмерение — это приписывание признакам объектов изучаемой совокупности определенных значений на определенной шкале.\n\nСо шкалой разобрались. Теперь надо разобраться с приписыванием. Мы будем рассматривать этот вопрос только с точки зрения статистики — теорию измерений не трогаем.\n\n2.4.1 Случайный эксперимент\nОтвлечемся на любимый объект статистиков — игральный кубик.\n\n\n\n\n\nСкажем просто:\n\nБросание игрального кубика — это случайный эксперимент,\nВыпавшее число — это случайная величина.\n\nТеперь более строго.\n\nОпределение 2.3 Случайный эксперимент (random experiment) — это математическая модель некоторого реального эксперимента, результат которого невозможно точно предсказать.\n\nВ каком смысле то, что мы называем сейчас экспериментом, случайно? В том, что результат такого эксперимента точно неизвестен. В частности, заранее неизвестно, какой стороной упадёт кубик при отдельном броске.\n\nОпределение 2.4 Случайная величина (random variable) — это некоторая переменная, значения которой представляют собой численные исходы некоторого случайного эксперимента.\n\nИсход бросания кубика — выпавшее число.\nИз психологического поля можно привести следующие примеры:\n\nв опросных (психометрических) исследованиях:\n\nответ респондента на пункт опросника — это случайный эксперимент\nвыбранный им балл на шкале Ликерта — это случайная величина\nв чём случайность? — неизвестно, какой балл выберет респондент\n\nв поведенческих экспериментах:\n\nклик на стимул на экране в эксперименте зрительного поиска — это случайный эксперимент\nвремя реакции, которое фиксирует PsychoPy — случайная величина\nв чём случайность? — неизвестно, когда точно испытуемый кликнет по стимулу\n\nв нейроисследованиях:\n\nзапись ЭЭГ-активности в конкретный момент времени — случайный эксперимент\nамплитуда колебаний ЭЭГ — случайная величина\nв чём случайность? — неизвестно, что мы зафиксируем в конкретный момент (в частности, потому что существуют технические шумы)\n\nи т. д.\n\n\n\n\n\n\n\nСлучайный эксперимент vs эксперимент как метод исследования\n\n\n\nОбратим внимание на то, что случайный эксперимент — это не то же самое, что эксперимент как метод исследования, изучаемый в рамках курса экспериментальной психологии. Случайный эксперимент происходит в момент измерения какой-либо переменной в рамках эксперимента.\nПосмотрим на примеры, приведённые выше. У нас есть поведенческий эксперимент, в котором существуют независимы и зависимые переменные, определённое количество проб на конкретное сочетание экспериментальных условий и другие аспекты дизайна эксперимента. Однако в процессе сбора данных в рамках этого исследования происходит множество случайный экспериментов, когда испытуемые проходят эксперимент. В каждой пробе осуществляется измерение зависимых переменных, и каждое такое измерение является случайным экспериментом, так как ответ испытуемого (координаты клика или время нажатия на клавишу) нельзя однозначно предсказать.\n\n\nИтого, мы постоянно имеем дело со случайными экспериментами в рамках любых исследований, но также, что более важно, по результатам этих случайных экспериментов [в рамках нашего эксперимента или заполнения опросника] мы собираем значения случайных величин. Вся статистика работает со случайными величинами.\n\n\n2.4.2 Случайная величина\nПопробуем ещё такой заход. Вот мы тут говорим об измерениях признаков/переменных. Эти переменные и есть случайные величины, которые мы измеряем. Случайные — потому что мы никогда не знаем, что же мы получим в конкретном измерении.\nПочему не знаем?\nЕсли у нас «хардовое» измерение (типа ЭЭГ или PsychoPy) — всегда есть погрешность измерения и «шум» в данных. Мы не можем предусмотреть всё и сделать так, чтобы нашего испытуемого ничего не отвлекало, он занимался только экспериментальной задачей, не думал о коте, который остался дома, или испытывал блаженство от ЭЭГ-шной шапочки на себе.\nЕсли это опросник — всё, вроде бы, ещё понятнее. Что нам именно сейчас отметит именно этот респондент — известно только одному никому. В каком состоянии он пришёл, какие у него личностные черты и свойства, насколько он нам доверяет, насколько он готов отвечать честно и т. д.\nК вопросу, зачем нам статистика и анализ данных — чтобы отделить случайности от закономерностей, которые нас интересуют как исследователей, и получить ответы на исследовательские вопросы.\nСлучайные величины бывают дискретные и непрерывные:\n\nнепрерывные — принимают любые значения (рост, возраст, время реакции и др.)\nдискретные — могут принимать только определенные значения (пол, город проживания, балл по шкале Ликерта и др.)\n\n\n\n\n\n\n\nПеременные vs Шкалы vs Случайные величины\n\n\n\nМы обозначили три понятия — переменные, шкалы и случайные величины — которые выглядят очень похоже друг на друга. Тем не менее, они не являются синонимами. Давайте разберемся в различиях между ними. Для этого рассмотрим следующие примеры.\n\n\n\n\n\n\n\n\n\nПеременная\nТип переменной\nШкала\nСлучайная величина\n\n\n\n\nПол\nНоминальная\nНоминальная\nДискретная\n\n\nУровень образования\nНоминальная / Ранговая\nНоминальная / Порядковая\nДискретная\n\n\nБалл по шкале Ликерта\nРанговая\nПорядковая\nДискретная\n\n\nКоличество детей в семье\nКоличественная дискретная\nАбсолютная\nДискретная\n\n\nТемпература по Цельсию\nКоличественная непрерывная\nИнтервальная\nНепрерывная\n\n\nТемпература по Кельвину\nКоличественная непрерывная\nАбсолютная\nНепрерывная\n\n\nВремя реакции\nКоличественная непрерывная\nАбсолютная\nНепрерывная\n\n\n\nТаким образом, можно наблюдать, что хотя эти понятия в некоторой мере пересекаются, всё же существуют различия между этими тремя терминами.\n\n\nЗачем нам различать дискретные и непрерывные случайные величины? Это различение оказывается критически важно, когда мы пытаемся математически описать случайные величины. Оказывается, что они по-разному ведут себя в отношении вероятности.\n\n\n2.4.3 Вероятность\nМатематически строгое введение понятия вероятности требует отдельного курса теории вероятности, которого у нас нет. Мы ограничимся во многом интуитивным пониманием вероятности, которого, в целом, для наших задач будет достаточно.\nПод вероятностью (probability, \\(\\mathbb{P}\\)) мы будем понимать меру возможности наступления некоторого события. Событием будем считать наблюдение (измерение) определённого значения случайной величины. Рассмотрим всю эту ситуацию на примерах дискретных и случайных величин.\n\n\n2.4.4 Дискретные случайные величины\nС дискретными случайными величинами все достаточно просто:\n\nесть ограниченный набор значений, которые случайная величина может принимать,\nесть вероятности, с которыми случайная величина принимает эти значения.\n\nДавайте на игральном кубике. Есть кубик — у него шесть граней. Возможные значения случайной величины \\(X\\) — \\(\\{1,2,3,4,5,6\\}\\). Вероятность того, что кубик упадет хотя бы какой-то из шести сторон — \\(1\\). Если кубик «честный», то каждая из граней выпадает равновероятно, то есть вероятность, с которой наша случайная величина принимает каждое из своих значений будет равна\n\\[\n\\mathbb{P}(X=1) = \\mathbb{P}(X=2) = \\mathbb{P}(X=3) = \\mathbb{P}(X=4) = \\mathbb{P}(X=5) = \\mathbb{P}(X=6 ) = \\frac{1}{6} \\approx 0.167\n\\]\nНо это мы рассчитали теоретически. Давайте проверим, будет ли это работать эмпирически. Подбросим кубик (на симуляции) 100 раз и посмотрим, сколько раз выпало та или иная грань (Таблица 2.3).\n\n\n\nТаблица 2.3: Результаты симуляции 100 бросков игрального кубика\n\n\n\n\n\n\n\nЗначение\n1\n2\n3\n4\n5\n6\n\n\n\n\nЧастота\n19\n15\n18\n11\n16\n21\n\n\nВероятность\n0.19\n0.15\n0.18\n0.11\n0.16\n0.21\n\n\n\n\n\n\n\n\nВнимание, мы построили таблицу частот, она же частотная таблица. Это способ описания поведения дискретной случайной величины в эксперименте.\nМожем ли мы это каким-то образом визуализировать? Да.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 2.2: Визуализация частоты выпадения значений при 100 бросках игрального кубика\n\n\n\nВниманием — столбчатая диаграмма (barplot). Как видите, по оси \\(x\\) идут значения нашей случайной величины, по оси \\(y\\) — частота, с которой случайная величина принимает данной значение. Изи.\nНо погодите, кубик должен падать одинаково часто на каждую из граней, а на графике частоты разные. Да, это правда. Как мы уже не раз упоминали, в данных всегда есть шум и ни один эксперимент не может пройти идеально. В том числе и симуляция. Поэтому те отклонения, которые мы видим на графике, это всего лишь шум — то, что нам нерелевантно.\nЧтобы убедиться, что кубик все-таки честный, давайте подкинем его 1000 раз.\n\n\n\nТаблица 2.4: Результаты симуляции 1000 бросков игрального кубика\n\n\n\n\n\n\n\nЗначение\n1\n2\n3\n4\n5\n6\n\n\n\n\nЧастота\n170\n176\n171\n157\n162\n164\n\n\nВероятность\n0.17\n0.176\n0.171\n0.157\n0.162\n0.164\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 2.3: Визуализация частоты выпадения значений при 1000 бросках игрального кубика\n\n\n\nХм… Больше бросков!\n\n\n\nТаблица 2.5: Результаты симуляции 100 000 бросков игрального кубика\n\n\n\n\n\n\n\nЗначение\n1\n2\n3\n4\n5\n6\n\n\n\n\nЧастота\n16685\n16818\n16656\n16536\n16774\n16531\n\n\nВероятность\n0.167\n0.168\n0.167\n0.165\n0.168\n0.165\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 2.4: Визуализация частоты выпадения значений при 100 000 бросках игрального кубика\n\n\n\nНу, почти. Нивелировать шум полностью нам не удастся никогда, поэтому будем считать, что мы достаточно убеждены, что кубик честен.\nТо, что мы сейчас с вами строили — в таблице или на графике — называется распределением случайной величины (distribution of a random variable, probability distribution). Распределение — это некоторый закон, который полностью описывает поведение случайной величины.\nИтак, мы сейчас обсудили как строить эмпирическое распределение нашей дискретной переменной. А как нам построить теоретическое распределение нашей случайной величины? Для этого нам нужно взять две оси — \\(x\\) и \\(y\\). По оси абсцисс расположить значения нашей случайной величины, по оси ординат — вероятности, с которыми наша случайная величина принимает данные значения.\nВыглядит это так:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 2.5: Функция вероятности дискретного равномерного распределения\n\n\n\nТо, что изображено на рисунке, называется функцией вероятности (probability mass function, PMF) дискретного равномерного распределения.\nДля порядка также скажем, что дискретные случайные величины вовсе не обязательно распределены равномерно. Например, есть такое распределение:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 2.6: Функция вероятности биномиального распределения\n\n\n\nВообще распределений существует довольно много. Мы в рамках этого курса познакомимся далеко не со всеми — только с теми, которые нам пригодятся для решения наших задач.\n\n\n2.4.5 Непрерывные случайные величины\nОкей, с дискретными разобрались. С непрерывными же всё то же самое?\nНе совсем. Есть один ключевой момент, который всё портит.\nМы говорили, что дискретные случайные величины могут принимать только некоторые значения, например, целочисленные — \\(1, 2, 3, -5, 0\\)… Их можно посчитать и сопоставить им вероятности, с которыми случайная величина принимает эти значения.\nЧуть выше мы разобрались с дискретным равномерным распределением. Давайте попробуем применить аналогичные размышления для непрерывного равномерного распределения.\nПусть мы случайным образом выбираем 1000 чисел из отрезка \\([0,1]\\), считая что все числа могут попасться равновероятно. Займемся симуляцией и попробуем отобразить частоты, с которыми выпадают числа:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 2.7: Визуализация частоты случайного выбора 100 чисел из отрезка \\([0, 1]\\)\n\n\n\nХм… Обратим внимание на некоторую интересность: частота каждого значения — единица, то есть каждое значение выпало только один раз. Но может это артефакт малого количества случайных экспериментов по выбору чисел? Давайте извлечём 1000.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 2.8: Визуализация частоты случайного выбора 1000 чисел из отрезка \\([0, 1]\\)\n\n\n\nХм… Ну, может 10 000 исправят ситуацию?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 2.9: Визуализация частоты случайного выбора 10 000 чисел из отрезка \\([0, 1]\\)\n\n\n\nОкак… Всё ещё наблюдаем, что каждое число встретилось в выборке всего один раз. Тогда таблица частот оказывается бессмысленной. Как же нам тогда описать распределение непрерывной случайной величины?\nТак, попробуем другой заход. Когда мы считали вероятность того, что на кубике выпадет определенное число, мы взяли все возможные исходы и поделили единицу на их количество — получили вероятность. Раз мы и сейчас предполагаем равную вероятность выпадения каждого из чисел, то попробуем сделаль тут так же.\n\n— Сколько всего чисел на отрезке \\([0, 1]\\)? — Бесконечность.\n\nЭто что же, получается,\n\\[\n\\mathbb{P}(X = a) \\overset{?}{=} \\frac{1}{\\infty}\n\\]\nтак что ли? Но это же какой-то сюр! Не совсем.\nНе вдаваясь в математические детали, перепишем выражение выше в более математически приличном виде:\n\\[\n\\mathbb{P}(X = a) = \\lim_{n \\to \\infty} \\frac{1}{n} = 0\n\\]\nЭта запись означает следующее:\n\n\n\n\n\n\nКлючевое свойство непрерывных случайных величин\n\n\n\nВероятность того, что непрерывная случайная величина принимает конкретное значение, равна нулю.\n\n\nНо как это? Ведь числа-то выпадают! Вероятность не может быть равна нулю!\nЭто справедливо, но чтобы ответить на все вопросы предельно точно, нам придется умереть в математических океанах. Воспользуемся эвристикой. Будем понимать под «вероятность того, что непрерывная случайная величина принимает конкретное значение, равна нулю» следующее:\n\nМы не можем ожидать, что беря числа из отрезка \\([0, 1]\\) мы попадём в какое-то конкретное число, например, \\(0.5\\).\nДаже если попадём во что-то очень похожее, это будет \\(0.50003\\) или \\(0.4999999999\\).\nРовно \\(0.5\\) никогда не выпадет. В этом смысле вероятность, действительно равна нулю.\n\nВот такое странное поведение у этих непрерывных величин. И тем не менее, хочется все-таки как-то с ними работать, описывать их поведение.\n\n— Зачем? Если они такие странные, а самая используемая в психологии шкала — порядковая, то мож не будет возиться с этой ерундой?  — Весь замес в том, что тестирование статистических гипотез, которое есть сердце анализа данных, полностью основано на работе с непрерывными случайными величинами. Всё-таки придётся разбираться.\n\nДа, мы не можем работать с конкретными значениями непрерывных случайных величин — но мы можем работать с интервалами на множестве значений. Так, если нам надо визуализировать распределение непрерывной случайной величины, мы уже не можем использовать barplot — будет результат подобный рисунку 2.9. Вместо этого будем использовать гистограмму (histogram):\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 2.10: Визуализации распределения чисел, сгенерированных из непрерывного равномерного распределения на отрезке \\([0,1]\\).\n\n\n\nХм… В общем, мы получили нечто похожее на Рисунок 2.4. Похоже мы движемся в правильном направлении.\n\n\n\n\n\n\nВ чем отличие гистограммы от столбиковой диаграммы?\n\n\n\n\nНа столбиковой диаграмме по оси \\(x\\) располагается дискретная переменная — каждый столбик соотносится с конкретным значением изучаемой переменной.\nНа гистограмме же ось \\(x\\) поделена на определенное количество отрезков (на рисунке их 30).\n\nВ границы каждого отрезка попадает сколько-то сгенерированных нами чисел — высота столбика отражает количество чисел, попавших в этот отрезок.\nПри этом, в отличие от барплота, количество столбиков не является строго фиксированным (см. 2.11).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 2.11: Визуализации распределения чисел, сгенерированных из непрерывного равномерного распределения на отрезке \\([0,1]\\) (разбиение на 20 столцов).\n\n\n\n\n\nГистограмма обычно используется для отображения эмпирического распределения непрерывной случайной величины. А как же быть с теоретическим?\nВновь мы не можем взять то, что было у дискретных величин — изобразить график функции вероятности невозможно, поскольку это будет прямая, совпадающая с осью \\(x\\). Возникает необходимость ввести какую-то иную характеристику, связанную с вероятностью, которую можно будет использоваться для описания поведения непрерывных случайных величин.\nВспомним, как выглядел график для дискретного равномерного распределения — вот так 2.5. Наверное, по аналогии нам бы хотелось, чтобы для рассматриваемого нами непрерывного равномерного распределения график выглядел как-то так (Рисунок 2.12):\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 2.12: Схема графика непрерывного равномерного распределения на \\([0, 1]\\)\n\n\n\nВизуально действительно выглядит так, что все числа из отрезка \\([0, 1]\\) выпадают равновероятно. Однако нечто, отображённое на оси \\(y\\) не может быть вероятностью, так как для все значений непрерывной случайной величины вероятность равна нулю.\nЕсли же мы сравним рисунки 2.12 и 2.10, то мы можем заметить, что 2.12 — это некий идеал для 2.10. Действительно, если увеличить количество сгенерированных чисел, то гистограмма будет практически идеально ровной.\nГистограмма нам показывает, сколько сгенерированных чисел лежит в определенном диапазоне отрезка, а поскольку мы сказали, что все числа выпадают равновероятно, то и в каждом выделенном диапазоне (столбике гистограммы) должно лежать одинаковое количество чисел. Иначе говоря, числе одинаково плотно распределены на всём отрезке.\n\n\n2.4.6 Плотность вероятности\nИдея плотности была взята на вооружение математиками, и они, сильно не заморачиваясь относительно названия, ввели понятие плотности вероятности. Мы не будем давать ей строгого математического определения, ибо оно довольно зубодробительно. Мы порисуем картинки.\nСобственно, для непрерывного равномерного распределния график плотности вероятности будет выглядеть именно так, как мы нарисовали — разве что надо ось \\(y\\) подписать и значение поставить.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 2.13: График функции плотности вероятности непрерывного равномерного распределения на \\([0, 1]\\)\n\n\n\nПолученный график называется графиком плотности вероятности (probability density function, PDF). Нам надо уметь его читать.\nПо оси \\(x\\) здесь значения нашей случайной величины (как и в случае PMF), а вот по оси \\(y\\) — эта самая загадочная плотность вероятности. А где же сама вероятность? Раз мы решили работать с интервалами значений, то нас будет интересовать вероятность попадания значений случайной величины в определенный интервал.\n\n\n\n\n\n\nВероятность для непрерывных случайных величин\n\n\n\nВероятность того, что значение непрерывной случайной величины попадёт в заданный интервал определяется как площадь под графиком функции плотности вероятности на этом интервале.\n\n\nПосмотрим на примере равномерного распределения. Какова вероятность, что случайно выбранное из отрезка \\([0,1]\\) число попадёт в интервал \\((0.25, 0.75)\\)? Интуитивно кажется, что должно быть \\(0.5\\), так как длина этого интервала — полочина длины отрезка. Нарисуем.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 2.14: Вероятность попадания случайного числа из непрерывного равномерного распределения на \\([0,1]\\) в интервал \\((0.25, 0.75)\\)\n\n\n\nВоистину площадь полученного прямоугольника равна \\(0.5\\). Значит, схема работает.\nРаботать с равномерным распределением довольно скучно. Посмотрим на другой пример, с которым позднее мы будем знакомиться гораздо подробнее. Пусть у нас есть такое распределения, что его функция плотности выглядит так:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 2.15: Функция плотности вероятности стандартного нормального распределения\n\n\n\nЧисто визуально кажется, что значения из «середины» распределения — скажем, от \\(-2\\) до \\(2\\) — будут встречаться с большей вероятностью, чем значения из крайних частей распределения. И действительно, если мы выберем интервал некоторой ширины, то сможем убедиться в этом.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 2.16: Функция плотности вероятности стандартного нормального распределения\n\n\n\nВ данном случае был взят интервал шириной \\(1\\). Вероятность попадания значений случайной величины в диапазон \\((-0.5, 0.5)\\) относительно велика — \\(0.38\\), а для диапазона \\((2, 3)\\) — всего \\(0.02\\). Ровно это и отображает график плотности вероятности — значения в «середине» лежат плотнее, чем по краям.\nТак работают плотность вероятности, случайные величины и шкалы. К случайным величинам мы будем возвращаться далее постоянно — пока же знакомства достаточно.",
    "crumbs": [
      "Введение в статистику",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Шкалы и случайные величины</span>"
    ]
  },
  {
    "objectID": "intro-randvals.html#измерение-в-социальных-науках",
    "href": "intro-randvals.html#измерение-в-социальных-науках",
    "title": "2  Шкалы и случайные величины",
    "section": "",
    "text": "Определение 2.1 Измерение (measurement) — это приписывание признакам объектов изучаемой совокупности определенных значений на определенной шкале.\n\n\n\nесть совокупность объектов, которые мы изучаем — выборка,\nв ней есть какие-то объекты,\nу объектов есть признаки,\nесли мы приписали признаку какое-то значение на некоторой шкале, значит мы измерили данный признак.\n\n\n\nрост\nвозраст\nпол (шкала из двух значений male и female)\nнациональность\nколичество детей в семье\nрейтинг студентов\nкурс обучения или уровень образования\nгеографические координаты (долгота и широта)\nтемпература\nдата\nIQ\nнарциссизм / макиавеллизм / психопатия\nвремя реакции\nточность ответов испытуемого в эксперименте\nи т. д.",
    "crumbs": [
      "Введение в статистику",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Шкалы и случайные величины</span>"
    ]
  },
  {
    "objectID": "desc-centraltend.html",
    "href": "desc-centraltend.html",
    "title": "3  Меры центральной тенденции",
    "section": "",
    "text": "3.1 Виды статистики\nМы знаем, что наши переменные-признаки могут быть некоторым образом распределены — как в генеральной совокупности, так и в выборке. Как именно они распределены, описывается распределением случайной величины.\nВот мы собрали некоторые данные и получили какое-то эмпирическое распределение наших переменных. Нам бы, конечно, хотелось понять, что там такое за распределение. И первым шагом к пониманию этого будет описание распределения.\nВообще статистика [как набор методов и инструментов] делится на два вида:\nМы начнем знакомиться со статистикой с описательной статистики, а именно с мер центральной тенденции.",
    "crumbs": [
      "Описательная статистика",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Меры центральной тенденции</span>"
    ]
  },
  {
    "objectID": "r-vis.html",
    "href": "r-vis.html",
    "title": "22  Визуализация данных",
    "section": "",
    "text": "22.1 Что есть ggplot2?\nggplot2 — это внешний пакет языка R, который позволяет строить красивые и сложные визуализации. Как и любой R-пакет, это набор функций, которые позволяют делать те или иные преобразования с графиками. Пакет ggplot2 является частью семейства пакетов tidyverse.\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors",
    "crumbs": [
      "Анализ данных в R",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Визуализация данных</span>"
    ]
  },
  {
    "objectID": "r-vis.html#грузим-данные",
    "href": "r-vis.html#грузим-данные",
    "title": "22  Визуализация данных",
    "section": "22.2 Грузим данные",
    "text": "22.2 Грузим данные\nДатасет номер раз:\n\ndirtDoz &lt;- read_csv(\"https://raw.githubusercontent.com/angelgardt/psy-hse-ggplot2/master/dirtyDozen.csv\")\n\nRows: 22 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): gender\ndbl (5): age, class, mac, nar, psy\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nДатасет номер два:\n\nshare &lt;- read_delim(\"https://raw.githubusercontent.com/angelgardt/psy-hse-ggplot2/master/share.csv\",\n                    delim = \" \", locale = locale(decimal_mark = \",\"))\n\nRows: 16200 Columns: 8\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \" \"\nchr (2): trialtype, platform\ndbl (4): setsize, time1, time2, id\nlgl (2): correct1, correct2\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.",
    "crumbs": [
      "Анализ данных в R",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Визуализация данных</span>"
    ]
  },
  {
    "objectID": "r-vis.html#философия-a-layered-grammar-of-graphics",
    "href": "r-vis.html#философия-a-layered-grammar-of-graphics",
    "title": "22  Визуализация данных",
    "section": "22.3 Философия A Layered Grammar of Graphics",
    "text": "22.3 Философия A Layered Grammar of Graphics\nИдея, воплощенная в ggplot2, восходит к работе L. Wilkinson «The Grammar of Graphics». Базируясь на идеях, изложенных в этой работе, Hadley Wickham разработал концепцию Layered Grammar of Graphics и создал мощный пакет для визуализации, ради которого мы все здесь собрались. Автором по этому пакету написана целая книга, но мы сосредоточимся на основных смысловых и ключевых моментах, которые необходимы, чтобы сделать что-то крутое.\n\nЧасто возникает вопрос: почему 2? Ответ примерно такой: был и первый ggplot, но попытка не задалась от слова совсем, и пришлось все переделать.",
    "crumbs": [
      "Анализ данных в R",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Визуализация данных</span>"
    ]
  },
  {
    "objectID": "r-vis.html#собственно-к-философии-построения-графиков",
    "href": "r-vis.html#собственно-к-философии-построения-графиков",
    "title": "22  Визуализация данных",
    "section": "22.4 Собственно к философии построения графиков",
    "text": "22.4 Собственно к философии построения графиков\nПо своей сути график представляет собой сложную аппликацию из нескольких слоев. На каждом слое располагаются сходные по содержанию элементы. Начиная с самого первого — базового — и постепенно добавляя слой за слоем необходимые элементы, можно создавать сложные визуализации для отображения инетерсных закономерностей в данных.\nПосле создания базового графика осуществляется настройка отдельных элементов по необходимости и в зависимости от требований издательства / преподавателя / научника / комиссии и т.д. И поскольку все элементы в определенной степени изолированы друг от друга, это открывает большие возможности кастомизации. Кроме того, чтобы оформить график в соответствии с конкретными требованиями, нет необходимости перерисовывать его целиком, так как содержательная часть графика независима от настроек внешнего облика. Все, что вам нужно — это добавить/удалить пару строк кода.\nНо — хватит слов! Поехали уже рисовать уже!",
    "crumbs": [
      "Анализ данных в R",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Визуализация данных</span>"
    ]
  },
  {
    "objectID": "r-vis.html#данные",
    "href": "r-vis.html#данные",
    "title": "22  Визуализация данных",
    "section": "22.5 Данные",
    "text": "22.5 Данные\nСегодня у нас есть двое данных. Первые — поведенческие. Это share. Это данные эксперимента, в котором пользователи Android и iOS искали иконки «share» обеих платформ среди универсальных иконок. Короче, зрительный поиск.\nПеременные в датасете следующие:\ntrialtype — тип пробы (tray/dots/both) setsize — количество стимулов в пробе (8/12/16) time1 — время первого клика time2 — время второго клика id — индентификатор испытуемого platform — платформа смартфона (Android/iOS) correct1 — был ли корректным первый клик (найден ли первый целевой стимул) correct2 — был ли корректным второй клик (найден ли второй целевой стимул) Вторые — опросниковые. Это dirtDoz. Это данные прохождения опросника «Темная дюжина» старшеклассниками российских школ.\nПеременные таковы:\nage — возраст респондента gender — гендерная принадлежность респондента (male/female/other) class — класс, в котором обучается респондент mac — балл по шкале макиавеллизма nar — балл по шкале нарциссизма psy — балл по шкале психопатии Ну, вот с данными мы познакомились — теперь можно расчехлять кисти!",
    "crumbs": [
      "Анализ данных в R",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Визуализация данных</span>"
    ]
  },
  {
    "objectID": "r-vis.html#базовая-визуализация",
    "href": "r-vis.html#базовая-визуализация",
    "title": "22  Визуализация данных",
    "section": "22.6 Базовая визуализация",
    "text": "22.6 Базовая визуализация\n\n22.6.1 Базовый слой\nКогда мы собираемся рисовать, мы берем холст. Когда мы начинаем рисовать график в ggplot2, первое, что нам надо ему сказать — «Дай мне холст!». На языке ggplot2 это делается с помощью команды ggplot():\n\nggplot()\n\n\n\n\n\n\n\n\nПолучите — распишитесь. ggplot2 дал нам холст. Иначе говоря, мы построили базовый слой, на котором далее будем располагать элементы нашего графика.\nСледующее, что нам нужно сделать, это указать данные, по которым мы будем строить нашу визуализацию. Это делается с помошью аргумента data:\n\nggplot(data = dirtDoz)\n\n\n\n\n\n\n\n\nВроде бы ничего не изменилось, да и собственно, не должно было, ведь мы никак не указали, что мы хотим отобразить. Давайте укажем.\n\n\n22.6.2 Разметка осей\nВажнейшие элементы любого графика — это оси. Мы строим двумерные графики, поэтому и оси у нас две — как учили в школе, x (горизонтальная ось, ось абсцисс) и y (вертикальная ось, ось ординат).\nЧтобы задать оси графика потребуется отдельная функция. Она называется aes(), и в общем задает эстетики графика.\n\n\n22.6.3 Эстетики (aesthetics)\nИтак, конкретнее об эстетиках. Иначе говоря, это то форматирование, которое связано с данными. Или еще один способ понимания: эстетики — это способы отображения переменных из датасета. У функции aes() есть ряд параметров, они тоже называются эстетики.\nВот список эстетик, которые используются чаще всего: x, y, color, fill, shape, size.\nНесложно догадаться, что переменные по осям задаются параметрами x и y. Что ж, зададим.\nДавайте визуализируем связь между нарциссизмом и макиавеллизмом (ернее, между баллами по этим шкалам):\n\nggplot(data = dirtDoz,\n       aes(nar, mac))\n\n\n\n\n\n\n\n\nТак, ну, допустим… А где картинка?\nКартинки нет, но ggplot2 честно отработал свою работу. Мы задали только оси — и он нам разметил их в соответствии с имеющимися в векторах значениях. Больше мы ему ничего не написали. Чтобы всё-таки получить картинку, необходимо указать, как мы хотим отобразим наши переменные.\n\n\n22.6.4 Геомы\nЗа то, каким образом будут отображены переменными, а конкретно, какими «геометрическими объектами», отвечает семейство функций geom_*. Когда мы переходим к этой функции, мы переходим на новый слой. Чтобы это обозначить используется плюсик +:\n\nggplot(data = dirtDoz,\n       aes(nar, mac)) +\n  geom_point()\n\n\n\n\n\n\n\n\nМы выбрали точки для отображения переменных, потому что это наиболее наглядный вариант отобразить зависимость между двумя переменными. Такой тип графика называется scatterplot, или диаграмма рассеяния.\nНо, вообще-то, можно и получше отобразить закономерность. Как минимум, добавить линию тренда с помощью специального геома:\n\nggplot(data = dirtDoz,\n       aes(nar, mac)) +\n  geom_point() +\n  geom_smooth()\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nКак видите, при добавлении нового «геометрического» способа отображения данных мы добавляем новый слой.\nСейчас мы гораздо отчетливее видим, что есть некоторый тренд — с ростом баллов по одной из шкал растут баллы и по другой. Но мы можем визуализировать закономерность ещё более явно. Так как geom_smooth() подразумевает «сглаживание», оно может происходить с помощью разных методов (используемый метод нам написали в консоль). Мы можем эскплицинто указать, какой метод хотим использовать. Например, линейную регрессию:\n\nggplot(data = dirtDoz,\n       aes(nar, mac)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nВот вам, пожалуйста, красивый линейный тренд.",
    "crumbs": [
      "Анализ данных в R",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Визуализация данных</span>"
    ]
  },
  {
    "objectID": "r-vis.html#больше-информации-на-график",
    "href": "r-vis.html#больше-информации-на-график",
    "title": "22  Визуализация данных",
    "section": "22.7 Больше информации на график",
    "text": "22.7 Больше информации на график\nКак мы помним из структуры данных (и теории), в Тёмную Триаду входят три1 черты. Мы пока отобразили зависимость между двумя. Хотелось бы добавить третью и при этом не выйти в 3D — всё-таки мы собираемся это печатать в статье.\n\n22.7.1 Цвет\nЦвет — удивительная шкала. Она может быть дискретной и непрерывной, порядковой и категориальной. То есть, мы можем сделать вот так:\n\nggplot(data = dirtDoz,\n       aes(nar, mac, color = psy)) +\n  geom_point()\n\n\n\n\n\n\n\n\nМы задачи отображение количественной переменной с помошью цвета и эффектно отобразили связь между тремя количественными переменными на двумерном графике. Ну и кто тебе скажет, что мы не боги визуализации?\n\n\n22.7.2 Фасетирование\nМы уже отобразили приличное количество информации, но недостаточное. Давайте ещё нашу выборку по гендеру разобьем — будет весело! Чтобы на одном субграфике были мальчики, а на другом девочки. Для этого есть семейство функций facet_*():\n\nggplot(data = dirtDoz,\n       aes(nar, mac, color = psy)) +\n  geom_point() +\n  facet_wrap(~ gender)\n\n\n\n\n\n\n\n\nЯ обещал, что будет весело. Давайте исключим из анализа единственную небинарную персону — заодно посмотрим, как филигранно tidyverse сплетается с ggplot2:\n\ndirtDoz %&gt;% \n  filter(gender != \"other\") %&gt;% \n  ggplot(aes(nar, mac, color = psy)) +\n  geom_point() +\n  facet_wrap(~ gender)\n\n\n\n\n\n\n\n\nНу, что-то такое. Вот теперь это окончательный вариант базовой визуализации. Ура!",
    "crumbs": [
      "Анализ данных в R",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Визуализация данных</span>"
    ]
  },
  {
    "objectID": "r-vis.html#настройка-графика",
    "href": "r-vis.html#настройка-графика",
    "title": "22  Визуализация данных",
    "section": "22.8 Настройка графика",
    "text": "22.8 Настройка графика\nНо рано радоваться — время кодить, солнце ещё не взошло!\nСодержание на график мы вывели, однако в таком виде публиковать его категорически нельзя. Необходимо поработать над деталями.\n\n22.8.1 Эстетики, но под другим углом\nОцените размер точек — кажется маловаты, да? Надо нарисовать их побольше. Для этого есть параметр size:\n\ndirtDoz %&gt;% \n  filter(gender != \"other\") %&gt;% \n  ggplot(aes(nar, mac, color = psy)) +\n  geom_point(size = 2) +\n  facet_wrap(~ gender)\n\n\n\n\n\n\n\n\nВот, так стало значительно приятнее и проще смотреть. Обратите внимание, что в этом случае мы задавали значение аргумента size вне функции aes(), так как он не связан с самими данными — значение 2 мы берем извне, задаем произвольно.\n\n\n22.8.2 Подписи осей\nПоддерживаете вы отечественного производителя или стремитесь опубликоваться в журнале «Природа» — переменные на графике должны быть подписаны нормально2. То есть из подписи оси (эстетики) должно быть понятно, какой показатель отображён на графике. Что ж, подпишем.\nДля этого есть функция labs(), которая позволяет подписать [почти] всё и сразу. И это будет новый слой:\n\ndirtDoz %&gt;% \n  filter(gender != \"other\") %&gt;% \n  ggplot(aes(nar, mac, color = psy)) +\n  geom_point(size = 2) +\n  facet_wrap(~ gender) +\n  labs(x = \"Нарциссизм\",\n       y = \"Макиавеллизм\",\n       color = \"Психопатия\",\n       title = \"Связь черт Тёмной Триады у старших школьников\")\n\n\n\n\n\n\n\n\nНу, уже как будто прилично.\n\n\n22.8.3 Тема\nНо серый дефолтный фон до добра ещё никого не доводил. Когда-то стандартная тема ggplot2 была очень популярна, так как позволяла заявить, что ты «могёшь в R» и «как мощны твои количественные методы», но нынче публика уже значительно искушенная в этом вопросе. Да и на самом деле, серый фон снижает контрастность, в результате чего восприятие визуализации затрудняется. Проведем этот день под лозунгом: «Даёшь контрастность каждой визуализации!»\nНам всего лишь надо сменить тему. Я люблю чёрно-белую, другие предпочитают минималистичную. Выбор за вами, но я сделаю вот так:\n\ndirtDoz %&gt;% \n  filter(gender != \"other\") %&gt;% \n  ggplot(aes(nar, mac, color = psy)) +\n  geom_point(size = 2) +\n  facet_wrap(~ gender) +\n  labs(x = \"Нарциссизм\",\n       y = \"Макиавеллизм\",\n       color = \"Психопатия\",\n       title = \"Связь черт Тёмной Триады у старших школьников\") +\n  theme_bw()\n\n\n\n\n\n\n\n\nКрасuво!\n\n\n22.8.4 Подписи фасетов\nО нет! Мы же забыли исправить названия субграфиков — они там всё ещё на латинице висят. Секундочку, щас всё будет!\nДля этого нам надо завести именованный вектор: имена — это исходные названия уровней категориальной переменной, а сами элементы вектора — это лейблы, которые должны отображаться на графике. В нашем случае вот так:\n\nla &lt;- c(male = \"Мальчики\",\n        female = \"Девочки\")\n\nТеперь мы можем сделать вот что:\n\ndirtDoz %&gt;% \n  filter(gender != \"other\") %&gt;% \n  ggplot(aes(nar, mac, color = psy)) +\n  geom_point(size = 2) +\n  facet_wrap(~ gender,\n             labeller = labeller(gender = la)) +\n  labs(x = \"Нарциссизм\",\n       y = \"Макиавеллизм\",\n       color = \"Психопатия\",\n       title = \"Связь черт Тёмной Триады у старших школьников\") +\n  theme_bw()\n\n\n\n\n\n\n\n\nФух, слава Богу… Поправили.\n\n\n22.8.5 Оптимизация\nКажется, что легеда, располагающаяся справа — это невыгодно. Почему? Нам мы хотелось показать взаимоотношения между переменными, растянув точки порише. Мы могли бы переместить легенду вниз, освободив пространство справа. Давайте так и сделаем. Для этого нам надо подправить некоторые элементы темы:\n\ndirtDoz %&gt;% \n  filter(gender != \"other\") %&gt;% \n  ggplot(aes(nar, mac, color = psy)) +\n  geom_point(size = 2) +\n  facet_wrap(~ gender,\n             labeller = labeller(gender = la)) +\n  labs(x = \"Нарциссизм\",\n       y = \"Макиавеллизм\",\n       color = \"Психопатия\",\n       title = \"Связь черт Тёмной Триады у старших школьников\") +\n  theme_bw() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\nТеперь и общая композиция симметричнее стала. Но вот маленькая напасть: подпись «Психопатия» теперь как будто проситься, чтобы её подтянули повыше — выповняли по центру с цветовой шкалой. Штош, это потребует чуть большего количества пальцедвижений, но её прошение мы удовлетворим.\nПод капотом ggplot2 развернута сложная система ООП, в которую мы вникать не будем, иначе нам никакого кофе не хватит. Но сейчас мы подойдём к ней максимально близко.\nПодпись «Психопатия» — это, во-первых, текстовый элемент, а во-вторых, заголовок легенды. Теперь внимательно следите за руками и названиями аргументов и функций:\n\ndirtDoz %&gt;% \n  filter(gender != \"other\") %&gt;% \n  ggplot(aes(nar, mac, color = psy)) +\n  geom_point(size = 2) +\n  facet_wrap(~ gender,\n             labeller = labeller(gender = la)) +\n  labs(x = \"Нарциссизм\",\n       y = \"Макиавеллизм\",\n       color = \"Психопатия\",\n       title = \"Связь черт Тёмной Триады у старших школьников\") +\n  theme_bw() +\n  theme(legend.position = \"bottom\",\n        legend.title = element_text(vjust = .9))\n\n\n\n\n\n\n\n\nМы взяли аргумент legend.title, который управляет заголовком легенды, а так как заголовок — это текстовый элемент, то аргумент ждёт результата работы функции element_text(). Из все возможных опций управления текстом нас сейччас интересует выравнивание по вертикали (vertical justification) (vjust). Число подбираем визуально.\nЭто было непросто, но мы справились. Давайте ещё заголовок графика до кучи по центру поставим — и отправляем в журнал:\n\ndirtDoz %&gt;% \n  filter(gender != \"other\") %&gt;% \n  ggplot(aes(nar, mac, color = psy)) +\n  geom_point(size = 2) +\n  facet_wrap(~ gender,\n             labeller = labeller(gender = la)) +\n  labs(x = \"Нарциссизм\",\n       y = \"Макиавеллизм\",\n       color = \"Психопатия\",\n       title = \"Связь черт Тёмной Триады у старших школьников\") +\n  theme_bw() +\n  theme(legend.position = \"bottom\",\n        legend.title = element_text(vjust = .9),\n        plot.title = element_text(hjust = .5))",
    "crumbs": [
      "Анализ данных в R",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Визуализация данных</span>"
    ]
  },
  {
    "objectID": "r-vis.html#встроенная-статистическая-обработка",
    "href": "r-vis.html#встроенная-статистическая-обработка",
    "title": "22  Визуализация данных",
    "section": "22.9 Встроенная статистическая обработка",
    "text": "22.9 Встроенная статистическая обработка\nХорошо. На простеньком мы размялись — теперь надо сделать что-то посерьёзнее.\nЧасто бывает так, что мы хотим отобразить на графике не сырые данные, а какие-либо посчитанные статистики. Получается, сначала надо предобработать данные, получить необходимые значения, а затем на основе них строить график.\nНо зачем? Если можно сразу в коде построения графика рассчитать все, что нам нужно! В ggplot2 уже встроены инструменты простейшей статистический обработки!\nПосотрим, как влияют на [среднее] время реакции различные экспериментальные условия. Начнём с самого простого — количества стимулов на экране.\n\n22.9.1 Статы\nСтаты — это те самые встроенные инструменты статистической обработки. Они позволяют прямо в коде графика обсчитать данные и сразу визуализировать результаты.\nНа самом деле, мы уже сталкивались со встроенными инструментами статистической обработки, ведь что делает geom_smooth(method = “lm”)? Не что иное, как визуализирует линейную регрессию, построенную на выбранных данных!\nНаиболее популярная функция из семейства stat_*() — это stat_summary(). С помощью неё можно удобно визуализировать средние.\nСразу зададим черно-белую тему на все последующие визуализации. Это делается так:\n\ntheme_set(theme_bw())\n\nИтак, мы хотим понять, как зависит среднее время реакции от количества стимулов. Нас будут интересовать пробы с одним целевым стимулом, поэтому отфильтруем все остальные, а также сразу расчертим базовый слой:\n\nshare %&gt;% \n  filter(trialtype != \"both\") %&gt;% \n  ggplot(aes(setsize, time1))\n\n\n\n\n\n\n\n\nТак, обратим внимание на следующий момент: на оси x обозначились числа 10 и 14, а таких сетсайзов в данных нет. Можем убедиться:\n\nunique(share$setsize)\n\n[1]  8 12 16\n\n\nЭто случилось потому, что переменная setsize записана в датасете как числовая, а для вычисления среднего времени реакции в каждом из условий будет нужна группировка наблюдений. По числовой переменно группировка невозможноЮ, поэтому необходимо прописать, что данную переменную мы будем рассматривать как фактор:\n\nshare %&gt;% \n  filter(trialtype != \"both\") %&gt;% \n  ggplot(aes(as_factor(setsize), time1))\n\n\n\n\n\n\n\n\nВо, теперь как надо.\nТеперь добавляем средние. Как и полагается, на новый слой:\n\nshare %&gt;% \n  filter(trialtype != \"both\") %&gt;% \n  ggplot(aes(as_factor(setsize), time1)) +\n  stat_summary(fun = mean, geom = \"point\")\n\n\n\n\n\n\n\n\nРазберемся, что тут написано. Первый аргумент (fun) принимает функцию, результат которой будет отложен по оси y. В нашем случае это среднее (mean). Она будет применена к переменой time1, причем наблюдения будут автоматически сгруппированы по интересующим нас группам. Второй аргумент — это уже знакомый нам геом, который отвечает за то, как «геометрически» будут отрисованы знаечния на графике. Наш выбор — точки. Как результат мы наблюдаем то, что хотели.\nОднако как мы знаем из статистики, чтобы узнать, есть ли различия между условиями, нам недостаточно только средних значений — необходимы доверительные интервалы. Что ж, отобразим и их.\nДобавим новый слой с помощью всё той же функции stat_summary(), но на этот раз она будет выглядеть немного по-другому:\n\nshare %&gt;% \n  filter(trialtype != \"both\") %&gt;% \n  ggplot(aes(as_factor(setsize), time1)) +\n  stat_summary(fun = mean, geom = \"point\") +\n  stat_summary(fun.data = mean_cl_boot, geom = \"errorbar\")\n\n\n\n\n\n\n\n\nКак мы видим, немного изменился первый аргумент. Это связано с изменением геома. Для отображения доверительных интервалов нам нужен геом errorbar, который требует не одно значение, а два — верхнюю и нижнюю границу доверительного интервала. То есть fun.data принимает как аргумент мини-датафрейм — как раз в таком формате и возвращается результат функции mean_cl_boot(). Можно посмотреть на её работу отдельно:\n\nmean_cl_boot(share$time1)\n\n         y     ymin    ymax\n1 1.599066 1.586527 1.61303\n\n\nСобственно, вот он датафрейм из одной строки. Здесь три значения, но errorbar игронирует первое (оно и есть среднее значение) и использует только второе и третье, строя по ним «усы».\nСобственно, график почти готов, однако добавим линии, которые будут соединять наши средние. Это допустимо в данной визуализации, так как мы отображаем повторные измерения и так более наглядно будет прослеживаться закономерность.\n\nshare %&gt;% \n  filter(trialtype != \"both\") %&gt;% \n  ggplot(aes(as_factor(setsize), time1)) +\n  stat_summary(fun = mean, geom = \"point\") +\n  stat_summary(fun.data = mean_cl_boot, geom = \"errorbar\") +\n  stat_summary(fun = mean, geom = \"line\")\n\n`geom_line()`: Each group consists of only one observation.\nℹ Do you need to adjust the group aesthetic?\n\n\n\n\n\n\n\n\n\nАга, вроде слой добавили, но ничего не изменилось. Еще и warning вылетел. Надо почитать!\nggplot2 нам говорит, что каждая группа у нас содержит одно наблюдение — и он категорически прав, ведь у нас в каждой группе отображается только среднее значение. Из-за этого он не понимает, как ему нужно соединять точки. Надо ему подсказать, что с точки зрения соединения точек у нас всего одна группа, так как мы хотим, чтобы наши средние были последовательно соединены. Так и запишем (используя аргумент group):\n\nshare %&gt;% \n  filter(trialtype != \"both\") %&gt;% \n  ggplot(aes(as_factor(setsize), time1)) +\n  stat_summary(fun = mean, geom = \"point\") +\n  stat_summary(fun.data = mean_cl_boot, geom = \"errorbar\") +\n  stat_summary(fun = mean, geom = \"line\",\n               aes(group = 1))\n\n\n\n\n\n\n\n\nВот такая у нас классная линейная закономерность получилась! Ну, а чего мы ждали — зрительный поиск же…\nДобавляем переменных Окей, как влияет число стимулов мы поняли. Теперь хотим посмотреть, как на этом фоне ведут себя другие факторы. Добавим тип пробы. Обозначим его, например, цветом:\n\nshare %&gt;% \n  filter(trialtype != \"both\") %&gt;% \n  ggplot(aes(as_factor(setsize), time1,\n             color = trialtype)) +\n  stat_summary(fun = mean, geom = \"point\") +\n  stat_summary(fun.data = mean_cl_boot, geom = \"errorbar\") +\n  stat_summary(fun = mean, geom = \"line\",\n               aes(group = 1))\n\n\n\n\n\n\n\n\nО, хорошо. Только с линией теперь надо что-то делать. Пока её уберём. И добавим ещё один фактор — используемая платформа смартфона. Пусть он обозначается формой точек:\n\nshare %&gt;% \n  filter(trialtype != \"both\") %&gt;% \n  ggplot(aes(as_factor(setsize), time1,\n             color = trialtype,\n             shape = platform)) +\n  stat_summary(fun = mean, geom = \"point\") +\n  stat_summary(fun.data = mean_cl_boot, geom = \"errorbar\")\n\n\n\n\n\n\n\n\nУф… Ну, групировка прошла успешно — уже хорошо, однако отображение хромает. Надо немного раздвинуть точки относительно друг друга в отдельных категориях, так как сейчас они явно друг на друга налезают. Для этого есть аргумент position, который принимает результат выполнения функции position_dodge()3.\nЧтобы упростить код, заведем переменную pd, в которую сохраним результаты работы функции position_dodge() и далее будем передавать эту переменную в аргумент position:\n\npd &lt;- position_dodge(.3)\nshare %&gt;% \n  filter(trialtype != \"both\") %&gt;% \n  ggplot(aes(as_factor(setsize), time1,\n             color = trialtype,\n             shape = platform)) +\n  stat_summary(fun = mean, geom = \"point\",\n               position = pd) +\n  stat_summary(fun.data = mean_cl_boot, geom = \"errorbar\",\n               position = pd)\n\n\n\n\n\n\n\n\nАга, ну, норм. Только «усы» доверительных интервалов широки — надо сделать их поуже:\n\nshare %&gt;% \n  filter(trialtype != \"both\") %&gt;% \n  ggplot(aes(as_factor(setsize), time1,\n             color = trialtype,\n             shape = platform)) +\n  stat_summary(fun = mean, geom = \"point\",\n               position = pd) +\n  stat_summary(fun.data = mean_cl_boot, geom = \"errorbar\",\n               position = pd, width = .3)\n\n\n\n\n\n\n\n\nКрасuво!\nОсталось только понять, как бы нам вернуть линии. Осмыслим, что нам надо соединить красные треугольники между собой, зелёные треугольники между собой, красный точки между собой и зелёные точки между собой. То есть группы точек у нас получаются в результате взаимодействия факторов. Так и напишем:\n\nshare %&gt;% \n  filter(trialtype != \"both\") %&gt;% \n  ggplot(aes(as_factor(setsize), time1,\n             color = trialtype,\n             shape = platform,\n             group = interaction(trialtype, platform))) +\n  stat_summary(fun = mean, geom = \"line\",\n               position = pd) +\n  stat_summary(fun.data = mean_cl_boot, geom = \"errorbar\",\n               position = pd, width = .3) +\n  stat_summary(fun = mean, geom = \"point\",\n               position = pd)",
    "crumbs": [
      "Анализ данных в R",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Визуализация данных</span>"
    ]
  },
  {
    "objectID": "r-vis.html#наводим-красоту",
    "href": "r-vis.html#наводим-красоту",
    "title": "22  Визуализация данных",
    "section": "22.10 Наводим красоту",
    "text": "22.10 Наводим красоту\nСделаем то, что мы уже умеем: увеличим размер точек, сдвинем легенду вниз, подпишем переменные. Попутно сделаем линни пунктирными, чтобы не сильно отвлекали внимание:\n\nshare %&gt;% \n  filter(trialtype != \"both\") %&gt;% \n  ggplot(aes(as_factor(setsize), time1,\n             color = trialtype,\n             shape = platform,\n             group = interaction(trialtype, platform))) +\n  stat_summary(fun = mean, geom = \"line\",\n               position = pd, linetype = \"dashed\", alpha = .7) +\n  stat_summary(fun.data = mean_cl_boot, geom = \"errorbar\",\n               position = pd, width = .3) +\n  stat_summary(fun = mean, geom = \"point\",\n               position = pd, size = 3) +\n  labs(x = \"Количество стимулов в пробе\",\n       y = \"Время реакции (первый клик), с\",\n       color = \"Тип пробы\",\n       shape = \"Платформа\",\n       title = \"Время реакции при взаимодействии факторов\",\n       subtitle = \"Тип пробы × Платформа × Количество стимулов в пробе\") +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\nОч. хор. Вот только мы отобразили интервальную оценку на графике, а ведь это может быть не только доверительный интервал — так же выглядит и стандартная ошибка и даже стандартное отклонение. Надо подписать в подписи:\n\nshare %&gt;% \n  filter(trialtype != \"both\") %&gt;% \n  ggplot(aes(as_factor(setsize), time1,\n             color = trialtype,\n             shape = platform,\n             group = interaction(trialtype, platform))) +\n  stat_summary(fun = mean, geom = \"line\",\n               position = pd, linetype = \"dashed\", alpha = .7) +\n  stat_summary(fun.data = mean_cl_boot, geom = \"errorbar\",\n               position = pd, width = .3) +\n  stat_summary(fun = mean, geom = \"point\",\n               position = pd, size = 3) +\n  labs(x = \"Количество стимулов в пробе\",\n       y = \"Время реакции (первый клик), с\",\n       color = \"Тип пробы\",\n       shape = \"Платформа\",\n       title = \"Время реакции при взаимодействии факторов\",\n       subtitle = \"Тип пробы × Платформа × Количество стимулов в пробе\",\n       caption = \"отображен 95% доверительный интервал\") +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\nНу, почти всё. Осталось только красиво подписать платформы и типы проб. Для этого есть функции семейства scale_*(). Работает это так:\n\nshare %&gt;% \n  filter(trialtype != \"both\") %&gt;% \n  ggplot(aes(as_factor(setsize), time1,\n             color = trialtype,\n             shape = platform,\n             group = interaction(trialtype, platform))) +\n  stat_summary(fun = mean, geom = \"line\",\n               position = pd, linetype = \"dashed\", alpha = .7) +\n  stat_summary(fun.data = mean_cl_boot, geom = \"errorbar\",\n               position = pd, width = .3) +\n  stat_summary(fun = mean, geom = \"point\",\n               position = pd, size = 3) +\n  labs(x = \"Количество стимулов в пробе\",\n       y = \"Время реакции (первый клик), с\",\n       color = \"Тип пробы\",\n       shape = \"Платформа\",\n       title = \"Время реакции при взаимодействии факторов\",\n       subtitle = \"Тип пробы × Платформа × Количество стимулов в пробе\",\n       caption = \"отображен 95% доверительный интервал\") +\n  scale_color_discrete(labels = c(\"Three Dots\", \"Outgoing Tray\")) +\n  scale_shape_discrete(labels = c(\"Android\", \"iOS\")) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\nСупер! Отправляем в журнал!",
    "crumbs": [
      "Анализ данных в R",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Визуализация данных</span>"
    ]
  },
  {
    "objectID": "r-vis.html#кастомизация-шкал",
    "href": "r-vis.html#кастомизация-шкал",
    "title": "22  Визуализация данных",
    "section": "22.11 Кастомизация шкал",
    "text": "22.11 Кастомизация шкал\nНо недолго мы радовались: пришло письмо от редактора. Краткое содержание — «очень хороший, отличный, прекрасный график! переделайте, пожалуйста». Редактору не понравилось использование цвета — журнал печатается в черно-белом варианте.\nОк, секудочку.\nМы уже приступили к кастомизации шкал, когда задавали лейблы для уровней наших категориальных переменных. Теперь включим кастом на всю силу — используем функции scale_*_manual():\n\nshare %&gt;% \n  filter(trialtype != \"both\") %&gt;% \n  ggplot(aes(as_factor(setsize), time1,\n             color = trialtype,\n             shape = platform,\n             group = interaction(trialtype, platform))) +\n  stat_summary(fun = mean, geom = \"line\",\n               position = pd, linetype = \"dashed\", alpha = .7) +\n  stat_summary(fun.data = mean_cl_boot, geom = \"errorbar\",\n               position = pd, width = .3) +\n  stat_summary(fun = mean, geom = \"point\",\n               position = pd, size = 3) +\n  labs(x = \"Количество стимулов в пробе\",\n       y = \"Время реакции (первый клик), с\",\n       color = \"Тип пробы\",\n       shape = \"Платформа\",\n       title = \"Время реакции при взаимодействии факторов\",\n       subtitle = \"Тип пробы × Платформа × Количество стимулов в пробе\",\n       caption = \"отображен 95% доверительный интервал\") +\n  scale_color_manual(values = c(\"gray50\", \"black\"),\n                     labels = c(\"Three Dots\", \"Outgoing Tray\")) +\n  scale_shape_discrete(labels = c(\"Android\", \"iOS\")) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\nЗдесь мы задаём цвета через названия. Можно также использовать HEX code.",
    "crumbs": [
      "Анализ данных в R",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Визуализация данных</span>"
    ]
  },
  {
    "objectID": "r-vis.html#шрифт",
    "href": "r-vis.html#шрифт",
    "title": "22  Визуализация данных",
    "section": "22.12 Шрифт",
    "text": "22.12 Шрифт\nЕщё редактору не понравился шрифт без засечек — он хочет Times New Roman.\nОк, секудочку.\n\nshare %&gt;% \n  filter(trialtype != \"both\") %&gt;% \n  ggplot(aes(as_factor(setsize), time1,\n             color = trialtype,\n             shape = platform,\n             group = interaction(trialtype, platform))) +\n  stat_summary(fun = mean, geom = \"line\",\n               position = pd, linetype = \"dashed\", alpha = .7) +\n  stat_summary(fun.data = mean_cl_boot, geom = \"errorbar\",\n               position = pd, width = .3) +\n  stat_summary(fun = mean, geom = \"point\",\n               position = pd, size = 3) +\n  labs(x = \"Количество стимулов в пробе\",\n       y = \"Время реакции (первый клик), с\",\n       color = \"Тип пробы\",\n       shape = \"Платформа\",\n       title = \"Время реакции при взаимодействии факторов\",\n       subtitle = \"Тип пробы × Платформа × Количество стимулов в пробе\",\n       caption = \"отображен 95% доверительный интервал\") +\n  scale_color_manual(values = c(\"gray50\", \"black\"),\n                     labels = c(\"Three Dots\", \"Outgoing Tray\")) +\n  scale_shape_discrete(labels = c(\"Android\", \"iOS\")) +\n  theme(legend.position = \"bottom\",\n        title = element_text(family = \"Times New Roman\"),\n        plot.title = element_text(face = \"bold\"),\n        axis.text = element_text(family = \"Times New Roman\"),\n        legend.text = element_text(family = \"Times New Roman\"))\n\n\n\n\n\n\n\n\nНу, вот теперь редактор доволен.",
    "crumbs": [
      "Анализ данных в R",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Визуализация данных</span>"
    ]
  },
  {
    "objectID": "r-vis.html#сохранение-графиков",
    "href": "r-vis.html#сохранение-графиков",
    "title": "22  Визуализация данных",
    "section": "22.13 Сохранение графиков",
    "text": "22.13 Сохранение графиков\nДля того, чтобы опубликовать график в статье или даже просто вставить в презентацию нужно его как-то выгрузить. Скриншоты нам не подходят, потому что качество их зачастую совершенно никуда не годится. На наше счастье есть функция для выгрузки картинок из R, которая называется ggsave().\nОна принимает следующие аргументы:\n\nfilename — название файла, в который будет сохранен график\nplot — график, который необходимо сохранить (по умолчанию — последний построенный)\nscale — степень масштабирования изображения\nwidth — ширина изображения\nheight — высота изображения\nunits — единицы изменения (дюймы, миллиметры, сантиметры)\ndpi — разрешение изображения (dots per inch, точки на дюйм)\n\nФункция позволяет сохранить изображения большинства форматов (JPEG, PNG, SVG, TIFF, PDF).\n\nggsave('graph1.png', width = 20, height = 20, units = 'cm', dpi = \"print\")\n\nВыполнив эту функцию мы получим в рабочей директории файл с графиком, который мы только что нарисовали.\n\nВот и весь основной флоу, которому можно следовать при создании публикабельных графиков. А если этого уже мало, то вполне можно нырять в невероятное чтиво и бороздить Google вопросами о конкретных вещах — на Stack Overflow найдется ответ практически на любой вопрос.\n\nЛёгкая внезапность.↩︎\nИбо, как гласит одна тибетская мудрость, «нормально делай — нормально будет».↩︎\nЕсть и другие position_*(), но мы их упустим.↩︎",
    "crumbs": [
      "Анализ данных в R",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Визуализация данных</span>"
    ]
  },
  {
    "objectID": "infer-stattesting.html",
    "href": "infer-stattesting.html",
    "title": "7  Тестирование статистических гипотез",
    "section": "",
    "text": "В ходе статистического анализа мы, главным образом, заняты тем, что тестируем статистические гипотезы. Ведь на какого рода вопросы мы отвечаем с помощью анализа?\nРазличаются ли группы между собой? Значимо ли влияние какого-либо фактора? → Различаются ли группы между собой? Хороша ли та модель, которую мы построили? → Отличается ли она от нулевой модели? И так далее. Так или иначе, всё сводится в тому, что мы ищем какие-то различия. Но силу того, что у нас неопределённость и вариация в данных, мы просто так «в лоб» сказать о различиях по оценкам параметров не можем. Приходится тестировать статистические гипотезы.\n8.1 Базовые понятия Гипотеза ( H ) — это предположение, которое подлежит проверке на основе результатов наблюдений.\nГипотезы бывают трех видов:\nТеоретическая — про конструкты. Эмпирическая — про переменные (зависимые и независимые). Статистическая — про данные (что мы получили в данный конкретный момент, собрав вот эти конкретные данные). Статистические гипотезы бывают простыми и сложными.\nПростая гипотеза — это такое предположение, которое включает в себя какое-либо однозначно определеяемое утверждение. Например, истинная величина параметра соответствует некоторому строго заданному значению:\nH : θ = θ 0 . Другой вариант — две генеральные совокупности имеют одно и то же значение одной и той же характеристики:\nH : θ 1 = θ 2 .\nСложная гипотеза предполагает множественность вариантов для параметра, которые укладываются в рамки проверяемого предположения. Например,\nH : θ &gt; θ 0 или\nH : θ 1 ≠ θ 2 .\nВ рамках самого хода тестирования гипотез существует проверяемая (нулевая) гипотеза ( H 0 ). Её обычно стараются предельно упростить, поэтому она формулируется как простая гипотеза. В противовес ей выдвигается альтернативная гипотеза ( H 1 ), которая будет иметь вид сложной гипотезы.\nДля проверки гипотезы нужны две вещи:\nрезультаты наблюдений и критерий. Результаты наблюдений, полученные на выборке, сами по себе, как правило, не используются. Однако на их основе рассчитываются выборочные статистики (показатели), которые непосредственно участвуют в проверке гипотезы.\nВ результате проверки статистических гипотез могут возникнуть четыре ситуации.\n8.2 Возможные результаты проверки гипотез Мы изучаем в исследовании какую-либо закономерность, которая в реальном мире может существовать, а может и не существовать. В силу неопределённости и вариативности наших данных мы может либо обнаружить интересующую нас закономерность, либо не обнаружить.\nВ качестве нулевой гипотезы мы выдвигаем предположение о том, что закономерность отсутствует — так мы упрощаем нашу нулевую гипотезу. Пусть\nH 0 обозначает, что предположение, которое мы проверяем справедливо, а\nH 1 — не справедливо. На основании данных мы можем либо не отклонить наше предположение ( ^ H 0 ), либо отклонить ( ^ H 1 ).\nТогда имеем следующую ситуацию:\nH 0\nH 1\n^ H 0 ✓ Ошибка II рода ^ H 1 Ошибка I рода ✓ Ошибка I рода возникает, когда в генеральной совокупности искомой закономерности нет, но мы в силу случайных флуктуаций в данных её нашли. Ошибка II рода возникает, когда в генеральной совокупности искомая закономерность есть, но мы в силу каких-либо причин её не нашли. Ошибки — это нехорошо, они нас не устраивают. Надо каким-то образом их контролировать.\nОшибка I рода контролируется достаточно просто. Так как мы нашли закономерность, которую искали, мы можем посчитать вероятность, с которой потенциально ошиблись. А собственно контролировать ошибку мы будем с помощью уровня значимости\nα , который выбирается до начала процедуры тестирования гипотезы. Он и задает вероятность, с который мы позволяем себе ошибиться — отклонить нулевую гипотезу, при условии, что она верна.\nОшибку II рода контролировать сложнее, так как мы не нашли закономерность, которую искали. Нам нужна какая-то метрика, которая позволит сказать, что мы сделали всё возможное для того, чтобы обнаружить искомую закономерность. Вероятность ошибки II рода обозначается\nβ — тогда вероятность того, что мы не совершили ошибку II рода будет\n1 − β . Эта величина называется статистической мощностью, и она связана с размером эффекта и объемом выборки. Статистическую мощность можно рассчитать как до проведения статистического анализа — для расчета требуемого объема выборки — так и после — для определения достигнутой статистической мощности.\nСоберем все обозначения в единую табличку1:\nH 0\nH 1\n^ H 0\nP ( ^ H 0 | H 0 )\nP ( ^ H 0 | H 1 ) = β\n^ H 1\nP ( ^ H 1 | H 0 ) = α\nP ( ^ H 1 | H 1 ) = 1 − β\nУровень значимости\nα выбирается близким к нулю — всем знакомо конвенциональное значение\n0.05 . Вообще\nα можно выбрать сколь угодно малым, однако при выборе уровня значимости руководствуются принципом разумной достаточности, так как если устремить\nα к нулю, то устремиться к нулю и вероятность отклонения нулевой гипотезы\nМатематические руны Достаточной статистической мощностью считается\n0.8 . Аналогично, устремляя мощность к единице ( ( 1 − β ) → 1 ⇒ β → 0 ), мы устремляем вероятность не отклонения нулевой гипотезы к нулю:\nЕщё математические руны Необходимо также помнить, что ошибки первого и второго рода связаны между собой так, что\nα → 0 ⇒ β → 1\nОпять математические руны 8.3 Асимметрия статистического вывода Выше мы сказали, что для проверки гипотезы нужны две вещи:\nрезультаты наблюдений и критерий. С результатами наблюдений более-менее очевидно.\nКритерий — это правило, согласно которому гипотезу либо принимают, либо отклоняют. Однако перед тем как проверять гипотезу, её так-то нужно сформулировать, и сделать это правильно, поскольку от формулировки гипотезы зависит интерпретация результатов проверки и дальнейшее использование полученной информации.\nИспользуемая статистика сама по себе является [непрерывной] случайной величиной, а значит может быть построено её распределение. Критерий будет разделять это распределение на непересекающиеся области. В результате чего возникает критическая область — область отклонения гипотезы. Дополнением к ней является область неотклонения гипотезы.\nКритическая область может быть односторонней (при\nH 1 : θ &gt; θ 0 или\nH 1 : θ &lt; θ 0 ) и двусторонней (при\nH 1 : θ ≠ θ 0 ). «Размер» критической области определяется уровнем значимости.\nСтатистический вывод — заключение о том, получили ли мы подтверждение альтернативной гипотезы — по структуре представляет собой импликацию. Если вам не знаком этот термин из логики, то вот:\nЕсли значение нашей статистики, которое мы рассчитали на выборке, попало в критическую область, то мы говорим о том, что нулевая гипотеза отклоняется. Если значение нашей статистики, которое мы рассчитали на выборке, не попало в критическую область, то мы не получаем оснований для того, чтобы отклонить нулевую гипотезу. Однако мы также не получаем оснований, чтобы её «принять». Мы остаёмся в некотором неведении: мы не нашли различий, а есть они там или нет — хто ж их знает… Итого, мы не можем сделать никакого вывода. В этом и заключается асимметрия статистического вывода. Как раз для того, чтобы с ней как-то жить, мы работаем со статистической мощностью.\nПосмотреть, как все эти штуки друг с другом соотносятся можно тут.\n8.4 Алгоритм тестирования статистических гипотез Для тестирования гипотез есть два сценария: первый и тот, которым мы будем пользоваться. Первый вариант чуть более классический, второй — более гибкий.\nСценарий номер раз\nФормулировка гипотезы Выбор статистического критерия Выбор уровня значимости\nα\nПостроение закона распредления статистики критерия при условии, что нулевая гипотеза верна Определение границ критической области Расчёт выборочной статистики Определение, попадает ли наблюдемое значение статистики в критическую область и вынесение решения Сценарий номер два\nФормулировка гипотезы Выбор статистического критерия Выбор уровня значимости\nα\nПостроение закона распредлеения статистики критерия при условии, что нулевая гипотеза верна Расчёт выборочной статистики Расчёт достигнутого уровня значимости p-value Сопоставление\nα и p-value и вынесение решения Почему второй вариант более гибкий? Представим, что мы захотели понизить уровень значимости с\n0.05 до\n0.01 — такие уровни значимости всречаются, например, в медицине. Если мы идем по первому сценарию, то нам надо заново пересчитать критические значения и вновь проанализировать, попадает ли наблюдаемое значение в критическую область. Если мы адепты второго сценария, то нам надо только выполнить одно новое сравнение нашего p-value с новым уровнем значимости.\nВероятно, пока мало что понятно. Поэтому в следующей главе разберем все это безобразие на примере.\nЗдесь использовано обозначение условной вероятности\nP ( A | B ) , то есть это вероятность того, что случилось событие\nA при условии, что случилось событие\nB .↩︎",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Тестирование статистических гипотез</span>"
    ]
  },
  {
    "objectID": "infer-categorical.html",
    "href": "infer-categorical.html",
    "title": "8  Анализ категориальных данных",
    "section": "",
    "text": "8.1\nСегодня мы изучим первый статистический метод, которые применяется при анализе категориальных данных. Напомню, что это категориальные данные — это те, которые измерены в номинальной (реже — порядковой) шкале. А раз они измерены в номинальной шкале, значит наши данные разбиваются на некоторые категории. А раз есть категории, значит можно посчитать их частоты. А раз можно посчитать частоты, значит можно построить таблицу частот.\n9.1 Таблица сопряженности Таблицы частот для одной переменной мы с вами строили — это довольно простая задача. Однако теперь нас интересует не одна переменная, а две — мы будем искать связь между двумя категориальными переменными.\nДавайте на примере. Пусть у нас есть данные о том, как студенты некоторого курса сдали экзамен по анализу данных. Экзамен проходил во вторник. При этом известно, что одна часть студентов усиленно готовилась к экзамену, а другая часть — отмечала понедельник в барах на Китай-городе.\nВ цифрах:\nвсего студентов на курсе 120 человек успешно сдали экзамен 94 студента готовились к экзамену 86 студентов готовились и не сдали экзамен 3 студента По этим данным мы можем построить таблицу сопряженности (contingency table, cross tabulation, crosstab).\nСдали экзамен Не сдали экзамен\nГотовились\n83\n3\n86\nОтмечали понедельник\n11\n23\n34\n94\n26\n120\nТаблица сопряженности отражает совместное распределение двух категориальных (в данном случае — бинарных) переменных. На основе такой таблицы проверяеются гипотезы о связях между двумя категориальными переменными. В общем случае таблица сопряженности будет выглядеть так:\nX 1\nX 2\nY 1\na\nb\na + b\nY 2\nc\nd\nc + d\na + c\nb + d\nN\nЭта таблица отражает эмпирические частоты — то есть те, которые получились из собранных нами данных. Здесь\nX и\nY — наши переменные, индексы\n1 и\n2 показывают категорию, к которой относится то или иное наблюдение. На пересечении столбца и строки — частота совместного появления признаков\nX i и\nY j . Суммы частот по строкам и столбцам — маргинальные частоты [строк и столбцов соответственно].\nИтак, эмпирические частоты у нас в наличии. Теперь вспомним алгоритм тестирования статистических гипотез:\nФормулировка гипотезы Выбор статистического критерия Выбор уровня значимости\nα\nПостроение закона распределения статистики критерия при условии, что нулевая гипотеза верна Расчёт выборочной статистики Расчёт достигнутого уровня значимости p-value Сопоставление\nα и p-value и вынесение решения Нам нужно сформулировать нулевую гипотезу. Как мы помним, нулевая гипотеза всегда об отсутствии каких-либо различий. В нашем случае если нет никакой связи между переменными\nX и\nY — подготовка к экзамену и успешность сдачи — то все частоты в таблице должны быть равны. То есть\nH 0 : a = b = c = d\nАльтернативная гипотеза в этом случае будет гласить, что хотя бы между двумя какими-либо ячейчас отсутствует статистическое равенство. Это сложно записать математически — можно, но будет длинно. Воспользуется логическим отрицанием — неверно, что все частоты равны между собой:\nH 1 : ¬ ( a = b = c = d )\nОкей, формулировка гипотезы — ✓ done!\nТеперь надо понять, как нам эту гипотезу протестировать. Мы бы, конечно, могли просто взять и сравнить наши частоты, но мы так делать не можем, ибо всё ещё вариативность и неопределенность статистических данных. Надо придумать другой ход.\nМы можем взять теоретическую ситуацию, когда между нашими переменными нет связи — а значит нет различия между частотами — и сравнить с тем, что у нас есть в таблице. Так и поступают. Поэтому сначала нам нужно рассчитать теоретические частоты.\n9.2 Расчёт теоретических частот Чтобы построить таблицу теоретического распределения частот, нам нужно понять, как были бы распределены наши данные в случае, если между нашими переменными не было бы связи. Это делается так:\nX ∗ 1\nX ∗ 2\nY ∗ 1\n( a + b ) ⋅ ( a + c ) N\n( a + b ) ⋅ ( b + d ) N\nY ∗ 2\n( c + d ) ⋅ ( a + c ) N\n( c + d ) ⋅ ( a + c ) N\nТо есть для расчета теоретической частоты в конкретной ячейке мы перемножаем соответствующие маргинальные вероятности и делим на число наблюдений. Рассчитаем теоретические частоты для нашего примера:\nСдали экзамен Не сдали экзамен Готовились\n86 ⋅ 94 120 = 67.37\n86 ⋅ 26 120 = 18.63\nОтмечали понедельник\n34 ⋅ 94 120 = 26.63\n34 ⋅ 26 120 = 7.37\nЧтобы понять, какое содержание стоит за расчетом теоретических частот, надо разложить расчет на два действия. Первое — вычисление долей сдавших и не сдавших экзамен:\np готовились = 86 120 ≈ 0.72 p отмечали = 34 120 ≈ 0.28\nВторое — находим части, равные рассчитанным долям, от количества сдавших и не сдавших экзамен:\nn готовились и сдали = 0.72 ⋅ 94 = 67.68 n готовились и не сдали = 0.72 ⋅ 26 = 18.72 n отмечали и сдали = 0.28 ⋅ 94 = 26.32 n отмечали и не сдали = 0.28 ⋅ 26 = 7.28\nНу, вот мы то же самое и получили [с точностью до промежуточного округления].\nИтак, у нас есть всё, что нужно, чтобы перейти к тестированию гипотезы.\n9.3 Критерий независимости Пирсона Переходим ко второму пункту алгоритма — выбор статистического критерия. Для поиска взаимосвязей между категориальными переменными разработан критерий независимости Пирсона ( χ 2 Пирсона). Это первый статистический критерий, с которым мы с вами знакомимся. У каждого статистического критерия есть статистика критерия, которая рассчитывается определенным образом. Для критерия\nχ 2 она рассчитывается так:\nχ 2 = ∑ i\n( O i − E i ) 2 E i ,\nгде\nO i — эмпирические (наблюдаемые, observed) частоты, а\nE i — теоретические (ожидаемые, expected) частоты.\nВнимательно присмотревшись в формуле, можно увидеть, что чем больше отклонения эмпирических частот от теоретических, тем больше числитель дроби, тем больше статистистика критерия. Несложно рассчитать значения статистического критерия для нашего примера:\nχ 2 = ( 83 − 67.37 ) 2 67.37 + ( 3 − 18.63 ) 2 18.63 + ( 11 − 26.63 ) 2 26.63 + ( 23 − 7.37 ) 2 7.37 ≈ 59.06\nДальше мы можем рассчитать критическое значения критерия\nχ 2 — договоримся, что если не оговорено иное, мы берем в качестве уровня значимости конвенциональный 0.05 — и сравнить его с полученным, но в прошлой главе мы договорились, что так делать не будем. Мы будем рассчитывать p-value, или достигнутый уровень значимости. Руками это делать трудно — надо в интегралы уметь и формулы для распределенрий знать — поэтому мы доверим это специально обученному программному обеспечению:",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Анализ категориальных данных</span>"
    ]
  },
  {
    "objectID": "infer-categorical.html#pearsons-chi-squared-test-with-yates-continuity-correction",
    "href": "infer-categorical.html#pearsons-chi-squared-test-with-yates-continuity-correction",
    "title": "8  Анализ категориальных данных",
    "section": "8.2 Pearson’s Chi-squared test with Yates’ continuity correction",
    "text": "8.2 Pearson’s Chi-squared test with Yates’ continuity correction",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Анализ категориальных данных</span>"
    ]
  },
  {
    "objectID": "infer-categorical.html#section-1",
    "href": "infer-categorical.html#section-1",
    "title": "8  Анализ категориальных данных",
    "section": "8.3 ",
    "text": "8.3",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Анализ категориальных данных</span>"
    ]
  },
  {
    "objectID": "infer-categorical.html#data-d",
    "href": "infer-categorical.html#data-d",
    "title": "8  Анализ категориальных данных",
    "section": "8.4 data: d",
    "text": "8.4 data: d",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Анализ категориальных данных</span>"
    ]
  },
  {
    "objectID": "infer-categorical.html#x-squared-55.378-df-1-p-value-9.946e-14",
    "href": "infer-categorical.html#x-squared-55.378-df-1-p-value-9.946e-14",
    "title": "8  Анализ категориальных данных",
    "section": "8.5 X-squared = 55.378, df = 1, p-value = 9.946e-14",
    "text": "8.5 X-squared = 55.378, df = 1, p-value = 9.946e-14\nПолучилось другое значение\nχ 2 , что связано со сделанными нами округлениями в ходе расчета теоретических частот. Но принципиально это ничего не меняет — мы видим p-value много меньше 0.05.\nКак мы говорили в прошлой главе, если p-value меньше выбранного уровня значимости, у нас есть оcнования отклонить нулевую гипотезу об отсутствии различий, и принять альтернативную гипотезу. Итого, связь между подготовкой к экзамену и успешностью его сдачи есть. Ну, ничего себе какой полезный вывод — а мы то и не в курсе были…\nЛадно, это всё хорошо — и даже достаточно для эвристического понимания того, как работает хи-вадрат, однако давайте все же посмотрим чуть глубже в то, что осталось под капотом.\n9.3.1 Распределение\nχ 2\nПочему вообще критерий называется хи-квадрат? Откуда берется p-value? И куда делось «построение закона распределения статистики критерия при условии, что нулевая гипотеза верна»?\nОбо всём по порядку. Еще раз вернемся к алгоритму:\nФормулировка гипотезы Выбор статистического критерия Выбор уровня значимости\nα\nПостроение закона распределения статистики критерия при условии, что нулевая гипотеза верна Расчёт выборочной статистики Расчёт достигнутого уровня значимости p-value Сопоставление\nα и p-value и вынесение решения Первые три пункта вычеркнуты — их мы обсудили. Гипотезу сформулировали, статистический критерий выбрали, уровень значимости оставили конвенциональным. Что дальше?\nСтатистика критерия — любого, не только\nχ 2 — это непрерывная случайная величина. И она подчинается некоторому распределению. В частности, статистика рассматриваемого нами критерия подчинается распределению\nχ 2 , которое выглядит вот так:\nВажно: так выглядит распределение статистики\nχ 2 при условии, что нулевая гипотеза верна! Именно его мы и строим. Ну, как строим: оно уже построено за нас. Нам надо только понять, какое из возможных использовать. Мы видим, что форма распределения зависит от количества степеней свободы. Значит нам надо научиться рассчитывать количество степеней свободы для конкретного случая. Это делается так:",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Анализ категориальных данных</span>"
    ]
  },
  {
    "objectID": "infer-categorical.html#f-m",
    "href": "infer-categorical.html#f-m",
    "title": "8  Анализ категориальных данных",
    "section": "9.1 f m",
    "text": "9.1 f m",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Анализ категориальных данных</span>"
    ]
  },
  {
    "objectID": "infer-categorical.html#section-2",
    "href": "infer-categorical.html#section-2",
    "title": "8  Анализ категориальных данных",
    "section": "9.2 233 262",
    "text": "9.2 233 262\nТеоретические частоты будут таковы — рассчитываются по формуле\np ⋅ N , где\np — теоретическая доля,\nN — количество наблюдений:\nfemale male 0.54 ⋅ 495 = 267.3\n0.46 ⋅ 495 = 227.7\nФормула для расчета статистики критерия вот:\nχ 2 = ∑ i\n( O i − E i ) 2 E i ,\nгде\nO i — эмпирические (наблюдаемые, observed) частоты, а\nE i — теоретические (ожидаемые, expected) частоты.\nНа что-то очень похоже, да?\nСтепени свободы, так как строчка в таблице только одна, рассчитываются следующим образом:",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Анализ категориальных данных</span>"
    ]
  },
  {
    "objectID": "infer-categorical.html#section-3",
    "href": "infer-categorical.html#section-3",
    "title": "8  Анализ категориальных данных",
    "section": "10.1 ",
    "text": "10.1",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Анализ категориальных данных</span>"
    ]
  },
  {
    "objectID": "infer-categorical.html#chi-squared-test-for-given-probabilities",
    "href": "infer-categorical.html#chi-squared-test-for-given-probabilities",
    "title": "8  Анализ категориальных данных",
    "section": "10.2 Chi-squared test for given probabilities",
    "text": "10.2 Chi-squared test for given probabilities",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Анализ категориальных данных</span>"
    ]
  },
  {
    "objectID": "infer-categorical.html#section-4",
    "href": "infer-categorical.html#section-4",
    "title": "8  Анализ категориальных данных",
    "section": "10.3 ",
    "text": "10.3",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Анализ категориальных данных</span>"
    ]
  },
  {
    "objectID": "infer-categorical.html#data-d_gender",
    "href": "infer-categorical.html#data-d_gender",
    "title": "8  Анализ категориальных данных",
    "section": "10.4 data: d_gender",
    "text": "10.4 data: d_gender",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Анализ категориальных данных</span>"
    ]
  },
  {
    "objectID": "infer-categorical.html#x-squared-9.5682-df-1-p-value-0.00198",
    "href": "infer-categorical.html#x-squared-9.5682-df-1-p-value-0.00198",
    "title": "8  Анализ категориальных данных",
    "section": "10.5 X-squared = 9.5682, df = 1, p-value = 0.00198",
    "text": "10.5 X-squared = 9.5682, df = 1, p-value = 0.00198\nСнова видим p-value\n&lt; α , значит мы получили значение статистики, не характерное для ситуации справедливости нулевой гипотезы, и у нас есть основания отклонить нулевую гипотезу и принять альтернативную о том, что эмпирические частоты отличаются от теоретических.\nПолучается, что наша выборка не особо репрезентативна. Грустно… :(\nНапоследок отметим, что если мы используем специально обученное ПО, мы вообще-то мало что делаем руками — только строчку кода пишем. Остальное же — формулирование гипотезы, построение распределения, подсчет статистики и p-value — за нас делает машина. Нам остается включить мозг, когда мы делаем статистический вывод.",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Анализ категориальных данных</span>"
    ]
  },
  {
    "objectID": "infer-correlation.html",
    "href": "infer-correlation.html",
    "title": "9  Корреляционный анализ",
    "section": "",
    "text": "Мы рассмотрели метод, позволяющий тестировать гипотезу об отсутствии связи между категориальными переменными. Теперь посмотрим, что делать, если нас интересуют гипотезы о связи между двумя количественными переменными.\n10.1 Ковариация Мы хотим описать имеющиеся взаимосвязи как можно проще и опираясь на то, что у нас уже есть. Мы знаем, что дисперсия, или вариация (variance), заключает в себе информацию об изменчивости признака. Если мы хотим исследовать взаимосвязь между признаками, то логично будет посмотреть, как изменяется один из признаков при изменении другого — иначе говоря, рассчитать совместную изменчивость признаков, или ко-вариацию (co-variance).\nКак мы её будем считать? Подумаем графически. Расположим две переменные на осях и сопоставим каждому имеющемуся наблюдению точку на плоскости.\nОтметим средние значения по обеим переменным.\nРазумеется, что у нас наблюдаются отклонения наблюдений от среднего. Заметим, что отклонения могут быть сонаправленными — одновременно по обеим переменным\nx и\ny в положительную или отрицательную сторону (зеленые стрелки) — или разнонаправленными — в положительную сторону по одной из переменных и в отрицательную по другой, и наоборот (рыжие стрелки).\nПри этом обратим внимание, что точки на графике, отображающие наши наблюдения, как бы идут более-менее в направлении какой-то прямой — серой, как на картинке:\nИ чем отклонения от средних по обеим переменным будут более согласованы, тем точнее они будут идти по этой прямой.\nПолучается, мы можем на основании согласованности отклонений уже следать заключение о направлении связи, ведь произведение отклонений по обеим величинам будет положительно, если отклонения сонаправленны, и отрицательно, если они разнонаправленны. Остается только понять, как совместные отклонения организованы «в среднем» — это и будет ковариацией двух величин:\ncov ( x , y ) = 1 n − 1 n ∑ i = 1\n( ¯ x − x i ) ( ¯ y − y i )\nКстати, а что такое ковариация переменной с самой собой?\nВот что Это все, конечно, кул, однако важно отметить, что ковариация улавливает только линейную составляющую взаимосвязи между признаками — мы говорили выше, что точки идут как бы по некоторой прямой — поэтому если\ncov ( x , y ) = 0 , то мы можем сказать, что между переменными нет линейной взаимосвязи, однако это не значит, что между этими переменными нет никакой другой зависимости.\nЕсли же ковариация отлична от нуля, то\nесли её значение положительно, то мы можем заподозрить прямую связь между переменными, если же её значение отрицательно, то мы можем предположить обратную связь между переменными. У ковариации есть два важных недостатка:\nэто размерная величина, поэтому её значение зависит от единиц измерения признаков, она зависит от дисперсий признаков, поэтому по её значению можно определить только направление связи (прямая или обратная), однако ничего нельзая сказать о силе связи. Поэтому нам нужно как-то модицифировать эту статистику, чтобы мы могли больше вытащить из её значения.\n10.2 Корреляция Раз ковариация зависит от дисперсии, то можно сделать некоторые математические преобразования, чтобы привести эмпирические распределения к какому-то одному виду — сделать так, чтобы они имели одинакое математическое ожидание (среднее) и одинаковую дисперсию. С этой задачей прекрасно справляется стандартизация. Напоминаю формулу:\nz i = x i − ¯ x s\nПосле такого преобразования математическое ожидание нашего распределения будет равно нулю, а стандартное отклонение — единице. Это избавит нас от влияния дисперсии на значение ковариации. Ковариация двух стандартно нормально распределенных величин называется корреляцией (correlation).\ncov ( z ( x ) , z ( y ) ) = 1 n − 1 n ∑ i = 1\nz ( x ) z ( y ) = corr ( x , y ) ,\nгде\nz ( x ) и\nz ( y ) — стандартизированные величины\nx и\ny соответственно.\nКорреляцию можно выразить через ковариацию:\ncorr ( x , y ) = 1 n − 1 n ∑ i = 1\n( ¯ x − x i s x ) ( ¯ y − y i s y ) = 1 s x s y ( 1 n − 1 n ∑ i = 1\n( ¯ x − x i ) ( ¯ y − y i ) ) = cov(x, y) s x s y\nЕсли внимательно всмотреться в формулу, то можно обнаружить, что корреляция это не что иное, как стандартизированное значение ковариации.\nКоэффициент корреляции имеет четкие пределы изменения:\n[ − 1 ; 1] . Крайнее левое значение говорит о том, что присутствует полная обратная линейная взаимосвязь, крайнее правое — что присутствует полная прямая линейная взаимосвязь. Как и ковариация, корреляция ловит только линейную составляющую связи, поэтому нулевое значение корреляци показывает, что между переменными отсутствует линейная взаимосвязь. Это всё еще не значит, что связи нет вовсе.\nПреимущество корреляции над ковариацией в том, что она отражает не только направление, но и силу связи:\nЗначение коэффициента Интерпретация − 1.0 – − 0.9 очень сильная обратная связь − 0.9 – − 0.7 сильная обратная связь − 0.7 – − 0.5 средняя обратная связь − 0.5 – − 0.3 слабая обратная связь − 0.3 – 0.0 очень слабая обратная связь 0.0 – 0.3 очень слабая прямая связь 0.3 – 0.5 слабая прямая связь 0.5 – 0.7 средняя прямая связь 0.7 – 0.9 сильная прямая связь 0.9 – 1.0 очень сильная прямая связь Пронаблюдать можно тут.\n10.3 Корреляция Пирсона То, что мы только что обсудили, называется коэффициентом корреляции Пирсона. Пирсон, как вы могли обратить внимание, много чего успел наделать на благо статистики — вот ещё и корреляцию нам придумал. Этот коэффициент применим, когда мы работаем с двумя нормально распределенными величинами или хотя бы двумя величинами, измеренями в метрических шкалах. Еще раз напомним чере его формулу:\nr x 1 x 2 = ∑ n i = 1 ( ¯ x 1 − x i 1 ) ( ¯ x 2 − x i 2 ) √ ∑ n i = 1 ( ¯ x 1 − x i 1 ) 2 ⋅ ∑ n i = 1 ( ¯ x 2 − x i 2 ) 2\nТеперь задумаемся — хоть это и неприятно — можем ли мы сказать по значению коэффициента корреляции, отличается ли он от нуля? Вспомнив, что мы занимаемся статистикой, сразу ответим — нет. Поскольку мы рассчитываем коэффициент корреляции на данных, а они содержат всякую вариативность и неопределенность, нам придется предпринять дополнительные усилия, чтобы заявить, что обнаруженная нами связь статистически значима.\n10.3.1 Тестирование статистической значимости коэффициента корреляции Итак, мы, как обычно, хотим ответить на вопрос, есть ли в генеральной совокупности связь между двумя изучаемыми переменными. Если в генеральной совокупности связь между признаками отсутствует, то есть\nρ x 1 x 2 = 0 , будет ли равен нулю\nr x 1 x 2 ? Можно с уверенностью сказать, что не будет, так как выборочный коэффициент корреляции — случайная величина. А мы помним, что вероятность принятия случайной величиной своего конкретного значения равна нулю.\nТогда необходимо протестировать статистическую гипотезу:\nH 0 : ρ x 1 x 2 = 0 H 1 : ρ x 1 x 2 ≠ 0\nНулевая гипотеза гласит, что между признаками нет линейной взаимосвязи, альтернативная говорит — что есть. Обычно мы не закладываем в гипотезу направление связи, потому что и положительная, и отрицательная нас устроит — это мы будем потом уже содержательно интерпретировать.\nГипотезу сформулировали, теперь надо подобрать статистический критерий. Он вот:\n\n10 t\nr x 1 x 2 √ 1 − r x 1 x 2 n − 2 H 0 ∼ t ( df = n − 2 )\nЭто t-критерий, и значение его статистики подчиняется t-распределению, или распределению Стьюдента. Число степеней свободы определяется по формуле в скобках и равно\n( n − 2 ) , где\nn — число наблюдений.\nСамо t-распределение выглядит так:\nМожет показаться, что оно похоже на нормальнгое распределение — и это правда, но только с 30+ степеней свободы. А до этого можно наблюдать высокие хвосты.\nСобственно, далее согласно уже знакомому нам алгоритмы тестирования статистических гипотез мы рассчитываем статистику критерия, p-value для неё и делаем статистический вывод. Все так же, как и в случае с хи-квадратом.\n10.3.2 Доверительный интервал для коэффициента корреляции Помимо того, что мы обязаны оценить статистическую значимость коэффициента корреляции, обычно мы еще строим доверительный интервал для него. С построением интервальной оценки возникают некоторые сложности. Мы не можем использовать рассмотренное выше распределение Стьюдента, так как оно строится для случая, когда верна нулевая гипотеза об отсутствии связи. Если же мы строим интервальную оценку, нас интересует случай наличия связи.\nСтатистики долго думали и придумали\nвот это безобразие Впрочем, не очень важно, что именно они там придумали, потому что всё равно мы доверим построить доверительный интервал машине. Нам важно понять, как интерпретировать получившийся результат.\nЕсли в доверительный интервал коэффициента корреляции попадает\n0 , значит коэффициент статистически равен нулю, то есть между изучаемыми переменными взаимосвязи нет. Если в доверительный интервал коэффициента корреляции не попадает\n0 , значит коэффициент статистически отличен от нуля, то есть между изучаемыми переменными взаимосвязь есть. 10.3.3 Размер эффекта для коэффициента корреляции Еще одна статистика, которая нам необходима — это размер эффекта. На этот моменте мы начинаем беседовать об ошибке второго рода. До этого мы говорили только об ошибке первого рода и начились её контролировать с помощью уровня значимости. Теперь вот повогорим об ошибке второго рода.\nВ целом, размер эффекта — это численное выражение силы взаимосвязи между переменными в генеральной совокупности.\nЗдесь нам необходимо призадуматься, и осознать, что вообще-то корреляция сама по себе выражает силу взаимосвязи между переменными. И, да, это правда — размером эффекта для коэффициента корреляции является сам коэффициент корреляции. Удобненько.\nТак, к сожалению, будет не всегда, но вот с корреляцией это так. Ну, и хорошо.\nРекомендации по интерпретация [абсолютного значения] коэффициента корреляции с точки зрения размера эффекта для социальных наук такие:\nЗначение коэффициента Размер эффекта 0.1 Малый (small) 0.3 Средний (medium) 0.7 Большой (large) 10.3.4 Расчет объема выборки для корреляционного анализа Размер эффекта нам требуется для расчета объема выборки, необходимой для корректного корреляционного анализа. В чем идея?\nМы говорили, что ошибку второго рода мы контролирует в помощью статистической мощности, которая равна\n1 − β , где\nβ — вероятность ошибки второго рода. Конвенционально достаточным уровнем статистической мощности считается\n80 % , то есть нам надо предпринять все усилия, чтобы достичь такого уровня статистической мощности. А что мы можем предпринять? Да, в общем-то только собрать достаточное количество наблюдений. Значит, надо рассчитать, сколько нам надо наблюдений, чтобы зафиксировать эффект, если он есть.\nСобственно, статистическая мощность, размер эффекта и объем выборки связаны вот как:\n↑ объем выборки → ↑ статистическая мощность ↑ размер эффекта → ↓ требуемый объем выборки\nИтого, если у нас есть ожидаемый размер эффекта и требуемый уровень статистической мощности, то мы можем рассчитать необходимый объем выборки. Формул не будет — мы рассчитываем объем выборки в специально обученном ПО.\nЧто надо запомнить?\nУровень статистической мощности (power) по умолчанию выбираем\n80 %\nРазмер эффекта можем взять из предыдущих исследований, на основе которых планируем текущее — это лучше — либо из рекомендаций по интерпретации размеров эффекта Например, в психологии большие корреляции — это вообще большая редкость, поэтому берем значения для малого или среднего размеров эффекта. Вгоняем это в программу, и оно там все само магически считается.\n10.3.5 Визуализация корреляции Как можно отображать взаимосвязи между переменными? Один пример графика мы уже видели в самом начале — это была диаграмма рассеяния (scatterplot). Это достаточно простой и понятный график: по осям идут две количественные переменные, точки отображают наблюдения. В итоге получается облако точек. Чем более они вытянуты в линию, тем больше значение корреляции, чем более облако точек «круглое», тем значение кореляции меньше. Дополнительно обычно на таком графике отображают ещё линию тренда, чтобы более наглядно визуализировать линейный компонент взаимосвязи переменных. Построение такой линии отдельная довольно интересная задача — мы вскоре ею займемся и назовем это регрессионный анализ.\nНиже примеры диаграмм рассения. Это визуализация результатов валидизации психометрической методики: на первом графике корреляция между итоговыми баллами двух опросников, а на втором — баллов по отдельным шкалам валидизируемого опросника и общим баллом другого опросника.\nМожно потренироваться визуально определять корреляцию по скаттерплотам.\nБывает, что нас интересует связь не между двумя какими-либо отдельными переменными, а много попарных корреляций между несколькими переменными. Для этого есть визуализация, называемая корреляционная матрица (corrplot). По «осям» идут переменные, а на пересечении цветом отображается корреляция между переменными. Обычно холодные оттенки используются для положительных значений, а теплые — для отрицательных. Чем интенсивнее оттенок, тем больше значение корреляции. В данном случае на графике отображены корреляции между пунктами отдельной шкалы опросника.\n10.4 Коэффициенты корреляции для разных шкал Выше мы подробно обсудили корреляцию Пирсона и отметили, что этот коэффициент применяется для метрических шкал да ещё и нормально распределенных величин. А что же делать, если в наших данных не так?\n10.4.1 Параметрические и непараметрические критерии Все статистические методы деляться на два типа: параметрические и непараметрические.\nПараметрические методы работают с непосредственно с параметрами распределения исследуемых переменных. Так, для вычисления корреляции Пирсона мы используем среднее и стандартное отклонение. Как следствие, одно из условий применимести таких методов — нормальное распределение изучаемых переменных. Если это требование не выполнено, мы не можем быть достаточно уверены в том, что статистический метод дает надежные результаты — как минимум, потому что сами среднее и стандартное отклонение в случае скошенных распределения не особо хорошо описывают данные. Непараметрические методы не используют в вычислениях собственных статистик параметры распределений. Например, изученный нам хи-квадрат относится к непараметрическим критериям. Они работают либо с частотами, либо в рангами — в зависимости от того, какие переменные мы анализируем. Поэтому если требования нормальности распределения не выполнено, используют методы этой группы. Практически каждый параметрический критерий имеет своего непараметрического собрата. Отметим, что сам статистический вывод в случае непараметрических критериев осуществляется точно так же, как и в случае параметрических.\n10.4.2 Непараметрические коэффициенты корреляции Дла разных шкал разработаны разные коэффициенты корреляции. Оценки коэффициентов будут рассчитываться по-разному, но логика тестирования статистических гипотез остаётся одинаковой.\nПеременная\nX Переменная\nY Мера связи Интервальная или отношений Интервальная или отношений Корреляция Пирсона Ранговая, интервальная или отношений Ранговая, интервальная или отношений Корреляция Спирмена Ранговая Ранговая Корреляция Кенделла У непараметрических критериев формулы несколько зубодробительны, поэтому оставим их покоиться с миром. В статистическом ПО нужно будет просто выбрать подходящий критерий из предложенных.\n10.5 Другие корреляции Этот раздел для отчаянных. Вас никто об это ни на экзамене, ни, возможно, в жизни не спросит.\nМожно коррелировать не только количественные и ранговые шкалы между собой, но и качественные тоже:\nПеременная\nX Переменная\nY Мера связи Дихотомическая Дихотомическая\nϕ -коэффициент Дихотомическая Ранговая Рангово-бисериальный коэффициент Дихотомическая Интервальная или отношений Бисериальный коэффициент 10.5.1\nϕ -коэффициент Этот коэффициент позволяет рассчитать корреляцию между двумы дихотомическими шкалами. Он основан на расчёте статистики\nχ 2 . По двум дихотомическим переменным строится, как мы знаем, таблицу сопряженности и рассчитывается\nχ 2 . Далее он нормируется следующим образом, чтобы получить значения от 0 до 1, которые можно интерпретироват аналогично коэффициенту корреляции:\n\n\n11 ϕ\n√ χ 2 N ,\nN — общее количество наблюдений.\n10.5.2 Бисериальный коэффициент корреляции Этот коэффициент используется для вычисления корреляции между количественной ( y ) и категориальной ( x ) шкалой и рассчитывается следующим образом:\n\n\n12 r\n¯ y x 1 − ¯ y x 2 s y √ n 1 n 2 N ( N − 1 ) ,\nгде\n¯ y x 1 — среднее по переменной\ny по элементам группы\nx 1 ,\n¯ y x 2 — среднее по переменной\ny по элементам группы\nx 2 ,\nn 1 — число элементов в группе\nx 1 ,\nn 2 — число элементов в группе\nx 2 ,\nN — общее число элементов.\nВажно отметить, что несмотря на то, что значение коэффициента может быть как положительным, так и отрицательным, это не влияет на интерпретацию. Это одно из исключений из общего правила.\n10.5.3 Рангово-бисериальный коэффициент корреляции Если у нас не количественная, а ранговая шкала, то применяется рангово-бисериальный коэффициент:\n\n\n13 r\n2 ( ¯ x 1 − ¯ x 2 ) N ,\nгде\n¯ x 1 — средний ранг в группе\nx 1 ,\n¯ x 2 — средний ранг в группе\nx 2 ,\nN — общее количество наблюдений.",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Корреляционный анализ</span>"
    ]
  },
  {
    "objectID": "desc-ci.html",
    "href": "desc-ci.html",
    "title": "6  Доверительные интервалы",
    "section": "",
    "text": "7.1 Точечные и интервальные оценки До этого момента мы работали только с точечными оценками. Это такие оценки, которые представляют собой одно число. Например, таковы меры центральной тенденции — медиана, среднее арифметическое — или меры разброса — межквартильный размах, дисперсия, стандартное отклонение. Когда мы рассчитываем каждый из этих показателей мы получаем только одно число. И всё.\nОднако поскольку мы имеет дело со статистическими данными, основные свойства которых это неопределенность и вариативность, нам необходимы, помимо точечных оценок, ещё и интервальные оценки.\nНеопределенность статистических данных означает, что мы никогда не знаем, что мы получим в результате данного конкретного измерения. Во-первых, потому что мы работаем со случайными величинами, а во-вторых, потому что наши измерительные инструменты не идеальны и всегда содержат ошибку измерения.\nВариативность статистических данных говорит нам о том, что наши измерения всегда обладают некоторым разбросом. Во-первых, потому что объекты нашего изучения — люди — разные, а во-вторых, потому наши измерительные инструменты всё ещё не идеальны и всегда содержат ошибку измерения.\nТаким образом, мы не можем быть до конца уверены, что мы получили суперточную оценку изучаемых нами параметров. Даже если мы пользуемся достаточно точными измерительными инструментами, собираем большие выборки и вообще делаем всё, чтобы быть максимально точными и объективными. Возникает необходимость найти какие-то способы выражения нашей неуверенности в точечной оценки параметра генеральной совокупности. Это и есть интервальные оценки — по сути, меры нашей неуверенности.\nЧтобы к ним подойти, нам придется познакомиться с одной важной статистической теоремой.\n7.2 Центральная предельная теорема Пожалуй, сразу бахнем формулировку, а потом будем разбираться, что она означает.\nCумма достаточно большого количества слабо зависимых случайных величин, имеющих примерно одинаковые масштабы (ни одно из слагаемых не доминирует, не вносит в сумму определяющего вклада), имеет распределение, близкое к нормальному.\nИтак, пусть есть некоторый параметр в генеральной совокупности, который асимметрично распределён. Возьмем случай именно асимметричого распределения, чтобы более наглядно увидеть эффект. Допустим, выглядит это как-то так:\nВот такая красивая штука у нас есть в генеральной совокупности. На всякий случай отмечу, то это некоторое теоретическое распределение — вообще-то мы не знаем наверняка, что там в генеральной совокупности творится. Но вот будем думать, что там что-то такое.\nПонятно, что наш параметр, наш параметр, наша случайная величина имеет некоторое среднее и некоторый разброс в генеральной совокупности:\nValue mean 0.4 sd 0.2 Ну, вот какие-то такие.\nЧтобы максимально точно приблизиться к оценке нашего параметра — будем оценивать среднее генеральной совокупности — нам надо извлечь много больших выборок из нашей генеральной совокупности. Ну, допустим мы извлекаем 1000 выборок по 50 наблюдений. Можно и больше, но давайте посмотрим пока, что будет на таких значениях.\nПосмотрим на распределения нашей переменной в нескольких из выборок:\nВот распределения в первых шестнадцати выборках. На что здесь стоит обратить внимание?\nОт выборки к выборки распределения отличаются. Причем достаточно сильно — где-то распределение больше похоже на нормальное, где-то оно более асимметричное, где-то менее, где-то вообще напоминает равномерное. Это мы в живую увидели вариативность и неопределенность. Каждая из выборок характеризуется каким-то своим средним и каким-то своим разбросом. Вот таблица: Sample Mean SD 1 0.4202292 0.2044323 2 0.3892443 0.2037850 3 0.3861993 0.2224778 4 0.3774064 0.1952898 5 0.4172960 0.2081190 6 0.3616459 0.2052460 7 0.4703232 0.2111924 8 0.4075789 0.2011449 9 0.4141822 0.2018535 10 0.4245290 0.2087136 11 0.3893637 0.1911761 12 0.3778744 0.1983516 13 0.4130055 0.2144898 14 0.3661605 0.1807597 15 0.3956731 0.1963239 16 0.3860937 0.2003544 Видимо, что есть некоторая вариативность выборочных средних. Но раз у нас есть 1000 выборок — а значит и 1000 средних — мы можем построить распределение выборочных средних.\nМы получили распределение выборочных средних значений, которое хотя и не очень похоже на нормальное в данном конкретном случае, но как минимум стало почти симметричным! Вот об этом и говорит центральная предельная теорема.\nБолее того, если мы посчитаем среднее и стандартное отклонение данного распределения, мы получим следующее:\nValue mean 0.3995205 sd 0.0285545 Обратите внимание, на сколько точную оценку генерального среднего мы получили! Да еще и такой ничтожный разброс! Ну, красота!\nТакже нужно обратить внимание еще на две важные детали:\nчем большее количество выборок мы наберем, тем ближе распределение будет к нормальном и тем более точную оценку среднего мы получим чем большее количество наблюдений будет в отдельной выборке, тем ближе распределение будет к нормальном и тем более точную оценку среднего мы получим Увидеть, как это работает, можно здесь.\nИтак, независимо от того, какое распределение переменной есть в генеральной совокупности, при извлечении достаточно большого количества выборок достаточно большого объема мы можем получить очень точную оценку среднего генеральной совокупности, а распределение выборочных средних будет стремиться к нормальному.\nС другими параметрами это также работает. Такие вот статистические приколы.\n7.3 Стандартная ошибка среднего Посмотрим на стандартное отклонение выборочных средних (пунктирная линия на графике — среднее выборочных средних, точечные линии — ± одно стандартное отклонение).\nЭто стандартное отклонение имеет собственное название — стандартная ошибка среднего (standard error of mean).\nЭто одна из интервальных оценок для среднего — в пределах\n[ ¯¯¯ ¯ x − s e ( ¯ x ) , ¯¯¯ ¯ x + s e ( ¯ x )] 1 лежит 68.2% выборочных средних.\nЗадумаемся. Это что же, чтобы рассчитать стандартную ошибку среднего нам каждый раз придется собирать 100500 выборок??7? Нет. Рассчитать стандартную ошибку среднего можно и по одной выборке вот так:\ns e ( x ) = s d ( x ) √ n ,\nгде\ns d ( x ) — это выборочное стандартное отклонение, а\nn — количество наблюдений в данной выборке.\nФормула, прямо скажем, не то чтобы очень интуитивна, однако вам придется мне поверить, что она верна.\nЯ недоверчив(а) Стандартная ошибка используется и сама по себе как одна из описательных статистик. Однако также на её основе рассчитывается другая интервальная оценка.\n7.4 Доверительные интервалы Еще раз вспомним о том, что стандартная ошибка — это не что иное как стандартное отклонение [выборочных средних]. Также вспомним, что главой ранее мы определяли, с какой вероятностью лежит значение нашей случайной величины в пределах скольких-либо стандартных отклонений. Это вот эта картинка (здесь z-распределение):\nМожем ли мы через стандартное отклонение выразить такой интервал, в котором будет лежать, скажем, 95% значений величины? Да.\nНа стандартном нормальной распределении это будет интервал\n[ − 1.96 , 1.96] . А чтобы перейти к размерности интересующей нас переменной, надо выполнить преобразование, обратное стандартизации — умножить на стандартное отклонение и прибавить/вычесть среднее. То есть, интервал, в котором с вероятностью 0.95 будут лежать значения распределения выборочных средних будет таков —\n[ ¯ x − 1.96 × s e , ¯ x + 1.96 × s e] .\nЭтот интервал называется 95%-ный доверительный интервал (95% confidence interval, 95% CI). Он является второй интервальной оценкой среднего и мерой нашей неуверенности относительно точности оценки среднего генеральной совокупности.\nВообще можно рассчитать любой доверительный интервал, который вам захочется, однако самые популярные варианты — это 90%, 95% и 99%. Выражаются через стандартную ошибку они так:\n90 % : ¯ x ± 1.645 × s e 95 % : ¯ x ± 1.96 × s e 99 % : ¯ x ± 2.576 × s e\nНаиболее широко в социальных науках используется 95%-ный. Им и будем пользоваться.\n7.4.1 Интерпретация границ доверительного интервала Теперь еще одна непростая задача — понять, что значит этот интервал.\nГлядя на график распределения выборочных средних, хочется сказать, что генеральное среднее лежит в граница 95%-ного доверительного интервала (вертикальные линии) с вероятностью 0.95.\nНо это не верно!!!\nЗдесь мы вплотную подошли к тестированию статистических гипотез. Неприятность в том, что мы живем во фреквентистском подходе. Подробнее мы будем говорить об этом в следующей главе, а пока же попытаемся смириться с тем, что в даннм подходе расчеты, полученные на конкретных данных, позволяют нам говорить только о том, что будет происходит далее, если мы будем извлекать новые выборки и пользоваться теми же расчетами.\nДавайте на примере самого доверительного интервала. Корректная статистическая интерпретация звучит так:\nЕсли мы будет бесконечно извлекать новые выборки из генеральной совокупности, рассчитывать на них средние и 95% доверительные интервалы к ним, то генеральное среднее попадёт в границы 95% таких доверительных интервалов.\nТо есть, если мы извлечем 100 выборок, посчитаем на каждой из них среднее и построим 95% доверительный интервал к каждому из 100 средних, то 95 доверительных интервалов из 100 будут содержать генеральное среднее — а 5 интервалов содержать его не будут.\nВизуализацию этого можно наблюдать здесь.\nКорректная статистическая интерпретация, конечно, корректная, однако трудноусваемая и сложноприменяемая в жизни. Попробуем сделать её более осязаемой. Есть два путя.\nСамый простой, но крайне некорректный. Если, ну, прям ваще никак не получается уложить статистическую интерпретацию, то можно думать о доверительном интервале так: «генеральное среднее, скорее всего, лежит где-то в этих пределах». Однако в приличных местах об этом говорить никому не стоит. И даже когда соберетесь прибегнуть к такой интерпретации, обязательно сначала вспомните, что она некорректная! Более корректный вариант. К подобной интерпретации также есть некоторые вопросы, однако по крайней мере она обоснована симуляциями. Дело в том, что статистики задались вопросом — а какова все же вероятность, что генеральное среднее попадет вот в этот конкретный рассчитанный нами здесь и сейчас доверительный интервал. Насимулировали там всякого и пришли к выводу, что эта вероятность равна 84.3%. Эту величину назвали capture percentage — то есть отдельный 95% доверительный интервал «ловит» генеральной среднее 843 раза из 1000. Конечно, я всячески рекомендую помедитировать над статистически корректной интерпретаций доверительного интервала и попробовать её осознать, позалипав на визуализацию. Если же это пока trudnovato, постарайтесь осмыслить второй вариант с capture percentage.\n7.4.2 Доверительный интервал и сравнение средних Чем нам может помочь интервальная оценка при поиске различий между группами? Посмотрим на возможные ситуации. Пусть у нас есть средние и доверительные интервалы к ним в двух группах наблюдений — например, балл по шкале депрессии HADS у жителей Москвы и Петербурга.\nПервоначально попробуем выяснить, справедливо ли утверждение «у жителей столиц нет клинически выраженной депрессии». Для этого необходимо, чтобы средний балл был меньше 11. Рассмотрим картинки.\nМы наблюдаем, что в случае Москвы интересующее нас значение 11 не попадает в доверительный интервал, в то время как в случае Петербурга — попадает. Поскольку доверительный интервал отображает нашу неуверенность в том, что наше выборочное среднее отражает генеральное среднее, для нас все значения в пределах доверительного интервала статистически равны между собой. Таким образом, так как 11 не попадает в 95%-ный доверительный интервал для Москвы, мы можем на уровне доверия 0.95 сказать, что средний уровень депрессии жителей Москвы ниже порога клинически выраженной депрессии. Про петербуржцев такого сказать не получится, так как 11 попало в доверительный интервал для Петербурга — а значит, средний уровень депресии 8.5 статистически равен 11, хотя по абсолютному значению ниже. Такая вот статистическая магия.\nЕще раз:\nесли некоторое число попадает в доверительный интервал для выборочного среднего, то мы говорим, что среднее статистически не отличается от этого числа — даже если по абсолютным значениям разница существенна; если некоторое число не попадает в доверительный интервал для выборочного среднего, то мы говорим, что среднее статистически отличается от этого числа — и больше или меньше в зависимости от абсолютных значений. Однако сравнивать выборочное среднее с некоторым числом — крайне маргинальная задача. Обычно мы сравниваем две группы между собой. Посмотрим на ситуации, которые принципиально возможны при сравнении средних в двух группах.\nПо оси\nx — группы наблюдений, по оси\ny — значение интересующей нас переменной. Видим четыре возможные ситуации:\nА — каждое среднее попадает в доверительный интервал другого среднего B — одно среднее попадает в доверительный интервал другого среднего, а второе — не попадает в данном случае, среднее второй группы попадо в доверительный интервал среднего первой группы, в то время как среднее первой группы лежит за границами доверительного интервала среднего второй группы С — ни одно из средних не попало в доверительный интервал другого среднего но мы видим пересечение доверительных интервалов D — доверительные интервалы не пересекаются, следовательно, ни одно из средних не попало в доверительный интервал другого среднего Исходя из рассуждений выше, можно отметить, что если хотя бы одно среднее попало в доверительный интервал другого — случаи A и B — то различий между группами нет. А вот если среднии не попадают в доверительные интервал друг друга — случаи C и D — то различия между группами есть.\nТакие дела.\n7.4.3 Связь доверительного интервала с разбросом и объемом выборки Так как доверительный интервал рассчитывается на основе стандартной ошибки, которая в свою очередь рассчитывается на основе стандартного отклонения и числа наблюдений, нетрудно заметить, что:\nЧем выше разброс в данных, тем будет шире доверительный интервал [так как больше стандартная ошибка] Чем больше наблюдений в нашей выборке, тем будет уже доверительный интервал [так как меньше стандартная ошибка] На этом — ура! — мы заканчиваем изучение описательной статистики! Впереди нас ждёт знакомство со статистическим выводом!",
    "crumbs": [
      "Описательная статистика",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Доверительные интервалы</span>"
    ]
  },
  {
    "objectID": "infer-anovaII.html",
    "href": "infer-anovaII.html",
    "title": "11  Многофакторный дисперсионный анализ",
    "section": "",
    "text": "11.1 $ANOVA\nОкей, мы разобрались с одним фактором. А что делать если у нас несколько независимых переменных? Ну, раз есть однофакторный дисперсионный, значит должен быть и многофакторный! Попробуем разобраться.\n12.1 Усложняем э-э-эксперимент Итак, в предыдущем варианте мы изучали, как валентность стимула связана со скоростью его опознания на задаче лексического решения. Во-первых, давайте сделаем так, чтобы каждый испытуемый проходил все экспериментальные условия, и таким образом посмотрим на дисперсионный анализ с повторными измерениями (repeated measures ANOVA, rmANOVA). Во-вторых, кроме валентности — положительной, отрицательной и нейтральной — важной характеристикой стимула с точки зрения исследования эмоций является ещё и arousal — степень выраженности эмоции от стимула (обычно переводят как «возбуждение», хотя, кажется, «интенсивность» по смыслу ближе). Оба перевода так себе, поэтому будем использовать термин «эраузал» — такие мы модные, шо жесть просто. Пусть у нас есть стимулы с высоким эраузалом и с низким эраузалом. Итого, нам эксперимент будет выглядеть как-то так:\nЗП — время реакции НП1 — валентность: три уровня — нейтральные, негативные, позитивные НП2 — эраузал: два уровня — низкий и высокий С точки зрения дисперсионного анализа у нас два фактора и одна зависимая переменная. Гениально.\nТак, стоп — если у нас два фактора, можно ли провести два однофакторных анализа и успокоиться?\nМожно. Нужно ли так делать?\nНе нужно.\n12.2 Взаимодействие факторов\nДело в том, что нам надо осмыслять картину происходящего как целое — во славу гештальта! — так как факторы могут взаимодействовать друг с другом. Получается, что в случае многофакторного дисперсионного анализа у нас появляются два эффекта:\nосновной эффект фактора — интерпретируется аналогично тому, как это делалось в однофакторном дисперсионном анализе эффект взаимодействия факторов — говорит нам о том, что влияние одного фактора на зависимую переменную различается на разных уровнях другого фактора. Посмотрим на картинки. Пусть есть два фактора A и B и какая-то зависимая переменная. Возможны следующие ситуации:\nВообще значимое взаимодействие факторов — это двоякая штука. С одной стороны, мы обнаружили интересную закономерность — возможно, именно ту, которую искали, и c’est cool. С другой стороны, взаимодействие,\nво-первых, может маскировать главные эффекты — если мы смотрим только на главные эффекты, то теряем часть информации о закономерности во-вторых, и это связано с первым пунктом, оно затрудняет интерпретацию основных эффектов.\nЕсли взаимодействие не значимо, то с интерпретацией главных эффектов трудностей не возникает. Если взаимодействие значимо, то обсуждать главнные эффекты необходимо аккуратно, или не обсуждать вовсе. В частности, нижний ряд рисунков выше показывает, как эффект фактора A частично маскирует эффект фактора B, что отражается во взаимодействии.\nКонечно, в модель можно ввести и более двух факторов, и логика тестирования статистической значимости останется, как и всегда, та же самая. Но помните, что чем сложнее модель, тем сложнее её интерпретация. А интерпретируя взаимодействие трёх предикторов вовсе можно сойти с ума.\nВ связи с этим, есть следующий момент. Когда вы планируете ваше исследование, сразу подумайте, как вы будете анализировать данные — что будет входить в модель в качестве основных предикторов, что в качестве ковариат, и какие взаимодействия в ней будут. Иначе измерить кучу переменных вы построите модель, результаты которой невозможно будет понять. Дизайн исследования очень тесно связан с аналитикой.\n12.3 Результаты многофакторного дисперсионного анализа и тестирование значимости факторов и взаимодействий Таблица результатов многофакторного анализа невероятно похожа на то, что было в однофакторном анализе, только строк чуть побольше, потому что факторов побольше:",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Многофакторный дисперсионный анализ</span>"
    ]
  },
  {
    "objectID": "infer-anovaII.html#effect-dfn-dfd-f-p-p.05-ges",
    "href": "infer-anovaII.html#effect-dfn-dfd-f-p-p.05-ges",
    "title": "11  Многофакторный дисперсионный анализ",
    "section": "11.2 Effect DFn DFd F p p<.05 ges",
    "text": "11.2 Effect DFn DFd F p p&lt;.05 ges",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Многофакторный дисперсионный анализ</span>"
    ]
  },
  {
    "objectID": "infer-anovaII.html#valency-2-118-12.416635-1.276747e-05-0.064098306",
    "href": "infer-anovaII.html#valency-2-118-12.416635-1.276747e-05-0.064098306",
    "title": "11  Многофакторный дисперсионный анализ",
    "section": "11.3 2 valency 2 118 12.416635 1.276747e-05 * 0.064098306",
    "text": "11.3 2 valency 2 118 12.416635 1.276747e-05 * 0.064098306",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Многофакторный дисперсионный анализ</span>"
    ]
  },
  {
    "objectID": "infer-anovaII.html#arousal-1-59-2.873217-9.533691e-02-0.008412731",
    "href": "infer-anovaII.html#arousal-1-59-2.873217-9.533691e-02-0.008412731",
    "title": "11  Многофакторный дисперсионный анализ",
    "section": "11.4 3 arousal 1 59 2.873217 9.533691e-02 0.008412731",
    "text": "11.4 3 arousal 1 59 2.873217 9.533691e-02 0.008412731",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Многофакторный дисперсионный анализ</span>"
    ]
  },
  {
    "objectID": "infer-anovaII.html#valencyarousal-2-118-4.742011-1.045078e-02-0.028560826",
    "href": "infer-anovaII.html#valencyarousal-2-118-4.742011-1.045078e-02-0.028560826",
    "title": "11  Многофакторный дисперсионный анализ",
    "section": "11.5 4 valency:arousal 2 118 4.742011 1.045078e-02 * 0.028560826",
    "text": "11.5 4 valency:arousal 2 118 4.742011 1.045078e-02 * 0.028560826",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Многофакторный дисперсионный анализ</span>"
    ]
  },
  {
    "objectID": "infer-anovaII.html#section",
    "href": "infer-anovaII.html#section",
    "title": "11  Многофакторный дисперсионный анализ",
    "section": "11.6 ",
    "text": "11.6",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Многофакторный дисперсионный анализ</span>"
    ]
  },
  {
    "objectID": "infer-anovaII.html#mauchlys-test-for-sphericity",
    "href": "infer-anovaII.html#mauchlys-test-for-sphericity",
    "title": "11  Многофакторный дисперсионный анализ",
    "section": "11.7 $Mauchly's Test for Sphericity",
    "text": "11.7 $Mauchly's Test for Sphericity",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Многофакторный дисперсионный анализ</span>"
    ]
  },
  {
    "objectID": "infer-anovaII.html#effect-w-p-p.05",
    "href": "infer-anovaII.html#effect-w-p-p.05",
    "title": "11  Многофакторный дисперсионный анализ",
    "section": "11.8 Effect W p p<.05",
    "text": "11.8 Effect W p p&lt;.05",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Многофакторный дисперсионный анализ</span>"
    ]
  },
  {
    "objectID": "infer-anovaII.html#valency-0.9829358-0.6070562",
    "href": "infer-anovaII.html#valency-0.9829358-0.6070562",
    "title": "11  Многофакторный дисперсионный анализ",
    "section": "11.9 2 valency 0.9829358 0.6070562",
    "text": "11.9 2 valency 0.9829358 0.6070562",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Многофакторный дисперсионный анализ</span>"
    ]
  },
  {
    "objectID": "infer-anovaII.html#valencyarousal-0.9420687-0.1771719",
    "href": "infer-anovaII.html#valencyarousal-0.9420687-0.1771719",
    "title": "11  Многофакторный дисперсионный анализ",
    "section": "11.10 4 valency:arousal 0.9420687 0.1771719",
    "text": "11.10 4 valency:arousal 0.9420687 0.1771719",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Многофакторный дисперсионный анализ</span>"
    ]
  },
  {
    "objectID": "infer-anovaII.html#section-1",
    "href": "infer-anovaII.html#section-1",
    "title": "11  Многофакторный дисперсионный анализ",
    "section": "11.11 ",
    "text": "11.11",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Многофакторный дисперсионный анализ</span>"
    ]
  },
  {
    "objectID": "infer-anovaII.html#sphericity-corrections",
    "href": "infer-anovaII.html#sphericity-corrections",
    "title": "11  Многофакторный дисперсионный анализ",
    "section": "11.12 $Sphericity Corrections",
    "text": "11.12 $Sphericity Corrections",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Многофакторный дисперсионный анализ</span>"
    ]
  },
  {
    "objectID": "infer-anovaII.html#effect-gge-pgg-pgg.05-hfe-phf",
    "href": "infer-anovaII.html#effect-gge-pgg-pgg.05-hfe-phf",
    "title": "11  Многофакторный дисперсионный анализ",
    "section": "11.13 Effect GGe p[GG] p[GG]<.05 HFe p[HF]",
    "text": "11.13 Effect GGe p[GG] p[GG]&lt;.05 HFe p[HF]",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Многофакторный дисперсионный анализ</span>"
    ]
  },
  {
    "objectID": "infer-anovaII.html#valency-0.9832221-1.467099e-05-1.0168281-1.276747e-05",
    "href": "infer-anovaII.html#valency-0.9832221-1.467099e-05-1.0168281-1.276747e-05",
    "title": "11  Многофакторный дисперсионный анализ",
    "section": "11.14 2 valency 0.9832221 1.467099e-05 * 1.0168281 1.276747e-05",
    "text": "11.14 2 valency 0.9832221 1.467099e-05 * 1.0168281 1.276747e-05",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Многофакторный дисперсионный анализ</span>"
    ]
  },
  {
    "objectID": "infer-anovaII.html#valencyarousal-0.9452410-1.186789e-02-0.9755722-1.106044e-02",
    "href": "infer-anovaII.html#valencyarousal-0.9452410-1.186789e-02-0.9755722-1.106044e-02",
    "title": "11  Многофакторный дисперсионный анализ",
    "section": "11.15 4 valency:arousal 0.9452410 1.186789e-02 * 0.9755722 1.106044e-02",
    "text": "11.15 4 valency:arousal 0.9452410 1.186789e-02 * 0.9755722 1.106044e-02",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Многофакторный дисперсионный анализ</span>"
    ]
  },
  {
    "objectID": "infer-anovaII.html#phf.05",
    "href": "infer-anovaII.html#phf.05",
    "title": "11  Многофакторный дисперсионный анализ",
    "section": "11.16 p[HF]<.05",
    "text": "11.16 p[HF]&lt;.05",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Многофакторный дисперсионный анализ</span>"
    ]
  },
  {
    "objectID": "infer-anovaII.html#section-2",
    "href": "infer-anovaII.html#section-2",
    "title": "11  Многофакторный дисперсионный анализ",
    "section": "11.17 2 *",
    "text": "11.17 2 *",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Многофакторный дисперсионный анализ</span>"
    ]
  },
  {
    "objectID": "infer-anovaII.html#section-3",
    "href": "infer-anovaII.html#section-3",
    "title": "11  Многофакторный дисперсионный анализ",
    "section": "11.18 4 *",
    "text": "11.18 4 *\nМы видим знакомую нам таблицу результатов дисперсионного анализа, где есть F-стастика и p-value. Статистический вывод осуществляется так же, как и обычно. В данном случае мы видим, что фактор валентности стистически значим, как и в предыдущем анализе, фактор эраузала — не значим, а вот их взаимодействие значимо. Ну, давайте нарисуем картинку, чтобы попытаться понять, что происходит.\nНу, вот как-то так — явственно явлено взаимодействие предикторов.\n12.4 Условия применения дисперсионного анализа с повторными измерениям Здесь их меньше, потому что допущения о независимости наблюдений между группами, очевидно, не выполнено.\nКоличественная непрерывная зависимая переменная Нормальное распределение признака в статистических совокупностях, из которых извлечены выборки. Сферичность данных Проверяется с помощью теста Моучли (Mauchly test) 12.4.1 Сферичность Как можно заметить, в списке нет допущения об гомогенности дисперсий — ведь у нас одна выборка, с которой мы получаем несколько измерений. В случае дисперсионного анализа с повторными измерениями проверяется предположение о сферичности данных (sphericity).\nСферичность — это модель данных, согласно которой дисперсии разностей между всеми парами уровней фактора равны. Нарушение допущение о сферичности — то есть отсутствие равенства дисперсий между парами уровней фактора — является серьезной проблемой для rmANOVA, так как при этом тест становится слишком либеральным, то есть увеличение вероятность ошибки I рода.\nК нашему счастью, если есть нарушение сферичности данных, то машина сама нам об этом сообщит, а также применит необходимые поправки, чтобы избежать рост вероятности ошибки I рода. Формулы смотреть не будет, потому что их все равно никто не знает.\n12.5 Типы сумм квадратов Когда у нас в анализе появляется несколько факторов, мы можем тестировать их значимость различными способами. Способ тестирования определяет типа сумм квадратов, которых существует три.\nПервый (I) тип сумм квадратов проводит последовательные тесты значимости факторов. Величина эффекта фактора зависит от объёма выборки. Кроме того, результат вычислений зависит от порядка включения факторов в модель, что не оч хор. Второй (II) тип сумм квадратов проводит иерархические тесты, поэтому в этом случае результаты не зависят от порядка включения факторов в модель, однако величина эффекта все ещё зависит от объема выборки. Третий (III) тип сумм квадратов проводит частные тесты. К данному подходу есть некоторые статистические вопросы, однако результаты в этом случае не зависят ни от порядка включения факторов в модель, ни от объёма выборки. По этой причине данный тип используют в случае несбалансированных данных, когда объемы групп по факторам различаются. Вероятно, и это вполне нормально, что про суммы квадратов сейчас ничего не понятно. Это ожидаемо и приемлемо, поскольку там надо немного глубоко копнуть в происходящее. Сейчас надо запомнить вот что:\nЕсли у нас экспериментальный дизайн исследования, то мы, во-первых, на уровне планирования исследования делаем всё возможное, чтобы группы были уравнены, а также у нас, как правило, есть возможность добрать испытуемых, если в какой-то из групп из не хватает. Тогда мы по умолчанию используем II тип суммы квадратов. Если же у нас опросниковое исследование или такой дизайн, где респонденты разбиваются на группы post factum, мы не можем гарантировать, что эти группы окажутся равными по численности. В этом случае нам может помочь III типа суммы квадратов.",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Многофакторный дисперсионный анализ</span>"
    ]
  },
  {
    "objectID": "infer-posthoc.html",
    "href": "infer-posthoc.html",
    "title": "12  Post hoc тесты",
    "section": "",
    "text": "Что ж, мы попытались разобраться в одном из самых часто используемых и полезных методов статистического анализа — дисперсионном анализе — и сделаем вид, что что-то поняли. Однако задумаемся вот над чем:\nдисперсионный анализ позволяет протестировать статистическую значимость связи между фактором и зависимой переменной технически это выражается в поиске различий между группами, на которые делится категориальной переменной наша выборка [наблюдений] статистическая значимость фактора говорит нам о том, что между какими-то группами есть различия но между какими именно??? Этот вопрос остается открытым и на него надо как-то ответить.\n13.1 Попарные сравнения Для того, чтобы ответить на этот вопрос, нам придется сравнивать все группы [наблюдений] друг с другом. Этот процесс называется попарные сравнения (pairwise comparison). Выполняются они довольно просто — с обычно помощью t-теста. Однако здесь есть одна важная деталь, о которой нам необходимо поговорить.\nСтоп, а если мы все равно сравниваем все группы друг с другом, зачем нам вообще дисперсионный анализ? Вопрос справелив. Однако обо всем по порядку. Начнем с нашей любимой ошибки первого рода.\n13.1.1 Проблема множественных сравнений Итак, мы сравниваем попарно все группы наблюдений между собой. В каждом сравнении мы фиксируем вероятность ошибки первого рода с помощью уровня значимости на уровне\n0.05 . А какова будет вероятность ошибки, если мы проводим несколько сравнений?\nСчитаем, что наши сравнения независимы, поэтому вероятности будут перемножаться1. Если верояность ошибиться в одном сравнении равна\nα , то вероятность сделать правильный вывод —\n1 − α . Тогда вероятность сделать правильный вывод в\nm сравнения —\n( 1 − α ) m . Отсюда мы можем вывести вероятность ошибиться хотя бы в одном сравнении:\nP ′ = 1 − ( 1 − α ) m\nПусть у нас есть три группы, которые нам надо сравнить друг с другом — получается необходимо провести три сравнения. Итого вероятность ошибиться получается:\nP ′ = 1 − ( 1 − 0.05 ) 3 ≈ 0.143\nЗначительно больше, чем\n0.05 , что нехорошо. И дальше только хуже. Поэтому нам надо либо корректировать уровень значимости, либо использовать мощные методы типа дисперсионного анализа.\n13.1.2 Корректировка уровня значимости Корректировать уровень значимости можно по-разному. Например, можно разделить\nα на количество попарных сравнений — такой способ называется поправкой Бонферрони (Bonferroni):\nα ′ = α n ,\nгде\nn — число попарных сравнений.\nПоправка Бонферрони считается самой консервативной поправкой — она достаточно сильно уменьшает уровень значимости, и мы можем не поймать искомую закономерность, то есть совершить ошибку второго рода2. Поэтому придумали более либеральные поправки, например, поправку Холма (Холма–Бонферрони, Holm) или поправку Тьюки (Tukey’s HSD test). Можно посмотреть на их формулы, но в целом, не обяз, потому что их все равно никто не знает, а в статистических пакетах мы либо допишем аргумент в функцию, либо нужную галку поставим.\nНа практике в силу того, что в статистических пакетах мы работаем с p-value, корректируется именно его значение.\nПо достаточно незамысловатой логике Таким образом, мы просто сравниваем уже скорретированное p-value, которое нам считает комплюхтер, с тем же самым\nα = 0.05 . Жизнь становится значительно проще и приятнее.\n13.1.3 Дисперсионный анализ и проблема множественных сравнений Использование методов типа дисперсионного анализа, которые позволяют проверить наличие статистическую значимость фактора в целом помогает следующим образом:\nесли фактор статистически НЕ значим, мы НЕ проводим попарные сравнения по группам, на которые он делит нашу выборку — различий между группами все равно не будет если фактор статистически значим, мы проводим попарные сравнения по группам, на которые он делит нашу выборку, чтобы узнать, между какими группами есть различия Особенно сильно это помогает в случае взаимодействия факторов, так как там может быть невероятное количество попарных сравнений3.\n13.2 Двухвыборочный t-тест С уровне значимости разобрались — теперь к самому статистическому тесту. Задача такова: протестировать гипотезу о том, что между двумя группами наблюдений нет различий, то есть:\nH 0 : μ 1 = μ 2 H 1 : μ 1 ≠ μ 2\nГипотезы сформулировали. Выбираем статистический критерий. Он таков:\n\n13 t\n¯ x 1 − ¯ x 2 √ s 2 1 n 1 + s 2 1 n 2\nЭта статистистика при справедливости нулевой гипотезы подчиняется t-распределению (распределению Стьюдента) с числом степеней свободы, рассчитывающимся по очень страшной формуле.\nВот такой Напоминаю, что t-распределение выглядит так:\nДалее мы рассчитываем статистику критерия — значение t, потом рассчитываем для него p-value, корректируем сообразно выбранному способу корректировки, и сравниваем с уровнем значимости\nα .\nИ, как обычно, по неизменному ни при каких обстоятельствах алгоритму, делаем вывод:\nЕсли p-value\n&lt; α , то мы получаем значение t-статистики, не характерное для случая, когда нулевая гипотеза верна, что даёт нам основания отклонить нулевую гипотезу об отсутствии различий между группами и принять альтернативную, о том, что хотя бы между двумя какими-либо группами есть различия. Если p-value\n&gt; α , то мы получаем значение t-статистики, характерное для случая, когда нулевая гипотеза верна, что не даёт нам оснований отклонить нулевую гипотезу об отсутствии различий между группами. Двухвыборочный t-тест пригоден, если наши выборки независимы. Если же у нас связанные, или зависимые, выборки, то нам необходим t-тест для зависимых выборок.\n13.3 Парный t-тест Он даже попроще. Или нет.\nГипотеза та же:\nH 0 : μ 1 = μ 2 H 1 : μ 1 ≠ μ 2\nСтатистика другая:\n\n\n14 t\nM d s d √ n ,\nгде\nM d = 1 n ∑ n i = 1 ( x i 1 − x i 2 ) ,\ns d = √ 1 n − 1 ∑ n i = 1 ( M d − ( x i 1 − x i 2 ) ) 2 .\nЭта статистистика при справедливости нулевой гипотезы подчиняется t-распределению (распределению Стьюдента) с числом степеней свободы\nn − 1 .\nСтатистический вывод идентичен предыдущем случаю.\n13.4 Че за post hoc? Итак, с помощью t-теста мы попарно сравниваем группы по фактору, который в дисперсионном анализе оказался статистически значимым, чтобы узнать, между какими группами есть различия.\nЗачем это нужно? Статистическая значимость фактора не обязывает все группы различаться между собой — может случиться так, что разница есть только между двумя из трех, или двумя из четырех групп. Это надо узнать, чтобы мы могли корректно интерпретировать результаты с точки зрения теории, которая стоит за нашим исследованием.\nЕсли в дисперсионном анализе участвуют только две группы — то есть фактор содержит два уровня — ничего дополнительно тестировать не нужно!\nДанный анализ незывается post hoc analysis или post hoc tests (от лат. post hoc — ‘after this’, ‘after this event’), так как мы проводим его после того, как провели основной анализ другим методом. Такие дела.\n13.5 t-тест — сильный и независимый Вообще t-тест может быть и самостоятельным методом статистического анализа, если у вас в исследовании только две группы наблюдений. Или вы выборочно сравниваете какие-то условия, которые вас интересуют, при сложном дизайне. Или вы проверяете какие-то группы на эквивалетность по каким либо параметрам. В общем, t-тест молодец-красавчик — и сам по себе тоже существует, но и другим статистическим методам помогает.\nОб этом нам рассказала теорема умножения вероятностей, которая гласит, что вероятность пересечения независимых событий равна произведению вероятностей этих событий.↩︎\nПомним, что при стремлении вероятности ошибки первого рода к нулю, вероятность ошибки второго рода стремиться к единице.↩︎\nДопустим для двух факторов с тремя уровнями количество групп будет\n3 × 3 = 9 , а количество попарных сравнений —\nn ( n − 1 ) 2 = 9 ⋅ 8 2 = 36 !↩︎",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Post hoc тесты</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html",
    "href": "infer-ancova.html",
    "title": "15  Ковариационный анализ",
    "section": "",
    "text": "15.1 # A tibble: 654 × 6\nВообще-то мы это уже сделали, просто не заметили.\nНачнём в этот раз с данных1.",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#id-age-fev-height-sex-smoker",
    "href": "infer-ancova.html#id-age-fev-height-sex-smoker",
    "title": "15  Ковариационный анализ",
    "section": "15.2 ID Age FEV Height Sex Smoker",
    "text": "15.2 ID Age FEV Height Sex Smoker",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#section",
    "href": "infer-ancova.html#section",
    "title": "15  Ковариационный анализ",
    "section": "15.3      ",
    "text": "15.3",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#female-non",
    "href": "infer-ancova.html#female-non",
    "title": "15  Ковариационный анализ",
    "section": "15.4 1 301 9 1.71 57 Female Non",
    "text": "15.4 1 301 9 1.71 57 Female Non",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#female-non-1",
    "href": "infer-ancova.html#female-non-1",
    "title": "15  Ковариационный анализ",
    "section": "15.5 2 451 8 1.72 67.5 Female Non",
    "text": "15.5 2 451 8 1.72 67.5 Female Non",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#female-non-2",
    "href": "infer-ancova.html#female-non-2",
    "title": "15  Ковариационный анализ",
    "section": "15.6 3 501 7 1.72 54.5 Female Non",
    "text": "15.6 3 501 7 1.72 54.5 Female Non",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#male-non",
    "href": "infer-ancova.html#male-non",
    "title": "15  Ковариационный анализ",
    "section": "15.7 4 642 9 1.56 53 Male Non",
    "text": "15.7 4 642 9 1.56 53 Male Non",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#male-non-1",
    "href": "infer-ancova.html#male-non-1",
    "title": "15  Ковариационный анализ",
    "section": "15.8 5 901 9 1.90 57 Male Non",
    "text": "15.8 5 901 9 1.90 57 Male Non",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#female-non-3",
    "href": "infer-ancova.html#female-non-3",
    "title": "15  Ковариационный анализ",
    "section": "15.9 6 1701 8 2.34 61 Female Non",
    "text": "15.9 6 1701 8 2.34 61 Female Non",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#female-non-4",
    "href": "infer-ancova.html#female-non-4",
    "title": "15  Ковариационный анализ",
    "section": "15.10 7 1752 6 1.92 58 Female Non",
    "text": "15.10 7 1752 6 1.92 58 Female Non",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#female-non-5",
    "href": "infer-ancova.html#female-non-5",
    "title": "15  Ковариационный анализ",
    "section": "15.11 8 1753 6 1.42 56 Female Non",
    "text": "15.11 8 1753 6 1.42 56 Female Non",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#female-non-6",
    "href": "infer-ancova.html#female-non-6",
    "title": "15  Ковариационный анализ",
    "section": "15.12 9 1901 8 1.99 58.5 Female Non",
    "text": "15.12 9 1901 8 1.99 58.5 Female Non",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#female-non-7",
    "href": "infer-ancova.html#female-non-7",
    "title": "15  Ковариационный анализ",
    "section": "15.13 10 1951 9 1.94 60 Female Non",
    "text": "15.13 10 1951 9 1.94 60 Female Non",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#with-644-more-rows",
    "href": "infer-ancova.html#with-644-more-rows",
    "title": "15  Ковариационный анализ",
    "section": "15.14 # … with 644 more rows",
    "text": "15.14 # … with 644 more rows\nУ нас есть данные об объёме форсированного выдоха (ОФВ) (forced expiratory volume, FEV)2 у курящих и некурящих детей (6–22 лет) и о поле, возрасте, росте и ID пациента.\nПоставим задачу: мы хотим выяснить, влияет ли статус курения на объем формированного выдоха у детей. Ожидаем, что влияет. Однако мы также понимаем, что рост ребенка будет связан с объёмом его лёгких, а значит, и с нашей целевой переменной.\nПостроим соответствующую модель. В качестве целевой переменной возьмем ОФВ (FEV), а в качестве предикторов статус курения (Smoker) и рост (Height), а также их взаимодействие, так как оно может быть потенциально значимо:",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#section-1",
    "href": "infer-ancova.html#section-1",
    "title": "15  Ковариационный анализ",
    "section": "15.15 ",
    "text": "15.15",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#call",
    "href": "infer-ancova.html#call",
    "title": "15  Ковариационный анализ",
    "section": "15.16 Call:",
    "text": "15.16 Call:",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#lmformula-fev-smoker-height-data-ofv",
    "href": "infer-ancova.html#lmformula-fev-smoker-height-data-ofv",
    "title": "15  Ковариационный анализ",
    "section": "15.17 lm(formula = FEV ~ Smoker * Height, data = ofv)",
    "text": "15.17 lm(formula = FEV ~ Smoker * Height, data = ofv)",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#section-2",
    "href": "infer-ancova.html#section-2",
    "title": "15  Ковариационный анализ",
    "section": "15.18 ",
    "text": "15.18",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#residuals",
    "href": "infer-ancova.html#residuals",
    "title": "15  Ковариационный анализ",
    "section": "15.19 Residuals:",
    "text": "15.19 Residuals:",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#min-1q-median-3q-max",
    "href": "infer-ancova.html#min-1q-median-3q-max",
    "title": "15  Ковариационный анализ",
    "section": "15.20 Min 1Q Median 3Q Max",
    "text": "15.20 Min 1Q Median 3Q Max",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#section-3",
    "href": "infer-ancova.html#section-3",
    "title": "15  Ковариационный анализ",
    "section": "15.21 -1.74332 -0.26960 -0.00462 0.23909 2.12941",
    "text": "15.21 -1.74332 -0.26960 -0.00462 0.23909 2.12941",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#section-4",
    "href": "infer-ancova.html#section-4",
    "title": "15  Ковариационный анализ",
    "section": "15.22 ",
    "text": "15.22",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#coefficients",
    "href": "infer-ancova.html#coefficients",
    "title": "15  Ковариационный анализ",
    "section": "15.23 Coefficients:",
    "text": "15.23 Coefficients:",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#estimate-std.-error-t-value-prt",
    "href": "infer-ancova.html#estimate-std.-error-t-value-prt",
    "title": "15  Ковариационный анализ",
    "section": "15.24 Estimate Std. Error t value Pr(>|t|)",
    "text": "15.24 Estimate Std. Error t value Pr(&gt;|t|)",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#intercept--7.40165-1.11228--6.654-6.04e-11",
    "href": "infer-ancova.html#intercept--7.40165-1.11228--6.654-6.04e-11",
    "title": "15  Ковариационный анализ",
    "section": "15.25 (Intercept) -7.40165 1.11228 -6.654 6.04e-11 ***",
    "text": "15.25 (Intercept) -7.40165 1.11228 -6.654 6.04e-11 ***",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#smokernon-2.03678-1.12846-1.805-0.0716-.",
    "href": "infer-ancova.html#smokernon-2.03678-1.12846-1.805-0.0716-.",
    "title": "15  Ковариационный анализ",
    "section": "15.26 SmokerNon 2.03678 1.12846 1.805 0.0716 .",
    "text": "15.26 SmokerNon 2.03678 1.12846 1.805 0.0716 .",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#height-0.16191-0.01685-9.612-2e-16",
    "href": "infer-ancova.html#height-0.16191-0.01685-9.612-2e-16",
    "title": "15  Ковариационный анализ",
    "section": "15.27 Height 0.16191 0.01685 9.612 < 2e-16 ***",
    "text": "15.27 Height 0.16191 0.01685 9.612 &lt; 2e-16 ***",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#smokernonheight--0.03106-0.01713--1.813-0.0703-.",
    "href": "infer-ancova.html#smokernonheight--0.03106-0.01713--1.813-0.0703-.",
    "title": "15  Ковариационный анализ",
    "section": "15.28 SmokerNon:Height -0.03106 0.01713 -1.813 0.0703 .",
    "text": "15.28 SmokerNon:Height -0.03106 0.01713 -1.813 0.0703 .",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#section-5",
    "href": "infer-ancova.html#section-5",
    "title": "15  Ковариационный анализ",
    "section": "15.29 —",
    "text": "15.29 —",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1",
    "href": "infer-ancova.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1",
    "title": "15  Ковариационный анализ",
    "section": "15.30 Signif. codes: 0 ‘’ 0.001 ’’ 0.01 ’’ 0.05 ‘.’ 0.1 ’ ’ 1",
    "text": "15.30 Signif. codes: 0 ‘’ 0.001 ’’ 0.01 ’’ 0.05 ‘.’ 0.1 ’ ’ 1",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#section-6",
    "href": "infer-ancova.html#section-6",
    "title": "15  Ковариационный анализ",
    "section": "15.31 ",
    "text": "15.31",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#residual-standard-error-0.4302-on-650-degrees-of-freedom",
    "href": "infer-ancova.html#residual-standard-error-0.4302-on-650-degrees-of-freedom",
    "title": "15  Ковариационный анализ",
    "section": "15.32 Residual standard error: 0.4302 on 650 degrees of freedom",
    "text": "15.32 Residual standard error: 0.4302 on 650 degrees of freedom",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#multiple-r-squared-0.7549-adjusted-r-squared-0.7538",
    "href": "infer-ancova.html#multiple-r-squared-0.7549-adjusted-r-squared-0.7538",
    "title": "15  Ковариационный анализ",
    "section": "15.33 Multiple R-squared: 0.7549, Adjusted R-squared: 0.7538",
    "text": "15.33 Multiple R-squared: 0.7549, Adjusted R-squared: 0.7538",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#f-statistic-667.3-on-3-and-650-df-p-value-2.2e-16",
    "href": "infer-ancova.html#f-statistic-667.3-on-3-and-650-df-p-value-2.2e-16",
    "title": "15  Ковариационный анализ",
    "section": "15.34 F-statistic: 667.3 on 3 and 650 DF, p-value: < 2.2e-16",
    "text": "15.34 F-statistic: 667.3 on 3 and 650 DF, p-value: &lt; 2.2e-16\nМодель статистически значима, объясняет 75% дисперсии данных. Это очень хорошо.\nВообще-то с точки зрения интерпретации результатов, чем проще модель, тем лучше. Мы видим, что взаимодействие предикторов оказалось статистически незначимым. Посмотрим, влияет ли его удаление на информативность модели:",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#single-term-deletions",
    "href": "infer-ancova.html#single-term-deletions",
    "title": "15  Ковариационный анализ",
    "section": "15.35 Single term deletions",
    "text": "15.35 Single term deletions",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#section-7",
    "href": "infer-ancova.html#section-7",
    "title": "15  Ковариационный анализ",
    "section": "15.36 ",
    "text": "15.36",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#model",
    "href": "infer-ancova.html#model",
    "title": "15  Ковариационный анализ",
    "section": "15.37 Model:",
    "text": "15.37 Model:",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#fev-smoker-height",
    "href": "infer-ancova.html#fev-smoker-height",
    "title": "15  Ковариационный анализ",
    "section": "15.38 FEV ~ Smoker * Height",
    "text": "15.38 FEV ~ Smoker * Height",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#df-sum-of-sq-rss-aic-f-value-prf",
    "href": "infer-ancova.html#df-sum-of-sq-rss-aic-f-value-prf",
    "title": "15  Ковариационный анализ",
    "section": "15.39 Df Sum of Sq RSS AIC F value Pr(>F)",
    "text": "15.39 Df Sum of Sq RSS AIC F value Pr(&gt;F)",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#section-8",
    "href": "infer-ancova.html#section-8",
    "title": "15  Ковариационный анализ",
    "section": "15.40  120.32 -1099.2",
    "text": "15.40  120.32 -1099.2",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#smokerheight-1-0.60843-120.93--1097.9-3.2868-0.0703-.",
    "href": "infer-ancova.html#smokerheight-1-0.60843-120.93--1097.9-3.2868-0.0703-.",
    "title": "15  Ковариационный анализ",
    "section": "15.41 Smoker:Height 1 0.60843 120.93 -1097.9 3.2868 0.0703 .",
    "text": "15.41 Smoker:Height 1 0.60843 120.93 -1097.9 3.2868 0.0703 .",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#section-9",
    "href": "infer-ancova.html#section-9",
    "title": "15  Ковариационный анализ",
    "section": "15.42 —",
    "text": "15.42 —",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1-1",
    "href": "infer-ancova.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1-1",
    "title": "15  Ковариационный анализ",
    "section": "15.43 Signif. codes: 0 ‘’ 0.001 ’’ 0.01 ’’ 0.05 ‘.’ 0.1 ’ ’ 1",
    "text": "15.43 Signif. codes: 0 ‘’ 0.001 ’’ 0.01 ’’ 0.05 ‘.’ 0.1 ’ ’ 1\nЧастный F-критерий показывает, что две модели — со взаимодействием и без него — статистически не отличаются друг от друга. Следовательно, взаимодействие можно удалить из модели.",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#section-10",
    "href": "infer-ancova.html#section-10",
    "title": "15  Ковариационный анализ",
    "section": "15.44 ",
    "text": "15.44",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#call-1",
    "href": "infer-ancova.html#call-1",
    "title": "15  Ковариационный анализ",
    "section": "15.45 Call:",
    "text": "15.45 Call:",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#lmformula-fev-smoker-height-data-ofv-1",
    "href": "infer-ancova.html#lmformula-fev-smoker-height-data-ofv-1",
    "title": "15  Ковариационный анализ",
    "section": "15.46 lm(formula = FEV ~ Smoker + Height, data = ofv)",
    "text": "15.46 lm(formula = FEV ~ Smoker + Height, data = ofv)",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#section-11",
    "href": "infer-ancova.html#section-11",
    "title": "15  Ковариационный анализ",
    "section": "15.47 ",
    "text": "15.47",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#residuals-1",
    "href": "infer-ancova.html#residuals-1",
    "title": "15  Ковариационный анализ",
    "section": "15.48 Residuals:",
    "text": "15.48 Residuals:",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#min-1q-median-3q-max-1",
    "href": "infer-ancova.html#min-1q-median-3q-max-1",
    "title": "15  Ковариационный анализ",
    "section": "15.49 Min 1Q Median 3Q Max",
    "text": "15.49 Min 1Q Median 3Q Max",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#section-12",
    "href": "infer-ancova.html#section-12",
    "title": "15  Ковариационный анализ",
    "section": "15.50 -1.7505 -0.2660 -0.0041 0.2447 2.1207",
    "text": "15.50 -1.7505 -0.2660 -0.0041 0.2447 2.1207",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#section-13",
    "href": "infer-ancova.html#section-13",
    "title": "15  Ковариационный анализ",
    "section": "15.51 ",
    "text": "15.51",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#coefficients-1",
    "href": "infer-ancova.html#coefficients-1",
    "title": "15  Ковариационный анализ",
    "section": "15.52 Coefficients:",
    "text": "15.52 Coefficients:",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#estimate-std.-error-t-value-prt-1",
    "href": "infer-ancova.html#estimate-std.-error-t-value-prt-1",
    "title": "15  Ковариационный анализ",
    "section": "15.53 Estimate Std. Error t value Pr(>|t|)",
    "text": "15.53 Estimate Std. Error t value Pr(&gt;|t|)",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#intercept--5.421300-0.210104--25.803-2e-16",
    "href": "infer-ancova.html#intercept--5.421300-0.210104--25.803-2e-16",
    "title": "15  Ковариационный анализ",
    "section": "15.54 (Intercept) -5.421300 0.210104 -25.803 <2e-16 ***",
    "text": "15.54 (Intercept) -5.421300 0.210104 -25.803 &lt;2e-16 ***",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#smokernon--0.006319-0.058686--0.108-0.914",
    "href": "infer-ancova.html#smokernon--0.006319-0.058686--0.108-0.914",
    "title": "15  Ковариационный анализ",
    "section": "15.55 SmokerNon -0.006319 0.058686 -0.108 0.914",
    "text": "15.55 SmokerNon -0.006319 0.058686 -0.108 0.914",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#height-0.131883-0.003081-42.808-2e-16",
    "href": "infer-ancova.html#height-0.131883-0.003081-42.808-2e-16",
    "title": "15  Ковариационный анализ",
    "section": "15.56 Height 0.131883 0.003081 42.808 <2e-16 ***",
    "text": "15.56 Height 0.131883 0.003081 42.808 &lt;2e-16 ***",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#section-14",
    "href": "infer-ancova.html#section-14",
    "title": "15  Ковариационный анализ",
    "section": "15.57 —",
    "text": "15.57 —",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1-2",
    "href": "infer-ancova.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1-2",
    "title": "15  Ковариационный анализ",
    "section": "15.58 Signif. codes: 0 ‘’ 0.001 ’’ 0.01 ’’ 0.05 ‘.’ 0.1 ’ ’ 1",
    "text": "15.58 Signif. codes: 0 ‘’ 0.001 ’’ 0.01 ’’ 0.05 ‘.’ 0.1 ’ ’ 1",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#section-15",
    "href": "infer-ancova.html#section-15",
    "title": "15  Ковариационный анализ",
    "section": "15.59 ",
    "text": "15.59",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#residual-standard-error-0.431-on-651-degrees-of-freedom",
    "href": "infer-ancova.html#residual-standard-error-0.431-on-651-degrees-of-freedom",
    "title": "15  Ковариационный анализ",
    "section": "15.60 Residual standard error: 0.431 on 651 degrees of freedom",
    "text": "15.60 Residual standard error: 0.431 on 651 degrees of freedom",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#multiple-r-squared-0.7537-adjusted-r-squared-0.7529",
    "href": "infer-ancova.html#multiple-r-squared-0.7537-adjusted-r-squared-0.7529",
    "title": "15  Ковариационный анализ",
    "section": "15.61 Multiple R-squared: 0.7537, Adjusted R-squared: 0.7529",
    "text": "15.61 Multiple R-squared: 0.7537, Adjusted R-squared: 0.7529",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#f-statistic-995.9-on-2-and-651-df-p-value-2.2e-16",
    "href": "infer-ancova.html#f-statistic-995.9-on-2-and-651-df-p-value-2.2e-16",
    "title": "15  Ковариационный анализ",
    "section": "15.62 F-statistic: 995.9 on 2 and 651 DF, p-value: < 2.2e-16",
    "text": "15.62 F-statistic: 995.9 on 2 and 651 DF, p-value: &lt; 2.2e-16\nВнимательно на неё посмотрим. И познакомимся. Ведь мы только что построили модель ковариационного анализа (analysis of covariance, ANCOVA).\n16.1 Модель ковариационного анализа Модель ковариационного анализа — это модель множественной линейной регрессии, в которой отсутствуют взаимодействия дискретных и непрерывных предикторов. Мы можем пойти с другой стороны и сказать, что модель ковариационного анализа — это модель дисперсионного анализа, в которую включён (включены) один или несколько непрерывных предикторов. Непрерывный предиктор называется ковариатой.\nКовариата — это переменная, которая [потенциально] связана с нашей целевой переменной, но её влияние не является целью нашего анализа. Например, в случае, рассмотренном выше, рост — это переменная, которая, несомненно, связана с ОФВ (наша целевая переменная), но эта связь — не наша основная цель, так как мы исследуем влияние статуса курения.\nМатематическая модель ровным счётом та же самая, что мы видели в случае множественной линейной регрессии:\n^ y i = b 0 + b 1 I 1 + b 2 x 2\nЭто самый простой вариант. Здесь\nI 1 — переменная-индикатор, кодирующая категориальный предиктор (принимает значения\n0 и\n1 ), а\nx 2 — ковариата, или непрерывный предиктор. Как можно заметить, взаимодействие в модель не включено.\n16.2 Влияние ковариаты Зачем вообще учитывать ковариаты? Рассмотрим такую модель:",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#section-16",
    "href": "infer-ancova.html#section-16",
    "title": "15  Ковариационный анализ",
    "section": "15.63 ",
    "text": "15.63",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#call-2",
    "href": "infer-ancova.html#call-2",
    "title": "15  Ковариационный анализ",
    "section": "15.64 Call:",
    "text": "15.64 Call:",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#lmformula-fev-smoker-data-ofv",
    "href": "infer-ancova.html#lmformula-fev-smoker-data-ofv",
    "title": "15  Ковариационный анализ",
    "section": "15.65 lm(formula = FEV ~ Smoker, data = ofv)",
    "text": "15.65 lm(formula = FEV ~ Smoker, data = ofv)",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#section-17",
    "href": "infer-ancova.html#section-17",
    "title": "15  Ковариационный анализ",
    "section": "15.66 ",
    "text": "15.66",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#residuals-2",
    "href": "infer-ancova.html#residuals-2",
    "title": "15  Ковариационный анализ",
    "section": "15.67 Residuals:",
    "text": "15.67 Residuals:",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#min-1q-median-3q-max-2",
    "href": "infer-ancova.html#min-1q-median-3q-max-2",
    "title": "15  Ковариационный анализ",
    "section": "15.68 Min 1Q Median 3Q Max",
    "text": "15.68 Min 1Q Median 3Q Max",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#section-18",
    "href": "infer-ancova.html#section-18",
    "title": "15  Ковариационный анализ",
    "section": "15.69 -1.7751 -0.6339 -0.1021 0.4804 3.2269",
    "text": "15.69 -1.7751 -0.6339 -0.1021 0.4804 3.2269",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#section-19",
    "href": "infer-ancova.html#section-19",
    "title": "15  Ковариационный анализ",
    "section": "15.70 ",
    "text": "15.70",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#coefficients-2",
    "href": "infer-ancova.html#coefficients-2",
    "title": "15  Ковариационный анализ",
    "section": "15.71 Coefficients:",
    "text": "15.71 Coefficients:",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#estimate-std.-error-t-value-prt-2",
    "href": "infer-ancova.html#estimate-std.-error-t-value-prt-2",
    "title": "15  Ковариационный анализ",
    "section": "15.72 Estimate Std. Error t value Pr(>|t|)",
    "text": "15.72 Estimate Std. Error t value Pr(&gt;|t|)",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#intercept-3.2769-0.1043-31.407-2e-16",
    "href": "infer-ancova.html#intercept-3.2769-0.1043-31.407-2e-16",
    "title": "15  Ковариационный анализ",
    "section": "15.73 (Intercept) 3.2769 0.1043 31.407 < 2e-16 ***",
    "text": "15.73 (Intercept) 3.2769 0.1043 31.407 &lt; 2e-16 ***",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#smokernon--0.7107-0.1099--6.464-1.99e-10",
    "href": "infer-ancova.html#smokernon--0.7107-0.1099--6.464-1.99e-10",
    "title": "15  Ковариационный анализ",
    "section": "15.74 SmokerNon -0.7107 0.1099 -6.464 1.99e-10 ***",
    "text": "15.74 SmokerNon -0.7107 0.1099 -6.464 1.99e-10 ***",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#section-20",
    "href": "infer-ancova.html#section-20",
    "title": "15  Ковариационный анализ",
    "section": "15.75 —",
    "text": "15.75 —",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1-3",
    "href": "infer-ancova.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1-3",
    "title": "15  Ковариационный анализ",
    "section": "15.76 Signif. codes: 0 ‘’ 0.001 ’’ 0.01 ’’ 0.05 ‘.’ 0.1 ’ ’ 1",
    "text": "15.76 Signif. codes: 0 ‘’ 0.001 ’’ 0.01 ’’ 0.05 ‘.’ 0.1 ’ ’ 1",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#section-21",
    "href": "infer-ancova.html#section-21",
    "title": "15  Ковариационный анализ",
    "section": "15.77 ",
    "text": "15.77",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#residual-standard-error-0.8412-on-652-degrees-of-freedom",
    "href": "infer-ancova.html#residual-standard-error-0.8412-on-652-degrees-of-freedom",
    "title": "15  Ковариационный анализ",
    "section": "15.78 Residual standard error: 0.8412 on 652 degrees of freedom",
    "text": "15.78 Residual standard error: 0.8412 on 652 degrees of freedom",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#multiple-r-squared-0.06023-adjusted-r-squared-0.05879",
    "href": "infer-ancova.html#multiple-r-squared-0.06023-adjusted-r-squared-0.05879",
    "title": "15  Ковариационный анализ",
    "section": "15.79 Multiple R-squared: 0.06023, Adjusted R-squared: 0.05879",
    "text": "15.79 Multiple R-squared: 0.06023, Adjusted R-squared: 0.05879",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#f-statistic-41.79-on-1-and-652-df-p-value-1.993e-10",
    "href": "infer-ancova.html#f-statistic-41.79-on-1-and-652-df-p-value-1.993e-10",
    "title": "15  Ковариационный анализ",
    "section": "15.80 F-statistic: 41.79 on 1 and 652 DF, p-value: 1.993e-10",
    "text": "15.80 F-statistic: 41.79 on 1 and 652 DF, p-value: 1.993e-10\nВидим, что предиктор Smoker (статус курения) оказывается статистически значимым. Если мы на этом завершим наш анализ, то мы сделаем некорректный вывод: статус курения детей значимо влияет на ОФВ, при этом у группы некурящих ОФВ на 0.7 л меньше. Здесь нас наталкивает на мысль об ошибке направление влияния нашего предиктора — согласно здравому смыслу, а также биологии и медицине, ОФВ должен быть ниже у курящей группы. Но мы можем получить результаты, адекватные текущей реальности и ничего не заподозрить.\nПроблема здесь кроется в том, что, как мы уже сказали, ОФВ связан не только со статусом курения. Ковариата, как и любой предиктор, будет объяснять часть дисперсии данных, поэтому значимость других предикторов модели при её введении может изменяться.\nВзглянем ещё раз на модель ANCOVA:",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#section-22",
    "href": "infer-ancova.html#section-22",
    "title": "15  Ковариационный анализ",
    "section": "15.81 ",
    "text": "15.81",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#call-3",
    "href": "infer-ancova.html#call-3",
    "title": "15  Ковариационный анализ",
    "section": "15.82 Call:",
    "text": "15.82 Call:",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#lmformula-fev-smoker-height-data-ofv-2",
    "href": "infer-ancova.html#lmformula-fev-smoker-height-data-ofv-2",
    "title": "15  Ковариационный анализ",
    "section": "15.83 lm(formula = FEV ~ Smoker + Height, data = ofv)",
    "text": "15.83 lm(formula = FEV ~ Smoker + Height, data = ofv)",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#section-23",
    "href": "infer-ancova.html#section-23",
    "title": "15  Ковариационный анализ",
    "section": "15.84 ",
    "text": "15.84",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#residuals-3",
    "href": "infer-ancova.html#residuals-3",
    "title": "15  Ковариационный анализ",
    "section": "15.85 Residuals:",
    "text": "15.85 Residuals:",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#min-1q-median-3q-max-3",
    "href": "infer-ancova.html#min-1q-median-3q-max-3",
    "title": "15  Ковариационный анализ",
    "section": "15.86 Min 1Q Median 3Q Max",
    "text": "15.86 Min 1Q Median 3Q Max",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#section-24",
    "href": "infer-ancova.html#section-24",
    "title": "15  Ковариационный анализ",
    "section": "15.87 -1.7505 -0.2660 -0.0041 0.2447 2.1207",
    "text": "15.87 -1.7505 -0.2660 -0.0041 0.2447 2.1207",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#section-25",
    "href": "infer-ancova.html#section-25",
    "title": "15  Ковариационный анализ",
    "section": "15.88 ",
    "text": "15.88",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#coefficients-3",
    "href": "infer-ancova.html#coefficients-3",
    "title": "15  Ковариационный анализ",
    "section": "15.89 Coefficients:",
    "text": "15.89 Coefficients:",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#estimate-std.-error-t-value-prt-3",
    "href": "infer-ancova.html#estimate-std.-error-t-value-prt-3",
    "title": "15  Ковариационный анализ",
    "section": "15.90 Estimate Std. Error t value Pr(>|t|)",
    "text": "15.90 Estimate Std. Error t value Pr(&gt;|t|)",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#intercept--5.421300-0.210104--25.803-2e-16-1",
    "href": "infer-ancova.html#intercept--5.421300-0.210104--25.803-2e-16-1",
    "title": "15  Ковариационный анализ",
    "section": "15.91 (Intercept) -5.421300 0.210104 -25.803 <2e-16 ***",
    "text": "15.91 (Intercept) -5.421300 0.210104 -25.803 &lt;2e-16 ***",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#smokernon--0.006319-0.058686--0.108-0.914-1",
    "href": "infer-ancova.html#smokernon--0.006319-0.058686--0.108-0.914-1",
    "title": "15  Ковариационный анализ",
    "section": "15.92 SmokerNon -0.006319 0.058686 -0.108 0.914",
    "text": "15.92 SmokerNon -0.006319 0.058686 -0.108 0.914",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#height-0.131883-0.003081-42.808-2e-16-1",
    "href": "infer-ancova.html#height-0.131883-0.003081-42.808-2e-16-1",
    "title": "15  Ковариационный анализ",
    "section": "15.93 Height 0.131883 0.003081 42.808 <2e-16 ***",
    "text": "15.93 Height 0.131883 0.003081 42.808 &lt;2e-16 ***",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#section-26",
    "href": "infer-ancova.html#section-26",
    "title": "15  Ковариационный анализ",
    "section": "15.94 —",
    "text": "15.94 —",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1-4",
    "href": "infer-ancova.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1-4",
    "title": "15  Ковариационный анализ",
    "section": "15.95 Signif. codes: 0 ‘’ 0.001 ’’ 0.01 ’’ 0.05 ‘.’ 0.1 ’ ’ 1",
    "text": "15.95 Signif. codes: 0 ‘’ 0.001 ’’ 0.01 ’’ 0.05 ‘.’ 0.1 ’ ’ 1",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#section-27",
    "href": "infer-ancova.html#section-27",
    "title": "15  Ковариационный анализ",
    "section": "15.96 ",
    "text": "15.96",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#residual-standard-error-0.431-on-651-degrees-of-freedom-1",
    "href": "infer-ancova.html#residual-standard-error-0.431-on-651-degrees-of-freedom-1",
    "title": "15  Ковариационный анализ",
    "section": "15.97 Residual standard error: 0.431 on 651 degrees of freedom",
    "text": "15.97 Residual standard error: 0.431 on 651 degrees of freedom",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#multiple-r-squared-0.7537-adjusted-r-squared-0.7529-1",
    "href": "infer-ancova.html#multiple-r-squared-0.7537-adjusted-r-squared-0.7529-1",
    "title": "15  Ковариационный анализ",
    "section": "15.98 Multiple R-squared: 0.7537, Adjusted R-squared: 0.7529",
    "text": "15.98 Multiple R-squared: 0.7537, Adjusted R-squared: 0.7529",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-ancova.html#f-statistic-995.9-on-2-and-651-df-p-value-2.2e-16-1",
    "href": "infer-ancova.html#f-statistic-995.9-on-2-and-651-df-p-value-2.2e-16-1",
    "title": "15  Ковариационный анализ",
    "section": "15.99 F-statistic: 995.9 on 2 and 651 DF, p-value: < 2.2e-16",
    "text": "15.99 F-statistic: 995.9 on 2 and 651 DF, p-value: &lt; 2.2e-16\nКовариата значима, а вот наш основной предиктор свою значимость утратил — причем практически абсолютно (p = 0.9). Что мы можем сказать, увидев такие результаты? Мы можем заключить, что разница в ОФВ между группами курящих и некурящих, которую мы видели в предыдущей модели, объясняется не статусом курения, а возрастом респондентов, вошедших в эту группу. Теперь и вывод о направлении связи не кажется таким безумным — в группу курящих, вероятно, просто в среднем старше, а соответственно, и объем легких — и ОФВ — у них больше.\nТаким образом, введя ковариату в анализ, мы обнаружили, что связи между статусом курения и одним из объективных показателей здоровья дыхательной системы нет. Как это интерпретировать? Ну, это зависит. Одним из возможных вариантов может быть как раз таки возраст респондентов — «запас прочности» организма ещё не исчерпан.\nСамое главное про ковариационный анализ:\nКовариационный анализ можно проводить только в том случае, если отсутствует значимое взаиможействие между факторами и ковариатами!\nЕсли взаимодействие значимо, мы не можем исключить его из модели — придется интерпретировать результаты со взаимодействием.\n16.3 Тестирование значимости предикторов и диагностика модели Так как ANCOVA — это всё ещё линейная регрессия, то и всё, что можно делать с регрессией, можно делать и с ней. Тестирование значимости предикторов происходит точно так же, как и в предыдущих главах. Диагностика модели также аналогична.\nКак видите, несмотря на то, что мы уже освоили достаточно много методов анализа данных, все они базируются на одной и той же модели — модели линейной регрессии — которая время от времени несколько модифицируется под те или иные типы данных. Спойлер, далее тоже ничего не измениться — мы будем в рамках всё той же линейной регрессии, только ход адаптации модели будет несколько более сложным. Но если сейчас вы чувствуете себя достаточно уверенно с регрессией, то дальше всё пойдёт ровно.\nОписание данных из источника: «FEV (forced expiratory volume) is an index of pulmonary function that measures the volume of air expelled after one second of constant effort. The data contains determinations of FEV on 654 children ages 6-22 who were seen in the Childhood Respiratory Desease Study in 1980 in East Boston, Massachusetts. The data are part of a larger study to follow the change in pulmonary function over time in children.»↩︎\nОбъём воздуха, выдыхаемого за первую секунду манёвра форсированного выдоха. Используется для расчёта индекса наличия/отсутствия ухудшения проходимости дыхательных путей.↩︎",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Ковариационный анализ</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html",
    "href": "infer-logreg.html",
    "title": "16  Логистическая регрессия",
    "section": "",
    "text": "17 y\n17.1 Ограничения общих линейных моделей Модели, которые мы изучали на предыдущих занятиях носят название общих линейных моделей (general linear models). Они достаточно просты и удобны в большинстве случаев, однако имеют ряд важных ограничений.\nВспомним, как выглядит уравнение такой модели:\nβ 0 + β 1 x 1 + ⋯ + β p x p + ε\nПредикторы в такой модели могут быть как дискретными, так и непрерывными.\nВажнейшим допущением и требованием этой модели является распределение ошибки:\nε ∼ N ( 0 , σ )\nПоскольку ошибка модели должна быть распределена нормально, а моделируется среднее значение, то можно сформулировать более общее допущение / требование:\ny i ∼ N ( μ i , σ )\nТаким образом, общие линейные модели позволяют моделировать зависимости только для нормальнораспределенных величин. Если же наша целевая переменная подчиняется другому распределению, эти модели не годятся.\nОднако нам на помощь приходят обобщенные линейные модели (generalized linear models), которые позволяют моделировать зависимости величин, подчиняющихся не только нормальному распределению, но и многим другим.\nМы познакомимся с общей логикой построения GLM, подробно рассмотрев один из вариантов таких моделей, а именно биномиальную регрессию.\n17.2 Бинарные переменные Эти переменные достаточно широко распространены как повседневности, так и в науке. Блюдо вкусное или невкусное, команда выиграла или проиграла, пациент в результате медицинских манипуляций выжил или умер, в ходе эксперимента была выбрана какая-то опция или нет, сдал студент экзамен или не сдал — и т.д.\nЭти события могут быть связаны с раздичными предикторами, и такую взаимосвязь можно описать с помощью регрессионных моделей.\n17.3 Данные Снова начнем с данных — на этот раз про менеджеров. Это часть данных большого датасета, собранного в рамках одного из HR-исследований.",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#a-tibble-6-10",
    "href": "infer-logreg.html#a-tibble-6-10",
    "title": "16  Логистическая регрессия",
    "section": "17.1 # A tibble: 6 × 10",
    "text": "17.1 # A tibble: 6 × 10",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#id-lvl-quali¹-auton²-subdi³-compa⁴-direc⁵-func_⁶-incom⁷-error⁸",
    "href": "infer-logreg.html#id-lvl-quali¹-auton²-subdi³-compa⁴-direc⁵-func_⁶-incom⁷-error⁸",
    "title": "16  Логистическая регрессия",
    "section": "17.2 id lvl quali…¹ auton…² subdi…³ compa…⁴ direc…⁵ func_…⁶ incom…⁷ error…⁸",
    "text": "17.2 id lvl quali…¹ auton…² subdi…³ compa…⁴ direc…⁵ func_…⁶ incom…⁷ error…⁸",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#section",
    "href": "infer-logreg.html#section",
    "title": "16  Логистическая регрессия",
    "section": "17.3          ",
    "text": "17.3",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#таб_154-сотр-5-2-1-1-1-1-1-1",
    "href": "infer-logreg.html#таб_154-сотр-5-2-1-1-1-1-1-1",
    "title": "16  Логистическая регрессия",
    "section": "17.4 1 таб_154… Сотр… 5 2 1 1 1 1 1 1",
    "text": "17.4 1 таб_154… Сотр… 5 2 1 1 1 1 1 1",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#таб_139-сотр-4-2-1-1-1-1-1-2",
    "href": "infer-logreg.html#таб_139-сотр-4-2-1-1-1-1-1-2",
    "title": "16  Логистическая регрессия",
    "section": "17.5 2 таб_139… Сотр… 4 2 1 1 1 1 1 2",
    "text": "17.5 2 таб_139… Сотр… 4 2 1 1 1 1 1 2",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#таб_407-сотр-2-2-1-1-1-1-1-1",
    "href": "infer-logreg.html#таб_407-сотр-2-2-1-1-1-1-1-1",
    "title": "16  Логистическая регрессия",
    "section": "17.6 3 таб_407… Сотр… 2 2 1 1 1 1 1 1",
    "text": "17.6 3 таб_407… Сотр… 2 2 1 1 1 1 1 1",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#таб_417-сотр-4-3-1-1-1-1-1-1",
    "href": "infer-logreg.html#таб_417-сотр-4-3-1-1-1-1-1-1",
    "title": "16  Логистическая регрессия",
    "section": "17.7 4 таб_417… Сотр… 4 3 1 1 1 1 1 1",
    "text": "17.7 4 таб_417… Сотр… 4 3 1 1 1 1 1 1",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#таб_633-мене-5-3-2-3-2-1-3-5",
    "href": "infer-logreg.html#таб_633-мене-5-3-2-3-2-1-3-5",
    "title": "16  Логистическая регрессия",
    "section": "17.8 5 таб_633… Мене… 5 3 2 3 2 1 3 5",
    "text": "17.8 5 таб_633… Мене… 5 3 2 3 2 1 3 5",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#таб_162-сотр-2-2-1-1-1-1-2-2",
    "href": "infer-logreg.html#таб_162-сотр-2-2-1-1-1-1-2-2",
    "title": "16  Логистическая регрессия",
    "section": "17.9 6 таб_162… Сотр… 2 2 1 1 1 1 2 2",
    "text": "17.9 6 таб_162… Сотр… 2 2 1 1 1 1 2 2",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#with-abbreviated-variable-names-¹qualification-²autonomy",
    "href": "infer-logreg.html#with-abbreviated-variable-names-¹qualification-²autonomy",
    "title": "16  Логистическая регрессия",
    "section": "17.10 # … with abbreviated variable names ¹​qualification, ²​autonomy,",
    "text": "17.10 # … with abbreviated variable names ¹​qualification, ²​autonomy,",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#subdiv_regulations-⁴company_regulations-⁵direct_juniors-⁶func_juniors",
    "href": "infer-logreg.html#subdiv_regulations-⁴company_regulations-⁵direct_juniors-⁶func_juniors",
    "title": "16  Логистическая регрессия",
    "section": "17.11 # ³​subdiv_regulations, ⁴​company_regulations, ⁵​direct_juniors, ⁶​func_juniors,",
    "text": "17.11 # ³​subdiv_regulations, ⁴​company_regulations, ⁵​direct_juniors, ⁶​func_juniors,",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#income_influence-⁸error_cost",
    "href": "infer-logreg.html#income_influence-⁸error_cost",
    "title": "16  Логистическая регрессия",
    "section": "17.12 # ⁷​income_influence, ⁸​error_cost",
    "text": "17.12 # ⁷​income_influence, ⁸​error_cost\nУ нас есть следуюшие переменные:\nid — табельный номер сотрудника lvl — уровень (Сотрудник или Менеджер) qualification — профессиональная квалификация autonomy — автономия в принятии решений subdiv_regulations — участие в формировании регламентов подразделения company_regulations — участие в формировании регламентов Компании direct_juniors — количество прямых подчинённых func_juniors — количество функциональных подчинённых income_influence — влияние на доход Компании error_cost — стоимость ошибки 17.4 Задача построения линейной модели В наших данных есть бинарная переменная lvl — она содержит две градации: Сотрудник и Менеджер. Вопрос, на который нам необходимо ответить: по каким параметрам различаются менеджеры и сотрудники?",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#section-1",
    "href": "infer-logreg.html#section-1",
    "title": "16  Логистическая регрессия",
    "section": "17.13 ",
    "text": "17.13",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#менеджер-сотрудник",
    "href": "infer-logreg.html#менеджер-сотрудник",
    "title": "16  Логистическая регрессия",
    "section": "17.14 Менеджер Сотрудник",
    "text": "17.14 Менеджер Сотрудник",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#section-2",
    "href": "infer-logreg.html#section-2",
    "title": "16  Логистическая регрессия",
    "section": "17.15 810 2400",
    "text": "17.15 810 2400\nПрежде всего надо вспомнить, что мы работаем с математической моделью, которой необходимы числа, поэтому придётся перекодировать нашу целевую переменную. Пусть 1 обозначает менеджеров, а 0 — сотрудников.\nТеперь мы можем построить модель, описывающую связь lvl с имеющимися предикторами.\nПопробуем обычную линейную регрессию.",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#section-3",
    "href": "infer-logreg.html#section-3",
    "title": "16  Логистическая регрессия",
    "section": "17.16 ",
    "text": "17.16",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#call",
    "href": "infer-logreg.html#call",
    "title": "16  Логистическая регрессия",
    "section": "17.17 Call:",
    "text": "17.17 Call:",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#lmformula-lvl-.-data-managers",
    "href": "infer-logreg.html#lmformula-lvl-.-data-managers",
    "title": "16  Логистическая регрессия",
    "section": "17.18 lm(formula = lvl ~ ., data = managers)",
    "text": "17.18 lm(formula = lvl ~ ., data = managers)",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#section-4",
    "href": "infer-logreg.html#section-4",
    "title": "16  Логистическая регрессия",
    "section": "17.19 ",
    "text": "17.19",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#residuals",
    "href": "infer-logreg.html#residuals",
    "title": "16  Логистическая регрессия",
    "section": "17.20 Residuals:",
    "text": "17.20 Residuals:",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#min-1q-median-3q-max",
    "href": "infer-logreg.html#min-1q-median-3q-max",
    "title": "16  Логистическая регрессия",
    "section": "17.21 Min 1Q Median 3Q Max",
    "text": "17.21 Min 1Q Median 3Q Max",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#section-5",
    "href": "infer-logreg.html#section-5",
    "title": "16  Логистическая регрессия",
    "section": "17.22 -1.47532 -0.07671 -0.04250 0.06891 1.02042",
    "text": "17.22 -1.47532 -0.07671 -0.04250 0.06891 1.02042",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#section-6",
    "href": "infer-logreg.html#section-6",
    "title": "16  Логистическая регрессия",
    "section": "17.23 ",
    "text": "17.23",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#coefficients",
    "href": "infer-logreg.html#coefficients",
    "title": "16  Логистическая регрессия",
    "section": "17.24 Coefficients:",
    "text": "17.24 Coefficients:",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#estimate-std.-error-t-value-prt",
    "href": "infer-logreg.html#estimate-std.-error-t-value-prt",
    "title": "16  Логистическая регрессия",
    "section": "17.25 Estimate Std. Error t value Pr(>|t|)",
    "text": "17.25 Estimate Std. Error t value Pr(&gt;|t|)",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#intercept--0.869056-0.015520--55.994-2e-16",
    "href": "infer-logreg.html#intercept--0.869056-0.015520--55.994-2e-16",
    "title": "16  Логистическая регрессия",
    "section": "17.26 (Intercept) -0.869056 0.015520 -55.994 < 2e-16 ***",
    "text": "17.26 (Intercept) -0.869056 0.015520 -55.994 &lt; 2e-16 ***",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#qualification-0.048487-0.004420-10.969-2e-16",
    "href": "infer-logreg.html#qualification-0.048487-0.004420-10.969-2e-16",
    "title": "16  Логистическая регрессия",
    "section": "17.27 qualification 0.048487 0.004420 10.969 < 2e-16 ***",
    "text": "17.27 qualification 0.048487 0.004420 10.969 &lt; 2e-16 ***",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#autonomy-0.016780-0.008309-2.019-0.043527",
    "href": "infer-logreg.html#autonomy-0.016780-0.008309-2.019-0.043527",
    "title": "16  Логистическая регрессия",
    "section": "17.28 autonomy 0.016780 0.008309 2.019 0.043527 *",
    "text": "17.28 autonomy 0.016780 0.008309 2.019 0.043527 *",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#subdiv_regulations-0.281009-0.014017-20.048-2e-16",
    "href": "infer-logreg.html#subdiv_regulations-0.281009-0.014017-20.048-2e-16",
    "title": "16  Логистическая регрессия",
    "section": "17.29 subdiv_regulations 0.281009 0.014017 20.048 < 2e-16 ***",
    "text": "17.29 subdiv_regulations 0.281009 0.014017 20.048 &lt; 2e-16 ***",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#company_regulations--0.068712-0.011403--6.026-1.88e-09",
    "href": "infer-logreg.html#company_regulations--0.068712-0.011403--6.026-1.88e-09",
    "title": "16  Логистическая регрессия",
    "section": "17.30 company_regulations -0.068712 0.011403 -6.026 1.88e-09 ***",
    "text": "17.30 company_regulations -0.068712 0.011403 -6.026 1.88e-09 ***",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#direct_juniors-0.369140-0.012549-29.416-2e-16",
    "href": "infer-logreg.html#direct_juniors-0.369140-0.012549-29.416-2e-16",
    "title": "16  Логистическая регрессия",
    "section": "17.31 direct_juniors 0.369140 0.012549 29.416 < 2e-16 ***",
    "text": "17.31 direct_juniors 0.369140 0.012549 29.416 &lt; 2e-16 ***",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#func_juniors-0.107304-0.008069-13.298-2e-16",
    "href": "infer-logreg.html#func_juniors-0.107304-0.008069-13.298-2e-16",
    "title": "16  Логистическая регрессия",
    "section": "17.32 func_juniors 0.107304 0.008069 13.298 < 2e-16 ***",
    "text": "17.32 func_juniors 0.107304 0.008069 13.298 &lt; 2e-16 ***",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#income_influence-0.072478-0.007434-9.749-2e-16",
    "href": "infer-logreg.html#income_influence-0.072478-0.007434-9.749-2e-16",
    "title": "16  Логистическая регрессия",
    "section": "17.33 income_influence 0.072478 0.007434 9.749 < 2e-16 ***",
    "text": "17.33 income_influence 0.072478 0.007434 9.749 &lt; 2e-16 ***",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#error_cost--0.026336-0.007985--3.298-0.000984",
    "href": "infer-logreg.html#error_cost--0.026336-0.007985--3.298-0.000984",
    "title": "16  Логистическая регрессия",
    "section": "17.34 error_cost -0.026336 0.007985 -3.298 0.000984 ***",
    "text": "17.34 error_cost -0.026336 0.007985 -3.298 0.000984 ***",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#section-7",
    "href": "infer-logreg.html#section-7",
    "title": "16  Логистическая регрессия",
    "section": "17.35 —",
    "text": "17.35 —",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1",
    "href": "infer-logreg.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1",
    "title": "16  Логистическая регрессия",
    "section": "17.36 Signif. codes: 0 ‘’ 0.001 ’’ 0.01 ’’ 0.05 ‘.’ 0.1 ’ ’ 1",
    "text": "17.36 Signif. codes: 0 ‘’ 0.001 ’’ 0.01 ’’ 0.05 ‘.’ 0.1 ’ ’ 1",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#section-8",
    "href": "infer-logreg.html#section-8",
    "title": "16  Логистическая регрессия",
    "section": "17.37 ",
    "text": "17.37",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#residual-standard-error-0.2235-on-3201-degrees-of-freedom",
    "href": "infer-logreg.html#residual-standard-error-0.2235-on-3201-degrees-of-freedom",
    "title": "16  Логистическая регрессия",
    "section": "17.38 Residual standard error: 0.2235 on 3201 degrees of freedom",
    "text": "17.38 Residual standard error: 0.2235 on 3201 degrees of freedom",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#multiple-r-squared-0.7361-adjusted-r-squared-0.7354",
    "href": "infer-logreg.html#multiple-r-squared-0.7361-adjusted-r-squared-0.7354",
    "title": "16  Логистическая регрессия",
    "section": "17.39 Multiple R-squared: 0.7361, Adjusted R-squared: 0.7354",
    "text": "17.39 Multiple R-squared: 0.7361, Adjusted R-squared: 0.7354",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#f-statistic-1116-on-8-and-3201-df-p-value-2.2e-16",
    "href": "infer-logreg.html#f-statistic-1116-on-8-and-3201-df-p-value-2.2e-16",
    "title": "16  Логистическая регрессия",
    "section": "17.40 F-statistic: 1116 on 8 and 3201 DF, p-value: < 2.2e-16",
    "text": "17.40 F-statistic: 1116 on 8 and 3201 DF, p-value: &lt; 2.2e-16\nМодель построилась, всё суперклассно.\nПопробуем визуализировать, что получилось.\nНо получается что-то странное…\nВо-первых, непонятно, какая величина отложена на оси\ny . Во-вторых, предсказания модели выходят за границы допустимых значений (модель предсказывает отрицательные и большие единицы значения). Поэтому простая линейная модель нам не подходит. Надо искать что-то еще.\n17.5 Переход от дискретной величины к непрерывной 17.5.1 Логистическая кривая Собственно бинарные переменные неудобны для работы, поэтому надо найти способ превратить такую дискретную бинарную шкалу в «безграничную» и непрерывную. При моделировании нулей и единиц переходят к моделированию вероятности получения единиц.\nСама зависимая переменная в зависимости от предиктора распределена примерно так:\nВведем новые обозначения:\np i — вероятность события\ny i = 1 при данных значениях предиктора, 1 − p i — вероятность альтернативного события\ny i = 0 . Получается непрерывная величина\n0 ≤ p i ≤ 1 .\nИ вроде бы как ее можно уже моделировать. Но нужно помнить, что вероятность изменяется в пределах от нуля до единицы, а прямая ничем не ограничена. Поэтому прямая — не лучший вариант.\nТакая закономерность моделируется логистической кривой.\nОна лежит как раз в пределах от 0 до 1. Наша логистическая кривая задается уравнением\np i = e β 0 + β 1 x i 1 + e β 0 + β 1 x i\nЛогистическую кривую мы больше никогда не увидим — печаль :( — но она используется внутри функций, которыми мы строим модель.\n17.5.2 Шансы и логиты Теперь нам надо побороться с ограниченностью логистической кривой. Для этого можно перейти от вероятностей к шансам.\nШанс (отношение шансов, odds, odds ratio) — это отношение вероятности успеха к вероятности неудачи. Их величина варьируется от\n0 до\n+ ∞ .\nУже лучше, но все еще не самый лучший вариант… Последний шаг, необходимый нам, чтобы все было хорошо, юзануть логарифм, который преобразуем шансы в логиты.\nl o g i t ( p ) = ln ( p i 1 − p i )\nЗначения логитов — трансформированные оценки вероятностей события. Они варьируют от\n− ∞ до\n+ ∞ , симметричны относительно нуля, и их удобно брать в качестве зависимой переменной для построения модели. Кроме того, logit-преобразование еще и линеаризует логистическую кривую, то есть превращает её в прямую.\nИ далет это примерно так Функция, используемая для линеаризации связи между предиктором и зависимой переменной, называется функцией связи (linked function). Функция logit-преобразоввания — одна из нескольких связывающих функций, применяемых для анализа бинарных переменных отклика.\nИтак, summary от всего, что было выше:\nОт дискретной оценки событий (0 и 1) переходим к оценке вероятностей. Связь вероятностей с предиктором описывается логистической кривой. Если при помощи функции связи перейти от вероятностей к логитам, то связь будет описываться прямой линией. Параметры линейной модели для такой прямой можно оценить с помощью регрессионного анализа. 17.6 Математическая модель p i = e β 0 + β 1 x 1 + ⋯ + β p x p 1 + e β 0 + β 1 x 1 + ⋯ + β p x p\nФункция связи (linked function):\nln ( p i 1 − p i ) = η i η i = β 0 + β 1 x 1 i + ⋯ + β p x p i\nДля перехода от логитов к вероятностям используется функция, обратная функции связи. В данном случае, логистическое преобразование:\np i = e η i 1 + e η i\n17.7 Результаты логистической регрессии В общем таблица достаточно похожа на обычную линейную регрессию:",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#section-9",
    "href": "infer-logreg.html#section-9",
    "title": "16  Логистическая регрессия",
    "section": "17.41 ",
    "text": "17.41",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#call-1",
    "href": "infer-logreg.html#call-1",
    "title": "16  Логистическая регрессия",
    "section": "17.42 Call:",
    "text": "17.42 Call:",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#glmformula-lvl-.-family-binomiallink-logit-data-managers",
    "href": "infer-logreg.html#glmformula-lvl-.-family-binomiallink-logit-data-managers",
    "title": "16  Логистическая регрессия",
    "section": "17.43 glm(formula = lvl ~ ., family = binomial(link = “logit”), data = managers)",
    "text": "17.43 glm(formula = lvl ~ ., family = binomial(link = “logit”), data = managers)",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#section-10",
    "href": "infer-logreg.html#section-10",
    "title": "16  Логистическая регрессия",
    "section": "17.44 ",
    "text": "17.44",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#deviance-residuals",
    "href": "infer-logreg.html#deviance-residuals",
    "title": "16  Логистическая регрессия",
    "section": "17.45 Deviance Residuals:",
    "text": "17.45 Deviance Residuals:",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#min-1q-median-3q-max-1",
    "href": "infer-logreg.html#min-1q-median-3q-max-1",
    "title": "16  Логистическая регрессия",
    "section": "17.46 Min 1Q Median 3Q Max",
    "text": "17.46 Min 1Q Median 3Q Max",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#section-11",
    "href": "infer-logreg.html#section-11",
    "title": "16  Логистическая регрессия",
    "section": "17.47 -3.8626 -0.0897 -0.0800 0.0000 3.5607",
    "text": "17.47 -3.8626 -0.0897 -0.0800 0.0000 3.5607",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#section-12",
    "href": "infer-logreg.html#section-12",
    "title": "16  Логистическая регрессия",
    "section": "17.48 ",
    "text": "17.48",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#coefficients-1",
    "href": "infer-logreg.html#coefficients-1",
    "title": "16  Логистическая регрессия",
    "section": "17.49 Coefficients:",
    "text": "17.49 Coefficients:",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#estimate-std.-error-z-value-prz",
    "href": "infer-logreg.html#estimate-std.-error-z-value-prz",
    "title": "16  Логистическая регрессия",
    "section": "17.50 Estimate Std. Error z value Pr(>|z|)",
    "text": "17.50 Estimate Std. Error z value Pr(&gt;|z|)",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#intercept--22.08642-1.13159--19.518-2e-16",
    "href": "infer-logreg.html#intercept--22.08642-1.13159--19.518-2e-16",
    "title": "16  Логистическая регрессия",
    "section": "17.51 (Intercept) -22.08642 1.13159 -19.518 < 2e-16 ***",
    "text": "17.51 (Intercept) -22.08642 1.13159 -19.518 &lt; 2e-16 ***",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#qualification-1.55224-0.14058-11.042-2e-16",
    "href": "infer-logreg.html#qualification-1.55224-0.14058-11.042-2e-16",
    "title": "16  Логистическая регрессия",
    "section": "17.52 qualification 1.55224 0.14058 11.042 < 2e-16 ***",
    "text": "17.52 qualification 1.55224 0.14058 11.042 &lt; 2e-16 ***",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#autonomy-0.18304-0.24017-0.762-0.446",
    "href": "infer-logreg.html#autonomy-0.18304-0.24017-0.762-0.446",
    "title": "16  Логистическая регрессия",
    "section": "17.53 autonomy 0.18304 0.24017 0.762 0.446",
    "text": "17.53 autonomy 0.18304 0.24017 0.762 0.446",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#subdiv_regulations--0.08816-0.27523--0.320-0.749",
    "href": "infer-logreg.html#subdiv_regulations--0.08816-0.27523--0.320-0.749",
    "title": "16  Логистическая регрессия",
    "section": "17.54 subdiv_regulations -0.08816 0.27523 -0.320 0.749",
    "text": "17.54 subdiv_regulations -0.08816 0.27523 -0.320 0.749",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#company_regulations-0.10685-0.21973-0.486-0.627",
    "href": "infer-logreg.html#company_regulations-0.10685-0.21973-0.486-0.627",
    "title": "16  Логистическая регрессия",
    "section": "17.55 company_regulations 0.10685 0.21973 0.486 0.627",
    "text": "17.55 company_regulations 0.10685 0.21973 0.486 0.627",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#direct_juniors-8.86211-0.70679-12.539-2e-16",
    "href": "infer-logreg.html#direct_juniors-8.86211-0.70679-12.539-2e-16",
    "title": "16  Логистическая регрессия",
    "section": "17.56 direct_juniors 8.86211 0.70679 12.539 < 2e-16 ***",
    "text": "17.56 direct_juniors 8.86211 0.70679 12.539 &lt; 2e-16 ***",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#func_juniors-2.98508-0.26324-11.340-2e-16",
    "href": "infer-logreg.html#func_juniors-2.98508-0.26324-11.340-2e-16",
    "title": "16  Логистическая регрессия",
    "section": "17.57 func_juniors 2.98508 0.26324 11.340 < 2e-16 ***",
    "text": "17.57 func_juniors 2.98508 0.26324 11.340 &lt; 2e-16 ***",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#income_influence-0.63992-0.16049-3.987-6.68e-05",
    "href": "infer-logreg.html#income_influence-0.63992-0.16049-3.987-6.68e-05",
    "title": "16  Логистическая регрессия",
    "section": "17.58 income_influence 0.63992 0.16049 3.987 6.68e-05 ***",
    "text": "17.58 income_influence 0.63992 0.16049 3.987 6.68e-05 ***",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#error_cost--0.04441-0.15745--0.282-0.778",
    "href": "infer-logreg.html#error_cost--0.04441-0.15745--0.282-0.778",
    "title": "16  Логистическая регрессия",
    "section": "17.59 error_cost -0.04441 0.15745 -0.282 0.778",
    "text": "17.59 error_cost -0.04441 0.15745 -0.282 0.778",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#section-13",
    "href": "infer-logreg.html#section-13",
    "title": "16  Логистическая регрессия",
    "section": "17.60 —",
    "text": "17.60 —",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1-1",
    "href": "infer-logreg.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1-1",
    "title": "16  Логистическая регрессия",
    "section": "17.61 Signif. codes: 0 ‘’ 0.001 ’’ 0.01 ’’ 0.05 ‘.’ 0.1 ’ ’ 1",
    "text": "17.61 Signif. codes: 0 ‘’ 0.001 ’’ 0.01 ’’ 0.05 ‘.’ 0.1 ’ ’ 1",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#section-14",
    "href": "infer-logreg.html#section-14",
    "title": "16  Логистическая регрессия",
    "section": "17.62 ",
    "text": "17.62",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#dispersion-parameter-for-binomial-family-taken-to-be-1",
    "href": "infer-logreg.html#dispersion-parameter-for-binomial-family-taken-to-be-1",
    "title": "16  Логистическая регрессия",
    "section": "17.63 (Dispersion parameter for binomial family taken to be 1)",
    "text": "17.63 (Dispersion parameter for binomial family taken to be 1)",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#section-15",
    "href": "infer-logreg.html#section-15",
    "title": "16  Логистическая регрессия",
    "section": "17.64 ",
    "text": "17.64",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#null-deviance-3626.58-on-3209-degrees-of-freedom",
    "href": "infer-logreg.html#null-deviance-3626.58-on-3209-degrees-of-freedom",
    "title": "16  Логистическая регрессия",
    "section": "17.65 Null deviance: 3626.58 on 3209 degrees of freedom",
    "text": "17.65 Null deviance: 3626.58 on 3209 degrees of freedom",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#residual-deviance-640.79-on-3201-degrees-of-freedom",
    "href": "infer-logreg.html#residual-deviance-640.79-on-3201-degrees-of-freedom",
    "title": "16  Логистическая регрессия",
    "section": "17.66 Residual deviance: 640.79 on 3201 degrees of freedom",
    "text": "17.66 Residual deviance: 640.79 on 3201 degrees of freedom",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#aic-658.79",
    "href": "infer-logreg.html#aic-658.79",
    "title": "16  Логистическая регрессия",
    "section": "17.67 AIC: 658.79",
    "text": "17.67 AIC: 658.79",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#section-16",
    "href": "infer-logreg.html#section-16",
    "title": "16  Логистическая регрессия",
    "section": "17.68 ",
    "text": "17.68",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#number-of-fisher-scoring-iterations-8",
    "href": "infer-logreg.html#number-of-fisher-scoring-iterations-8",
    "title": "16  Логистическая регрессия",
    "section": "17.69 Number of Fisher Scoring iterations: 8",
    "text": "17.69 Number of Fisher Scoring iterations: 8\nОднако есть некоторые отличия.\nВо-первых, нет F-статистики. Во-вторых, нет\nR 2 .\nЭто связано с тем, что алгоритм GLM не работает с дисперсией и суммой квадратов, так как задача подбора коэффициентов модели логистической регрессии не имеет аналитического решения, как было в случае линейной регрессии. Поэтому модель подбирается методом максимального правдоподобия.\nЧё за метод такой? 17.8 Анализ модели Итак, продолжим изучать аутпут логистической регрессии.",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#section-17",
    "href": "infer-logreg.html#section-17",
    "title": "16  Логистическая регрессия",
    "section": "17.70 ",
    "text": "17.70",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#call-2",
    "href": "infer-logreg.html#call-2",
    "title": "16  Логистическая регрессия",
    "section": "17.71 Call:",
    "text": "17.71 Call:",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#glmformula-lvl-.-family-binomiallink-logit-data-managers-1",
    "href": "infer-logreg.html#glmformula-lvl-.-family-binomiallink-logit-data-managers-1",
    "title": "16  Логистическая регрессия",
    "section": "17.72 glm(formula = lvl ~ ., family = binomial(link = “logit”), data = managers)",
    "text": "17.72 glm(formula = lvl ~ ., family = binomial(link = “logit”), data = managers)",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#section-18",
    "href": "infer-logreg.html#section-18",
    "title": "16  Логистическая регрессия",
    "section": "17.73 ",
    "text": "17.73",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#deviance-residuals-1",
    "href": "infer-logreg.html#deviance-residuals-1",
    "title": "16  Логистическая регрессия",
    "section": "17.74 Deviance Residuals:",
    "text": "17.74 Deviance Residuals:",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#min-1q-median-3q-max-2",
    "href": "infer-logreg.html#min-1q-median-3q-max-2",
    "title": "16  Логистическая регрессия",
    "section": "17.75 Min 1Q Median 3Q Max",
    "text": "17.75 Min 1Q Median 3Q Max",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#section-19",
    "href": "infer-logreg.html#section-19",
    "title": "16  Логистическая регрессия",
    "section": "17.76 -3.8626 -0.0897 -0.0800 0.0000 3.5607",
    "text": "17.76 -3.8626 -0.0897 -0.0800 0.0000 3.5607",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#section-20",
    "href": "infer-logreg.html#section-20",
    "title": "16  Логистическая регрессия",
    "section": "17.77 ",
    "text": "17.77",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#coefficients-2",
    "href": "infer-logreg.html#coefficients-2",
    "title": "16  Логистическая регрессия",
    "section": "17.78 Coefficients:",
    "text": "17.78 Coefficients:",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#estimate-std.-error-z-value-prz-1",
    "href": "infer-logreg.html#estimate-std.-error-z-value-prz-1",
    "title": "16  Логистическая регрессия",
    "section": "17.79 Estimate Std. Error z value Pr(>|z|)",
    "text": "17.79 Estimate Std. Error z value Pr(&gt;|z|)",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#intercept--22.08642-1.13159--19.518-2e-16-1",
    "href": "infer-logreg.html#intercept--22.08642-1.13159--19.518-2e-16-1",
    "title": "16  Логистическая регрессия",
    "section": "17.80 (Intercept) -22.08642 1.13159 -19.518 < 2e-16 ***",
    "text": "17.80 (Intercept) -22.08642 1.13159 -19.518 &lt; 2e-16 ***",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#qualification-1.55224-0.14058-11.042-2e-16-1",
    "href": "infer-logreg.html#qualification-1.55224-0.14058-11.042-2e-16-1",
    "title": "16  Логистическая регрессия",
    "section": "17.81 qualification 1.55224 0.14058 11.042 < 2e-16 ***",
    "text": "17.81 qualification 1.55224 0.14058 11.042 &lt; 2e-16 ***",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#autonomy-0.18304-0.24017-0.762-0.446-1",
    "href": "infer-logreg.html#autonomy-0.18304-0.24017-0.762-0.446-1",
    "title": "16  Логистическая регрессия",
    "section": "17.82 autonomy 0.18304 0.24017 0.762 0.446",
    "text": "17.82 autonomy 0.18304 0.24017 0.762 0.446",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#subdiv_regulations--0.08816-0.27523--0.320-0.749-1",
    "href": "infer-logreg.html#subdiv_regulations--0.08816-0.27523--0.320-0.749-1",
    "title": "16  Логистическая регрессия",
    "section": "17.83 subdiv_regulations -0.08816 0.27523 -0.320 0.749",
    "text": "17.83 subdiv_regulations -0.08816 0.27523 -0.320 0.749",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#company_regulations-0.10685-0.21973-0.486-0.627-1",
    "href": "infer-logreg.html#company_regulations-0.10685-0.21973-0.486-0.627-1",
    "title": "16  Логистическая регрессия",
    "section": "17.84 company_regulations 0.10685 0.21973 0.486 0.627",
    "text": "17.84 company_regulations 0.10685 0.21973 0.486 0.627",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#direct_juniors-8.86211-0.70679-12.539-2e-16-1",
    "href": "infer-logreg.html#direct_juniors-8.86211-0.70679-12.539-2e-16-1",
    "title": "16  Логистическая регрессия",
    "section": "17.85 direct_juniors 8.86211 0.70679 12.539 < 2e-16 ***",
    "text": "17.85 direct_juniors 8.86211 0.70679 12.539 &lt; 2e-16 ***",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#func_juniors-2.98508-0.26324-11.340-2e-16-1",
    "href": "infer-logreg.html#func_juniors-2.98508-0.26324-11.340-2e-16-1",
    "title": "16  Логистическая регрессия",
    "section": "17.86 func_juniors 2.98508 0.26324 11.340 < 2e-16 ***",
    "text": "17.86 func_juniors 2.98508 0.26324 11.340 &lt; 2e-16 ***",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#income_influence-0.63992-0.16049-3.987-6.68e-05-1",
    "href": "infer-logreg.html#income_influence-0.63992-0.16049-3.987-6.68e-05-1",
    "title": "16  Логистическая регрессия",
    "section": "17.87 income_influence 0.63992 0.16049 3.987 6.68e-05 ***",
    "text": "17.87 income_influence 0.63992 0.16049 3.987 6.68e-05 ***",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#error_cost--0.04441-0.15745--0.282-0.778-1",
    "href": "infer-logreg.html#error_cost--0.04441-0.15745--0.282-0.778-1",
    "title": "16  Логистическая регрессия",
    "section": "17.88 error_cost -0.04441 0.15745 -0.282 0.778",
    "text": "17.88 error_cost -0.04441 0.15745 -0.282 0.778",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#section-21",
    "href": "infer-logreg.html#section-21",
    "title": "16  Логистическая регрессия",
    "section": "17.89 —",
    "text": "17.89 —",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1-2",
    "href": "infer-logreg.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1-2",
    "title": "16  Логистическая регрессия",
    "section": "17.90 Signif. codes: 0 ‘’ 0.001 ’’ 0.01 ’’ 0.05 ‘.’ 0.1 ’ ’ 1",
    "text": "17.90 Signif. codes: 0 ‘’ 0.001 ’’ 0.01 ’’ 0.05 ‘.’ 0.1 ’ ’ 1",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#section-22",
    "href": "infer-logreg.html#section-22",
    "title": "16  Логистическая регрессия",
    "section": "17.91 ",
    "text": "17.91",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#dispersion-parameter-for-binomial-family-taken-to-be-1-1",
    "href": "infer-logreg.html#dispersion-parameter-for-binomial-family-taken-to-be-1-1",
    "title": "16  Логистическая регрессия",
    "section": "17.92 (Dispersion parameter for binomial family taken to be 1)",
    "text": "17.92 (Dispersion parameter for binomial family taken to be 1)",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#section-23",
    "href": "infer-logreg.html#section-23",
    "title": "16  Логистическая регрессия",
    "section": "17.93 ",
    "text": "17.93",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#null-deviance-3626.58-on-3209-degrees-of-freedom-1",
    "href": "infer-logreg.html#null-deviance-3626.58-on-3209-degrees-of-freedom-1",
    "title": "16  Логистическая регрессия",
    "section": "17.94 Null deviance: 3626.58 on 3209 degrees of freedom",
    "text": "17.94 Null deviance: 3626.58 on 3209 degrees of freedom",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#residual-deviance-640.79-on-3201-degrees-of-freedom-1",
    "href": "infer-logreg.html#residual-deviance-640.79-on-3201-degrees-of-freedom-1",
    "title": "16  Логистическая регрессия",
    "section": "17.95 Residual deviance: 640.79 on 3201 degrees of freedom",
    "text": "17.95 Residual deviance: 640.79 on 3201 degrees of freedom",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#aic-658.79-1",
    "href": "infer-logreg.html#aic-658.79-1",
    "title": "16  Логистическая регрессия",
    "section": "17.96 AIC: 658.79",
    "text": "17.96 AIC: 658.79",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#section-24",
    "href": "infer-logreg.html#section-24",
    "title": "16  Логистическая регрессия",
    "section": "17.97 ",
    "text": "17.97",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#number-of-fisher-scoring-iterations-8-1",
    "href": "infer-logreg.html#number-of-fisher-scoring-iterations-8-1",
    "title": "16  Логистическая регрессия",
    "section": "17.98 Number of Fisher Scoring iterations: 8",
    "text": "17.98 Number of Fisher Scoring iterations: 8\nМы видим знакомую нам табличку с оценками коэффициентов. У каждого предиктора есть информация о значении коэффициента при нем (Estimate), значение стандартной ошибки, z-value и p-value, рассчитанный для последнего.\nСудя по аутпуту, значимыми являются следующие предикторы: профессиональная квалификация, количество прямых и функциональных подчинённых и влияние на доход компании. Заметьте, что в этой модели значимых предикторов меньше, чем в модели обычной линейной регрессии. Но так ли это?\nВнимательно посмотрим на эту табличку. Раньше у нас были значения t-статистики — теперь z-статистики. К чему это может приводить?\nЧтобы ответить на этот вопрос, надо разобраться, что такое этот z-тест.\n17.8.1 Тест Вальда\nЗначение z-value является результатом подсчета теста Вальда и позволяет оценить значимость коэффициента модели. Расчет статистики похож на подсчет t-теста, только распределение данной статистики ассимптотически стремиться к нормальному (отсюда и z). Ассимптотика приводит к тому, что опеределение значимости коэффициентов на маленьких выборках будет неточным.\nH 0 : β k = 0 H 1 : β k ≠ 0 z = b k − β k S E b k = b k S E b k ∼ N ( 0 , 1 )\n17.8.2 Анализ девиансы и статистическая значимость модели Для получения более точных оценок необходимо поработать c логарифмами правдоподобий. Вообще логарифмы правдоподобий используются в GLM много для чего:\nдля описания качества подгонки модели; для тестирования значимости подобранной модели в целом; для тестирования значимости отдельных предикторов; для отбора моделей. Дла понимания механики анализа нам потребуется несколько полезных абстракций:\nНасыщенная модель (saturated model) — каждое уникальное наблюдение (сочетание предикторов) описывается одним из\nn параметров. ln L s a t = 0 d f s a t = n − p s a t = n − n = 0\nНулевая модель (null model) — все наблюдения описываются одним параметром (средним значением). ^ y i = β 0 ln L n u l l ≠ 0 → − ∞ d f n u l l = n − p n u l l = n − 1\nНаша реальная (предложенная) модель, которую мы подбираем, будет находится где-то между насыщенной и нулевой моделью (вернее, не сама модель, а значение логарифма её правдоподобия).\n^ y i = β 0 + β 1 x 1 i + ⋯ + β p x p i ln L m o d e l ≠ 0 d f m o d e l = n − p m o d e l\nДевианса является мерой различия правдоподобий двух моделей (оценка разницы логарифмов правдоподобий). [см. рисунок выше]\nОстаточная девианса d r e s i d = 2 ( ln L s a t − ln L m o d e l ) = − 2 ln ( L m o d e l )\nНулевая девианса d n u l l = 2 ( ln L s a t − ln L n u l l ) = − 2 ln ( L n u l l )\nСравнение нулевой и остаточной девианс позволяет судить о статистической значимости модели в целом. Такое сравнение проводится с помощью теста отношения правдоподобий (likelihood ratio test, LRT).\nd n u l l − d r e s i d = − 2 ( ln L n u l l − ln L m o d e l ) = 2 ( ln L m o d e l − ln L n u l l ) = 2 ln ( L m o d e l L n u l l ) L R T = 2 ln ( L M 1 L M 2 ) = 2 ( ln L M 1 − ln L M 2 ) , где\nM 1 , M 2 — вложенные модели ( M 1 — более полная,\nM 2 — уменьшенная),\nL M 1 , L M 2 — правдоподобия.\nРаспределение разницы логарифмов правдоподобий аппроксиммируется распределением\nχ 2 с числом степеней свободы\nd f = d f M 2 − d f M 1 .\nLRT для тестирования значимости модели в целом:\nL R T = 2 ln ( L m o d e l L n u l l ) = 2 ( ln L m o d e l − ln L n u l l ) = d n u l l − d r e s i d d f = p m o d e l − 1\nВ конечном счете результаты анализа девиансы выглядят так:",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#analysis-of-deviance-table",
    "href": "infer-logreg.html#analysis-of-deviance-table",
    "title": "16  Логистическая регрессия",
    "section": "17.99 Analysis of Deviance Table",
    "text": "17.99 Analysis of Deviance Table",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#section-25",
    "href": "infer-logreg.html#section-25",
    "title": "16  Логистическая регрессия",
    "section": "17.100 ",
    "text": "17.100",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#model-1-lvl-1",
    "href": "infer-logreg.html#model-1-lvl-1",
    "title": "16  Логистическая регрессия",
    "section": "17.101 Model 1: lvl ~ 1",
    "text": "17.101 Model 1: lvl ~ 1",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#model-2-lvl-qualification-autonomy-subdiv_regulations-company_regulations",
    "href": "infer-logreg.html#model-2-lvl-qualification-autonomy-subdiv_regulations-company_regulations",
    "title": "16  Логистическая регрессия",
    "section": "17.102 Model 2: lvl ~ qualification + autonomy + subdiv_regulations + company_regulations +",
    "text": "17.102 Model 2: lvl ~ qualification + autonomy + subdiv_regulations + company_regulations +",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#direct_juniors-func_juniors-income_influence-error_cost",
    "href": "infer-logreg.html#direct_juniors-func_juniors-income_influence-error_cost",
    "title": "16  Логистическая регрессия",
    "section": "17.103 direct_juniors + func_juniors + income_influence + error_cost",
    "text": "17.103 direct_juniors + func_juniors + income_influence + error_cost",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#resid.-df-resid.-dev-df-deviance-prchi",
    "href": "infer-logreg.html#resid.-df-resid.-dev-df-deviance-prchi",
    "title": "16  Логистическая регрессия",
    "section": "17.104 Resid. Df Resid. Dev Df Deviance Pr(>Chi)",
    "text": "17.104 Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#section-26",
    "href": "infer-logreg.html#section-26",
    "title": "16  Логистическая регрессия",
    "section": "17.105 1 3209 3626.6",
    "text": "17.105 1 3209 3626.6",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#e-16",
    "href": "infer-logreg.html#e-16",
    "title": "16  Логистическая регрессия",
    "section": "17.106 2 3201 640.8 8 2985.8 < 2.2e-16 ***",
    "text": "17.106 2 3201 640.8 8 2985.8 &lt; 2.2e-16 ***",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#section-27",
    "href": "infer-logreg.html#section-27",
    "title": "16  Логистическая регрессия",
    "section": "17.107 —",
    "text": "17.107 —",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1-3",
    "href": "infer-logreg.html#signif.-codes-0-0.001-0.01-0.05-.-0.1-1-3",
    "title": "16  Логистическая регрессия",
    "section": "17.108 Signif. codes: 0 ‘’ 0.001 ’’ 0.01 ’’ 0.05 ‘.’ 0.1 ’ ’ 1",
    "text": "17.108 Signif. codes: 0 ‘’ 0.001 ’’ 0.01 ’’ 0.05 ‘.’ 0.1 ’ ’ 1\nКак можно увидеть, наша модель получилась статистически значима. Ура!\nКроме статистических тестов для сравнения моделей можно использовать информационные критерии, как мы делали в случае обычной линейной регрессии.\nAIC (Akaike information criterion):",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#df-aic",
    "href": "infer-logreg.html#df-aic",
    "title": "16  Логистическая регрессия",
    "section": "17.109 df AIC",
    "text": "17.109 df AIC",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#model_null-1-3628.5775",
    "href": "infer-logreg.html#model_null-1-3628.5775",
    "title": "16  Логистическая регрессия",
    "section": "17.110 model_null 1 3628.5775",
    "text": "17.110 model_null 1 3628.5775",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#model-9-658.7949",
    "href": "infer-logreg.html#model-9-658.7949",
    "title": "16  Логистическая регрессия",
    "section": "17.111 model 9 658.7949",
    "text": "17.111 model 9 658.7949\nBIC (Bayesian information criterion):",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#df-bic",
    "href": "infer-logreg.html#df-bic",
    "title": "16  Логистическая регрессия",
    "section": "17.112 df BIC",
    "text": "17.112 df BIC",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#model_null-1-3634.6516",
    "href": "infer-logreg.html#model_null-1-3634.6516",
    "title": "16  Логистическая регрессия",
    "section": "17.113 model_null 1 3634.6516",
    "text": "17.113 model_null 1 3634.6516",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "infer-logreg.html#model-9-713.4611",
    "href": "infer-logreg.html#model-9-713.4611",
    "title": "16  Логистическая регрессия",
    "section": "17.114 model 9 713.4611",
    "text": "17.114 model 9 713.4611\n17.9 Интерпретация коэффициентов модели Чтобы было проще интерпретировать результаты, удалим из модели незначимые предикторы. Останется приемлемый аутпут:\nmodel_new &lt;- update(model, .~. -autonomy -subdiv_regulations -company_regulations -error_cost) ## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred summary(model_new) ## ## Call: ## glm(formula = lvl ~ qualification + direct_juniors + func_juniors + ## income_influence, family = binomial(link = “logit”), data = managers) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max\n## -3.8408 -0.0852 -0.0852 0.0000 3.5391\n## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|)\n## (Intercept) -22.0070 1.1112 -19.804 &lt; 2e-16  ## qualification 1.6056 0.1112 14.441 &lt; 2e-16  ## direct_juniors 8.8192 0.6459 13.653 &lt; 2e-16  ## func_juniors 3.0718 0.2423 12.680 &lt; 2e-16  ## income_influence 0.6440 0.1458 4.418 9.97e-06 *** ## — ## Signif. codes: 0 ‘’ 0.001 ’’ 0.01 ’’ 0.05 ‘.’ 0.1 ’ ’ 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 3626.58 on 3209 degrees of freedom ## Residual deviance: 641.78 on 3205 degrees of freedom ## AIC: 651.78 ## ## Number of Fisher Scoring iterations: 9 Что значат эти непонятные коэффициенты при предикторах? В общих линейных моделях все ясно как белый день, а тут какая-то дичь…\nВспомним, что наша зависимая переменная — логарифм отношения шансов. От этого и будем толкаться.\nln ( p i 1 − p i ) = η i η i = − 22.0 + 1.6 qualification i + 8.8 direct_juniors i + 3.1 func_juniors i + 0.6 income_influence i\nТогда,\nb 0 , интерсепт, показывает логарифм отношения шансов для случая, когда все остальные предикторы равны нулю — в данном примере он сложноинетерпретабелен; b j показывает, на сколько единиц изменяется логарифм отношения шансов при изменении значения предиктора на единицу. Корректно, но непонятно… Чтобы разобраться лучше, немного потупим в алгебру.\n17.9.1 Немного алгебры для понимания сути коэффициентов Пусть у нас есть модель с одним непрервным предиктором. Тогда она будет записываться так:",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "r-intro.html",
    "href": "r-intro.html",
    "title": "20  Основы R",
    "section": "",
    "text": "Знакомство с R и RStudio — Я вот не могу выбрать: делать на R или на Python? — Да какая разница! Главное — делай!\nЧто это и откуда? R — популярный язык программирования среди исследователей в социальных и гуманитарных науках. Если совсем коротко, то начиналось всё с языка S, который был языком программирования для статистического анализа. Потом его доработали и получился R.\nХотя сегодня всё ещё можно услышать, что «R — это язык программирования для статистической обработки данных», это ложь. Да, когда-то давно дела обстояли именно так, но сейчас R — это полноценный язык программирования, который позволяет решать широкий спект задач от статистического анализа и data wrangling до машинного обучения, моделирования и создания сайтов и приложений.\nПочему R? свободное ПО (часть GNU Project) динамично развивается громадные возможности расширения функционала более 10 000 пакетов открытый исходный код возможность написать свои пакеты\nSource\nбольшое сообщество по всему миру, много ресурсов для задавания вопросов Linear Warriors vs Quadratic Wizards в SPSS (и другие GUI пакеты) ниже порог вхождения, но развитие навыков — линейное в R порог вхождения выше, но впоследствии случается резкий буст, и вы становитесь богами дата саенс\nSource\nрепродуцируемость результатов А он лучше Питона?\nSource\nНет. Но он и не хуже.\nВообще файт R vs Python, на мой взгляд, несколько бессмысленный, поскольку, по факту, всё упирается в синтаксис языка. Ну, и запрос работодателя, конечно. Возможности обоих языков и скорость работы сопоставимы. Области применения по большей части тоже. Поэтому я пользуюсь следующей эвристикой:\nаналитика, статистика, графики, покрутить данные — R машинное обучение, нейросети, другой ИИ, интерфейсы и [собственно] программирование — Python Многие, наверняка, оспорят такое разделение — я же не стану отстаивать его истинность.\nМы будем работать на R, поскольку он всё же более популярен в наших кругах — среди «социально-гуманитарных аналитиков».\nУстановка R и RStudio Чтобы нам радостно и приятно жилось, нужно установить:\nСначала R на Windows на Mac на Linux Затем RStudio Если что-то не установилось или вы предпочитаете облачные сервисы, то можно работать через браузер в RStudio Cloud.\nА зачем обе штуки ставить? Вопрос не безосновательный. Не углубляясь в мелкие детали, скажем так: R — это собственно язык программирования, а RStudio — это среда (IDE, integrated development environment), которая позволяет в этом языке удобно и просто работать, а также расширяет его возможности.\nRStudio — не единственная среда для работы в R, но, определённо, самая топовая. Почти все пользуются именно ею, и нет смысла искать что-то более удобное.\nГде спросить вопрос или искать ответ? Google — препарат выбора Stack Overflow — ответы на вопросы, и не только по R Stack Overflow на русском — то же самое, только отечественные специалисты Cookbook for R — хорошая книжка для старта RStudio Community — ответы на вопросы по R R-bloggers — про новинки в R и рядом с ним Хабр про R … Интерфейс RStudio Итак, посмотрим на RStudio. При запуске у вас откроется что-то такое:\nВидно четыре (или три1) окна. Давайте последовательно разбираться, что в каждом из них происходит.\nConsole В консоль можно писать команды и запускать их нажатием Enter. Они будут сразу выполняться. После некоторых команд будет выводиться какой-то результат. С помощью стрелок ↑ и ↓ можно вывести предыдущие команды, например, чтобы запустить их ещё раз, не вводя повторно, или каким-либо образом их изменить.\nМожно, в прицнипе, работать только из консоли, но на практике это не очень удобно. Главным образом, из-за того, что команды улетают «вникуда» и к некоторым уже будет нельзя вернуться. Поэтому существует редактор кода.\nCode Editor По своей сути это обычный блокнот с той лишь разницей, что здесь некоторые слова раскрашены. И в этом блокноте мы пишем текст программы (скрипт), который состоит из комманд. Чтобы выполнить команду, нам необхожимо отправить её в консоль с помощью Ctrl + Enter (⌘ + Enter). Нажатие Enter здесь как и в обычном текстовом редакторе осуществляет переход на новую строку. Результат выполнения команды отображается в консоли, как будто вы изначально запускали команду там.\nВ консоли удобно что-то быстро посчитать, скрипт же удобнее при работе с длинными командами и для сохранения кода (текста) для дальнейшей работы. Чтобы сохранить скрипт, сделайте File → Save (as…) или нажмите Ctrl + S (⌘ + S).\nНесмотря на то, что файл сохраняется с расширением .R, это всё ещё обычный текст, который можно открыть и редактировать в любом текстовом редакторе (типа Notebook или TextEdit).\nКодировка Компьютер умеет хранить в памяти только цифры. А текст мы набираем буквами. Поэтому ему приходится перекодировать буквы в цифры. Делать это можно по-разному — поэтому существуют разные кодировки.\nПри сохранении скрипта важно следить за кодировкой, особенно если в тексте встречаются кириллические знаки. В разных операционных систем разная кодировка по умолчанию, поэтому на другом компьютере файл может открываться с неведомой кракозяброй типа этой:\nОбычно при сохрании файла с кириллицей программа автоматически спрашивает, в какой кодировке его надо сохранить. Выбирайте UTF-8 — она корректно откроется в любой операционной системе. Также вы можете сохранить файл в определенной кодировке в помощью File → Save with Encoding….\nЕсли при открытии файла у вас отображается кракозябра, подобная той, которая показана выше, нужно узнать кодировку файла2 (для Win это обычно ASCII, для Mac — UTF-8) и выполнить File → Reopen with Encoding….\nEnvironment (Workspace) и History Здесь, в Environment, можно наблюдать переменные и другие объекты, которые создаются в процессе работы кода, а также некоторую информацию о них. Это удобно, поскольку код, бывает, разрастается до сумасшедшего количества строк, и что вы там насоздавали тремястами строками выше — уже и не упомнить. А тут всё под рукой.\nВ окне History можно найти историю команд, которые вы выполняли. Может быть полезно, чтобы не листать консоль, которая, как правило, завалена результатами и ошибками.\nPlots, Files, Packages, Help, Viewer Очень полезное окно в кучей всего.\nсюда выводятся графики, которые вы строите здесь можно найти справку по функциям и пакетам проверить, какие у вас установлены пакеты и их версии посмотреть файлы в рабочей директории наблюдать 3D-визуализации, превью отчетов, презентаций и много чего ещё R как калькулятор R — полноценный язык программирования с множеством возможностей, но давайте начнём с малого. Первое, от чего стоит избавиться — это страх консоли. Боязни калькулятора вроде не бывает (но это не точно3), поэтому стартанём с этого.\nАрифметические операции В R есть все привычные нам математические операции и операторы для них: +, -, *, /, ^. Выполняются они тоже вполне предсказуемо:\n2 + 5 # сложение ## [1] 7 10 - 4 # вычитание ## [1] 6 3 * 7 # умножение ## [1] 21 30 / 3 # деление ## [1] 10 2 ^ 10 # возведение в степень ## [1] 1024 Также есть два особых деления:\n5 %/% 2 # целочисленное деление ## [1] 2 5 %% 2 # взятие остатка от деления (5 mod 2) ## [1] 1\nSource\nВ R есть скобки — (). Их назначение такое же, как и в математике. Порядок выполнения арифметических действий (приоритет операторов4, operator precedence) тоже как в математике. Итого имеем:\n4 * 4 + 4 ## [1] 20 4 * (4 + 4) ## [1] 32 5 * 5 ^ 5 ## [1] 15625 (5 * 5) ^ 5 ## [1] 9765625 Так что используйте скобки, если вы не уверены, в каком порядке будут выполняться действия. Или смотрите таблицу приоритета операторов по команде ?Syntax.\nФункции Но что, если нам надо посчитать что-то более сложное? Например, извлечь корень или вычислить логарифм?\nДля вычисления подобных штук существуют функции. К вопросу, что есть функция, мы ещё не раз вернемся, а пока ограничимся самым общим пониманием: функция это некоторая команда, которая имеет вид название_функции(), просит что-то указать у себя в скобках (например, число) и после выполнения возвращает нам некоторый ответ (например, снова число).\nНа примере с квадратным корнем это выглядит так:\nsqrt(4) ## [1] 2 R чувствителен к регистру (case-sensitive), то есть SQRT(4) не сработает.\nА вот логарифм:\nlog(16) ## [1] 2.772589 Вот только здесь есть одна важная деталь. Если мы вспомним определение логарифма, то окажется, что log𝑎𝑏=𝑐⇔𝑎𝑐=𝑏 &gt; Логарифм некоторого числа — это показатель степени, в которую нужно возвести основание, чтобы получить данное число.\nЗдесь придется чуть углубиться в аргументы функции. Аргументы — это то самое «что-то», что мы записываем в скобках. Бывают обязательные аргументы, без которых функция просто не будет работать и выдаст ошибку, например,\nlog() # попробуйте выполнить эту команду и необязательные аргументы, у которых уже задано некоторое значение по умолчанию, например, аргумент base у функции log(), который отвечает как раз за задание основания логарифма.\nСписок аргументов функции можно посмотреть в справке по данной функции, открыв окно Help и введя в поиск название функции, или выполнив одну из следующих команд:\nhelp(log) # ищет справку по функции ?log # синоним предыдущей команды Также в справке можно найти много другой полезной информации.\nСогласно хелпу, значение по умолчанию равно 𝑒 , то есть вычисляется натуральный логарифм, если основание не указано. Но подождите, в хелпе не написано никакого 𝑒 , там есть что-то странное в виде exp(1). Да, тут спорить бессмысленно, однако exp(1) — это не что иное, как экспонента от единицы, то есть 𝑒1=𝑒 , что равно:\nexp(1) ## [1] 2.718282 Итак, мы выучили две важные вещи: (1) функцию exp() и то, что (2) в качестве аргументов функции можно передавать результаты другой функции. Посмотрите примеры:\nlog(x = 16, base = 2) # эксплицитно задаём основание и число ## [1] 4 log(x = 16, b = 2) # имена аргументов можно не дописывать, если они не совпадают с другими ## [1] 4 log(base = 2, x = 16) # при таком способе задания порядок аргументов можно менять ## [1] 4 log(625, 25) # имя аргумента можно не писать, но тогда соблюдать порядок следования ## [1] 2 log(16, base = exp(sqrt(2))) # задаём аргумент через результат функций ## [1] 1.960516 log10(1000) # десятичный логарифм ## [1] 3 log2(512) # двоичный логарифм ## [1] 9 На логарифмах, естественно, свет клином не сошёлся, есть и множество других функций, например, тригонометрические (sin(), cos(), …). Да и сами арифметические операции, на самом деле, это тоже функции:\n‘+’(7, 3) ## [1] 10 К функциям, как я говорил, мы ещё вернемся, а пока двинемся дальше.\nНо перед этим ещё одна важная деталь. Вы, наверняка, заметили, что после команд я часто пишу # и далее текст. Это комментарии. Они крайне важны в коде, поэтому я, и не только я, настоятельно советую вам их оставлять — и чем больше, тем лучше. Сейчас это может казаться бессмысленным, но поверьте, когда ваш код будет занимать 50+ строк — а это очень небольшой код — разобраться уже будет непросто, не говоря о том, что делать, если вы открыли его через месяц или, не дай боже, год…\nSource\nЗакомментить несколько строк сразу можно сочетанием Ctrl + Shift + C (Cmd + Shift + C).\nСравнение и логические операции Как мы знаем, числа можно сравнивать. Также мы знаем, что существуют операторы сравнения — все они есть и в R: &gt;, &lt;, &gt;=, &lt;=, ==, != — больше, меньше, больше или равно, меньше или равно, равно (ли), не равно.\nОбратите внимание, что сравнение на равенство осуществляется с помощью оператора ==! Одинарное «равно» (=) имеет другой смысл (см. ниже).\nПосмотрим на ряд простых примеров:\n2 &gt; 4 ## [1] FALSE 2 &lt; 6 ## [1] TRUE 3 == 5 - 2 ## [1] TRUE 7 &gt;= 7 ## [1] TRUE 4 != 8 ^ 2 ## [1] TRUE Вроде все логично и понятно. Единственное, что стоит помнить, это то, что приоритет операторов сравнения ниже, чем у арифметических операций.\nСамо по себе сравнение интуитивно понятно, однако нам интересен здесь получаемый результат. Ранее мы имели дело с числами — здесь что-то другое. С одно стороны, программы выдает на слово, но это не простое слово. Это особый тип данных — логическое значение («истина» TRUE или «ложь» FALSE). Типы данных мы обсудим далее, пока же снова ограничимся простым и интуитивным пониманием.\nМы можем составлять из простых сравнений сложные высказывания с помощью логических операторов. Самые известные и часто используемые из них — «И» (&) и «ИЛИ» (|). Подробно об их смысле здесь. Если в двух словах, то «И» истинно, когда оба соединяемых им утверждений истинны, а «ИЛИ» истинно, когда хотя бы одно из соединяемых им утвердений истинно. Например,\n2 &gt; 6 & 8 &lt; 12 ## [1] FALSE 1 != 4 & 5 == 10 / 2 ## [1] TRUE 6 + 2 &lt; 10 | 8 == 10 # что по сути эквивалентно 8 &lt;= 10 ## [1] TRUE 1 + 1 == 2 | FALSE & 4 != 2 * 2 ## [1] TRUE (1 + 1 == 2 | FALSE) & 4 != 2 * 2 ## [1] FALSE Как видно из примеров, приоритет логических операторов ниже приоритета операторов сравнения, а приоритет у & выше, чем у |.\nAssignment и переменные Мы что-то считаем в R и нам важно не терять результаты вычислений. Для этого существуют переменные, в которые можно записывать промежуточные результаты. Делается это так:\nx &lt;- 3 В данном случае мы записали в переменную x значение 3 . Разберёмся подробно:\nОбозначаем название переменной, в данном случае x. На самом деле, название может быть любое, однако рекомендуется давать им осмысленные имена, чтобы потом не запутаться. Длинные названия — это, скорее, хорошо. Это немного съедает времени сейчас, но значительно экономит его в будущем! Также НЕ рекомендуется использовать для обозначения переменных названия функций (например, data(), str() и др). Говорим, что надо записать в переменную значение или же присвоить какой-то результат функции. Делается это с помощью оператора присваивания (assignment) &lt;-, который вводится с клавиатуры шорткатом Alt + - (Option + -). Этот оператор записывает то, что справа в то, что слева. Пишем то, что нужно присвоить в переменную. Это может быть конкретное значение, но чаще это результат какой-либо функции, например: y &lt;- sin(90) После создания переменной, она появляется в Environment. Далее переменные можно использовать в вычислениях:\nx + y ## [1] 3.893997 x^y * x^2 ## [1] 24.03186 log(y, x) ## [1] -0.1019953 x == y ## [1] FALSE Обратите внимание ещё раз, что сравнивания переменные мы используем оператор ==. А что будет если использовать одно «равно»?\nx = y x ## [1] 0.8939967 Выполнилась операция присваивания. Да, её можно записывать и через «равно», но это не очень принято. Традиционно &lt;- используют для присваивания, а = для задания аргументов функций. У оператора присваивания самый низкий приоритет из всех, то есть присваивание выполняется после всех вычислений. Хм, как неожиданно и логично.\nРабочая директория. Projects В ходе нализа данных мы работаем со множеством файлов: скрипты, файлы сырых данных данных, файлы предобработанны данных, файл объектов из рабочего пространства, графики, результаты анализа… Это всё куда-то надо сохранять — вопрос куда?\nВ R есть понятие рабочей директории. Директория — это синоним папки. Рабочая директория — это папка, в которую смотрит R во время работы. Что это за папка можно узнать через команду:\ngetwd() # get working directory ## [1] “/Users/antonangelgardt/Downloads/Telegram Desktop/hse_rs_appandan_2023” У меня он смотрел вот в эту папку, у вас, скорее всего, будет что-то типа C://users/имя_пользователя или /Users/имя_пользователя, что указывает на папку пользователя по умолчанию.\nМожно установить другую рабочую директорию с помощью команды setwd():\nsetwd(“/Users/antonangelgardt/R”) # set working directory Теперь он будет смотреть в папку R, которая лежит в дефолтной папке пользователя. Такой способ достаточно удобен, однако можно сделать ещё лучше — создать проект (Project).\nProjects Кто-то любит работать в проектах, кто-то нет — дело вкуса. Мне это нравится, даже если вам не понравится. Простите, если мы вдруг не сойдёмся во вкусах, но, повторюсь, это нравится мне, сугубо, лично… Поэтому я буду про это рассказывать и рекламировать.\nЗайдите в File → New Project…. У вас откроется такое окно:\nВыберите New Directory, затем еще раз New Project:\nОткроется вот это:\nВ Directory name указываем название нашей папки, во втором поле указываем путь к той папке, в которой будет лежать создаваемая папка. Нажимаем Create Project, после чего R перезапускает сессию, и открывается привычное окно. Однако в верхнем правом углу R теперь указано название проекта, в котором мы работаем.\nМного ли это приносит профита? Ну, не так уж и много… По сути, что открыть проект, что выполнить setwd(“пусть_к_папке”) — примерно одно и то же. Вот только строку кода можно забыть запустить после открытия скрипта, а если мы запустили проект, мы уверены, что у нас все автоматически настроилось и ошибок не будет.\nТипы данных Итак, до какого-то момента мы работали только с числами, а затем начали их сравнивать, и получили что-то новое типа TRUE и FALSE. И как мы отметили, это новый тип данных.\nА что такое вообще тип данных? Тип данных — это характеристика данных, которая определяет:\nмножество допустимых значений, которые могут принимать данные этого типа, и набор операций, которые можно осуществлять с данными этого типа. Что это значит, будем разбираться на конкретных примерах.\nnumeric Этот тип данных нам уже знаком — это числа. Например, если мы создадим переменную со значением 7 и захотим узнать её тип, то это будет выглядеть так:\na &lt;- 7 class(a) # эта команда выводит тип данных ## [1] “numeric” Итак, действительно, 7 — это число, нас не обманули.\nВообще-то, в R много типов числовых данных: integer (целые числа), double (числа с десятичной дробной частью), complex (комплексные числа). Последние вам вряд ли встретятся в ближайшее время, а по поводу деления первых можно особо не заморачиваться — R сам разберется, что к чему, и переконвертирует как надо.\nОднако для интересующихся есть спойлер — все дело в том, как храняться числа] на железе. А о комплексных числах в R немного можно почитать тут.\nЕсли мы всё же хотим выяснить, что это за числовые данные, то воспользуется функцией typeof():\ntypeof(a) ## [1] “double” На числовых данных выполняются все математические операции и различные функции, с чем мы развлекались на протяжении предыдущей главы. А множество значений этого типа, как вы понимаете, бесконечно.\nlogical Здесь все гораздо проще. Есть всего два значение TRUE и FALSE, то есть «истина» и «ложь». Получаются логические данные в результате сравнения — и мы это уже тоже видели в предыдущей главе — и на себе сравнение они также допускают.\nTRUE == TRUE # но вообще-то это операция, которая не несет никакого смысла ## [1] TRUE FALSE != FALSE # эта тоже не несет ## [1] FALSE FALSE == TRUE # и эта ## [1] FALSE TRUE и FALSE — это логические константы, и, обратите внимание, записываются они прописными буквами. true и True не сработают. Правда есть вариант записывать их только одной буквой T и F, но c’est mauvais ton, и вот почему:\nT == TRUE ## [1] TRUE T &lt;- FALSE T == TRUE ## [1] FALSE Константы TRUE и FALSE защищены от перезаписи (на то они и константы).\nПоэтому мы не будем жалеть времени и символы и в угоду удобочитаемости и стабильности кода будем писать логические константы полностью.\nКроме сравнения, логический тип данных допускается на себе логические операции, что в общем-то логично.\nОсновных операций две:\nлогическое И (конъюнкция, &, ∧ , ⋅ ) логическое ИЛИ (дизъюнкция, |, ∨ , + ) Работают они следующим образом в соответствии с таблицей истинности:\nTRUE & TRUE ## [1] TRUE TRUE & FALSE ## [1] FALSE FALSE & TRUE ## [1] FALSE FALSE & FALSE ## [1] FALSE TRUE | TRUE ## [1] TRUE TRUE | FALSE ## [1] TRUE FALSE | TRUE ## [1] TRUE FALSE | FALSE ## [1] FALSE Можем создать и более сложные конструкции. Например, с участие переменных:\nx &lt;- 2 y &lt;- 6 n &lt;- 7\nx &gt; 2 & y &lt; 10 ## [1] FALSE x != 100 | n != 7 ## [1] TRUE !(x != 100 | n != 7) ## [1] FALSE Заметьте, что ! существует не только в составе !=, но и как самостоятельный логический оператор и обозначает логическое отрицание.\nТакже есть оператор xor() (который выглядит как функция5), обозначающий исключающее ИЛИ. Это логическая функция от двух переменных и работает вот так:\nxor(TRUE, TRUE) ## [1] FALSE xor(TRUE, FALSE) ## [1] TRUE xor(FALSE, TRUE) ## [1] TRUE xor(FALSE, FALSE) ## [1] FALSE Он используется редко, но может когда-нибудь внезапно пригодиться.\ncharacter Очевидно, что в практике мы не всегда имеет дело только с цифрами, мы храним ещё и текстовую информацию. Для этого есть тип данных character (хотя другие языки программирования с R бы поспорили).\nx &lt;- “Доброе утро, девочки!” class(x) ## [1] “character” character — это строки (strings) символов, поэтому они должны быть закавычены одинарными (’) или двойными (“) кавычками. Так R поймёт, где строка начинается и где заканчивается. Большой разницы между одинарными и двойными кавычками нет, но если у вас кавычки внутри кавычек, здесь надо быть аккуратным:\nx &lt;- ‘Мужчина громко зашёл в комнату и высказал решительное “здравствуйте”’ x ## [1] “Мужчина громко зашёл в комнату и высказал решительное \"здравствуйте\"” А вообще, есть беспроигрышный [и типографически верный] вариант:\nx &lt;- ‘Мужчина громко зашёл в комнату и высказал решительное «здравствуйте»’ x ## [1] “Мужчина громко зашёл в комнату и высказал решительное «здравствуйте»” Строковый тип данных мы еще подробно обсудим в теме работы со строками, а пока посмотрим вот на что…\nКонечно, чтобы разговор и типах данных был полным, необходимо сказать о таком типе данных как factor. Хотя он не является «базовым» типом, Всё же ему необходимо уделить некоторое внимание.\nfactor Фактор — это строковые данные, которые хранятся как числа. Почему там делать удобно? Потому что фактор содержит определённый (как правило, небольшой) набор уникальных значений (чаще всего около 2–5).\nДля чего используются факторы? Для задания каких-либо групп в данных. Например, у вас есть экспериментальные данные, в которых есть два экспериментальных условия и одно контрольное. Тогда вектор, задающий эти условия может выглядет примерно так:\nconditions &lt;- c(‘exp1’, ‘exp2’, ‘control’, ‘exp1’, ‘exp1’, ‘exp2’, ‘control’, ‘exp2’, ‘control’) conditions ## [1] “exp1” “exp2” “control” “exp1” “exp1” “exp2” “control” ## [8] “exp2” “control” Сейчас это строковый вектор — это достаточно просто превратить в фактор:\nas.factor(conditions) ## [1] exp1 exp2 control exp1 exp1 exp2 control exp2 control ## Levels: control exp1 exp2 В аутпуте добавилась строчка Levels, которая как раз и определяет набор уникальных значений. По умолчанию уровни фактора выстраиваются в алфавитном (лексикографическом) порядке. Если вам принципиален порядок факторов — например, в случае эксперимента на зрительный поиск у вас есть несколько visual set size (количество стимулов в пробе) — тогда можно воспользоваться специальной функцией и создать упорядоченный фактор:\nvis_set_size &lt;- factor(rep(c(3, 6, 9), times = 10), levels = c(3, 6, 9), # задаём порядок уровней ordered = TRUE) # указываем, что нам нужн упорядоченный вектор vis_set_size ## [1] 3 6 9 3 6 9 3 6 9 3 6 9 3 6 9 3 6 9 3 6 9 3 6 9 3 6 9 3 6 9 ## Levels: 3 &lt; 6 &lt; 9 Теперь в строке Levels указаны не только сами уровни, но и отношение порядка для множестве значений. Как видите, в фактор можно превратить не только текстовый вектор, но и числовой.\nВ актуальных версиях R обычно текстовые векторы автоматически приводятся к факторам в тех случаях, когда это нужно. Однако если нам нужен числовой вектор как факторный, это придется делать вручную. Хотя, конечно, числовые данные мы чаще всего рассмтариваем именно как числовые.\nCoercion [part one] А что будет, если мы пренебрежём допустимыми операциями и попробуем, например, сложить не-числа? Допустим, так:\nTRUE + TRUE # складываем две истины ## [1] 2 Внезапно, команда выполнилась. Можно задаться вопросом, почему именно так, ведь правила алгебры логики говорят, что должно быть по-другому. Опуская детали, скажем, что оператор + несет только арифметический, но не логический смысл, поэтому произошло следующее:\nоператор + умеет работать только с числовыми значениями но получил логические поэтому попробовал привести их к числовым у него получилось — TRUE легко и непринуждено приводится к 1, а FALSE к 0 далее выполнилось сложение Такое поведение называется приведение типов (coercion). Подробно мы его будем обсуждать позже, когда изучим структуры данных и поймем, какие опасности это может за собой влечь. Сейчас же ознакомимся с некоторыми примерами.\nПриведение типов сработает не всегда. Например, если мы попытаемся сложить строки6, то получим ошибку:\n“abc” + “cbd” ## Error in “abc” + “cbd”: non-numeric argument to binary operator Чтобы контролировать приведение типов, есть семейство функций as.*(). Посмотрим, как они работают.\n\n21 приводим логические данные в числовым\nas.numeric(TRUE) ## [1] 1 as.numeric(FALSE) ## [1] 0 # приводим числовые данные к логическим as.logical(1) ## [1] TRUE as.logical(0) ## [1] FALSE as.logical(-1) ## наблюдаем, что все не так однозначно ## [1] TRUE as.logical(0.4) ## [1] TRUE as.logical(sqrt(2)) ## [1] TRUE # числовые данные к строке as.character(23) ## [1] “23” as.character(-150) ## [1] “-150” # логические данные к строке as.character(TRUE) ## [1] “TRUE” as.character(FALSE) ## [1] “FALSE” Поздравляю! Мы закончили с основами основ! Пора переходить к самому важному и интересному — структурам данных, а именно – векторам!\nСтруктуры данных С тем, какие существуют данные, мы разобрались. Теперь надо понять, как мы их можем организовать.\nВекторы Простейший способ организации данных — это вектор. Казалось бы, мы знаем, что вектор — это направленный отрезок. Безусловно, это так — в рамках Евклидовой геометрии, которую мы в давнем прошлом учили. Однако это не единственный способ смотреть на вещи. С точки зрения структур данных, вектор — это одномерный массив, а если по-русски, то набор элементов одного типа (например, чисел).\nЭти два представления, на самом деле, не противоречат друг другу. Геометрически, как мы сказали, вектор — это направленный отрезок. Он задаётся через координаты начала и конца. Если мы условимся всегда начинать вектор из начала координат — то есть будет считать равными все векторы, которые имеют одинаковую длину и одинаковое направление7 — то мы сможем задавать вектор только через координаты его конца. В случае двумерного пространства вектор будет однозначно задаваться парой чисел (𝑥,𝑦) , в случае трёхмерного — тройкой чисел (𝑥,𝑦,𝑧) , а в случае 𝑛 -мерного пространства — набором чисел (𝑥1,𝑥2,𝑥3,…,𝑥𝑛) .\nЧтобы создать вектор в R надо воспользоваться функцией c(). Она принимает неограниченное количесво аргументов, которые объединяет в вектор. В вектор можно объединить элементы только одного типа.\nv &lt;- c(1,2,3,5,6,7) Сохраним получившийся числовой вектор в переменную v. Присваивание векторов ничем не отличается от присваивания чисел, во-первых, потому что в R нет скаляров, и все числа — это векторы типа numeric длиной 1, а во-вторых, потому что и число, и вектор, и другие структуры данных (и даже функции!) — всё это объекты. А assignment — не что иное, как присваивание имени некоторому объекту, и нет разницы, что мы называем — число, матрицу, список, датафрейм или функцию.\nCoercion [part two] Взбунтуемся, и объеденим в один вектор разные типы данных:\nv0 &lt;- c(1, 2, TRUE, FALSE) v0 ## [1] 1 2 1 0 Бунт не удался — вектор всё равно был создан. Но что произошло?\nС приведением типов мы уже сталкивались, когда пытались складывать логические константы. Аналогично R действовал и здесь:\nесть задача создать вектор но на выход функции поступили данные различных типов придётся сделать так, чтобы тип был всё-таки один numeric к logical однозначно привести сложно (что есть 2 — TRUE или FALSE?) logical к numeric приводится очень хорошо и красиво (TRUE — 1, FALSE — 0) после приведения типов можно выполнить команду создания вектора. Сделаем вектор из полного салата — добавим сторовые значения:\nv0 &lt;- c(1, 2, TRUE, FALSE, ‘text’, ‘string’) v0 ## [1] “1” “2” “TRUE” “FALSE” “text” “string” Наблюдаем, что все свелось к типу character, что вполне ожидаемо, так как 2 в “2” превращается однозначно, а вот в какое число (или логическую константу) превратить “string”, не очень понятно.\nСобственно, можно вывести иерархию приведения типов:\nlogical &lt; integer &lt; numeric &lt; complex &lt; character Генерация числовых последовательностей Создавать руками векторы — это, конечно, радостно и приятно, но не очень юзабельно. На практике часто возникает потребность сгенерировать определенную числовую последовательность. Например, у вас есть опросниковые данные, из которых необходимо удалить персональные данные, но при этом сохранить возможность соотнести персональные данные и результаты анализа по каждому респонденту — вам нужно сгенерировать переменную ID. Вам поможет оператор :, который генерирует последовательность в заданных пределах с шагом 1:\n1:10 ## [1] 1 2 3 4 5 6 7 8 9 10 15:0 ## [1] 15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 0 Если вам нужна последовательно с другим шагом, например, 0.5, то подойдет функция seq():\nseq(from = 1, to = 10, by = 0.5) # задаём шаг последовательности ## [1] 1.0 1.5 2.0 2.5 3.0 3.5 4.0 4.5 5.0 5.5 6.0 6.5 7.0 7.5 8.0 ## [16] 8.5 9.0 9.5 10.0 seq(0, -6, -1.5) # или без указания названий аргументов ## [1] 0.0 -1.5 -3.0 -4.5 -6.0 seq(from = 5, to = 30, length.out = 20) # задаём длину последовательности ## [1] 5.000000 6.315789 7.631579 8.947368 10.263158 11.578947 12.894737 ## [8] 14.210526 15.526316 16.842105 18.157895 19.473684 20.789474 22.105263 ## [15] 23.421053 24.736842 26.052632 27.368421 28.684211 30.000000 Допустим, у вас есть данные (пусть выборка будет 15 человек), в которых каждые две строки относятся к одному респонденту, но к двум различным экспериментальным условиям (экспериментальному и контрольному). Тогда можно сделать такие переменные:\nrep(1:15, each = 2) # для id ## [1] 1 1 2 2 3 3 4 4 5 5 6 6 7 7 8 8 9 9 10 10 11 11 12 12 13 ## [26] 13 14 14 15 15 rep(c(‘exp’, ‘control’), times = 15) # для обозначения условия ## [1] “exp” “control” “exp” “control” “exp” “control” “exp”\n## [8] “control” “exp” “control” “exp” “control” “exp” “control” ## [15] “exp” “control” “exp” “control” “exp” “control” “exp”\n## [22] “control” “exp” “control” “exp” “control” “exp” “control” ## [29] “exp” “control” Также можно сгенерировать случайную последовательность чисел (например, для того, чтобы использовать её при сабсете случайной подвыборки данных):\nsample(x = 1:30, size = 15) ## [1] 4 13 20 16 25 24 10 1 8 23 17 2 15 5 12 Чтобы результат генерации при повторном запуске кода получался одним и тем же, перед выполнением команды sample(…) нужно выполнить команду set.seed(…):\nset.seed(69) Число внутри функции может быть абсолютно любым.\nОперации с векторами Операции, которые можно выполнять над векторами зависят от типа данных, которые содержатся в векторе. Чаще всего мы будем работать с числовыми векторами, поэтому разберем подробно именно их.\nПусть у нас будет два вектора:\nset.seed(42) # задаём положение для датчика случайных чисел v1 &lt;- sample(1:100, 20) v2 &lt;- sample(-50:100, 20) Над векторами можно выполнять арифметические операции:\nv1 + v2 ## [1] 56 56 -2 66 110 200 132 9 88 147 78 -27 74 66 -4 110 115 70 -14 ## [20] 154 v1 - v2 ## [1] 42 74 52 82 -74 0 -38 39 54 31 -4 67 -22 -60 86 -56 -43 -60 82 ## [20] 20 v1 * v2 ## [1] 343 -585 -675 -592 1656 10000 3995 -360 1207 5162 1517 -940 ## [13] 1248 189 -1845 2241 2844 325 -1632 5829 v1 / v2 ## [1] 7.00000000 -7.22222222 -0.92592593 -9.25000000 0.19565217 1.00000000 ## [7] 0.55294118 -1.60000000 4.17647059 1.53448276 0.90243902 -0.42553191 ## [13] 0.54166667 0.04761905 -0.91111111 0.32530120 0.45569620 0.07692308 ## [19] -0.70833333 1.29850746 Они выполняются поэлементно, то есть соответсвующие элементы двух векторов складываются (вычитаются, умножаются, делятся), и в результате получается новый вектор.\nКроме того, векторы можно поэлементно сравнивать:\nv1 &lt; v2 ## [1] FALSE FALSE FALSE FALSE TRUE FALSE TRUE FALSE FALSE FALSE TRUE FALSE ## [13] TRUE TRUE FALSE TRUE TRUE TRUE FALSE FALSE v1 == v2 ## [1] FALSE FALSE FALSE FALSE FALSE TRUE FALSE FALSE FALSE FALSE FALSE FALSE ## [13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE v2 &lt;= v1 ## [1] TRUE TRUE TRUE TRUE FALSE TRUE FALSE TRUE TRUE TRUE FALSE TRUE ## [13] FALSE FALSE TRUE FALSE FALSE FALSE TRUE TRUE Также к вектору можно применять и функции:\nsin(v1) ## [1] -0.9537527 0.8268287 -0.1323518 -0.9851463 -0.7509872 -0.5063656 ## [7] 0.1235731 -0.9055784 0.9510547 0.8600694 -0.6435381 0.9129453 ## [13] 0.7625585 0.1411200 -0.1586227 0.9563759 -0.9917789 -0.9589243 ## [19] 0.5290827 -0.8218178 log(v1) ## [1] 3.891820 4.174387 3.218876 4.304065 2.890372 4.605170 3.850148 3.178054 ## [9] 4.262680 4.488636 3.610918 2.995732 3.258097 1.098612 3.713572 3.295837 ## [17] 3.583519 1.609438 3.526361 4.465908 exp(v2) ## [1] 1.096633e+03 1.234098e-04 1.879529e-12 3.354626e-04 9.017628e+39 ## [6] 2.688117e+43 8.223013e+36 3.059023e-07 2.415495e+07 1.545539e+25 ## [11] 6.398435e+17 3.873998e-21 7.016736e+20 2.293783e+27 2.862519e-20 ## [16] 1.112864e+36 2.038281e+34 1.694889e+28 1.425164e-21 1.252363e+29 Можно применять несколько функций подряд:\nlog(abs(v2)) ## [1] 1.945910 2.197225 3.295837 2.079442 4.521789 4.605170 4.442651 2.708050 ## [9] 2.833213 4.060443 3.713572 3.850148 3.871201 4.143135 3.806662 4.418841 ## [17] 4.369448 4.174387 3.871201 4.204693 Большинство арифметических функций выполняется поэлементно, однако существуют такие, которые поэлементно не могут быть выполнены, например сумма по вектору:\nsum(v1) ## [1] 878 Или функция, которая вычисляет длину вектора (в смысле количества элементов в нём):\nlength(v2) ## [1] 20 Recycling Доныне мы складывали векторы одинаковой длины. С ними всё ясно — они складываются поэлементно. А что будет, если мы сложим векторы разной длины?\nv3 &lt;- rep(1, times = 10); v3 # создаём векторы ## [1] 1 1 1 1 1 1 1 1 1 1 v4 &lt;- sample(1:100, 2); v4 ## [1] 21 2 v5 &lt;- sample(1:100, 3); v5 ## [1] 58 10 40 length(v3) # проверяем длину ## [1] 10 length(v4) ## [1] 2 length(v5) ## [1] 3 Итак, сумма:\nv3 + v4 ## [1] 22 3 22 3 22 3 22 3 22 3 v3 + v5 ## Warning in v3 + v5: longer object length is not a multiple of shorter object ## length ## [1] 59 11 41 59 11 41 59 11 41 59 Внимательно посмотрим на результат. В первом случае мы складывали вектор из десяти элементов и вектор из двух элементов. Чтобы выполнирь эту операцию R выполняет зацикливание (recycling) более короткого из двух, чтобы каждый элемент большего по длине вектора получил в соответствии элементн меньшего. Так как десять кратно двум, то по сути было выполнена следующая команда:\nv3 + rep(v4, times = length(v3) / length(v4)) ## [1] 22 3 22 3 22 3 22 3 22 3 Во втором случае длина меньшего вектора не кратна длине большего, поэтому recycling происходит до тех пор, пока не будут покрыты все элемент большего вектора. Вектор из трех элементов укладывается на вектор из десяти элементов три раза — поэтому мы видим в результате три раза последовательность 59, 11, 41 — и остается ещё один десятый элемент, который суммируется в первым элементом меньшего вектора — поэтому последний элемент в векторе результата 59.\nИндексация векторов В практике мы постоянно сталкиваемся в необходимость анализировать не все данные в векторе, а их часть. Поэтому встаёт вопрос о том, как эту часть извлечь?\nИзвлечение части данных из вектора называется индексацией. Это делается так:\nv1[1:10] # первые десять элементов вектора ## [1] 49 65 25 74 18 100 47 24 71 89 v1[c(1,3,5,7)] # 1-й, 3-й, 5-й и 7-й элементы вектора ## [1] 49 25 18 47 v1[sample(1:20, 5)] # случайная подвыборка пяти элементов ## [1] 18 49 36 47 74 Логика проста — чтобы взять часть вектора, нам нужен вектор индексов тех элементов, которые мы хотим вытащить. Его мы поместим в квадратные скобки — и будет нам счастье. Вектор индектов можно получить любыми способами:\nсгенерировать последовательноть (как в первом варианте), задать индексы вручную, не забыв при этом обернуть их в фнукцию c(), чтобы указать, что это вектор, (как во втором варианте), воспользоваться функцией, которая возвращает вектор. Полезно также является индексация через отрицательные индексы:\nv2 ## [1] 7 -9 -27 -8 92 100 85 -15 17 58 41 -47 48 63 -45 83 79 65 -48 ## [20] 67 v2[-1] # все элементы, кроме первого ## [1] -9 -27 -8 92 100 85 -15 17 58 41 -47 48 63 -45 83 79 65 -48 67 v2[-(1:5)] # все элементы, кроме первых пяти ## [1] 100 85 -15 17 58 41 -47 48 63 -45 83 79 65 -48 67 Особого внимания заслуживает индексация логическими векторами. Например, мы хотим отобрать все элементы вектора, которые больше некоторого числа. Как это сделать?\nНам нужен вектор, которым мы будем индексировать исходный вектор. Как его получить? Известно, что при сравнении векторов между собой получается логический вектор. Но ведь число — это тоже вектор, просто единичной длины? Значит, если мы будем сравнивать вектор с числом, произойдёт recycling, в результате которого каждый элемент вектора будет сравнен с этим числом. То есть:\nv1 &gt; 40 ## [1] TRUE TRUE FALSE TRUE FALSE TRUE TRUE FALSE TRUE TRUE FALSE FALSE ## [13] FALSE FALSE TRUE FALSE FALSE FALSE FALSE TRUE Отлично! Вектор есть. Можно ли им проидексировать наш исходный вектор v1? Можно! Аналогично тому, как мы это уже делали.\nv1[v1 &gt; 40] ## [1] 49 65 74 100 47 71 89 41 87 Конструкция, возможно, выглядит немного странновато — но работает!\nNA, NaN, NULL Взбунтуемся ещё раз и посмотрим, что получится, если мы будем вытаскивать из вектора элементы, используя индексы, которые выходят за границы длины вектора. Например, у нас есть вектор v2, длина которого\nlength(v2) ## [1] 20 Попробуем сделать так:\nv2[15:25] ## [1] -45 83 79 65 -48 67 NA NA NA NA NA Мы получили нечто, с чем ранее не сталкивались. NA (от not available) обозначает значение, которое недоступно. Как правило, в реальных данных они появляются при каких-либо ошибках записи данных. Впрочем, не всегда. Можно придумать и такой дизайн исследования, когда пропуски также будут информативны и могут анализировться. В нашем случае мы обратились к элементам, которых нет в нашем векторе, поэтому R ничего более не смог сделать, как вернуть нам свидетельство того, что такие элементы он из вектора достать не смог.\nNA ведёт себя весьма специфично. Например, если мы попробуем посчитать сумму по получившемуся вектору, то результат будет следующим:\nsum(v2[15:25]) ## [1] NA Аналогичная ситуация возникнет, если мы будем вычислять среднее:\nmean(v2[15:25]) ## [1] NA Такое поведение функций может поначалу напрягать, однако оказывается очень полезным при работе с реальными данными.\nИ всё же функция sum() не так проста, и умеет бороться с NA. Для этого у неё есть аргумент na.rm, которому нужно задать значение TRUE, если мы хотим, чтобы сумма все же была посчитана:\nsum(v2[15:25], na.rm = TRUE) ## [1] 201 Попробуем вычислить логарифм по вектору v2:\nlog(v2) ## Warning in log(v2): NaNs produced ## [1] 1.945910 NaN NaN NaN 4.521789 4.605170 4.442651 NaN ## [9] 2.833213 4.060443 3.713572 NaN 3.871201 4.143135 NaN 4.418841 ## [17] 4.369448 4.174387 NaN 4.204693 Опять всё не слава богу. Теперь у нас NaN. Это почти как NA, но не совсем. NaN обозначает не-число (not a number). То есть, это не пропущенное значение, оно существует, но R его не может вычислить. Если мы сравним два вектора,\nv2; log(v2) ## [1] 7 -9 -27 -8 92 100 85 -15 17 58 41 -47 48 63 -45 83 79 65 -48 ## [20] 67 ## Warning in log(v2): NaNs produced ## [1] 1.945910 NaN NaN NaN 4.521789 4.605170 4.442651 NaN ## [9] 2.833213 4.060443 3.713572 NaN 3.871201 4.143135 NaN 4.418841 ## [17] 4.369448 4.174387 NaN 4.204693 то обнаружим, что NaN появляется там, где мы пытаемся вычислить логарим отрицательного числа. А, как мы помним, функция логарифма определена только на положительно полуоси 𝑥 . Вот и получается, что логарифм отрицательного аргумента — это какая-то неведомая сущность, то точно не-число.\nВ функциях NaN ведёт себя аналогично NA:\nsum(log(v2)) ## Warning in log(v2): NaNs produced ## [1] NaN Мы поговорили о двух важный константах используемых в R. Есть ещё одна, и имя её NULL. Это имя обозначает «ничего», то есть, что объект пуст.\nНапример, возьмем вектор v, который мы создавали в самом начале, и положим в него NULL:\nv &lt;- NULL v ## NULL Теперь в этом векторе ничего не лежит.\nNULL может использоваться при задании аргументов функций или как результат работы функций, если возвращается пустой объект.\nМатрицы Говоря о векторах, мы обозначили, что вектор — это одномерный массив. А раз есть одномерные массивы, значит бывают какие-то ещё? Да. Сгенерируем некоторый вектор:\nv6 &lt;- sample(1:100, 12); v6 ## [1] 73 29 76 84 9 35 93 16 92 69 2 82 и попробуем его «сложить» в «таблицу» так, чтобы в каждой строке было по три числа:\nm1 &lt;- matrix(v6, ncol = 3); m1 ## [,1] [,2] [,3] ## [1,] 73 9 92 ## [2,] 29 35 69 ## [3,] 76 93 2 ## [4,] 84 16 82 Так как мы «складываем друг на друга» части одномерного массива, у нашего нового массива возникает новое измерение — если вектор был только одной строкой, то теперь в нашем массиве есть и строки, и столбцы. Двумерный массив назвается матрицей.\nclass(m1) ## [1] “matrix” “array” И поэтому для его создания мы использовали функцию matrix(). В качестве основных аргументов она хочет видеть вектор, который мы будет «упаковывать» в матрицу, а также количество строк или столбцов новой матрицы.\nИндексация матриц От того, что мы свернули вектор в матрицу, он не перестал быть вектором. [Шок!] То есть матрица по сути всё ещё тот же самый вектор, поэтому индексировать её можно точно так же, как и вектор:\nv6[1]; m1[1] ## [1] 73 ## [1] 73 v6[4]; m1[4] ## [1] 84 ## [1] 84 v6[11]; m1[11] ## [1] 2 ## [1] 2 Однако поскольку матрица — это всё же матрица, она отличается от вектора тем, что у неё есть дополнительный атрибут dim, который отображает её размерность:\ndim(m1) ## [1] 4 3 В данном случае наблюдаем, что размерность матрицы 4×3 , и это справедливо, ведь именно такую матрицу мы и создавали. А раз у нас имеется указание на количество строк и столбцов в матрице, то мы можем вытащить элемент(ы) как раз по его позиции:\nm1[1, 2] # вытаскиваем элемент из первой строки и второго столбца ## [1] 9 Те же квадратные скобки, только указываем мы теперь две «координаты» — сначала строки, затем столбцы. Как не запутаться? Аналогия с координатами не случайна: строки — горизонтальны, первая координата на координата на координатной плоскости (𝑥 ) тоже задаёт положение точки на горизонтальной оси; столбцы — вертикальны, вторая координата (𝑦 ) задает положение точки на вертикальной оси.\nТакже мы можем вытащить не только отдельный элемент, но и какую-то часть матрицы. Всё работает аналогично векторам:\nm1[1:3, 2:3] ## [,1] [,2] ## [1,] 9 92 ## [2,] 35 69 ## [3,] 93 2 Если мы выползем за границы индексации, R начнёт ругаться:\nm1[1:3, 2:4] ## Error in m1[1:3, 2:4]: subscript out of bounds Операции c матрицами См. книжку.\nСписки До текущего момента мы говорили о структурах данных, которые требуют одинакового типа данных в себе. Давайте теперь вообразим вектор без ограничения на однотипность данных. Это будет список (list).\nl &lt;- list(69, “text”, TRUE) l ## [[1]] ## [1] 69 ## ## [[2]] ## [1] “text” ## ## [[3]] ## [1] TRUE Но список даёт нам ещё больше возможностей, потому что он может собирать в себя вообще любые объекты:\nl2 &lt;- list(c(“This”, “list”, “contains”, “a”, “matrix”), m1, l) l2 ## [[1]] ## [1] “This” “list” “contains” “a” “matrix”\n## ## [[2]] ## [,1] [,2] [,3] ## [1,] 73 9 92 ## [2,] 29 35 69 ## [3,] 76 93 2 ## [4,] 84 16 82 ## ## [[3]] ## [[3]][[1]] ## [1] 69 ## ## [[3]][[2]] ## [1] “text” ## ## [[3]][[3]] ## [1] TRUE Таким образом, список может являть собой крайне сложную структуру. Чтобы разобраться, как устроен конкретный список, можно воспользоваться функцией str(), которая отобразит структуру списка:\nstr(l2) ## List of 3 ## $ : chr [1:5] “This” “list” “contains” “a” … ## $ : int [1:4, 1:3] 73 29 76 84 9 35 93 16 92 69 … ## $ :List of 3 ## ..$ : num 69 ## ..$ : chr “text” ## ..$ : logi TRUE Как видно в аутпуте функции, список содержит три элемента: текстовый вектор длиной 5, массив целых чисел, размером 4×3, и список, который в свою очерель состоит также из трёх элементов — числа 69, строкового вектора, содержащего одно значение (“text”) и логического вектора длиной 1, который содержит значение «истина».\nМожно назвать отдельные элементы списка собственными именами:\n\n\n22 создадим список такой же, как l2, только именованный\nl3 &lt;- list(description = c(“This”, “list”, “contains”, “a”, “matrix”), matrix = m1, inner_list = l) l3 ## $description ## [1] “This” “list” “contains” “a” “matrix”\n## ## $matrix ## [,1] [,2] [,3] ## [1,] 73 9 92 ## [2,] 29 35 69 ## [3,] 76 93 2 ## [4,] 84 16 82 ## ## $inner_list ## $inner_list[[1]] ## [1] 69 ## ## $inner_list[[2]] ## [1] “text” ## ## $inner_list[[3]] ## [1] TRUE Индексация списков Списки в R появляются достаточно часто — и, главным образом, как результат работы функций. Собственными руками мы их создавать вряд ли когда либо будем, а вот вытаскивать из них инфу по частям нам научиться надо обязательно.\nПоскольку список как и вектор состоит из отдельных элементов, которые в нём расположены в определённом порядке, то можно поступить со списком как с вектором:\nl3[1] ## $description ## [1] “This” “list” “contains” “a” “matrix” Мы помним, что с списке l3 первым элементом был строковый вектор. Однако когда мы обратились к первому элементу, нам вернулся список, содержащий этот вектор. Да, такова особенность индексации списков — если мы используем одинарные квадратные скобки, то возвращается список из одного элемента. Почему так? Потому что если мы заходим вытащить, например, первые два элемента, то они могут оказаться различной структуры, и вернуть их вместе, кроме как списком, нет варианта.\nl3[1:2] ## $description ## [1] “This” “list” “contains” “a” “matrix”\n## ## $matrix ## [,1] [,2] [,3] ## [1,] 73 9 92 ## [2,] 29 35 69 ## [3,] 76 93 2 ## [4,] 84 16 82 Чтобы вытащить сам вектор, нам потребуются двойные квадратные скобки:\nl3[[1]] ## [1] “This” “list” “contains” “a” “matrix” Можно пойти далее и вытащить какой-то элемент из вектора прямо в этой же строке:\nl3[[1]][c(1, 5)] # вытащим сразу первый и пятый ## [1] “This” “matrix” Раз у нас именованный список, то можно вытащить элемент по имени (с векторами тоже работает):\nl3[‘matrix’] # так вернётся список ## $matrix ## [,1] [,2] [,3] ## [1,] 73 9 92 ## [2,] 29 35 69 ## [3,] 76 93 2 ## [4,] 84 16 82 l3[[‘matrix’]] # а так сама матрица ## [,1] [,2] [,3] ## [1,] 73 9 92 ## [2,] 29 35 69 ## [3,] 76 93 2 ## [4,] 84 16 82 Но списки нам предоставляют ещё одну удобную и полезную фичу — индексацию по имени, но другим способом:\nl3\\(description\n## [1] \"This\"     \"list\"     \"contains\" \"a\"        \"matrix\"\nl3\\)matrix ## [,1] [,2] [,3] ## [1,] 73 9 92 ## [2,] 29 35 69 ## [3,] 76 93 2 ## [4,] 84 16 82 Обратите внимание, что в таком случае сразу возвращается «голый» объект — вектор, матрица, etc. Запомните этот способ — так мы будем делать о-о-очень часто (примерно всегда).\nДатафреймы Ура! Мы добрались до самого интересноо в самого важного!\nКратко вспомним, что мы умеем к этому моменту:\nманипулировать с векторами (создавать, индексировать, производить разные математические операции) работать с матрицами (создавать, индексировать, производить разные математические операции) обращаться со списками (создавать и индексировать различными способами) Так вот все эти знания и умения нам нужны, чтобы мастерски жонглировать датафреймами. Датафрейм — это детище большой любви матрицы и списка:\nВ одном из домашних заданий вы создавали матрицу, которая содержала имена респондентов, их пол, город проживания и любимый цвет. Но ождиаемое ограничение было в том, что все данные неизбежно приводились к строковому типу. И в таком варианте вроде бы ничего криминального, но если мы захотим добавить данные о возраста — что делать? Хорошо мы, чтобы они сохранились в числовом формате, ведь так с ними дальше будет удобно работать.\n\n\n23 немного изменим набор переменных для демонстрации возможностей\ndf &lt;- data.frame(name = c(‘Илья’, ‘Алёна’, ‘Виктор’, ‘Елена’, ‘Кристина’), age = c(21, 34, 19, 52, 26), sex = c(‘муж’, ‘жен’, ‘муж’, ‘жен’, ‘жен’), city = c(“Орёл”, “Тверь”, “Тирасполь”, “Питер”, “Москва”)) df ## name age sex city ## 1 Илья 21 муж Орёл ## 2 Алёна 34 жен Тверь ## 3 Виктор 19 муж Тирасполь ## 4 Елена 52 жен Питер ## 5 Кристина 26 жен Москва Обратите внимание, датафрейм создается практически так же, как и список, только функция другая. А в итоге получается привычная нам таблица! Magique!\nКак устроена эта таблица? По сути датафрейм — это именованный список, каждый элемент которого — это вектор определённой длины (одинаковой для всех векторов, входящих в этот список). Так они одинаковой длины, то их можно «поставить рядом друг с другом» как колонки матрицы. Собственно, так и получается. Вот только в данному случае разные столбцы могут содержать разный тип данных.\nИ тем не менее, поскольку датафрейм наследует свойства обоих своих «родителей», обращаться с ним можно и как со списком, и как с матрицей:\nstr(df) # изучаем структуру ## ‘data.frame’: 5 obs. of 4 variables: ## $ name: chr “Илья” “Алёна” “Виктор” “Елена” … ## $ age : num 21 34 19 52 26 ## $ sex : chr “муж” “жен” “муж” “жен” … ## $ city: chr “Орёл” “Тверь” “Тирасполь” “Питер” … df\\(name # вытаскиваем элемент списка (вектор имён респондентов)\n## [1] \"Илья\"     \"Алёна\"    \"Виктор\"   \"Елена\"    \"Кристина\"\ndf\\)name[1:3] # индексируем вектор имён респондентов ## [1] “Илья” “Алёна” “Виктор” df[, 1] # так тоже срабоает ## [1] “Илья” “Алёна” “Виктор” “Елена” “Кристина” df[1] # и даже так, но какая структура данных вернулась? ## name ## 1 Илья ## 2 Алёна ## 3 Виктор ## 4 Елена ## 5 Кристина df[1:2, 3:4] # ну это просто пушка ## sex city ## 1 муж Орёл ## 2 жен Тверь Можно добавить новые переменные:\ndf$married &lt;- FALSE # recycling has happened Функции См. книжку.\nОткрытый исходный код В R можно не только написать свои функции, но и посмотреть, как написаны другие, то есть увидеть исходный код. Для этого надо написать название функции и выполнить её как команду (без скобок):\nsd # стандартное отклонение — корень из дисперсии ## function (x, na.rm = FALSE) ## sqrt(var(if (is.vector(x) || is.factor(x)) x else as.double(x), ## na.rm = na.rm)) ## &lt;bytecode: 0x7fb7fa7d1870&gt; ## &lt;environment: namespace:stats&gt; lm # функция для построения линейной регрессионной модели ## function (formula, data, subset, weights, na.action, method = “qr”, ## model = TRUE, x = FALSE, y = FALSE, qr = TRUE, singular.ok = TRUE, ## contrasts = NULL, offset, …) ## { ## ret.x &lt;- x ## ret.y &lt;- y ## cl &lt;- match.call() ## mf &lt;- match.call(expand.dots = FALSE) ## m &lt;- match(c(“formula”, “data”, “subset”, “weights”, “na.action”, ## “offset”), names(mf), 0L) ## mf &lt;- mf[c(1L, m)] ## mf\\(drop.unused.levels &lt;- TRUE\n##     mf[[1L]] &lt;- quote(stats::model.frame)\n##     mf &lt;- eval(mf, parent.frame())\n##     if (method == \"model.frame\")\n##         return(mf)\n##     else if (method != \"qr\")\n##         warning(gettextf(\"method = '%s' is not supported. Using 'qr'\",\n##             method), domain = NA)\n##     mt &lt;- attr(mf, \"terms\")\n##     y &lt;- model.response(mf, \"numeric\")\n##     w &lt;- as.vector(model.weights(mf))\n##     if (!is.null(w) && !is.numeric(w))\n##         stop(\"'weights' must be a numeric vector\")\n##     offset &lt;- model.offset(mf)\n##     mlm &lt;- is.matrix(y)\n##     ny &lt;- if (mlm)\n##         nrow(y)\n##     else length(y)\n##     if (!is.null(offset)) {\n##         if (!mlm)\n##             offset &lt;- as.vector(offset)\n##         if (NROW(offset) != ny)\n##             stop(gettextf(\"number of offsets is %d, should equal %d (number of observations)\",\n##                 NROW(offset), ny), domain = NA)\n##     }\n##     if (is.empty.model(mt)) {\n##         x &lt;- NULL\n##         z &lt;- list(coefficients = if (mlm) matrix(NA_real_, 0,\n##             ncol(y)) else numeric(), residuals = y, fitted.values = 0 *\n##             y, weights = w, rank = 0L, df.residual = if (!is.null(w)) sum(w !=\n##             0) else ny)\n##         if (!is.null(offset)) {\n##             z\\)fitted.values &lt;- offset ## z\\(residuals &lt;- y - offset\n##         }\n##     }\n##     else {\n##         x &lt;- model.matrix(mt, mf, contrasts)\n##         z &lt;- if (is.null(w))\n##             lm.fit(x, y, offset = offset, singular.ok = singular.ok,\n##                 ...)\n##         else lm.wfit(x, y, w, offset = offset, singular.ok = singular.ok,\n##             ...)\n##     }\n##     class(z) &lt;- c(if (mlm) \"mlm\", \"lm\")\n##     z\\)na.action &lt;- attr(mf, “na.action”) ## z\\(offset &lt;- offset\n##     z\\)contrasts &lt;- attr(x, “contrasts”) ## z\\(xlevels &lt;- .getXlevels(mt, mf)\n##     z\\)call &lt;- cl ## z\\(terms &lt;- mt\n##     if (model)\n##         z\\)model &lt;- mf ## if (ret.x) ## z\\(x &lt;- x\n##     if (ret.y)\n##         z\\)y &lt;- y ## if (!qr) ## z$qr &lt;- NULL ## z ## } ## &lt;bytecode: 0x7fb7f6c95f80&gt; ## &lt;environment: namespace:stats&gt; Строки Мы уже знакомились со строковым типом данных character. Но мы обозначили, что многие операции над этим типом невозможны (например, нельзя сложить две строки). Возникает вопрос: что делать?\nДля начала научимся ставить дополнительные пакеты.\nУстановка дополнительных пакетов В самом начале мы упоминали, что R имеет большие возможности расширения функционала с помощью специальных пакетов. Для работы со строками нам будут нужны два — stringi («стринг-ай») и stringr («стринг-ар»). На их примере мы и разберем механизм установки и подключения дополнительных пакетов.\nПакет — это набор функций, не входящих в «базовую комплектацию R», которые, как правило, специализированы под те или иные задачи. В нашем случае — под работу со строками. Поэтому сначала пакет необходимо скачать на комп:\ninstall.packages(c(“stringi”, “stringr”)) В функцию install.packages() необходимо передать строковый вектор, содержащий названия пакетов, которые мы бы хотели установить.\nЧасто одни пакеты ссылаются на функции других, поэтому можно указать в аргументе dependencies TRUE, чтобы попутно установились зависимые пакеты.\ninstall.packages(c(“stringi”, “stringr”), dependencies = TRUE) По умолчанию пакеты скачиваются с репозитория CRAN — основное хранилище, где лежит подавляющее большинство пакетов и всякого разного. Но может быть такое, что установить соединение с этим репозиторием по каким-либо причинам не получается. Чтобы пофиксить сей баг, нужно указать в настройках какое-либо из зеркал. Options → Packages → Primary CRAN repository → Change…, и выбрать что-то. Если не помогло — попробуйте ещё.\nНо мало просто скачать пакет. Надо его ещё подключить к текущей сессии, в которой мы работаем. Для этого используется функция\nlibrary(stringi) library(stringr) Ей уже надо скормить название пакета без кавычек, и для подключения каждого пакета потребуется написать новую строчку.\nТут запутываются термины «пакет» и «библиотека», но опустим эти детали и примем сей момент как есть…\nПосле того, как мы подключили пакет к данной сессии, мы можем использовать функции из него.\nКайф, поехали!\nСоздание строк Можно сделать строку руками (наблюдайте за кавычками):\ns1 &lt;- “сложившаяся структура организации влечет за собой процесс внедрения и модернизации новых предложений” s1 ## [1] “сложившаяся структура организации влечет за собой процесс внедрения и модернизации новых предложений” s2 &lt;- ‘С другой стороны постоянный количественный “рост” и сфера нашей активности позволяет выполнять важные задания по разработке соответствующий условий активизации’ s2 ## [1] “С другой стороны постоянный количественный \"рост\" и сфера нашей активности позволяет выполнять важные задания по разработке соответствующий условий активизации” s3 &lt;- “С другой стороны постоянный количественный”рост” и сфера нашей активности позволяет выполнять важные задания по разработке соответствующий условий активизации” s3 ## Error: :1:52: unexpected symbol ## 1: s3 &lt;- “С другой стороны постоянный количественный”рост ## ^ s4 &lt;- “С другой стороны постоянный количественный ‘рост’ и сфера нашей активности позволяет выполнять важные задания по разработке соответствующий условий активизации” s4 ## [1] “С другой стороны постоянный количественный ‘рост’ и сфера нашей активности позволяет выполнять важные задания по разработке соответствующий условий активизации” s5 &lt;- “С другой стороны постоянный количественный «рост» и сфера нашей активности позволяет выполнять важные задания по разработке соответствующий условий активизации” s5 ## [1] “С другой стороны постоянный количественный «рост» и сфера нашей активности позволяет выполнять важные задания по разработке соответствующий условий активизации” s6 &lt;- “” # это пустая строка s6 ## [1] “” Также можно использовать функцию character()8 для создания вектора из пустых строк:\ncharacter(5) ## [1] “” “” “” “” “” А также функции для приведения типов, которые мы уже обсуждали:\nas.character(1:30) ## [1] “1” “2” “3” “4” “5” “6” “7” “8” “9” “10” “11” “12” “13” “14” “15” ## [16] “16” “17” “18” “19” “20” “21” “22” “23” “24” “25” “26” “27” “28” “29” “30” Кроме того, существуют встроенные текстовые векторы:\nletters ## [1] “a” “b” “c” “d” “e” “f” “g” “h” “i” “j” “k” “l” “m” “n” “o” “p” “q” “r” “s” ## [20] “t” “u” “v” “w” “x” “y” “z” LETTERS ## [1] “A” “B” “C” “D” “E” “F” “G” “H” “I” “J” “K” “L” “M” “N” “O” “P” “Q” “R” “S” ## [20] “T” “U” “V” “W” “X” “Y” “Z” Есть ещё встроенные векторы, которые содержат названия месяцев и аббревиатуры названий месяцев. Можете их отыскать.\nМы умеем генерировать числавые последовательности. Можно также генерировать и строки. Например, когда вы хотите сгенерировать ID для испытуемых не просто как числа, а как уникальные текстовые значения:\nstri_rand_strings(n = 10, length = 5) ## [1] “DDOwx” “jjX0b” “pkSXX” “0MbpM” “PZaiO” “uxEiu” “bdwqZ” “o7lc9” “4Smjo” ## [10] “AwI9i” Фнукции из пакета stringi начинаются с префикса stri, а функции пакета stringr — с префикса str. Их легко можно опознать.\nКонкатенация строк Строки можно соединять воедино:\npaste(‘first’, ‘second’, ‘third’) # базовый R ## [1] “first second third” paste(‘first’, ‘second’, ‘third’, sep = “_“) ## [1]”first_second_third” paste0(‘first’, ‘second’, ‘third’) ## [1] “firstsecondthird” stri_c(‘first’, ‘second’, ‘third’) # пакет stringi ## [1] “firstsecondthird” stri_c(‘first’, ‘second’, ‘third’, sep = ” & “) # пакет stringi ## [1]”first & second & third” Разделение строк Если добрый коллега записал экспериментальные условия в одну переменную как выше, а вам нужно делать по ним, например, какую-нибудь анову, то можно на него долго ругаться, а можно разделить строки обратно:\ns_exp &lt;- paste(‘first’, ‘second’, ‘third’, sep = “”) s_exp ## [1] ”first_second_third” str_split(s_exp, pattern = ””) ## [[1]] ## [1] “first” “second” “third” Нам вернулся список. Шо с ним делать — вопрос хороший. Можно развернуть список в вектор и индексацией вытащить нужные нам части.\nНо есть более удобная функция separate(), которая разбивает субстроки сразу по колонкам. Её мы вспомним, когда будет говорить о предобработке данных.\nСортировка строк Строки можно сортировать:\nunsorted_s &lt;- paste0( sample(LETTERS, size = length(LETTERS), replace = TRUE), sample(letters, size = length(letters)), sample(letters, size = length(letters)) ) # делаем несортированный вектор из трёхбуквенных «слов» unsorted_s ## [1] “Xbz” “Aja” “Ywe” “Ylc” “Siv” “Qam” “Nzk” “Ntq” “Okd” “Fnt” “Xsy” “Oxi” ## [13] “Kpp” “Eru” “Pyl” “Qvn” “Vfr” “Qes” “Rqo” “Buh” “Fgj” “Vmb” “Fcw” “Fhf” ## [25] “Tdx” “Oog” Сортируем:\nsort(unsorted_s) # можно базовой функцией ## [1] “Aja” “Buh” “Eru” “Fcw” “Fgj” “Fhf” “Fnt” “Kpp” “Ntq” “Nzk” “Okd” “Oog” ## [13] “Oxi” “Pyl” “Qam” “Qes” “Qvn” “Rqo” “Siv” “Tdx” “Vfr” “Vmb” “Xbz” “Xsy” ## [25] “Ylc” “Ywe” str_sort(unsorted_s) # можно функцией из пакета stringr ## [1] “Aja” “Buh” “Eru” “Fcw” “Fgj” “Fhf” “Fnt” “Kpp” “Ntq” “Nzk” “Okd” “Oog” ## [13] “Oxi” “Pyl” “Qam” “Qes” “Qvn” “Rqo” “Siv” “Tdx” “Vfr” “Vmb” “Xbz” “Xsy” ## [25] “Ylc” “Ywe” Строки сортируются в лексикографическом порядке. Обратите внимание, что порядок сортировки зависит от того, в какой локали мы работаем, то есть от того, алфавит какого языка используется для определения лексикографического порядка:\nstr_sort(c(“э”, “а”, “у”, “i”), locale = ‘en’) # по умолчанию ## [1] “i” “а” “у” “э” str_sort(c(“э”, “а”, “у”, “i”), locale = ‘ru’) # русский ## [1] “а” “у” “э” “i” Сортировок существует много разных. Но чем больше у вас данные, тем медленнее будет работать базовый sort(). Поэтому используйте str_sort().\nИзменение регистра Допусти вы собирали данные онлайн, и у вас было поле ступень образования, в которой респонденты должны быть указать бакалавриат/магистратура/аспирантура. Но по каким-то причинам, разработчик онлайн-формы не подумал, что хорошо бы сделать это поле списком, из котрого можно выбирать, и оставил его как обычное текстовое поле. Теперь у вас в данных есть «бакалавриат», «Бакалавриат» и какой-нибудь «БАкалавриат», то вообще-то одно и то же. Напасти подобного рода можно победить, если привести строки к единому регистру:\nstr_to_lower(c(“Бакалавриат”, “БАКАЛАВРИАТ”, “АСпирантура”, “магистратура”)) ## [1] “бакалавриат” “бакалавриат” “аспирантура” “магистратура” str_to_upper(c(“Бакалавриат”, “БАКАЛАВРИАТ”, “АСпирантура”, “магистратура”)) ## [1] “БАКАЛАВРИАТ” “БАКАЛАВРИАТ” “АСПИРАНТУРА” “МАГИСТРАТУРА” Но при таком способе сбора данных могли возникнуть и другие ошибки, так что лучше задуматься об их предотвращении заранее!\nПоиск подстроки Если нам надо найти какую-то подстроку, то мы можем использоваться функцию str_detect():\nstr_detect(unsorted_s, ‘b’) # ищем все элементы, в которых есть маленькая «b» ## [1] TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE TRUE FALSE FALSE ## [25] FALSE FALSE unsorted_s[str_detect(unsorted_s, ‘b’)] # а вот и сами элементы ## [1] “Xbz” “Vmb” Можно подсчитать число вхождений подстроки в строке:\nstr_count(unsorted_s, ‘a’) ## [1] 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Изменение строк Раз мы умеем искать подстроку, то, наверное, её можно и как-то изменять.\nВыделение подстроки str_sub(unsorted_s, start = 1, end = 2) # по индексам ## [1] “Xb” “Aj” “Yw” “Yl” “Si” “Qa” “Nz” “Nt” “Ok” “Fn” “Xs” “Ox” “Kp” “Er” “Py” ## [16] “Qv” “Vf” “Qe” “Rq” “Bu” “Fg” “Vm” “Fc” “Fh” “Td” “Oo” Замена подстроки str_replace(unsorted_s, pattern = “b”, replacement = “Ц”) ## [1] “XЦz” “Aja” “Ywe” “Ylc” “Siv” “Qam” “Nzk” “Ntq” “Okd” “Fnt” “Xsy” “Oxi” ## [13] “Kpp” “Eru” “Pyl” “Qvn” “Vfr” “Qes” “Rqo” “Buh” “Fgj” “VmЦ” “Fcw” “Fhf” ## [25] “Tdx” “Oog” Удаление подстроки str_remove(unsorted_s, ‘b’) ## [1] “Xz” “Aja” “Ywe” “Ylc” “Siv” “Qam” “Nzk” “Ntq” “Okd” “Fnt” “Xsy” “Oxi” ## [13] “Kpp” “Eru” “Pyl” “Qvn” “Vfr” “Qes” “Rqo” “Buh” “Fgj” “Vm” “Fcw” “Fhf” ## [25] “Tdx” “Oog” Транслитерация строк stri_trans_general(“русский текст, который должен быть написан латиницей”, ‘cyrillic-latin’) ## [1] “russkij tekst, kotoryj dolžen bytʹ napisan latinicej” Регулярные выражения Но часто нас интересует не конкретная подстрока, и все варианты подстрок, которые имеют определенную структуру. Например, мы хотим найти корректно введенные даты рождения в нашем датасете. Пусть по условию дата должна иметь формат DD.MM.YYYY. И у нас есть вот такой вектор:\ndates &lt;- c(‘21.92.2001’, ‘01.04.1994’, ‘5-3-2011’, ‘6/04/1999’) Ну, так как у нас сейчас совсем игрушечные данные, мы можем смотреть на них глазами и видеть, что у нас в прицнипе три адекватные даты, но записаны по-разному, и одна верного формата, но с 92 месяцем.\nЧтобы задать структуру паттерна, который мы хотим найти, используются регулярные выражения.\nЧтобы отображать их работу, будем пользоваться функцией str_view_all().\nМетасимволы Если мы попробуем поискать точки в наших датах, то просто так мы их не найдем:\nstr_view_all(dates, pattern = “.”) 21.92.2001 01.04.1994 5-3-2011 6/04/1999 Подсветились все символы, так как точка в регулярных выражениях — специальный символ. Поэтому чтобы указать, что нас интересуют собственно точки, нужно их экранировать.\nstr_view_all(dates, pattern = ‘\\.’) 21.92.2001 01.04.1994 5-3-2011 6/04/1999 Так лучше. Еще к специальным знакам (метасимфолам) относятся $, *, +, ?, ^, [, ], и другие.\nКлассы знаков В датах нас интересуют цифры, и для них есть специальное обозначение:\nstr_view_all(dates, pattern = ‘\\d’) # ищем цифры 21.92.2001 01.04.1994 5-3-2011 6/04/1999 str_view_all(dates, pattern = ‘\\D’) # ищем не-цифры 21.92.2001 01.04.1994 5-3-2011 6/04/1999 Другие классы символов можно найти в следующих примерах:\nstr_view_all(‘успешный балбес’, ‘\\s’) # пробелы успешный балбес str_view_all(‘успешный балбес’, ‘\\S’) # не-пробелы успешный балбес str_view_all(‘верно ведь, что здесь что-то есть’, ‘\\w’) # не пробелы и не знаки препинания верно ведь, что здесь что-то есть str_view_all(‘верно ведь, что здесь что-то есть’, ‘\\W’) # пробелы и знаки препинания верно ведь, что здесь что-то есть Квантификация Можно указать, сколько раз должен встречаться тот или иной символ:\n? — ноль или один раз * — ноль или более раз + — один или более раз {n} — n раз Например, найдем все группировки по два числа:\nstr_view_all(dates, ‘\\d{2}’) 21.92.2001 01.04.1994 5-3-2011 6/04/1999 Итак, теперь мы можем вытащить все корректные даты, которые есть в нашем векторе:\nstr_view_all(dates, ‘\\d{2}\\.[01]\\d{1}\\.\\d{4}’) 21.92.2001 01.04.1994 5-3-2011 6/04/1999 Она получилась всего одна. Но в целом в нашим набором условий это справедливо.\nРабота с реальными данными Работу с реальными данными мы будем обсуждать в ходе курса. Сейчас же я хочу, чтобы вы попробовали выполнить саму первую задачу при работе с данными — чтение данных. Это первое, где можно существенно встрять и с чем надо уметь разбираться. Мы будем тренироваться на данных о фильмах и сериалах Netflix.\nИмпорт данных Окей, файл с данными у нас есть. Теперь наша задача его как-то загрузить в R, чтобы мы могли с ним работать. Вариантов существует несколько. Разберём сначала следующий.\nпереложите скачанный файл из «Загрузок» в папку data обратите внимание на расширение этого файла: netflix_title.csv Такие файлы можно прочитать с помощью функции read.csv(). В аргументах это функции надо указать файл, который надо прочитать (а также путь к нему, начиная с подпапки рабочей директории). То есть:\nnetflix &lt;- read.csv(‘data/netflix_titles.csv’) Почему так? Так как мы установили рабочую директорию (или запустили проект), то R по умолчанию теперь смотрит в папку нашего курса. А вот далее его надо сориентировать — поэтому мы пишем data/netflix_titles.csv. То есть говорим ему: «иди дальше в папку data и принеси мне файл netflix_titles.csv. Собственно, он нам его и принёс.\nМожно это проверить:\nhead(netflix) ## show_id type title director ## 1 s1 TV Show 3%\n## 2 s2 Movie 7:19 Jorge Michel Grau ## 3 s3 Movie 23:59 Gilbert Chan ## 4 s4 Movie 9 Shane Acker ## 5 s5 Movie 21 Robert Luketic ## 6 s6 TV Show 46 Serdar Akar ## cast ## 1 João Miguel, Bianca Comparato, Michel Gomes, Rodolfo Valente, Vaneza Oliveira, Rafael Lozano, Viviane Porto, Mel Fronckowiak, Sergio Mamberti, Zezé Motta, Celso Frateschi ## 2 Demián Bichir, Héctor Bonilla, Oscar Serrano, Azalia Ortiz, Octavio Michel, Carmen Beato ## 3 Tedd Chan, Stella Chung, Henley Hii, Lawrence Koh, Tommy Kuan, Josh Lai, Mark Lee, Susan Leong, Benjamin Lim ## 4 Elijah Wood, John C. Reilly, Jennifer Connelly, Christopher Plummer, Crispin Glover, Martin Landau, Fred Tatasciore, Alan Oppenheimer, Tom Kane ## 5 Jim Sturgess, Kevin Spacey, Kate Bosworth, Aaron Yoo, Liza Lapira, Jacob Pitts, Laurence Fishburne, Jack McGee, Josh Gad, Sam Golzari, Helen Carey, Jack Gilpin ## 6 Erdal Beşikçioğlu, Yasemin Allen, Melis Birkan, Saygın Soysal, Berkan Şal, Metin Belgin, Ayça Eren, Selin Uludoğan, Özay Fecht, Suna Yıldızoğlu ## country date_added release_year rating duration ## 1 Brazil August 14, 2020 2020 TV-MA 4 Seasons ## 2 Mexico December 23, 2016 2016 TV-MA 93 min ## 3 Singapore December 20, 2018 2011 R 78 min ## 4 United States November 16, 2017 2009 PG-13 80 min ## 5 United States January 1, 2020 2008 PG-13 123 min ## 6 Turkey July 1, 2017 2016 TV-MA 1 Season ## listed_in ## 1 International TV Shows, TV Dramas, TV Sci-Fi & Fantasy ## 2 Dramas, International Movies ## 3 Horror Movies, International Movies ## 4 Action & Adventure, Independent Movies, Sci-Fi & Fantasy ## 5 Dramas ## 6 International TV Shows, TV Dramas, TV Mysteries ## description ## 1 In a future where the elite inhabit an island paradise far from the crowded slums, you get one chance to join the 3% saved from squalor. ## 2 After a devastating earthquake hits Mexico City, trapped survivors from all walks of life wait to be rescued while trying desperately to stay alive. ## 3 When an army recruit is found dead, his fellow soldiers are forced to confront a terrifying secret that’s haunting their jungle island training camp. ## 4 In a postapocalyptic world, rag-doll robots hide in fear from dangerous machines out to exterminate them, until a brave newcomer joins the group. ## 5 A brilliant group of students become card-counting experts with the intent of swindling millions out of Las Vegas casinos by playing blackjack. ## 6 A genetics professor experiments with a treatment for his comatose sister that blends medical and shamanic cures, but unlocks a shocking side effect. Что-то загрузилось. Это хорошо. Что именно — выясним чуть позже.\nМожно ли не прописывать data? Можно, но тогда придётся переложить файл данных в рабочую директорию (то есть папку курса). С одним файлом ничего, можно жить. А есть у вас 30 или 50 файлов разных респондентов? Уже тяжеловато и бардак. Поэтому, на мой взгляд, такая организация — хороший компромисс: кода пишем чуть-чуть больше, но зато есть порядок.\nКонечно, можно хранить файлы данных где-то совсем отдельно. Но тогда и прописывать придётся путь от конревой папки компа:\n\n\n24 например, можно прочитать файл прямо из папки «Загрузки»\nnetflix &lt;- read.csv(‘/Users/antonangelgardt/Downloads/netflix_titles.csv’) Это выглядит не очень удобно.\nНа самом деле, в мире облачных технологий можно и вовсе обойтись без скачивания файлов на десктоп. Функция read.csv() вполне может прочитать файл прямо из интернета:\n\n\n25 это ссылка на мой GitHub, где лежит нужный нам файл\nnetflix &lt;- read.csv(‘https://raw.githubusercontent.com/angelgardt/hseuxlab-wlm2021/master/data/netflix_titles.csv’) Однако стоит помнить, что наши собранные руками данные в облаках, скорее всего, не лежат. Поэтому надо уметь загрузить файл и из интернета, и с компа.\nФорматы данных Мы тактично соскользнули с момента расширения файла. Напомню, что у нас файл netflix_titles.csv. Пришло время уделить этому внимание.\nМы говорили о типах данных, о структурах данных — а теперь поговорим о форматах данных.\nФормат данных — это характеристика данных, которая определяет много чего:\nкакие программы могут работать с этим файлом как структурирован файл внутри как структурированный файл разбирается на неструктирированные последовательности байтов (для хранения в памяти компьютера) и преобразуются обратно… Ну, короче куча-куча всего. Формат файла (не вдаваясь в детали) задаётся его разширением, то есть тем, что написано после точки в его названии (.R, .doc, .xlsx, .xml, .txt, …).\nНас, прежде всего, интересуют файлы данных, поэтому об их форматах мы и поговорим.\nТекстовые форматы Проще всего хранить данные в тексте. Это удобно, такие файлы мало весят и в них можно поместить большое количество информации. Самый простой текстовый формат — это .txt. Это тот самый «Блокнот», с которым наверняка когда-то все сталкивались. Никакого форматирования, никакой лишней мишуры — только текст. Но нам ведь нужно из этого текста каким-то образом потом вытащить датафрейм. Для этого существуют разделители. Чаще всего в табличных .txt формате столбцы таблицы разделены между собой символами табуляции (‘’), а строки — символом переноса строки (‘’). Файл .txt. можно считать с помощью функции read.table():\ndf &lt;- read.table(‘data/text_data.txt’) # это данные про качесво красного вина # так как у вас нет отдельно скачанного этого датасета, то запустите вот эту команду, чтобы прочитать текстовый файл # read.table() тоже умеет читать прямо из интернета df &lt;- read.table(‘https://raw.githubusercontent.com/angelgardt/hseuxlab-wlm2021/master/book/wlm2021-book/data/text_data.txt’) Если использовать другие разделители, например, запятую, то получится файл, содержащий значения, разделённые запятыми (comma separated values). Это и есть .csv-файлы, с которыми мы будем чаще всего работать.\nНесмотря на то, что по умолчанию операционная система пытается открыть CSV-шки в табличном редакторе (например, Excel), не надо на это вестись! CSV — это текстовый формат данных.\nПо умолчанию, в CSV-файле столбцы разделяются запятыми, а строки — символом переноса строки, поэтому функция read.csv() имеет соответствующие дефолтные настройки. Однако так бывает не всегда. Например, попробуем прочесть следующий файл:\n\n\n26 снова про качество вина\nwine &lt;- read.csv(‘https://raw.githubusercontent.com/angelgardt/hseuxlab-wlm2021/master/book/wlm2021-book/data/winequality-red.csv’) Файл CSV-шный. Посмотрим, что получилось:\nhead(wine) # команда выводит часть датасета в консоль ## fixed.acidity.volatile.acidity.citric.acid.residual.sugar.chlorides.free.sulfur.dioxide.total.sulfur.dioxide.density.pH.sulphates.alcohol.quality ## 1 7.4;0.7;0;1.9;0.076;11;34;0.9978;3.51;0.56;9.4;5 ## 2 7.8;0.88;0;2.6;0.098;25;67;0.9968;3.2;0.68;9.8;5 ## 3 7.8;0.76;0.04;2.3;0.092;15;54;0.997;3.26;0.65;9.8;5 ## 4 11.2;0.28;0.56;1.9;0.075;17;60;0.998;3.16;0.58;9.8;6 ## 5 7.4;0.7;0;1.9;0.076;11;34;0.9978;3.51;0.56;9.4;5 ## 6 7.4;0.66;0;1.8;0.075;13;40;0.9978;3.51;0.56;9.4;5 Что-то получилось. Но мы хотели увидеть нечто, напоминающее таблицу (вернее, датафрейм), а получилось явно что-то не то… Почему так? Потому что расширение .csv ещё не гарант того, что в файле в качестве разделителя использовалась запятая. Глобально — это может быть вообще любой знак. В данном случае была использована точка с запятой. Если мы немного изменим команду и вручную укажем разделитель (separator), то всё будет ок:\nwine &lt;- read.csv(‘https://raw.githubusercontent.com/angelgardt/hseuxlab-wlm2021/master/book/wlm2021-book/data/winequality-red.csv’, sep = ‘;’) head(wine) ## fixed.acidity volatile.acidity citric.acid residual.sugar chlorides ## 1 7.4 0.70 0.00 1.9 0.076 ## 2 7.8 0.88 0.00 2.6 0.098 ## 3 7.8 0.76 0.04 2.3 0.092 ## 4 11.2 0.28 0.56 1.9 0.075 ## 5 7.4 0.70 0.00 1.9 0.076 ## 6 7.4 0.66 0.00 1.8 0.075 ## free.sulfur.dioxide total.sulfur.dioxide density pH sulphates alcohol ## 1 11 34 0.9978 3.51 0.56 9.4 ## 2 25 67 0.9968 3.20 0.68 9.8 ## 3 15 54 0.9970 3.26 0.65 9.8 ## 4 17 60 0.9980 3.16 0.58 9.8 ## 5 11 34 0.9978 3.51 0.56 9.4 ## 6 13 40 0.9978 3.51 0.56 9.4 ## quality ## 1 5 ## 2 5 ## 3 5 ## 4 6 ## 5 5 ## 6 5 Вот теперь хорошо.\nТабличные форматы Данные могут храниться и в табличных форматах — это привычные нам Excel-таблицы с расширениями .xls и .xlsx. Поскольку это уже не текст, а именно таблица, то и вопросов с разделителями здесь не возникает. Однако, как мы знаем, Excel books могут состоять из нескольких листов, и данные могут располагаться на любом из них, хотя, конечно, чаще всего они располагаются на первом листе. Функций для импорта табличных данных существует несколько, я предлагаю вам вот эту:\ndf &lt;- readxl::read_excel(‘path/to/file.xlsx’, sheet = 2) Здесь мы уже привычно задаем в качестве первого аргумента путь к файлу, а вторым (опциональным) аргументом можно указать номер листа, с которого нужно считать данные. По умолчанию этот аргумент равен 1 .\nЗаметьте ещё одну особенность обращения к функциям из внешних пакетов. Если нам нужна только одна функция из пакета, то не обязательно погружать весь пакет к сессии через функцию library(). Можно указать название пакета9, из которого нам нужна функция, далее поставить два двоеточия10 и затем использовать функцию, которая нам нужна.\nФорматы данных с особой разметкой Есть и более экзотичные персонажи в мире форматов данных. Таковы, например, .json и .xml. Они главным образом заточены под передачу даных в интернете, поэтому если мы не соприкасаетесь с данной областью напрямую, то, скорее всего, не столкнетесь с ними никогда. Однако для общего представления будет полезно знать о том, что такие звери существуют.\nКак импортируется JSON можно посмотреть тут, а про XML есть здесь.\nФайлы данных других статистических программ В нашей исследовательской области всё ещё остаются активно распространены другие статистические программы, например, SPSS. И вы вполне можете столкнуться с необходимостью чтения данных из файлов формата .sav — это специальные файлы данных программы SPSS. В целом, в них нет чего-либо супернеобычного, однако есть некоторые особенности.\nДля их чтения потребуется пакет foreign11:\ndf &lt;- foreign::read.spss(‘path/to/file.sav’, use.value.labels = TRUE, to.data.frame = TRUE, use.missings = TRUE) Из всего пакета нам снова нужна только одна функция, которая импортирует файлы .sav. Можно наблюдать, что она хочет ряд дополнительных аргументов. Они не обязательные, но чтобы быть уверенным в корректном импорте, лучше их прописать. use.value.labels определяет загрузку факторным переменных, to.data.frame говорит, что мы хотим получить на выходе датафрейм (если указать FALSE, то будет список), use.missings означает, что вместо пропусков будут указаны NA (а нам это надо).\nИсследование данных Мы вдоволь наговорились о форматах данных. Теперь попробуем поработать с тем, что у нас есть. Напомню, что мы загрузили данные о фильмах и сериалах Netflix в переменную netflix.\nКогда мы загрузили датасет, нам, прежде всего, хочется посмотреть, как оно выглядит. Это можно сделать несколькими способами. Если мы хотим более привычный для неискущённого пользователя вариант, то можно воспользоваться командой View() (именно с заглавной):\nView(netflix) В соседней вкладке откроется датасет в привычном табличном виде, и можно будет посмотреть, корректно ли прочитались данные. Вариант удобный, но если у вас датасет в 1000 строк, «отсматривать глазами» косяки чтения данных совершенно бессмысленно.\nМожно вывести первые несколько строк датасета в консоль — это мы уже делали:\nhead(netflix) ## show_id type title director ## 1 s1 TV Show 3%\n## 2 s2 Movie 7:19 Jorge Michel Grau ## 3 s3 Movie 23:59 Gilbert Chan ## 4 s4 Movie 9 Shane Acker ## 5 s5 Movie 21 Robert Luketic ## 6 s6 TV Show 46 Serdar Akar ## cast ## 1 João Miguel, Bianca Comparato, Michel Gomes, Rodolfo Valente, Vaneza Oliveira, Rafael Lozano, Viviane Porto, Mel Fronckowiak, Sergio Mamberti, Zezé Motta, Celso Frateschi ## 2 Demián Bichir, Héctor Bonilla, Oscar Serrano, Azalia Ortiz, Octavio Michel, Carmen Beato ## 3 Tedd Chan, Stella Chung, Henley Hii, Lawrence Koh, Tommy Kuan, Josh Lai, Mark Lee, Susan Leong, Benjamin Lim ## 4 Elijah Wood, John C. Reilly, Jennifer Connelly, Christopher Plummer, Crispin Glover, Martin Landau, Fred Tatasciore, Alan Oppenheimer, Tom Kane ## 5 Jim Sturgess, Kevin Spacey, Kate Bosworth, Aaron Yoo, Liza Lapira, Jacob Pitts, Laurence Fishburne, Jack McGee, Josh Gad, Sam Golzari, Helen Carey, Jack Gilpin ## 6 Erdal Beşikçioğlu, Yasemin Allen, Melis Birkan, Saygın Soysal, Berkan Şal, Metin Belgin, Ayça Eren, Selin Uludoğan, Özay Fecht, Suna Yıldızoğlu ## country date_added release_year rating duration ## 1 Brazil August 14, 2020 2020 TV-MA 4 Seasons ## 2 Mexico December 23, 2016 2016 TV-MA 93 min ## 3 Singapore December 20, 2018 2011 R 78 min ## 4 United States November 16, 2017 2009 PG-13 80 min ## 5 United States January 1, 2020 2008 PG-13 123 min ## 6 Turkey July 1, 2017 2016 TV-MA 1 Season ## listed_in ## 1 International TV Shows, TV Dramas, TV Sci-Fi & Fantasy ## 2 Dramas, International Movies ## 3 Horror Movies, International Movies ## 4 Action & Adventure, Independent Movies, Sci-Fi & Fantasy ## 5 Dramas ## 6 International TV Shows, TV Dramas, TV Mysteries ## description ## 1 In a future where the elite inhabit an island paradise far from the crowded slums, you get one chance to join the 3% saved from squalor. ## 2 After a devastating earthquake hits Mexico City, trapped survivors from all walks of life wait to be rescued while trying desperately to stay alive. ## 3 When an army recruit is found dead, his fellow soldiers are forced to confront a terrifying secret that’s haunting their jungle island training camp. ## 4 In a postapocalyptic world, rag-doll robots hide in fear from dangerous machines out to exterminate them, until a brave newcomer joins the group. ## 5 A brilliant group of students become card-counting experts with the intent of swindling millions out of Las Vegas casinos by playing blackjack. ## 6 A genetics professor experiments with a treatment for his comatose sister that blends medical and shamanic cures, but unlocks a shocking side effect. По умолчанию выводится шесть строк, однако этот парамент можно задать вручную:\nhead(netflix, n = 4) ## show_id type title director ## 1 s1 TV Show 3%\n## 2 s2 Movie 7:19 Jorge Michel Grau ## 3 s3 Movie 23:59 Gilbert Chan ## 4 s4 Movie 9 Shane Acker ## cast ## 1 João Miguel, Bianca Comparato, Michel Gomes, Rodolfo Valente, Vaneza Oliveira, Rafael Lozano, Viviane Porto, Mel Fronckowiak, Sergio Mamberti, Zezé Motta, Celso Frateschi ## 2 Demián Bichir, Héctor Bonilla, Oscar Serrano, Azalia Ortiz, Octavio Michel, Carmen Beato ## 3 Tedd Chan, Stella Chung, Henley Hii, Lawrence Koh, Tommy Kuan, Josh Lai, Mark Lee, Susan Leong, Benjamin Lim ## 4 Elijah Wood, John C. Reilly, Jennifer Connelly, Christopher Plummer, Crispin Glover, Martin Landau, Fred Tatasciore, Alan Oppenheimer, Tom Kane ## country date_added release_year rating duration ## 1 Brazil August 14, 2020 2020 TV-MA 4 Seasons ## 2 Mexico December 23, 2016 2016 TV-MA 93 min ## 3 Singapore December 20, 2018 2011 R 78 min ## 4 United States November 16, 2017 2009 PG-13 80 min ## listed_in ## 1 International TV Shows, TV Dramas, TV Sci-Fi & Fantasy ## 2 Dramas, International Movies ## 3 Horror Movies, International Movies ## 4 Action & Adventure, Independent Movies, Sci-Fi & Fantasy ## description ## 1 In a future where the elite inhabit an island paradise far from the crowded slums, you get one chance to join the 3% saved from squalor. ## 2 After a devastating earthquake hits Mexico City, trapped survivors from all walks of life wait to be rescued while trying desperately to stay alive. ## 3 When an army recruit is found dead, his fellow soldiers are forced to confront a terrifying secret that’s haunting their jungle island training camp. ## 4 In a postapocalyptic world, rag-doll robots hide in fear from dangerous machines out to exterminate them, until a brave newcomer joins the group. Аналогично можно вывести несколько последних строк:\ntail(netflix, n = 9) ## show_id type title director ## 7779 s7779 Movie Zombieland Ruben Fleischer ## 7780 s7780 TV Show Zona Rosa\n## 7781 s7781 Movie Zoo Shlok Sharma ## 7782 s7782 Movie Zoom Peter Hewitt ## 7783 s7783 Movie Zozo Josef Fares ## 7784 s7784 Movie Zubaan Mozez Singh ## 7785 s7785 Movie Zulu Man in Japan\n## 7786 s7786 TV Show Zumbo’s Just Desserts\n## 7787 s7787 Movie ZZ TOP: THAT LITTLE OL’ BAND FROM TEXAS Sam Dunn ## cast ## 7779 Jesse Eisenberg, Woody Harrelson, Emma Stone, Abigail Breslin, Amber Heard, Bill Murray, Derek Graf ## 7780 Manu NNa, Ana Julia Yeyé, Ray Contreras, Pablo Morán ## 7781 Shashank Arora, Shweta Tripathi, Rahul Kumar, Gopal K. Singh, Yogesh Kurme, Prince Daniel ## 7782 Tim Allen, Courteney Cox, Chevy Chase, Kate Mara, Ryan Newman, Michael Cassidy, Spencer Breslin, Rip Torn, Kevin Zegers ## 7783 Imad Creidi, Antoinette Turk, Elias Gergi, Carmen Lebbos, Viktor Axelsson, Charbel Iskandar, Yasmine Awad ## 7784 Vicky Kaushal, Sarah-Jane Dias, Raaghav Chanana, Manish Chaudhary, Meghna Malik, Malkeet Rauni, Anita Shabdish, Chittaranjan Tripathy ## 7785 Nasty C ## 7786 Adriano Zumbo, Rachel Khoo ## 7787\n## country ## 7779 United States ## 7780 Mexico ## 7781 India ## 7782 United States ## 7783 Sweden, Czech Republic, United Kingdom, Denmark, Netherlands ## 7784 India ## 7785\n## 7786 Australia ## 7787 United Kingdom, Canada, United States ## date_added release_year rating duration ## 7779 November 1, 2019 2009 R 88 min ## 7780 November 26, 2019 2019 TV-MA 1 Season ## 7781 July 1, 2018 2018 TV-MA 94 min ## 7782 January 11, 2020 2006 PG 88 min ## 7783 October 19, 2020 2005 TV-MA 99 min ## 7784 March 2, 2019 2015 TV-14 111 min ## 7785 September 25, 2020 2019 TV-MA 44 min ## 7786 October 31, 2020 2019 TV-PG 1 Season ## 7787 March 1, 2020 2019 TV-MA 90 min ## listed_in ## 7779 Comedies, Horror Movies ## 7780 International TV Shows, Spanish-Language TV Shows, Stand-Up Comedy & Talk Shows ## 7781 Dramas, Independent Movies, International Movies ## 7782 Children & Family Movies, Comedies ## 7783 Dramas, International Movies ## 7784 Dramas, International Movies, Music & Musicals ## 7785 Documentaries, International Movies, Music & Musicals ## 7786 International TV Shows, Reality TV ## 7787 Documentaries, Music & Musicals ## description ## 7779 Looking to survive in a world taken over by zombies, a dorky college student teams with an urban roughneck and a pair of grifter sisters. ## 7780 An assortment of talent takes the stage for a night of honest stand-up featuring four of Mexico’s funniest LGBTQ comedians. ## 7781 A drug dealer starts having doubts about his trade as his brother, his client, and two rappers from the slums each battle their own secret addictions. ## 7782 Dragged from civilian life, a former superhero must train a new crop of youthful saviors when the military preps for an attack by a familiar villain. ## 7783 When Lebanon’s Civil War deprives Zozo of his family, he’s left with grief and little means as he escapes to Sweden in search of his grandparents. ## 7784 A scrappy but poor boy worms his way into a tycoon’s dysfunctional family, while facing his fear of music and the truth about his past. ## 7785 In this documentary, South African rapper Nasty C hits the stage and streets of Tokyo, introducing himself to the city’s sights, sounds and culture. ## 7786 Dessert wizard Adriano Zumbo looks for the next “Willy Wonka” in this tense competition that finds skilled amateurs competing for a $100,000 prize. ## 7787 This documentary delves into the mystique behind the blues-rock trio and explores how the enigmatic band created their iconic look and sound. Но мы помним, что датафрейм — это список. А на списках работала функция str(), которая показывала структуру списка. Значит, можно выполнить эту функцию и на датафрейме? Да!\nstr(netflix) ## ‘data.frame’: 7787 obs. of 12 variables: ## $ show_id : chr “s1” “s2” “s3” “s4” … ## $ type : chr “TV Show” “Movie” “Movie” “Movie” … ## $ title : chr “3%” “7:19” “23:59” “9” … ## $ director : chr “” “Jorge Michel Grau” “Gilbert Chan” “Shane Acker” … ## $ cast : chr “João Miguel, Bianca Comparato, Michel Gomes, Rodolfo Valente, Vaneza Oliveira, Rafael Lozano, Viviane Porto, Me”| truncated “Demián Bichir, Héctor Bonilla, Oscar Serrano, Azalia Ortiz, Octavio Michel, Carmen Beato” “Tedd Chan, Stella Chung, Henley Hii, Lawrence Koh, Tommy Kuan, Josh Lai, Mark Lee, Susan Leong, Benjamin Lim” “Elijah Wood, John C. Reilly, Jennifer Connelly, Christopher Plummer, Crispin Glover, Martin Landau, Fred Tatasc”| truncated … ## $ country : chr “Brazil” “Mexico” “Singapore” “United States” … ## $ date_added : chr “August 14, 2020” “December 23, 2016” “December 20, 2018” “November 16, 2017” … ## $ release_year: int 2020 2016 2011 2009 2008 2016 2019 1997 2019 2008 … ## $ rating : chr “TV-MA” “TV-MA” “R” “PG-13” … ## $ duration : chr “4 Seasons” “93 min” “78 min” “80 min” … ## $ listed_in : chr “International TV Shows, TV Dramas, TV Sci-Fi & Fantasy” “Dramas, International Movies” “Horror Movies, International Movies” “Action & Adventure, Independent Movies, Sci-Fi & Fantasy” … ## $ description : chr “In a future where the elite inhabit an island paradise far from the crowded slums, you get one chance to join t”| truncated “After a devastating earthquake hits Mexico City, trapped survivors from all walks of life wait to be rescued wh”| truncated “When an army recruit is found dead, his fellow soldiers are forced to confront a terrifying secret that’s haunt”| truncated “In a postapocalyptic world, rag-doll robots hide in fear from dangerous machines out to exterminate them, until”| truncated … Тут даже попроще аутпут. Функция выводит структуру датафрейма, в которой отображены количество наблюдений (строк) и количество переменных (столбцов), сами переменные, в нём содержащиеся, их тип, а также первые несколько значений каждой переменной. Это позволяет составить общее представление о том, что есть в наших данных.\nЕсть ещё одна полезная функция, чтобы понять, всё ли ок с данными:\nsummary(netflix) ## show_id type title director\n## Length:7787 Length:7787 Length:7787 Length:7787\n## Class :character Class :character Class :character Class :character\n## Mode :character Mode :character Mode :character Mode :character\n##\n##\n##\n## cast country date_added release_year ## Length:7787 Length:7787 Length:7787 Min. :1925\n## Class :character Class :character Class :character 1st Qu.:2013\n## Mode :character Mode :character Mode :character Median :2017\n## Mean :2014\n## 3rd Qu.:2018\n## Max. :2021\n## rating duration listed_in description\n## Length:7787 Length:7787 Length:7787 Length:7787\n## Class :character Class :character Class :character Class :character\n## Mode :character Mode :character Mode :character Mode :character\n##\n##\n## Эта функция выводит «саммари» (неужели!) по каждой из переменных датасета. Если переменная числовая, то выводятся базовые описательные статистики (например, как в случае release_year). Наш же датасет оказался богат на строковые переменные, для которых summary() может посчитать только количество наблюдений и указать класс (тип) переменной.\nВ целом, этого достаточно, чтобы базово проверить, верно ли прочитались данные. А далее нас ждет интересное путешествие в их предобработку и статистический анализ!\nФайл .RData Ну, и на последнок нечто, что может вам в определенные моменты облегчить жизнь.\nЧасто возникает потребность сохранить наработки, когда работа ещё не завершена. Допустим, у вас в Environment накопилась дикая куча объектов, с которыми вы работаете — датафреймы, матрицы, вектора, списки результатов работы статистических функций… — и хотелось бы как-то это все положить на полку, чтобы в следующий раз не перезапускать все 100500 строк кода, которыми вы это множество объектов получили.\nТакая возможность есть. Для этого вам нужно сохранить образ вашего Environment. Это делается с помошью функции save.image():\nsave.image(‘netflix.RData’) В аргументе функции мы указваем название файла, в котором будет лежать этот образ. Файл имеет расширение .RData. Можно прописать какой-либо путь к другому месту на компьютере, но в целом можно и оставить в рабочей директории. Когда понадобится продолжить работу, его будет нужно подгрузить с помощью функции load(),\nload(‘netflix.RData’) и продолжать работу с той строки скрипта, на которой вы остановились. Все созданные ранее объекты уже будут в Environment.\nПри завершении сессии в R он может предложить вам сохранить файл .RData. Не советую это делать — лучше сохранять образ Environment вручную, чтобы знать, что там лежит. Если сохранить файл .RData при выходе по предложению R, то, во-первых, его будет сложно достать, потому что он будет не видим невооруженным глазом в директории (сохраняется как скрытый файл), а во-вторых, он может подгрузиться тогда, когда вы его не просили и сломать вам весь кайф. Придётся числить Environment, прогонять заново код — а оно нам надо? Кажется, нет!\nПри первом запуске может не быть окна Code Editor. Чтобы его открыть, сделайте File → New File → R Script или нажмите Ctrl + Shift + N (⌘ + Shift + N).↩︎\nЧтобы не возникало лишних вопросов, лучше снабдить папку с файлами документом README.md, где описать все важные детали, в том числе и кодировку файла. Об это ещё немного поговорим поздее.↩︎\nБывает, что вот это распространяют и на калькуляторы тоже. [Кек]↩︎\nА вообще в разных языках программирования этот вопрос решается по-разному.↩︎\nТак-то любой оператор (арифметический или логический) — это функция от двух переменных. В предудщей главе был пример +(7, 3), а теперь попробуйте выполнить &(TRUE, FALSE).↩︎\nХотя, например, для JavaScript сложение строк — стандартная процедура.↩︎\nТакие векторы называются свободными.↩︎\nЕщё есть numeric() и logical(), например.↩︎\nПакет должен быть установлен (например, через install.packages()).↩︎\nДва двоеточия — указание на обращение к определенному пространству имён. В данном случае пространство имён — синоним пакета, так как в разных пакетах могут содержаться функции с одинаковым названием (именем). Такое эксплицитное указание на пакет (пространство имён) также может понадобиться в случае, когда подгруженные функции из внешнего пакета конфликтуют с базовыми, хотя это достаточно редкая история.↩︎\nЕсть и другие, но этот достаточно прост и интуитивен, как по мне. В нём есть функции не только для чтения SPSS-ных файлов, а ещё куча-куча всего.↩︎",
    "crumbs": [
      "Анализ данных в R",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Основы R</span>"
    ]
  },
  {
    "objectID": "r-preproc.html",
    "href": "r-preproc.html",
    "title": "21  Предобработка данных",
    "section": "",
    "text": "22 install.packages(“tidyverse”, dependencies = TRUE)\nlibrary(tidyverse)",
    "crumbs": [
      "Анализ данных в R",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Предобработка данных</span>"
    ]
  },
  {
    "objectID": "r-preproc.html#working-dir",
    "href": "r-preproc.html#working-dir",
    "title": "21  Предобработка данных",
    "section": "22.1 working dir",
    "text": "22.1 working dir",
    "crumbs": [
      "Анализ данных в R",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Предобработка данных</span>"
    ]
  },
  {
    "objectID": "r-preproc.html#get-data",
    "href": "r-preproc.html#get-data",
    "title": "21  Предобработка данных",
    "section": "24.1 get data",
    "text": "24.1 get data",
    "crumbs": [
      "Анализ данных в R",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Предобработка данных</span>"
    ]
  },
  {
    "objectID": "r-preproc.html#httpswww.kaggle.comdatasetsmylesoneillgame-of-thrones",
    "href": "r-preproc.html#httpswww.kaggle.comdatasetsmylesoneillgame-of-thrones",
    "title": "21  Предобработка данных",
    "section": "24.2 https://www.kaggle.com/datasets/mylesoneill/game-of-thrones",
    "text": "24.2 https://www.kaggle.com/datasets/mylesoneill/game-of-thrones\ndeaths &lt;- read_csv(“data/character-deaths.csv”) str(deaths)\nView(deaths)\nnrow(deaths) ncol(deaths)\ndeaths$Allegiances\nunique(deaths\\(Allegiances)\nunique(deaths\\)Gender) class(deaths$Gender)\ntable(deaths\\(Gender)\nsum(deaths\\)Gender) / length(deaths\\(Gender)\nmean(deaths\\)Gender)\ncolnames(deaths) # table(deaths\\(Book of Death)\ntable(deaths\\)Book of Death)\nsort(table(deaths\\(Allegiances))\nmax(table(deaths\\)Allegiances))",
    "crumbs": [
      "Анализ данных в R",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Предобработка данных</span>"
    ]
  },
  {
    "objectID": "r-preproc.html#what-is-pipe-and-how-it-works",
    "href": "r-preproc.html#what-is-pipe-and-how-it-works",
    "title": "21  Предобработка данных",
    "section": "24.3 what is pipe and how it works",
    "text": "24.3 what is pipe and how it works\ncos(0) 0 %&gt;% cos()\nsqrt(cos(sin(4 * 8)))\n(4 * 8) %&gt;% sin() %&gt;% cos() %&gt;% sqrt()\ncolnames(deaths) deaths %&gt;% rename(“Death_Year” = “Death Year”, “Book_of_Death” = “Book of Death”, “Death_Chapter” = “Death Chapter”, “Book_Intro_Chapter” = “Book Intro Chapter”) %&gt;% filter(Allegiances == “None”) -&gt; deaths_no_allegiance",
    "crumbs": [
      "Анализ данных в R",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Предобработка данных</span>"
    ]
  },
  {
    "objectID": "r-preproc.html#nas",
    "href": "r-preproc.html#nas",
    "title": "21  Предобработка данных",
    "section": "32.1 NAs",
    "text": "32.1 NAs\ndeaths$Allegiances == NA\nis.na(deaths\\(Allegiances)\nis.na(deaths\\)Allegiances) %&gt;% sum() deaths$Allegiances %&gt;% is.na() %&gt;% sum()\nis.na(deaths$Death Year) %&gt;% sum()\ndeaths %&gt;% sapply(is.na) %&gt;% apply(2, sum) deaths %&gt;% sapply(function(x) sum(is.na(x)))\ndeaths %&gt;% drop_na() # %&gt;% nrow() deaths %&gt;% filter(!is.na(Book of Death)) deaths %&gt;% filter(!(is.na(Book of Death) & is.na(Death Chapter) & is.na(Death Year)))\ndeaths %&gt;% mutate(Allegiances_Binary = ifelse(Allegiances == “None”, “No”, “Yes”)) %&gt;% # distinct(Allegiances_Binary, Nobility) summarise(n = n(), .by = c(Allegiances_Binary, Nobility))\ndeaths %&gt;% mutate(Allegiances = ifelse(Allegiances == “House Stark”, “Stark”, Allegiances)) %&gt;% filter(Allegiances == “Stark”) %&gt;% summarise(n = n(), .by = c(Allegiances, Gender))",
    "crumbs": [
      "Анализ данных в R",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Предобработка данных</span>"
    ]
  },
  {
    "objectID": "r-preproc.html#install-required-packages",
    "href": "r-preproc.html#install-required-packages",
    "title": "21  Предобработка данных",
    "section": "32.2 install required packages",
    "text": "32.2 install required packages",
    "crumbs": [
      "Анализ данных в R",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Предобработка данных</span>"
    ]
  },
  {
    "objectID": "r-preproc.html#another-way-to-install-required-packages-more-safe",
    "href": "r-preproc.html#another-way-to-install-required-packages-more-safe",
    "title": "21  Предобработка данных",
    "section": "33.1 another way to install required packages, more safe",
    "text": "33.1 another way to install required packages, more safe\npkgs &lt;- c(“tidyverse”, “moments”) install.packages(pkgs[!pkgs %in% installed.packages()])",
    "crumbs": [
      "Анализ данных в R",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Предобработка данных</span>"
    ]
  },
  {
    "objectID": "r-preproc.html#load-required-package",
    "href": "r-preproc.html#load-required-package",
    "title": "21  Предобработка данных",
    "section": "33.2 load required package",
    "text": "33.2 load required package\nlibrary(tidyverse)",
    "crumbs": [
      "Анализ данных в R",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Предобработка данных</span>"
    ]
  },
  {
    "objectID": "r-preproc.html#create-subfolder-for-data-files",
    "href": "r-preproc.html#create-subfolder-for-data-files",
    "title": "21  Предобработка данных",
    "section": "33.3 create subfolder for data files",
    "text": "33.3 create subfolder for data files",
    "crumbs": [
      "Анализ данных в R",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Предобработка данных</span>"
    ]
  },
  {
    "objectID": "r-preproc.html#read-csv-file-separator-is-comma-data-of-got-charaster-deaths",
    "href": "r-preproc.html#read-csv-file-separator-is-comma-data-of-got-charaster-deaths",
    "title": "21  Предобработка данных",
    "section": "34.1 read csv file, separator is comma — data of GoT charaster deaths",
    "text": "34.1 read csv file, separator is comma — data of GoT charaster deaths",
    "crumbs": [
      "Анализ данных в R",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Предобработка данных</span>"
    ]
  },
  {
    "objectID": "r-preproc.html#source-httpswww.kaggle.comdatasetsmylesoneillgame-of-thrones",
    "href": "r-preproc.html#source-httpswww.kaggle.comdatasetsmylesoneillgame-of-thrones",
    "title": "21  Предобработка данных",
    "section": "34.2 source: ## https://www.kaggle.com/datasets/mylesoneill/game-of-thrones",
    "text": "34.2 source: ## https://www.kaggle.com/datasets/mylesoneill/game-of-thrones\ndeaths &lt;- read_csv(“data/character-deaths.csv”) str(deaths) ## check structure rm(deaths) ## remove object, we’ll not use it in this script",
    "crumbs": [
      "Анализ данных в R",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Предобработка данных</span>"
    ]
  },
  {
    "objectID": "r-preproc.html#rmlist-ls-remove-all-objects-from-environment-use-carefully",
    "href": "r-preproc.html#rmlist-ls-remove-all-objects-from-environment-use-carefully",
    "title": "21  Предобработка данных",
    "section": "34.3 rm(list = ls()) ## remove all objects from environment – use carefully!",
    "text": "34.3 rm(list = ls()) ## remove all objects from environment – use carefully!",
    "crumbs": [
      "Анализ данных в R",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Предобработка данных</span>"
    ]
  },
  {
    "objectID": "r-preproc.html#read-another-csv-file-16pf-questionnaire",
    "href": "r-preproc.html#read-another-csv-file-16pf-questionnaire",
    "title": "21  Предобработка данных",
    "section": "34.4 read another csv file — 16PF questionnaire",
    "text": "34.4 read another csv file — 16PF questionnaire",
    "crumbs": [
      "Анализ данных в R",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Предобработка данных</span>"
    ]
  },
  {
    "objectID": "r-preproc.html#source-httpswww.kaggle.comdatasetstunguzcattells-16-personality-factors",
    "href": "r-preproc.html#source-httpswww.kaggle.comdatasetstunguzcattells-16-personality-factors",
    "title": "21  Предобработка данных",
    "section": "34.5 source: https://www.kaggle.com/datasets/tunguz/cattells-16-personality-factors",
    "text": "34.5 source: https://www.kaggle.com/datasets/tunguz/cattells-16-personality-factors\nket &lt;- read_csv(“data/ket.csv”) ## pay attertion to message in console str(ket) ## check structure — see smth strange?",
    "crumbs": [
      "Анализ данных в R",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Предобработка данных</span>"
    ]
  },
  {
    "objectID": "r-preproc.html#read-ket.csv-with-correct-tab-separator",
    "href": "r-preproc.html#read-ket.csv-with-correct-tab-separator",
    "title": "21  Предобработка данных",
    "section": "34.6 read ket.csv with correct tab separator",
    "text": "34.6 read ket.csv with correct tab separator\nket &lt;- read_tsv(“data/ket.csv”) ## rewrite ket object str(ket) ## check structure again — now looks good View(ket) ## another way to check head(ket) ## look at several (6 by default) first rows tail(ket, n = 4) ## look at several (4 in this case) last rows",
    "crumbs": [
      "Анализ данных в R",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Предобработка данных</span>"
    ]
  },
  {
    "objectID": "r-preproc.html#get-some-basic-info-about-the-data",
    "href": "r-preproc.html#get-some-basic-info-about-the-data",
    "title": "21  Предобработка данных",
    "section": "34.7 get some basic info about the data",
    "text": "34.7 get some basic info about the data\nnrow(ket) ## number of rows ncol(ket) ## number of columns colnames(ket) ## names of columns class(ket) ## wow, that’s dataframe/tibble sapply(ket, class) ## check data type of each column — apply class function to each column of our data",
    "crumbs": [
      "Анализ данных в R",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Предобработка данных</span>"
    ]
  },
  {
    "objectID": "r-preproc.html#get-some-descriptive-stats",
    "href": "r-preproc.html#get-some-descriptive-stats",
    "title": "21  Предобработка данных",
    "section": "34.8 get some descriptive stats",
    "text": "34.8 get some descriptive stats",
    "crumbs": [
      "Анализ данных в R",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Предобработка данных</span>"
    ]
  },
  {
    "objectID": "r-preproc.html#lets-start-with-a1-column-a1-item-in-questionnaire",
    "href": "r-preproc.html#lets-start-with-a1-column-a1-item-in-questionnaire",
    "title": "21  Предобработка данных",
    "section": "34.9 let’s start with A1 column (A1 item in questionnaire)",
    "text": "34.9 let’s start with A1 column (A1 item in questionnaire)\nmean(ket\\(A1) ## [arithmetic] mean\nmean(ket\\)A1, trim = .2) ## trimmed mean\n?mean ## what’s the ‘trim’ argument in previous? let’s see help about the ‘mean’ function help(mean) ## or let’s see help this way\nvar(ket\\(A1) ## variance (dispersion)\nsd(ket\\)A1) ## standard deviation median(ket\\(A1) ## median\nquantile(ket\\)A1) ## by default — return quartiles quantile(ket\\(A1, probs = .20) ## you may tell R, what specific quantile you are interested in\nmax(ket\\)A1) ## get max value min(ket\\(A1) ## get min value\ntable(ket\\)A1) ## get prop table, A1 is discrete var, it will work table(ket\\(country) ## or same for countries --- doesn't look so good\nsort(table(ket\\)country)) ## let’s sort previous output (ascending by default) — now looks better sort(table(ket\\(country), decreasing = TRUE) ## you may sort it descending as well\nket\\)country %&gt;% table() %&gt;% sort(decreasing = TRUE) ## same as previous line, but tidyverse-styles with pipe",
    "crumbs": [
      "Анализ данных в R",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Предобработка данных</span>"
    ]
  },
  {
    "objectID": "r-preproc.html#or-another-way-using-group_by-summarise",
    "href": "r-preproc.html#or-another-way-using-group_by-summarise",
    "title": "21  Предобработка данных",
    "section": "34.10 or another way using group_by() %>% summarise()",
    "text": "34.10 or another way using group_by() %&gt;% summarise()\nket %&gt;% ## take data group_by(country) %&gt;% ## group data by country summarise( ## calculate something n = n() ## number of observations ) %&gt;% # arrange(n) ## arrange (sort) aggregated data by new column ‘n’ — ascending by default arrange(desc(n)) ## arrange (sort) aggregated data by new column ‘n’ — now descending\nket %&gt;% filter(country == “US”) %&gt;% nrow() ket %&gt;% filter(country == “US” & country == “FR”) %&gt;% nrow() ket %&gt;% filter(country == “US” | country == “RU”) %&gt;% nrow() ket %&gt;% filter(age &lt; 18) %&gt;% nrow() ket %&gt;% filter(age &gt; 18 & age &lt; 35) %&gt;% nrow() ket %&gt;% filter(age &lt; 18 & age &gt; 60) %&gt;% nrow()\nsummary(ket) ## get basic descriptive stats for all columns\nket$A1 %&gt;% is.na() %&gt;% sum() ## check number of NA in A1 columns — no NA, cool! ket %&gt;% sapply(is.na) %&gt;% apply(2, sum) ## check number of NA for all columns ket %&gt;% sapply(function(x) x %&gt;% is.na() %&gt;% sum()) ## check number of NA for all columns another way — same result\nunique(ket$gender) ## check unique values of gender variable — hmmm, need codebook…",
    "crumbs": [
      "Анализ данных в R",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Предобработка данных</span>"
    ]
  },
  {
    "objectID": "r-preproc.html#lets-fix-gender-var",
    "href": "r-preproc.html#lets-fix-gender-var",
    "title": "21  Предобработка данных",
    "section": "34.11 let’s fix gender var",
    "text": "34.11 let’s fix gender var\nket %&gt;% mutate( gender = ifelse(gender == 0, NA, ifelse(gender == 1, “male”, ifelse(gender == 2, “female”, “other”))) ) %&gt;% pull(gender) %&gt;% ## pull gender column as vector # is.na() %&gt;% sum() ## check number of NA unique() ## check unique values ## we didn’t save these changes!",
    "crumbs": [
      "Анализ данных в R",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Предобработка данных</span>"
    ]
  },
  {
    "objectID": "r-preproc.html#or-another-shorter-way",
    "href": "r-preproc.html#or-another-shorter-way",
    "title": "21  Предобработка данных",
    "section": "34.12 or another shorter way",
    "text": "34.12 or another shorter way\nket %&gt;% ## take data mutate( ## change something gender = recode( ## save to gender (rewrite column) as follow [according codebook] gender, ## take gender var “0” = NA_character_, ## set NA for 0 — recode function requires explicit type of NA “1” = “male”, ## set ‘male’ for 1 “2” = “female”, ## set ‘female’ for 2 “3” = “other” ## set ‘other’ for 3 ) ) -&gt; ket ## save changes ket %&gt;% pull(gender) %&gt;% unique() ## check new gender values",
    "crumbs": [
      "Анализ данных в R",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Предобработка данных</span>"
    ]
  },
  {
    "objectID": "r-preproc.html#lets-remove-na",
    "href": "r-preproc.html#lets-remove-na",
    "title": "21  Предобработка данных",
    "section": "34.13 let’s remove NA",
    "text": "34.13 let’s remove NA\nket %&gt;% drop_na() ## remove all rows that contains at least one NA ket %&gt;% drop_na() %&gt;% nrow() ## check the number of rows after NA removing — ok, appropriate ket %&gt;% drop_na() -&gt; cattel ## save the data without NA to new object",
    "crumbs": [
      "Анализ данных в R",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Предобработка данных</span>"
    ]
  },
  {
    "objectID": "r-preproc.html#lets-count-desriptive-stats-for-each-item-more-stylish",
    "href": "r-preproc.html#lets-count-desriptive-stats-for-each-item-more-stylish",
    "title": "21  Предобработка данных",
    "section": "34.14 let’s count desriptive stats for each item more stylish",
    "text": "34.14 let’s count desriptive stats for each item more stylish",
    "crumbs": [
      "Анализ данных в R",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Предобработка данных</span>"
    ]
  },
  {
    "objectID": "r-preproc.html#lets-do-it-for-the-age-first",
    "href": "r-preproc.html#lets-do-it-for-the-age-first",
    "title": "21  Предобработка данных",
    "section": "34.15 let’s do it for the age first",
    "text": "34.15 let’s do it for the age first\ncattel %&gt;% ## take data summarise( ## calculate something n_age = n(), ## number of observations — name output column as ‘n_age’ mean_age = mean(age), ## mean age — name output column as ‘mean_age’ sd_age = sd(age), ## standard deviation of age — name output column as ‘sd_age’ max_age = max(age), ## max age — name output column as ‘max_age’ min_age = min(age) ## min age — name output column as ‘min_age’ ) ## or simplier cattel %&gt;% ## take data summarise( ## calculate something n = n(), ## number of observations — name output column as ‘n’ mean = mean(age), ## mean age — name output column as ‘mean’ sd = sd(age), ## standard deviation of age — name output column as ‘sd’ max = max(age), ## max age — name output column as ‘max’ min = min(age) ## min age — name output column as ‘min’ ) ## hmmm, look at max age",
    "crumbs": [
      "Анализ данных в R",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Предобработка данных</span>"
    ]
  },
  {
    "objectID": "r-preproc.html#breefly-check-basic-graphs",
    "href": "r-preproc.html#breefly-check-basic-graphs",
    "title": "21  Предобработка данных",
    "section": "34.16 breefly check basic graphs",
    "text": "34.16 breefly check basic graphs\nhist(cattel\\(age) ## histogram\nboxplot(cattel\\)age) ## boxplot",
    "crumbs": [
      "Анализ данных в R",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Предобработка данных</span>"
    ]
  },
  {
    "objectID": "r-preproc.html#what-happens-if-we-set-some-threshold-for-the-age",
    "href": "r-preproc.html#what-happens-if-we-set-some-threshold-for-the-age",
    "title": "21  Предобработка данных",
    "section": "34.17 what happens, if we set some threshold for the age?",
    "text": "34.17 what happens, if we set some threshold for the age?\ncattel %&gt;% # nrow() filter(age &lt;= 100) %&gt;% # nrow() pull(age) %&gt;% boxplot() ## ok, more or less\ncattel %&gt;% filter(age &lt;= 100) -&gt; cattel ## remove inappropriate observations (based on age), rewrite data",
    "crumbs": [
      "Анализ данных в R",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Предобработка данных</span>"
    ]
  },
  {
    "objectID": "r-preproc.html#lets-get-descripstipe-stats-for-all-items-at-once",
    "href": "r-preproc.html#lets-get-descripstipe-stats-for-all-items-at-once",
    "title": "21  Предобработка данных",
    "section": "34.18 let’s get descripstipe stats for all items at once",
    "text": "34.18 let’s get descripstipe stats for all items at once\ncattel %&gt;% # colnames() select(cols = -c(age, gender, accuracy, country, source, elapsed)) %&gt;% # colnames() ## [de]select cols pivot_longer( ## pivot data to long format cols = everything(), ## with all columns names_to = “item”, ## name column with titles as ‘item’ values_to = “score” ## name column with values as ‘score’ ) %&gt;% summarise( ## calculate something n = n(), ## number of observations mean = mean(score), ## mean score median = median(score), ## median score sd = sd(score), ## sd of score min = min(score), ## min score max = max(score), ## max score skew = moments::skewness(score), ## skewness of score — call function skewness() from moments package kurt = moments::kurtosis(score), ## kurtosis of score — call function kurtosis() from moments package .by = “item” ## group rows by ‘item’ variable ) # %&gt;% filter(str_detect(item, “^A”)) ## filter rows where item name starts with A",
    "crumbs": [
      "Анализ данных в R",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Предобработка данных</span>"
    ]
  },
  {
    "objectID": "r-preproc.html#or-we-can-do-it-by-scale-using-selectstarts_with",
    "href": "r-preproc.html#or-we-can-do-it-by-scale-using-selectstarts_with",
    "title": "21  Предобработка данных",
    "section": "34.19 or we can do it by scale using select(starts_with(…))",
    "text": "34.19 or we can do it by scale using select(starts_with(…))\ncattel %&gt;% select(cols = -c(age, gender, accuracy, country, source, elapsed)) %&gt;% # colnames() ## [de]select cols select(starts_with(“A”)) %&gt;% ## select all columns where name starts with ‘A’ pivot_longer( ## pivot data to long format cols = everything(), ## with all columns names_to = “item”, ## name column with titles as ‘item’ values_to = “score” ## name column with values as ‘score’ ) %&gt;% summarise( ## calculate something n = n(), ## number of observations mean = mean(score), ## mean score median = median(score), ## median score sd = sd(score), ## sd of score min = min(score), ## min score max = max(score), ## max score skew = moments::skewness(score), ## skewness of score — call function skewness() from moments package kurt = moments::kurtosis(score), ## kurtosis of score — call function kurtosis() from moments package .by = “item” ## group rows by ‘item’ variable )",
    "crumbs": [
      "Анализ данных в R",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Предобработка данных</span>"
    ]
  },
  {
    "objectID": "r-preproc.html#lets-draw-something-beautiful",
    "href": "r-preproc.html#lets-draw-something-beautiful",
    "title": "21  Предобработка данных",
    "section": "34.20 let’s draw something beautiful",
    "text": "34.20 let’s draw something beautiful\nggplot() ## we need canvas\ncattel %&gt;% ## and also we need data ggplot() ## not really impressive for now",
    "crumbs": [
      "Анализ данных в R",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Предобработка данных</span>"
    ]
  },
  {
    "objectID": "r-preproc.html#lets-draw-barplot-for-gender",
    "href": "r-preproc.html#lets-draw-barplot-for-gender",
    "title": "21  Предобработка данных",
    "section": "34.21 let’s draw barplot for gender",
    "text": "34.21 let’s draw barplot for gender\ncattel %&gt;% ggplot(aes(gender)) ## tell ggplot what variable we would like to draw ## hmmm, ok\ncattel %&gt;% ggplot(aes(gender)) + geom_bar() ## tell ggplot how we would like to draw it ## well, kinda",
    "crumbs": [
      "Анализ данных в R",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Предобработка данных</span>"
    ]
  },
  {
    "objectID": "r-preproc.html#lets-add-some-shine",
    "href": "r-preproc.html#lets-add-some-shine",
    "title": "21  Предобработка данных",
    "section": "34.22 let’s add some shine",
    "text": "34.22 let’s add some shine\ncattel %&gt;% ggplot(aes(gender)) + geom_bar() + theme_bw() + labs(x = “Пол”, y = “Частота”) + scale_x_discrete(labels = c(“female” = “Женский”, “male” = “Мужской”, “other” = “Другое”))",
    "crumbs": [
      "Анализ данных в R",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Предобработка данных</span>"
    ]
  },
  {
    "objectID": "r-preproc.html#lets-draw-distributions-of-items-scores",
    "href": "r-preproc.html#lets-draw-distributions-of-items-scores",
    "title": "21  Предобработка данных",
    "section": "34.23 let’s draw distributions of items scores",
    "text": "34.23 let’s draw distributions of items scores\ntheme_set(theme_minimal()) ## set minimalistic theme for all future graphs cattel %&gt;% select(starts_with(“A”, ignore.case = FALSE)) %&gt;% pivot_longer(cols = everything()) %&gt;% ggplot(aes(value)) + geom_bar() + facet_wrap(~ name) ## make subgraph for each item ## well, not bad",
    "crumbs": [
      "Анализ данных в R",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Предобработка данных</span>"
    ]
  },
  {
    "objectID": "r-preproc.html#again-we-can-do-something-to-make-it-better",
    "href": "r-preproc.html#again-we-can-do-something-to-make-it-better",
    "title": "21  Предобработка данных",
    "section": "34.24 again we can do something to make it better",
    "text": "34.24 again we can do something to make it better\ncattel %&gt;% select(starts_with(“A”, ignore.case = FALSE)) %&gt;% pivot_longer(cols = everything()) %&gt;% ggplot(aes(value)) + geom_bar() + facet_wrap(~ factor(name, ## make subgraph for each item ordered = TRUE, levels = paste0(“A”, 1:10) ## order them correctly ), scales = “free_x” ## save x-labels for each subgraph ) + scale_x_continuous(breaks = 0:5) + ## make all point on x axis visible labs(x = “Балл”, ## set label to x axis y = “Частота” ## set label to y axis )",
    "crumbs": [
      "Анализ данных в R",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Предобработка данных</span>"
    ]
  },
  {
    "objectID": "r-preproc.html#lets-do-a-scatterplot-relation-between-age-and-total-score-of-scale-b-for-participants-from-us",
    "href": "r-preproc.html#lets-do-a-scatterplot-relation-between-age-and-total-score-of-scale-b-for-participants-from-us",
    "title": "21  Предобработка данных",
    "section": "34.25 let’s do a scatterplot — relation between age and total score of scale B for participants from US",
    "text": "34.25 let’s do a scatterplot — relation between age and total score of scale B for participants from US\ncattel %&gt;% mutate(id = 1:nrow(cattel)) %&gt;% ## create id column — just a number of the row in dataset filter(country == “US”) %&gt;% ## filter US participants select(starts_with(“B”), age, id) %&gt;% ## select columns we need pivot_longer( cols = -c(age, id), ## pivot to long format, ignore columns age and id names_to = “item”, ## put name to ‘item’ column values_to = “score” ## put values to ‘score’ column ) %&gt;% ## summarise( ## calculate something total_score = sum(score), ## total score as sum of item scores .by = c(age, id) ## for each participant (id) and preserve age column for future visualization ) %&gt;% ggplot(aes(age, total_score)) + ## use age as x and total as y geom_point() ## draw points",
    "crumbs": [
      "Анализ данных в R",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Предобработка данных</span>"
    ]
  },
  {
    "objectID": "r-preproc.html#and-again-add-some-shine",
    "href": "r-preproc.html#and-again-add-some-shine",
    "title": "21  Предобработка данных",
    "section": "34.26 and again add some shine",
    "text": "34.26 and again add some shine\ncattel %&gt;% mutate(id = 1:nrow(cattel)) %&gt;% filter(country == “US”) %&gt;% select(starts_with(“B”), age, id) %&gt;% pivot_longer(cols = -c(age, id), names_to = “item”, values_to = “score”) %&gt;% summarise(total_score = sum(score), .by = c(age, id)) %&gt;% ggplot(aes(age, total_score)) + geom_point(alpha = .5) + ## set transparency for points (alpha channel) labs( x = “Возраст”, ## set x label y = “Суммарный балл”, ## set y label title = “Связь выраженности личностных черт респондентов с их возрастом”, ## set graph title subtitle = “Шкала B опросника 16PF”, ## set graph subtitle caption = “данные по респондентам из США” ## add graph caption )",
    "crumbs": [
      "Анализ данных в R",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Предобработка данных</span>"
    ]
  },
  {
    "objectID": "r-preproc.html#oh-maybe-we-need-gender-on-the-plot",
    "href": "r-preproc.html#oh-maybe-we-need-gender-on-the-plot",
    "title": "21  Предобработка данных",
    "section": "34.27 oh, maybe we need gender on the plot?",
    "text": "34.27 oh, maybe we need gender on the plot?\ncattel %&gt;% mutate(id = 1:nrow(cattel)) %&gt;% filter(country == “US”) %&gt;% select(starts_with(“B”), age, id, gender) %&gt;% ## now select all B scale items, age, id, and gender pivot_longer(cols = -c(age, id, gender), ## pivot to long format, ignore columns age, id, and gender names_to = “item”, values_to = “score”) %&gt;% summarise( ## calculate something total_score = sum(score), ## total score as sum of item scores .by = c(age, id) ## for each participant (id) and preserve age and gender columns for future visualization ) %&gt;% ggplot(aes(age, ## use age as x total_score, ## use total_score as y color = gender) ## and display gender with color ) + geom_point(alpha = .5) + ## set transparency for points theme(legend.position = “bottom”) + ## place color legend below the plot scale_color_discrete(labels = c(“female” = “Женский”, ## set labels for color “male” = “Мужской”, “other” = “Другое”)) + labs(x = “Возраст”, y = “Суммарный балл”, color = “Пол”, ## set label for color legend title = “Связь выраженности личностных черт респондентов с их возрастом”, subtitle = “Шкала B опросника 16PF”, caption = “данные по респондентам из США”)",
    "crumbs": [
      "Анализ данных в R",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Предобработка данных</span>"
    ]
  },
  {
    "objectID": "r-lm.html",
    "href": "r-lm.html",
    "title": "23  Корреляция и регрессия",
    "section": "",
    "text": "library(tidyverse) theme_set(theme_bw())\nmanagers &lt;- read_csv(“https://raw.githubusercontent.com/angelgardt/wlm2023/refs/heads/master/data/pr10/managers_reg.csv”) str(managers)\nplot(x = managers\\(experience, y = managers\\)fot) plot(y = managers\\(fot, x = managers\\)experience) plot(managers\\(experience, managers\\)fot)\nhist(managers\\(fot)\nboxplot(managers\\)fot) hist(managers\\(experience)\nboxplot(managers\\)experience)\ncor(managers\\(fot, managers\\)experience) cor(managers\\(fot, managers\\)experience, method = “sp”)\ncor.test(managers\\(fot, managers\\)experience) cor.test(managers\\(fot, managers\\)experience, method = “sp”) cor.test(managers\\(fot, managers\\)experience, alternative = “less”)\ncor.test(managers\\(fot, managers\\)grade_score)\nmanagers %&gt;% ggplot(aes(grade_score, fot, color = region)) + geom_point() + geom_smooth(method = “lm”)\nmodel1 &lt;- lm(fot ~ grade_score, managers) summary(model1)\nmodel2 &lt;- lm(fot ~ grade_score + experience, managers) summary(model2)\nmodel3 &lt;- lm(fot ~ grade_score + region, managers) summary(model3)\nmodel4 &lt;- lm(fot ~ grade_score * region, managers) summary(model4)\nplot(model4) anova(model3, model4)",
    "crumbs": [
      "Анализ данных в R",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Корреляция и регрессия</span>"
    ]
  },
  {
    "objectID": "r-anova.html",
    "href": "r-anova.html",
    "title": "24  Дисперсионный анализ",
    "section": "",
    "text": "25 install.packages(“ez”)\n\n\n26 install.packages(“moments”)\nlibrary(tidyverse) theme_set(theme_bw()) library(ez)\n\n\n27 share &lt;- read_csv(“https://raw.githubusercontent.com/angelgardt/wlm2023/master/data/hw5/share.csv”)\n\n\n28 share &lt;- read_csv2(“https://raw.githubusercontent.com/angelgardt/wlm2023/master/data/hw5/share.csv”)\nshare &lt;- read_delim(“https://raw.githubusercontent.com/angelgardt/wlm2023/master/data/hw5/share.csv”, delim = ” “, locale = locale(decimal_mark =”,“)) str(share)\nshare %&gt;% summarise(mean = mean(time1), median = median(time1), sd = sd(time1), min = min(time1), max = max(time1), skew = moments::skewness(time1), kurt = moments::kurtosis(time1), .by = c(platform, trialtype, setsize))\nshare %&gt;% sapply(is.na) %&gt;% apply(2, sum) unique(share\\(id)\nunique(share\\)trialtype)\n\n\n29 quantile(share$time1, .75)\nshare %&gt;% # nrow() filter(trialtype != “both” & correct1) %&gt;% # nrow() group_by(id, setsize, platform, trialtype) %&gt;% mutate(is_outlier = ifelse( time1 &gt; quantile(time1, .75) + 1.5 * IQR(time1) | time1 &lt; quantile(time1, .25) - 1.5 * IQR(time1), TRUE, FALSE ) ) %&gt;% filter(!is_outlier) %&gt;% mutate(setsize = as_factor(setsize)) -&gt; share2\n\n\n30 unique(share2$platform)\nt.test(share2\\(time1 ~ share2\\)platform)\nfit1 &lt;- aov(time1 ~ platform, share2) summary(fit1)\nfit1.1 &lt;- lm(time1 ~ platform, share2) summary(fit1.1) anova(fit1.1)\nezANOVA(data = share2, dv = time1, wid = id, within = .(setsize, trialtype), between = platform)\npairwise.t.test(x = share2\\(time1,\n                g = interaction(share2\\)setsize, share2$trialtype), p.adjust.method = “bonf”)\nshare2 %&gt;% ggplot(aes(setsize, time1, color = platform, shape = trialtype, group = interaction(trialtype, platform))) + stat_summary(fun.data = mean_cl_boot, geom = “pointrange”, position = position_dodge(.3)) + stat_summary(fun.data = mean_cl_boot, geom = “line”, linetype = “dashed”, position = position_dodge(.3)) + theme(legend.position = “bottom”)",
    "crumbs": [
      "Анализ данных в R",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Дисперсионный анализ</span>"
    ]
  },
  {
    "objectID": "r-glm.html",
    "href": "r-glm.html",
    "title": "25  Логистическая регрессия",
    "section": "",
    "text": "library(tidyverse)\nmanagers &lt;- read_csv(“data/managers_log.csv”)\nstr(managers) unique(managers$lvl)\nmanagers %&gt;% mutate(lvl = ifelse(lvl == “Менеджер”, 1, 0)) %&gt;% select(-…1, -id) -&gt; managers managers$lvl %&gt;% unique()\nmodel1 &lt;- glm(lvl ~ ., data = managers, family = binomial) model0 &lt;- glm(lvl ~ 1, data = managers, family = binomial) anova(model0, model1, test = “Chi”) summary(model1)\n\n26 summary(model0)\n\n\n27 anova(model1, model0, test = “Chi”)\nmodel2 &lt;- update(model1, .~. -subdiv_regulations -autonomy -company_regulations -error_cost) summary(model2) exp(1.605)\nAIC(model1, model0) BIC(model1, model0) AIC(model1, model2) BIC(model1, model2)",
    "crumbs": [
      "Анализ данных в R",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Логистическая регрессия</span>"
    ]
  },
  {
    "objectID": "r-cluster.html",
    "href": "r-cluster.html",
    "title": "26  Кластерный анализ",
    "section": "",
    "text": "pkgs &lt;- c(“GGally”, “fpc”, “factoextra”, “cluster”) install.packages(pkgs[!pkgs %in% installed.packages()])\nlibrary(tidyverse) theme_set(theme_bw()) theme_update(legend.position = “bottom”) library(factoextra) library(cluster)\niris unique(iris$Species)\npairs(iris[, 1:4], col = iris[, 5]) GGally::ggpairs(iris, columns = 1:4, aes(color = Species))\nd &lt;- dist(iris[1:4], method = “eucl”)\nhc_complete &lt;- hclust(d, method = “complete”) plot(hc_complete)\nhc_complete_cl2 &lt;- cutree(hc_complete, k = 2)\nGGally::ggpairs(iris, columns = 1:4, aes(color = Species, shape = as.character(hc_complete_cl2)), upper = NULL, diag = NULL) table(iris$Species, hc_complete_cl2)\nhc_complete_cl3 &lt;- cutree(hc_complete, k = 3)\nGGally::ggpairs(iris, columns = 1:4, aes(color = Species, shape = as.character(hc_complete_cl3)), upper = NULL, diag = NULL) table(iris$Species, hc_complete_cl3)\nhc_single &lt;- hclust(d, method = “single”) plot(hc_single)\nhc_single_cl2 &lt;- cutree(hc_single, k = 2) GGally::ggpairs(iris, columns = 1:4, aes(color = Species, shape = as.character(hc_single_cl2)), upper = NULL, diag = NULL) table(iris$Species, hc_single_cl2)\nhc_average &lt;- hclust(d, method = “average”) plot(hc_average)\nhc_average_cl2 &lt;- cutree(hc_average, k = 2) GGally::ggpairs(iris, columns = 1:4, aes(color = Species, shape = as.character(hc_average_cl2)), upper = NULL, diag = NULL) table(iris$Species, hc_average_cl2)\nkm2 &lt;- kmeans(iris[1:4], centers = 2) str(km2)\nGGally::ggpairs(iris, columns = 1:4, aes(color = Species, shape = as.character(km2$cluster)), upper = NULL, diag = NULL)\nset.seed(123) km3 &lt;- kmeans(iris[1:4], centers = 3) GGally::ggpairs(iris, columns = 1:4, aes(color = Species, shape = as.character(km3$cluster)), upper = NULL, diag = NULL)\nkm4 &lt;- kmeans(iris[1:4], centers = 4) GGally::ggpairs(iris, columns = 1:4, aes(color = Species, shape = as.character(km4$cluster)), upper = NULL, diag = NULL)",
    "crumbs": [
      "Анализ данных в R",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Кластерный анализ</span>"
    ]
  },
  {
    "objectID": "r-efa.html",
    "href": "r-efa.html",
    "title": "27  Эксплораторный факторный анализ",
    "section": "",
    "text": "library(tidyverse) theme_set(theme_bw())\n\n27.0.1 TAIA\ntaia &lt;- read_csv( sprintf( “https://docs.google.com/uc?id=%s&export=download”, “1L-6pG9eaJz09ILrG6sKipnHoOxiU_T2S” ) ) str(taia)\nEFAtools::BARTLETT(taia) EFAtools::KMO(taia)\nfa1 &lt;- factanal(taia, factors = 6, scores = ‘regression’) fa1 fa1$scores\nfactanal(taia, factors = 6, scores = ‘regression’, rotation = “promax”)\nfactanal(taia, factors = 5, scores = ‘regression’, rotation = “varimax”)\nfactanal(taia, factors = 5, scores = ‘regression’, rotation = “promax”)\n\n\n27.0.2 PIZZA\npizza &lt;- read_csv(‘https://raw.githubusercontent.com/angelgardt/hseuxlab-andan/master/Pizza.csv’) str(pizza)\npizza %&gt;% select(-id, -brand) -&gt; pizza_efa\nEFAtools::BARTLETT(pizza_efa) EFAtools::KMO(pizza_efa)\nfactanal(pizza_efa, factors = 5, scores = ‘regression’)\nfactanal(pizza_efa, factors = 4, scores = ‘regression’)\nfan &lt;- factanal(pizza_efa, factors = 3, scores = ‘regression’) # укажем scores, чтобы сохранились сами значения факторов fan\nfan2 &lt;- factanal(pizza_efa, factors = 2, scores = ‘regression’) fan2 fan2$scores\npizza %&gt;% ggplot(aes(fan2\\(scores[,1],\n             fan2\\)scores[,2], color = brand)) + geom_point()",
    "crumbs": [
      "Анализ данных в R",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Эксплораторный факторный анализ</span>"
    ]
  },
  {
    "objectID": "r-cfa.html",
    "href": "r-cfa.html",
    "title": "28  Конфирматорный факторный анализ",
    "section": "",
    "text": "library(tidyverse) library(lavaan) library(semPlot)\n\n28.0.1 TOLERANCE TO UNCERTAINTY\n\n\n29 reading data\ntolunc &lt;- read_csv2(‘https://raw.githubusercontent.com/angelgardt/hseuxlab-wlm2021/master/data/tolerance_uncertainty.csv’)\n\n\n30 checking data\nstr(tolunc) summary(tolunc)\n\n\n31 CFA model\nm1 &lt;- “F1 =~ tu1 + tu2 + tu3 + tu4 + tu5 + tu6 + tu7 + tu8 + tu9 + tu10 + tu11 + tu12 + tu13 + tu14 + tu15 + tu16 + tu17 + tu18 + tu19 + tu20 + tu21 + tu22” fit1 &lt;- cfa(m1, data = tolunc) summary(fit1)\n\n\n32 standardized solution\nsfit &lt;- standardizedsolution(fit1)\n\n\n33 factor loadings\nsfit %&gt;% filter(op == “=~”)\n\n\n34 correlations\n\n\n35 in this case, no correlations coz there is none in our model\nsfit %&gt;% filter(op == “~~” & lhs != rhs)\n\n\n36 residuals\nsfit %&gt;% filter(op == “~~” & sfit\\(lhs == sfit\\)rhs)\n\n\n37 fit measures\nfitmeasures(fit1, c(“chisq”, “gfi”, “agfi”,“cfi”, “tli”, “srmr”, “rmsea”))\n\n\n38 residual correlations\nresid(fit1, type = ‘cor’)\n\n\n39 visualization\nsemPaths(fit1, ‘std’)\n\n\n40 modification indices\n\n\n41 modindices(fit1)\nmodificationindices(fit1) %&gt;% #nrow() arrange(desc(mi)) %&gt;% filter(mi &gt; 100)\n\n\n42 model comparison\nm2 &lt;- “F1 =~ tu1 + tu2 + tu3 + tu4 + tu5 + tu6 + tu7 + tu8 + tu9 + tu10 + tu11 + tu12 + tu13 + tu14 + tu15 + tu16 + tu17 + tu18 + tu19 + tu20 + tu21 + tu22 tu1 ~~ tu2”\nfit2 &lt;- cfa(m2, data = tolunc) summary(fit2)\nanova(fit1, fit2)\n\n42.0.1 TAIA\ntaia &lt;- read_csv( sprintf( “https://docs.google.com/uc?id=%s&export=download”, “1L-6pG9eaJz09ILrG6sKipnHoOxiU_T2S” ) )\nmdl1 &lt;- ” PR =~ pr01 + pr02 + pr03 + pr04 + pr05 + pr06 + pr07 + pr08 + pr09 + pr10 CO =~ co01 + co02 + co03 + co04 + co05 + co06 + co08 + co09 + co10 UT =~ ut01 + ut02 + ut03 + ut04 + ut05 + ut06 + ut07 + ut08 + ut09 + ut11 + ut12 FA =~ fa01 + fa02 + fa03 + fa04 + fa05 + fa06 + fa07 + fa08 + fa09 + fa10 DE =~ de01 + de02 + de03 + de05 + de06 + de07 + de08 + de09 + de10 + de11 UN =~ un01 + un02 + un03 + un04 + un05 + un06 + un07 + un08 + un09 + un10 + un11 + un12 ”\nmodel1 &lt;- cfa(mdl1, taia) summary(model1)\nfitmeasures(model1, c(“chisq”, “df”, “pvalue”, “cfi”, “tli”, “srmr”, “rmsea”))\nsmodel1 &lt;- standardizedsolution(model1)\nsmodel1 %&gt;% filter(op == “=~”) %&gt;% filter(lhs == “PR”)\nsmodel1 %&gt;% filter(op == “~~” & lhs != rhs)\nsmodel1 %&gt;% filter(op == “~~” & lhs == rhs)\nsemPaths(model1, what = “std”, whatLabels = “est”, style = “lisrel”, residScale = 10, theme = “colorblind”, rotation = 1, layout = “tree”, cardinal = “lat cov”, curvePivot = TRUE, sizeMan = 3, sizeLat = 7)\nmdl2 &lt;- ” PR =~ pr01 + pr02 + pr03 + pr04 + pr05 + pr06 + pr07 + pr08 + pr09 + pr10 CO =~ co01 + co02 + co03 + co04 + co05 + co06 + co08 + co09 + co10 UT =~ ut01 + ut02 + ut03 + ut04 + ut05 + ut06 + ut07 + ut08 + ut09 + ut11 + ut12 FA =~ fa01 + fa02 + fa03 + fa04 + fa05 + fa06 + fa07 + fa08 + fa09 + fa10 DE =~ de01 + de02 + de03 + de05 + de06 + de07 + de08 + de09 + de10 + de11 UN =~ un01 + un02 + un03 + un04 + un05 + un06 + un07 + un08 + un09 + un10 + un11 + un12 DT =~ PR + CO + UT + FA + DE + UN ”\nmodel2 &lt;- cfa(mdl2, taia) summary(model2)\nfitmeasures(model2, c(“chisq”, “df”, “pvalue”, “cfi”, “tli”, “srmr”, “rmsea”))\nsmodel2 &lt;- standardizedsolution(model2) smodel2 %&gt;% filter(op == “=~”)\nsmodel2 %&gt;% filter(op == “~~”)\nmodin &lt;- modificationindices(model1)\nmodin %&gt;% arrange(desc(mi))",
    "crumbs": [
      "Анализ данных в R",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Конфирматорный факторный анализ</span>"
    ]
  },
  {
    "objectID": "intro-randvals.html#footnotes",
    "href": "intro-randvals.html#footnotes",
    "title": "2  Шкалы и случайные величины",
    "section": "",
    "text": "Разумеется, с учетом поставленного исследовательского вопроса и выдвинутых гипотез.↩︎\nОтносительно шкалы Ликерта, активнейшим образом используемой в психометрике, делаются некоторые допущения о её квазинепрерывности и псевдоинтервальности. Однако это вопросы курса психометрики, и пока что мы в них погружаться не будем.↩︎",
    "crumbs": [
      "Введение в статистику",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Шкалы и случайные величины</span>"
    ]
  },
  {
    "objectID": "desc-centraltend.html#виды-статистики",
    "href": "desc-centraltend.html#виды-статистики",
    "title": "3  Меры центральной тенденции",
    "section": "",
    "text": "Описательная статистика (descriptive statistics1) занимается обработкой статистических данных, их наглядным представлением, и собственно описанием через некоторые характеристики.\n\nЭти характеристики, количественно описывающие особенности имеющихся данных, называются описательными статистиками (descriptive statistics2).\nЗадача описательной статистики — ёмко описать имеющиеся данные и составить на основе этих описаний общее представление о них, а также обнаружить особенности, которые могут повлиять на дальнейший анализ.\n\nСтатистика вывода (inferential statistics) занимается поиском ответов на содержательные вопросы, которые мы задаем данным в ходе их анализа в рамках научных и практических исследований.\n\nСостоит из двух компонентов — тестирования статистических гипотез и статистических методов.\n\n\n\n\n\n\n\n\nЗамечание о машинном обучении\n\n\n\nВы наверняка не раз слышали словосочетание «машинное обучение». Это что-то, что время от времени становится то менее, то более хайпово. На самом деле, статистические методы лежат где-то между статистикой вывода и машинным обучением.\nПочему?\nДело в том, что на статистические методы можно смотреть по-разному.\n\nЕсли нашей задачей является поиск ответов на исследовательские вопросы о закономерностях, о связи каких-либо факторов или влиянии переменных друг на друга, то мы будем смотреть на статистические модели с точки зрения статистики вывода. Это позволит нам находить ответы на интересующие нас вопросы — причем не важно, говорим мы о научных исследованиях или об исследованиях в индустрии.\nЕсли перед нами стоит задача хорошо предсказывать одни переменные на основании значений других — например, выдавать рекомендации на Яндекс Музыке или в Яндекс Лавке — то мы будем смотреть на те же статистические модели с точки зрения машинного обучения.\n\nТо есть, модели абсолютно одни и те же, но то, какую модель мы назовем хорошей и как мы эту «хорошесть» определим, будет различаться в зависимости от задачи — исследовательская или предиктивная — которая перед нами стоит.",
    "crumbs": [
      "Описательная статистика",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Меры центральной тенденции</span>"
    ]
  },
  {
    "objectID": "desc-centraltend.html#footnotes",
    "href": "desc-centraltend.html#footnotes",
    "title": "3  Меры центральной тенденции",
    "section": "",
    "text": "Mass (uncountable) noun.↩︎\nCountable noun, plural in this case.↩︎\nPer se (лат.) — в чистом виде.↩︎",
    "crumbs": [
      "Описательная статистика",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Меры центральной тенденции</span>"
    ]
  },
  {
    "objectID": "desc-centraltend.html#меры-центральной-тенденции",
    "href": "desc-centraltend.html#меры-центральной-тенденции",
    "title": "3  Меры центральной тенденции",
    "section": "3.2 Меры центральной тенденции",
    "text": "3.2 Меры центральной тенденции\nИтак, мы хотим описать наши данные. Точнее, распределения переменных, которые у нас в данных есть. Хотим мы сделать это просто и ёмко. Насколько просто и ёмко? Ну, допустим максимально — одним числом. Кажется, значение переменной, которое лежит в центре распределения, неплохо для этого подойдет.\nКак мы будем искать, что там в центре распределения? Зависит от шкалы, в которой измерена конкретная переменная.\n\n\n\nШкала\nМера центральной тенденции\n\n\n\n\nНоминальная\nМода\n\n\nПорядковая\nМедиана\n\n\nИнтервальная\nСреднее арифметическое\n\n\nАбсолютная\nСреднее арифметическое, геометрическое и др.\n\n\n\nОднако есть некоторые нюансы.\n\n3.2.1 Мода\n\nОпределение 3.1 Мода (mode) — наиболее часто встречающееся значение данной переменной.\n\nТут все достаточно просто и интуитивно понятно. Пусть у нас есть следующий ряд наблюдений:\n\n\n [1] 1 3 4 6 4 2 4 3 2 4 1\n\n\nЕсли мы составим таблицу частот, то получим следующее:\n\n\nx\n1 2 3 4 6 \n2 2 2 4 1 \n\n\nОчевидно, что \\(4\\) встречается чаще других значений — это и есть мода.\nПонятно, что если на нашей шкале нет чисел, а есть текстовые лейблы, это ничего не меняет:\n\n\n [1] \"Москва\"                   \"Казань\"                  \n [3] \"Кёнигсберг\"               \"Барнаул (Алтайский край)\"\n [5] \"Москва\"                   \"Санкт-Петербург\"         \n [7] \"Санкт-Петербург\"          \"Москва\"                  \n [9] \"Санкт-Петербург\"          \"Москва\"                  \n[11] \"Кёнигсберг\"               \"Санкт-Петербург\"         \n[13] \"Москва\"                   \"Казань\"                  \n[15] \"Санкт-Петербург\"          \"Санкт-Петербург\"         \n[17] \"Казань\"                   \"Казань\"                  \n[19] \"Санкт-Петербург\"          \"Москва\"                  \n[21] \"Москва\"                   \"Санкт-Петербург\"         \n[23] \"Санкт-Петербург\"          \"Санкт-Петербург\"         \n[25] \"Санкт-Петербург\"          \"Москва\"                  \n[27] \"Кёнигсберг\"               \"Санкт-Петербург\"         \n[29] \"Казань\"                  \n\n\n\n\ny\nБарнаул (Алтайский край)                   Казань               Кёнигсберг \n                       1                        5                        3 \n                  Москва          Санкт-Петербург \n                       8                       12 \n\n\nМода, получается, Санкт-Петербург.\nТак мы поступаем с эмпирическим распределением. Если мы имеем дело с генеральной совокупностью, то можем формально определить моду через функцию вероятности (probability mass function, PMF). Модой будет являться значение случайной величины, при котором PMF принимает своё максимальное значение.\n\\[\n\\text{mode}(X) = \\arg \\max \\big( \\text{PMF}(X) \\big)\n\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 3.1: Определение моды для дискретной случайной величины по функции вероятности\n\n\n\nМода — 7.\n\n\n3.2.2 Медиана\n\nОпределение 3.2 Медиана (median) — значение переменной, которые располагается на середине отсортированного ряда значений.\n\nТо есть, она делит все наблюдения переменной ровно пополам, и половина наблюдений оказывается по одну сторону от медианы, а половина — по другую.\nЕсли у нас нечетное число наблюдений, то всё ясно. Пусть есть такой ряд наблюдений:\n\n\n [1]  2  3 14  9 16 19 28  7 26 18  1\n\n\nОтсортируем его:\n\n\n [1]  1  2  3  7  9 14 16 18 19 26 28\n\n\nПосмотрим в середину — найдем медиану:\n\n\n[1] 14\n\n\nА что делать, если число наблюдений чётное? Ведь тогда середина ряда будет между двух чисел. Ну, возьмем их среднее арифметическое — это и будет медиана.\nВозьмём такой ряд наблюдений:\n\n\n [1] 14 10  9 16 30  3 25  8 18  7\n\n\nОтсортируем:\n\n\n [1]  3  7  8  9 10 14 16 18 25 30\n\n\nНайдём медиану как \\((10 + 14) / 2\\):\n\n\n[1] 12\n\n\nФормально это можно написать так:\n\\[\n\\text{median}(X) = \\cases{\nX_{\\frac{n+1}{2}}, \\quad \\text{if} \\, n \\, \\text{is odd} \\\\\n\\frac{X_{\\frac{n}{2}} + X_{\\frac{n}{2}+1}}{2}, \\quad \\text{otherwise}\n}\n\\]\nгде \\(X\\) — ряд наблюдений данной переменной, \\(n\\) — число наблюдений, \\(X_i\\) — наблюдение с индексом \\(i\\) в сортированном векторе \\(X\\).\n\n\n3.2.3 Среднее арифметическое\nС этим существом все знакомы еще со школы.\n\nОпределение 3.3 Арифметическое среднее (arithmetic mean, mean, average) — сумма всех значений переменной, делёная на их количество.\n\nИначе говоря:\n\\[\nM(X) = \\overline{X} = \\frac{1}{n} \\sum_{i=1}^n x_i\n\\]\nгде \\(\\overline X\\) — среднее арифметическое, \\(x_i\\) — наблюдение в векторе \\(X\\), \\(n\\) — количество наблюдений.\nНу, то есть всё сложить и поделить на количество того, чего сложили. Изи.\nВот, скажем, средние по двум рядам наблюдений, которые мы встречали в разделе про медиану:\n\n\n [1]  2  3 14  9 16 19 28  7 26 18  1\n\n\n[1] 13\n\n\n\n\n [1] 14 10  9 16 30  3 25  8 18  7\n\n\n[1] 14\n\n\n\n\n3.2.4 Среднее взвешенное\nЧасто возникает такая ситуация, когда нам нужно посчитать среднее по каким-либо имеющимся характеристикам, но одни характеристики для нас важнее, чем другие. Например, мы хотим вычислить суммарный балл обучающегося за курс на основе ряда работ, выполненных в течение курса. Мы могли бы взять оценки за все работы и усреднить их. Однако мы понимаем, что, скажем, тест из десяти вопросов с множественным выбором явно менее показателен, чем, например, аналитическое эссе или экзаменационная оценка. Что делать? Взвесить параметры!\nЧто значит взвесить? Умножить на некоторое число. На самом деле, любое. Пусть мы посчитали, что написать эссе в три абстрактных раза тяжелее, чем написать тест, а сдать экзамен в два раза тяжелее, чем написать эссе. Тогда мы можем присвоить баллу за тест вес \\(1\\), баллу за аналитическое эссе вес \\(3\\), а экзамену — вес \\(6\\). Тогда итоговая оценка за курс будет рассчитываться следующим образом:\n\\[\n\\text{final score} = 1 \\cdot \\text{test} + 3 \\cdot \\text{essay} + 6 \\cdot \\text{exam}\n\\]\nСуперкласс. Однако! Весьма вероятно, что в учебном заведении принята единая система оценивания для всех видов работ — ну, скажем, некая абстрактная десятибалльная система в сферическом вакууме. Получается, если и за тест, и за эссе, и за экзамен у студента по 10 баллов, то суммарный балл 100, что, кажется, больше, чем 10. Чтобы вернуться к изначальным границам баллов, нужно поделить суммарный балл на сумму весов параметров:\n\\[\n\\text{final score} =\n\\frac{1 \\cdot \\text{test} + 3 \\cdot \\text{essay} + 6 \\cdot \\text{exam}}\n{1 + 3 + 6}\n\\]\nКайф! Собственно, это и есть взвешенное среднее. Коэффициенты, на которые мы умножаем значения переменных, называются весами. В общем виде формула принимает следующий вид:\n\\[\n\\overline X = \\frac{\\sum_{i=1}^n w_i \\cdot x_i}{\\sum_{i=1}^n w_i},\n\\]\nгде \\(x_i\\) — значения переменной, \\(w_i\\) — веса для этих значений.\nВзвешенное среднее часто применяется именно во всякого рода ассессментах, и не только образовательных. Например, вы HR-аналитик и оцениваете персонал. Вы аналитически вычисляете веса коэффициентов (допустим, с помощью линейной регрессии), а далее на их основе высчитываете интегральный балл, по которому будете оценивать сотрудников. Это как один из индустриальных примеров.\n\n\n3.2.5 Другие средние\nСреднее бывает не только арифметическое. Правда встретятся вам другие его виды примерно нигде — то есть о-о-о-очень редко и, скорее всего, в каких-то узкоспециализированных статьях. Но упомянуть их, пожалуй, стоит как минимум ради того, чтобы вы не перепугались излишне, ежели вдруг с ними столкнётесь.\n\n3.2.5.1 Квадратичное среднее\nЭто весьма полезная вещь.\n\nОпределение 3.4 Квадратичное среднее (quadratic mean, root mean square, RMS) — это квадратный корень из среднего квадрата наблюдений.\n\nНичего не понятно, поэтому по порядку:\n\nесть наблюдение \\(x_i\\)\nзначит есть и его квадрат \\(x_i^2\\)\nмы умеем считать обычно среднее арифметическое\n\nно ведь \\(x_i^2\\) — это тоже наблюдение (число), просто в квадрате\n\nзначит можем посчитать среднее арифметическое квадратов наблюдений — средний квадрат (mean square) — \\(\\displaystyle \\frac{1}{n} \\sum_{i=1}^n x_i^2\\)\nтеперь извлечём из этого дела корень, чтобы вернуться к исходным единицам измерения — получим то, что нам надо\n\n\\[\n\\text{RMS}(X) = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n x_i^2}\n\\]\nPer se3 мы его вряд ли ещё когда-то увидим, но пару раз оно внезапно всплывет.\n\n\n3.2.5.2 Геометрическое среднее\nВ психологии и социальных науках встречается редко. Применяется там, где необходимо изучать средние скорости изменения — например, в экономике и финансах при изучении доходности, прибыли и выручки; в демографии при расчете индекса человеческого потенциала и др.\n\\[\nG(X) = \\sqrt[n]{\\prod_{i=1}^n x_i}\n\\]\n\n\n3.2.5.3 Гармоническое\nВесьма экзотическая конструкция, используемая при работе с величинами, заданными через обратные значения. Встречается в финансах и экономике, страховании, физике.\n\\[\nH(X) = \\frac{n}{\\displaystyle \\sum_{i=1}^n \\frac{1}{x_i}}\n\\]",
    "crumbs": [
      "Описательная статистика",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Меры центральной тенденции</span>"
    ]
  },
  {
    "objectID": "desc-centraltend.html#сравнение-мер-центральной-тенденции",
    "href": "desc-centraltend.html#сравнение-мер-центральной-тенденции",
    "title": "3  Меры центральной тенденции",
    "section": "3.3 Сравнение мер центральной тенденции",
    "text": "3.3 Сравнение мер центральной тенденции\nСравнивать будем моду, медиану и среднее [арифметическое].\nВсе три статистики — мода, медиана и среднее — описывают центральную тенденцию — значение изучаемой нами переменной, вокруг которого собираются другие значения. Но если их три и все они используются, значит между ними должны быть какие-то различия. Посмотрим, какие.\n\n3.3.1 Меры центральной тенденции и типы переменных\n\nВо-первых, очевидно, что моду невозможно посчитать для непрерывной переменной.\n\n\n\n\n\n\n\nНет, не очевидно\n\n\n\n\n\nТак как вероятность того, что непрерывная случайная величина принимает своё конкретное значение, равна нулю, каждое наблюдение в нашей выборке будет уникально — встретится ровно один раз. Вспомните пример из предыдущей главы (Рисунок 2.9), где мы набирали числа из отрезка. Получается, что мода теряет свой смысл.\n\n\n\n\nВо-вторых, медиану нельзя посчитать на номинальной шкале. Кстати, почему?\n\n\n\n\n\n\n\nПотому что\n\n\n\n\n\nна номинальной шкале нет отношения порядка между элементами — на ней нельзя сравнивать на больше-меньше. Следовательно, невозможно отсортировать наблюдения, а значит, и найти медиану.\n\n\n\n\nВ-третьих, среднее тоже нельзя посчитать на номинальной шкале.\n\n\n\n\n\n\n\nМожно, но осторожно\n\n\n\n\n\nВообще, конечно, да — нельзя, потому что на номинальной шкале не определена операция сложения, входящая в вычисление среднего. Однако если на номинальной шкале есть только две категории, которые закодированы 0 и 1, то посчитать среднее можно. Но что оно будет значить?\nИсходный математический смысл среднего явно утерян. Посмотрим на это по-другому: посчитать сумму единиц это всё равно, что посчитать количество единиц. То есть, если мы сложим все нули и единицы, то получим количество единиц среди всех наших наблюдений. А разделив количество единиц на количество наблюдений, мы получим долю единиц — то есть долю наблюдений с лейблом 1.\nокак\n\n\n\n\nВ-четвертых, для дискретной переменной значение среднего арифметического будет не особо осмысленно. Ну, скажем, странно сказать, что в аудитории в среднем стоят 15.86 столов или в российских семьях в среднем 1.5 ребенка. Конечно, в ряде случаев можно это как-то более-менее содержательно интерпретировать, но это требует усилий, а мы ленивые, поэтому лучше использовать медиану.\n\n\n\n\n\n\n\nИтого, делаем следующие выводы\n\n\n\n\nдля номинальной шкалы пригодна только мода\nдля дискретных переменных подходят мода и медиана\nмода иногда лучше, так как точно всегда будет целым числом\nдля непрерывных переменных подходят медиана и среднее\n\n\n\n\n\n3.3.2 Меры центральной тенденции и форма распределения\nПомимо того, что среднее, мода и медиана информативны сами по себе, полезно смотреть на их взаимное расположение.\n\nНа симметричном распределении мода, медиана и среднее совпадают [или, по крайней мере, находятся очень близко друг к другу].\n\n\nЗдесь и далее: красная (сплошная) линия — среднее, синяя (короткопунктирная) — медиана, зелёная (длиннопунктирная) — мода.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 3.2: Взаимное расположение моды, медианы и среднего на симметричном распределении\n\n\n\n\nНа асимметричном распределении мода [практически] в пи́ке\n\n.Практически, потому что мода для непрерывной переменной определена по функции плотности вероятности [черная линия на графике], которая не всегда точно аппроксимирует (в данном случае то же, что и сглаживает) эмпирическое распределение. На картинке ниже мы видим, что по гистограмме мода должна была бы быть в районе самого высокго столбика, однако при сглаживании гистограммы пик немного съехал, и мода оказалась в вершине графика функции плотности вероятности.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 3.3: Взаимное расположение моды, медианы и среднего на распределении с правосторонней асимметрией\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 3.4: Взаимное расположение моды, медианы и среднего на распределении с левосторонней асимметрией\n\n\n\n\nНа асимметричном распределении медиана и среднее смещены в сторону хвоста. Среднее смещено сильнее медианы.\n\nЭто связано с тем, что медиана зависит только от количества наблюдений, а среднее — ещё и от самих значений. На картинках выше примеры для распределения с правосторонней асимметрией (потому что хвост справа) — среднее (красная линия) правее медианы (синяя линия) — и левосторонней асимметрией (так как хвост слева) — среднее (красная линия) левее медианы (синяя линия).\nДля того, чтобы лучше разобраться с тем, как большие и малые значения влияют на моду и медиану посмотрим такой пример. Пусть у нас есть оценки за выпускную квалификационную работу. Например, такие:\nmarks [1] 6 7 7 8 8 Посчитаем медиану и среднее:\nmedian(marks) [1] 7 mean(marks) [1] 7.2\nСреднее\n7.2 округлиться до\n7 , то есть можно считать, что среднее и медиана совпали. Ну, ок.\nНо в комиссии сидят два требовательных доктора наук, которые поставили оценки, сильно отличающиеся от остальных:\nmarks [1] 6 7 7 8 8 3 4 Посчитаем медиану и среднее теперь:\nmedian(marks) [1] 7 mean(marks) [1] 6.142857 Медиана осталась на месте — всё ещё\n7 . А вот среднее\n6.1 округлится до\n6 . Казалось бы, это немного, но в смысле оценок — это прилично, и может сильно повлиять на GPA.\nИтого, среднее более чувствительно к нетипичным значениям (очень большим или очень малым).\nЕсть ещё один интересный вариант распределений — бимодальные. Значит ли, что у этого распределения две моды? Не всегда. Посмотрим пример ниже:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 3.5: Взаимное расположение моды, медианы и среднего на бимодальном распределении\n\n\n\nМы видим, что на графике есть два пика, однако строго математически мода всё же одна (зелёная пунктирная линия) — и она в более высоком пике. Это логично, ибо там самые часто встречающиеся (самые вероятные) значения.\nИ все жё содержательно мы не можем пренебречь вторым пиком (зелёная точечная линия). Почему он нам важен? Обычно бимодальное распределение — это повод задуматься о том, что наша выборка неоднородна. Бимодальное распределение как бы сложено из двух с центрами в двух пиках. Иначе говоря, в нашей выборке как будто бы две подвыборки, которые обладают разными распределениями интересующего нам признака.\nЧто с этим делать? Хорошо всегда иметь в данных какие-либо дополнительные переменные — как минимум соцдем — чтобы мы могли по данным попытаться предположить, какую группировку мы могли забыть учесть при планировании исследования.\nСо средним и медианой в случае бимодального распределения происходит примерно то же, что и в случае асимметричного распределения — второй пик смещает к себе обе меры центральной тенденции, причем среднее вновь сильнее, чем медиану.",
    "crumbs": [
      "Описательная статистика",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Меры центральной тенденции</span>"
    ]
  },
  {
    "objectID": "desc-centraltend.html#свойства-среднего-арифметического",
    "href": "desc-centraltend.html#свойства-среднего-арифметического",
    "title": "3  Меры центральной тенденции",
    "section": "3.4 Свойства среднего арифметического",
    "text": "3.4 Свойства среднего арифметического\nМы упомянем три основных свойства, к которым будем обращаться в последующих темах.\n\nУтверждение 3.1 Если к каждому значению распределения прибавить некоторое число (константу), то среднее увеличится на ту же константу.\n\\[\nM_{X+c} = M_X + c\n\\]\n\n\nДоказательство. \\[\n\\begin{split}\nM_{X+c} &= \\frac{\\sum_{i=1}^n (x_i + c)}{n} = \\\\\n&= \\frac{\\sum_{i=1}^n x_i + nc}{n} = \\\\\n&= \\frac{\\sum_{i=1}^n x_i}{n} + c = M_X + c\n\\end{split}\n\\]\n\nИначе говоря, распределение просто сдвинется. Например, если к каждому значению синего распределения прибавить \\(2\\), получится красное:\n\n\n\n\n\n\n\n\n\n\nУтверждение 3.2 Если каждое значение распределение умножить на некоторое число (константу), то среднее увеличится во столько же раз.\n\\[\nM_{X \\times c} = M_X \\times c\n\\]\n\n\nДоказательство. \\[\n\\begin{split}\nM_{X \\times c} &= \\frac{\\sum_{i=1}^n (x_i \\times c)}{n} = \\\\\n&= \\frac{c \\times \\sum_{i=1}^n x_i}{n} = \\\\\n&= \\frac{\\sum_{i=1}^n x_i}{n} \\times c = M_X \\times c\n\\end{split}\n\\]\n\nНапример, здесь каждое значение синего распределения умножили на \\(3\\) и получили красное:\n\n\n\n\n\n\n\n\n\nТут, правда, явно что-то ещё произошло, но мы пока этого не знаем.\n\nУтверждение 3.3 Сумма отклонений от среднего значения равна нулю.\n\\[\n\\sum_{i=1}^n(x_i - M_X) = 0\n\\]\n\n\nДоказательство. \\[\n\\begin{split}\n\\sum_{i=1}^n(x_i - M_X) &= \\sum_{i=1}^n x_i - \\sum_{i=1}^n M_X = \\\\\n& = \\sum_{i=1}^n x_i - nM_X = \\\\\n& = \\sum_{i=1}^n x_i - n \\times \\frac{1}{n} \\sum_{i=1}^n x_i = \\\\\n&= \\sum_{i=1}^n x_i - \\sum_{i=1}^n x_i = 0\n\\end{split}\n\\]\n\nНо можно это осмыслить и более просто графически.\n\n\n\n\n\n\n\n\n\n\nОпределение 3.5 Отклонение — это разность между конкретным значением переменной и средним по этой переменной.\n\\[\nd_i = \\overline X - x_i\n\\]\n\nИ, действительно, так как среднее находится в центре распределения, то часть значений лежит справа, а часть слева. Значит, будут как положительные, так и отрицательные отклонения — и их сумма в итоге будет равна нулю.",
    "crumbs": [
      "Описательная статистика",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Меры центральной тенденции</span>"
    ]
  }
]