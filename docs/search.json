[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "SFDA | PSY HSE",
    "section": "",
    "text": "Начало",
    "crumbs": [
      "Начало"
    ]
  },
  {
    "objectID": "index.html#врубаем-тэхно-для-рабочего-настроения",
    "href": "index.html#врубаем-тэхно-для-рабочего-настроения",
    "title": "SFDA | PSY HSE",
    "section": "Врубаем тэхно для рабочего настроения",
    "text": "Врубаем тэхно для рабочего настроения\n\nПрежде всего, разумно будет попытаться разобраться в том, заради чего мы тут собрались. Ну, попробуем…\n\nВот, скажем, решили мы замерить уровень счастья российского населения — задача, прямо скажем, не суперпростая. Дать опросник 144 миллионам людей весьма энергозатратно, и хотелось бы как-то упростить себе задачу. Сколько нам надо опросить людей, чтобы наш замер отражал реальность? Как нам их выбрать? Как потом обсчитать цифры, которые мы получим? И вообще, наш опросник — он точный? Надежный? Им вообще законно что-либо измерять?\nИли вот мы — учёный. Решили провести некоторый суровый когнитивный эксперимент, чтобы узнать, как пользователи Android и iOS ищут иконки разных приложений. Скачали статей, выдвинули гипотезы, придумали дизайн, запрогали эксп, нашли несчастных, которые прошли этот эксп — по итогу получили какие-то цифири. Возникает справедливый вопрос: и чё? Как нам сказать, что данные подтвердили или опровергли наши гипотезы? Можем ли мы вообще по этим данным что-то сказать? Ну, допустим, мы ленивые и вообще программировать это для умных — отдадим специально обученным аналитикам посчитать это всё. И получим цифири. О, нет — опять! Возникает ещё один справедливый вопрос: и чё? Как нам сказать, что эти цифры подтверждают или опровергают наши гипотезы? Можем ли мы вообще по этим цифрам что-либо сказать осмысленное? А содержательно как это интерпретировать? Иконки-то как пользователи ищут?\nНу, или мы — HR в компании на 100500 тыщ человек сотрудников. Пришел гендир, сказал «уволить нельзя премировать, только непонятно кого». Дал нам экселевскую таблицу со всякими показателями эффективности и сказал «завтра к вечеру должна быть система грейдов, по которой будем оценить сотрудников». И что делать? Придется всю ночь ворочать цифры и статистически моделировать.\nА вот, скажем, залезли мы в ковидные новости очередной волны — там что-то страшное, да в графиках, да снова цифры какие-то ужасные. Хлебнули чаю, включили статистический взгляд — а, ну так все норм же. Оценили риски для себя, друзей, родных, убедились в том, что журналисты снова навели излишней суеты, восхитились собой, пошли инвестировать в крипту.\nОпять какие-то графики увидели, тренды, прогнозы и всё такое. Как понять? Как прочитать это всё? Как оценить, куда надо стипуху вкласть? Вспомнили статистику, навели шороху, собрали достойный инвестиционный портфельчик — хлебнули кофе, пошли покупать билеты на Бали.\nДальше можно расписывать огромное количество подобных случаев. Приходится признать, что сегодня мы живем в окружении огромного количества алгоритмов, основанных на статистическом анализе. Всё то, что называется модным словосочетанием «машинное обучение» базируется на тех статистических методах, которые мы будем с вами изучать.\nМожно ли жить без этого знания? В принципе, да. Однако\n\nкогнитивщикам и нейроисследователям необходимо анализировать свои данные своих экспериментов и — что значительное более важно — корректно интерпретировать результаты статистического анализа, что невозможно без понимания того, как используемые статистические методы работают\nсоциальщикам и личностникам-исследователям также необходимо анализировать данные своих исследований — и используемые ими модели даже сложнее, чем у когнитивщиков и нейроученых\nорганизационщикам придется также работать с данными, потому что HR-аналитика на хайпе и экспертный подход к оценке персонала постепенно теряет актуальность [а ещё айтишников нанимать придётся]\nличностникам-консультантам надо быть в теме того, что творят личностники-исследователи, а значит придется читать статьи и оценивать их адекватность, в том числе, в аспекте анализа данных\nвсем [даже некоторым когнитивщикам] придется работать с опросниками — а вся психометрика строится на статистике\nвсем придется в жизни анализировать потоки информации, возрастающие с невероятной скоростью, данные и графики, критически и оценивать, выявлять неочевидные закономерности, чтобы понимать, что происходит — и статистика в этом сильно поможет\nвсе мы продолжаем жить в мире гаджетов и технологий, и понимание того, какие модели лежат в их основе, очень прилично апгрейдит наше понимание того, что восстание машин будет о-о-о-очень не скоро.\n\nКонечно, мы не можем обсудить всё. Мы находимся в рамках суровых институциональных ограничений. Но мы постараемся заложить достаточно прочный фундамент, который при правильном применении и должном уходе поможет вам преуспеть и в жизни, и в работе и вообще.",
    "crumbs": [
      "Начало"
    ]
  },
  {
    "objectID": "index.html#зачем-изучать-анализ-данных-в-эпоху-нейросетей",
    "href": "index.html#зачем-изучать-анализ-данных-в-эпоху-нейросетей",
    "title": "SFDA | PSY HSE",
    "section": "Зачем изучать анализ данных в эпоху нейросетей?",
    "text": "Зачем изучать анализ данных в эпоху нейросетей?\nА действительно? Можно же просто закинуть промпт, и всё готово…\nНу, закинем промпт.\n\nЗачем изучать анализ данных, если существуют нейросети, которые могут проанализировать данные за меня?\n\n\n\n\n\n\n\nОтвет ChatGPT-4 (30 мая 2024)\n\n\n\nЭто отличный вопрос! Действительно, нейросети и другие методы машинного обучения становятся все более мощными инструментами для анализа данных. Однако есть несколько причин, почему важно изучать анализ данных, даже если существуют такие технологии:\n\nПонимание процесса: Понимание основ анализа данных позволяет лучше понять, как работают нейросети и другие алгоритмы машинного обучения. Это помогает в настройке, интерпретации и улучшении моделей.\nВыбор методов: Анализ данных помогает выбирать подходящие методы и инструменты для конкретной задачи. Нейросети — не всегда лучший выбор, особенно для небольших наборов данных или когда требуется интерпретируемость результатов.\nКачество данных: Анализ данных включает в себя предварительную обработку данных — очистку, нормализацию, выявление и исправление ошибок. Без этого этапа нейросеть может обучиться на “грязных” данных и выдавать неправильные результаты.\nИнтерпретируемость моделей: Многие модели машинного обучения (включая нейросети) сложны для интерпретации. Традиционные методы анализа данных, такие как регрессия или дерево решений, могут предложить более простые и интерпретируемые модели, что важно в некоторых приложениях, например, в медицине или финансах.\nОбоснование результатов: В некоторых ситуациях требуется не только предсказать результат, но и объяснить, почему модель приняла то или иное решение. Это особенно важно в регулируемых отраслях, таких как банковское дело или страхование.\nКомбинаторика методов: Возможно объединение различных методов анализа данных и машинного обучения для достижения лучших результатов. Глубокое понимание как статистических методов, так и нейросетей позволяет строить гибридные модели.\nИнновации и новые подходы: Знания в области анализа данных способствуют разработке новых алгоритмов и подходов, что может привести к появлению более эффективных способов решения задач.\n\nВ целом, изучение анализа данных дает фундаментальные знания, которые помогут лучше использовать и усовершенствовать нейросетевые модели и другие инструменты машинного обучения.\n\n\n\nЗачем мне как аналитику уметь писать код, если можно попросить нейросеть написать код под конкретную задачу по анализу данных?\n\n\n\n\n\n\n\nОтвет ChatGPT-4 (30 мая 2024)\n\n\n\nИспользование нейросетей для генерации кода под задачи анализа данных может быть полезным, но есть несколько причин, по которым важно уметь писать код самостоятельно, даже если вы аналитик:\n\nПонимание данных и процессов: Знание программирования помогает лучше понять структуру данных и методы, которые вы используете для их анализа. Это особенно важно для интерпретации результатов и их корректного применения.\nОтладка и валидность результатов: Автоматически сгенерированный код может привести к ошибкам или неправильным выводам. Умение самостоятельно писать и проверять код позволяет убедиться, что все работает корректно.\nГибкость и адаптация: Ваши задачи могут изменяться, требуя новой логики анализа или дополнительных шагов обработки данных. Умение писать код позволяет легче адаптироваться к новым требованиям и быстро вносить изменения.\nКачество данных: Предварительная обработка данных — ключевой этап анализа. Знание программирования помогает эффективно очистить, нормализовать и обработать данные перед анализом.\nОптимизация: Автоматически сгенерированный код может быть неоптимальным. Умение писать собственный код позволяет вам сделать анализ данных более эффективным и производительным.\nИнтерпретируемость: Полное понимание кода делает результаты вашего анализа более понятными и объяснимыми для заинтересованных сторон.\nКомандная работа и документация: В команде аналитиков важно уметь читать и писать структурированный код, чтобы эффективно сотрудничать с коллегами и поддерживать документацию проекта.\nНавык решения уникальных задач: Задачи анализа данных могут быть очень разнообразными и требовать индивидуального подхода. Нейросеть может не всегда справиться с уникальными или нестандартными задачами без надлежащего контекста.\nПрофессиональный рост: Знание программирования является важным навыком для роста и развития в карьере аналитика. Это открывает двери к более сложным и интересным проектам.\nБезопасность и конфиденциальность: Используя нейросеть, вы можете столкнуться с проблемами, связанными с конфиденциальностью данных. Самостоятельная работа с кодом помогает лучше контролировать безопасность и защиту данных.\n\nХотя нейросети могут быть полезным инструментом, знание программирования остается важным навыком для аналитиков, обеспечивая гибкость, контроль и качество работы.\n\n\nВ общем-то, автор согласен с мнением большой языковой модели. Пусть и не все обозначенные ею пункты в полной мере актуальны для психологов, так или иначе каждый тезис находит своё отражение в исследовательской работе психолога.\nКроме того, если мы уж и решили использовать нейросеть для генерации кода или подбора статистического метода под имеющуюся у вас задачу, надо каким-то образом надо сформулировать промпт. А как его сформулировать, если не знать хотя бы на концептуальном уровне, что должно получиться в результате анализа данных?\nПолучается, что всё-таки имеет смысл разобраться в статистике и анализе данных хотя бы на некотором базовом уровне, чтобы использоваться нейросетки с умом.",
    "crumbs": [
      "Начало"
    ]
  },
  {
    "objectID": "intro-intro.html",
    "href": "intro-intro.html",
    "title": "1  Основания статистики",
    "section": "",
    "text": "1.1 Выборка и генеральная совокупность\nЗвучит красиво. Осталось понять, что это значит.\nМассовые явления затрагивают огромные массы людей. Огромность масс, конечно, различна. Скажем, базовые перцептивные закономерности, связанные с тем, как устроена зрительная система, охватывают всех людей. Уровень удовлетворенности жизнью россиян охватывает только население России. Городские блага москвичей — только для жителей Москвы. Учебная мотивация студентов департамента психологии НИУ ВШЭ — это только про людей с психологических бакалавриата и магистратур НИУ ВШЭ.\nКороче, надо исследовать много людей, а времени и денег нет, поэтому мы никогда не сможем полностью изучить всю интересующая нас генеральную совокупность. Однако исследования всё же проводить нужно, поэтому приходится из генеральной совокупности извлекать выборку (sample) — некоторую часть нашей генеральной совокупности (объемом \\(n\\)). При этом \\(n \\ll N\\) (много меньше).\nНас, конечно же, интересуют какие-то признаки, которыми обладают объекты нашей генеральной совокупности. Эти признаки могут быть выражены количественно в определенных показателях (Таблица 1.1).\nПризнаки могут быть очень разными, как и показатели, которыми мы их пытаемся измерить. Не будем сильно в это углубляться, ибо подробнее об этом будет рассказано в других курсах. Мы же остановимся\nЧто нам важно сейчас: генеральная совокупность характеризуется параметром.\nНу, то есть в принципе существует средний уровень нейротизма студентов-психологов, или средняя удовлетворенность условиями труда сотрудниками IT-компаний, или средний уровень академической мотивации выпускников бакалавриата. Проблема в том, что величина параметра, который мы изучаем, неизвестна. И никогда не будет известна.\nНо почему?\nПоэтому величину параметра мы можем только предсказать с определённой статистической точностью. Измеряя что-либо на выборке, мы получаем выборочную характеристику, или оценку.\nТак, оценкой для среднего уровня нейротизма студентов-психологов может служить средний балл нескольких тысяч студентов-психологов по соответствующей шкале опросника BFI (Big Five Inventory), а оценкой для средней академической мотивации выпускников бакалавриата будет, например, средний балл нескольких тысяч выпускников по опроснику академической мотивации.",
    "crumbs": [
      "Введение в статистику",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Основания статистики</span>"
    ]
  },
  {
    "objectID": "intro-intro.html#intro-sample-pop",
    "href": "intro-intro.html#intro-sample-pop",
    "title": "1  Основания статистики",
    "section": "",
    "text": "Определение 1.1 Статистика (statistics) — это междисциплинарная область знаний, а также практической деятельности, изучающая массовые явления, а также принципы и методы работы с данными, характеризующими эти явления.\n\n\n\n\nОпределение 1.2 Генеральная совокупность (population) — множество всех [существующих] исследуемых объектов, а также сведения о них.\n\n\nОпределение 1.3 Объем совокупности (\\(N\\)) — число единиц, образующих совокупность.\n\n\n\n\n\n\nТаблица 1.1: Примеры признаков и показателей\n\n\n\n\n\n\n\n\n\nПризнак\nПоказатель\n\n\n\n\nРабочая память\nОбъем рабочей памяти\n\n\nНейротизм\nУровень нейротизма по BFI\n\n\nЗаработная плата\nСредняя заработная плата\n\n\nКогнитивная нагрузка\nУровень когнитивной нагрузки по ЭЭГ-коррелятам\n\n\nДоверие к ИИ\nУровень доверия к ИИ по опроснику TAIA\n\n\nИндивидуализм/коллективизм\nИндекс индивидуализма/коллективизма по модели Хофстеде\n\n\n\n\n\n\n\n\n\nОпределение 1.4 Параметр (statistical parameter) (\\(\\theta\\)) — относительно постоянная [от одной совокупности к другой] величина, характеризующая генеральную совокупность по некоторому показателю.\n\n\n\n\nМы не можем изучить всю генеральную совокупность — в ней слишком много объектов\nНаши измерения всегда содержат ошибку — мы даже длину линейкой точно не можем измерить, что уж о психологических измерениях говорить\n\n\n\nОпределение 1.5 Выборочная оценка (estimation) (\\(\\hat \\theta\\)) — эмпирический (измеримый) аналог параметра.\n\n\n\nВыше приводились примеры, где в качестве параметров и их оценок выступали средние. Чаще всего мы в психологии действительно работаем со средними [арифметическими], однако в других науных областях могут встречаться и более хитрые параметры и оценки.",
    "crumbs": [
      "Введение в статистику",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Основания статистики</span>"
    ]
  },
  {
    "objectID": "intro-intro.html#intro-main-task",
    "href": "intro-intro.html#intro-main-task",
    "title": "1  Основания статистики",
    "section": "1.2 Основная задача статистики",
    "text": "1.2 Основная задача статистики\nМы в какой-то малоприятной ситуации… Мы пытаемся измерить то, что в определенном смысле невозможно измерить, при этом достаточно точно, чтобы потом это можно было сравнивать или строить какие-то модели. Задача выглядит заведомо провальной…\nОднако именно в этот момент на помощь нам приходит статистика. Не в гордом одиночестве, конечно. Она приводит с собой теорию вероятности, теорию измерений, психометрику, теорию обнаружения сигнала и др. Всё это работает в нашей психологической науке в комплексе. Мы же в данном курсе сосредотачиваемся на статистической части этого салата.\nСтатистика даёт нам теоретический и математический инструментарий, чтобы мы могли делать какие-либо выводы о генеральной совокупности по собранным на выборке данным. К сожалению, как бы нам не хотелось, мы не можем делать выводы по сырым данным, потому что измерения по выборке не отражают вот прям ровно то, что есть в генеральной совокупности. Нам их надо определенным образом обсчитать, чтобы наши выводы были корректными. Этим и занимается статистика.\nЕсли мы попытаемся нарисовать какую-то концептуальную схему работы с выборкой в ходе исследования, то получится нечто такое (Рисунок 1.1).\n\n\n\n\n\n\nРисунок 1.1: Схема работы с выборкой в ходе исследования\n\n\n\nМы желаем изучить некую генеральную совокупность (population), которая недоступна нам в полном объёме. По этой причине мы извлекаем (sampling) из неё выборку (sample). На выборке мы собираем данные (data), по которым хотим делать вывод (inference) о генеральной совокупности. Как именно нам сделать такой вывод и рассказывает статистика.\nВероятно, сейчас это звучит достаточно абстрактно, но на данном этапе будет достаточно некоторого интуитивного понимания того, зачем нужна статистика. Далее интуиция обрастёт содержанием и уложится, хотелось бы надеяться, в достаточно стройную систему.\n\n\n\n\n\n\nИтог\n\n\n\nCтатистика помогает нам делать выводы об изучаемой генеральной совокупности по выборке.",
    "crumbs": [
      "Введение в статистику",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Основания статистики</span>"
    ]
  },
  {
    "objectID": "intro-intro.html#intro-main-sample",
    "href": "intro-intro.html#intro-main-sample",
    "title": "1  Основания статистики",
    "section": "1.3 Основная характеристика выборки",
    "text": "1.3 Основная характеристика выборки\nОкей, статистика даёт нам теоретический и математический аппарат, который позволяет делать выводы о генеральной совокупности по выборке. Однако если мы криво собрали данные, то никакая математика нас не спасет от некорректных выводов.\n\nОдин из принципов машинного обучения, актуальный и для нас, гласит: garbage in, garbage out, что значит «плохие данные на входе — бессмысленные результаты на выходе».\n\nТогда возникает вопрос: как собрать хорошие данные? Аспектов в этом вопросе много, и все они решаются при разработке дизайна исследования. Мы не будем здесь подробно разбирать, как корректно разрабатывать дизайн исследования, ибо это не является задачей курса статистики. Однако одни из ключевых элементов дизайна любого исследования — его выборка и способ её формирования.\nСреди характеристик выборки можно назвать много чего — например, объём и сбалансированность — но в целом все отдельные характеристики обобщаются в понятие репрезентативности.\nРепрезентативность выборки — это степень соответствия характеристик выборки характеристикам генеральной совокупности.\nНапример, мы хотим исследовать связь учебной мотивации и академической успеваемости бакалавров психологии. Если мы соберем данные только со своих однокурсников, будет нехорошо, так как в нашу выборку не попали (1) другие курсы психологического бакалавриата нашего вуза, (2) бакалавры-психологи других вузов Москвы и (3) бакалавры-психологи вузов других городов России.\nИ так работает всегда.\n\nНу, почти. Есть соблазн проводить исследования на студентах-психологах, потому что они достаточно близко и их можно загнать на эксперименты за баллы. Более-менее сносно это может работать на каких-то базовых когнитивных феноменах из восприятия и памяти. Обычно у нас нет оснований предполагать, что восприятие и память работают принципиально по-разному у людей разного возраста и разных социальных страт. Хотя, например, относительно памяти уже надо разбираться в том, что мы конкретно хотим про память изучать. Всё становится сложнее, если мы собираемся изучать что-то более высокоуровневое — например, мышление — или феномены личностной или социальной психологии.\n\nПочему выборка должна быть репрезентативной?\nПотому что если мы делаем нормально, то хотим обобщать результаты нашего исследования, полученные на выборке, на генеральную совокупность. Если выборка нерепрезентативна, то мы не можем этого сделать. Зачем в таком случае проводить исследование — решительно неясно.\nТогда возникает вопрос: как собрать репрезентативную выборку? Можно предложить следующий общий алгоритм.\n\nОсознать, кто наша генеральная совокупность.\n\nВ самом начале этой страницы приводились примеры разных генеральных совокупностей, и для каждой генеральной совокупности репрезентативная выборка будет своя.\n\nПонять, есть ли какая-то группировка, важная для нашего исследования, в нашей генеральной совокупности.\n\nСоциальная страта, специальность образования, сфера работы, пол или гендер, возрастные группы, регион проживания, семейное положение, что-либо ещё.\n\nРассчитать достаточный объём выборки\n\nэто не самая простая задача, и о ней мы будем говорить отдельно\nпока отметим в назывном порядке, что на объем выборки будут влиять дизайн исследования, изменчивость признака, уровень значимости и размер эффекта [что бы это ни значило]\n\nОбеспечить случайное попадание респондентов в выборку.\n\nНа последнем пункте стоит остановиться подробнее. Если у нас есть ресурсы набрать много людей в выборку — скажем, раза в 2–3 больше, чем достаточный объем выборки — то можно просто случайным образом откуда-то доставать людей, и всё будет хорошо. Некоторые статистические теоремы говорят, что такой вариант вполне пригоден для обеспечения репрезентативности выборки.\nЕсли мы всё же не можем набрать много людей, то надо набрать выборку достаточного объема и проверить репрезентативна ли она — отражает ли выборка те группировки изучаемых объектов, которые есть в генеральной совокупности.\nИдеальная выборка — это когда каждый человек имеет равную вероятность попасть в число респондентов (или испытуемых). Такая выборка называется вероятностной (probability sampling). Полностью случайный отбор трудно достижим — это очень дорого — но к нему нужно стремиться. Кроме того, сам метод сбора данных может деформировать выборку (например, онлайн-опросы отсекают пенсионеров), поэтому думать о сборе данных необходимо уже на этапе планирования исследования.",
    "crumbs": [
      "Введение в статистику",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Основания статистики</span>"
    ]
  },
  {
    "objectID": "intro-intro.html#intro-sampling",
    "href": "intro-intro.html#intro-sampling",
    "title": "1  Основания статистики",
    "section": "1.4 Способы формирования выборки",
    "text": "1.4 Способы формирования выборки\nСпособов формирования выборки существует много. Для каждого отдельного исследования существующие способы можно модифицировать, что даст нам ещё кучу новых способов. Однако в рамках курса мы рассмотрим три основные способа формирования вероятностной выборки.\n\n1.4.1 Простая случайная выборка\nВ случае простой случайной выборки (simple random sample) элементы генеральной совокупности случайным образом попадают в выборку. Представим, что на этой картинке изображена вся генеральная совокупность:\n\n\n\n\n\n\n\n\n\nЕсли мы наберем простую случайную выборку из этой генеральной совокупности, она будет выглядеть так:\n\n\n\n\n\n\n\n\n\nКак можно заметить, в выборку попали объекты из всех частей нашей генеральной совокупности — это говорит о том, что выборка репрезентативна.\nПростая случайная выборка, конечно, хороша своей простотой, однако у неё есть два существенных недостатка. Во-первых, действительно случайное попадание респондентов (или испытуемых) в выборку обеспечить практически невозможно — всегда будут ограничение на доступ к каким-либо частям генеральной совокупности. Во-вторых, простая случайная выборка будет репрезентативной только при большом объёме. Так, если мы посмотрим на простую случайную выборку малого объёма для той жё генеральной совокупности, что была выше, то получим следующее:\n\n\n\n\n\n\n\n\n\nНа рисунке видно, что многие части генеральной совокупности не представлены в выборке, что свидетельсвует о нерепрезентативности выборки.\n\n\n1.4.2 Стратифицированная выборка\nВ случае стратифицированной выборки (stratified sample) генеральная совокупность разбивается на несколько обособленных и различных по своей природе групп (страт). В каком смысле обособленных? В том, что каждый объект (респондент, испытуемый) может принадлежать только к одной страте. Например, возрастная группа (дети, подростки, молодежь, взрослые, пожилые), пол, среднемесячный доход семьи и др. Важно отметить, что страта — это характеристика изучаемых объектов, важная с точки зрения дизайна исследования. Ровно поэтому мы хотим учесть её при формировании выборки, обеспечив её репрезентативность по данной характеристике.\nПусть наша генеральная совокупность выглядит как-то так и состоит из четырёх страт:\n\n\n\n\n\n\n\n\n\nЕсли мы поделим это месиво точек по стратам, то получим следующее:\n\n\n\n\n\n\n\n\n\nТеперь из каждой страты случайным образом выберем несколько объектов, которые и попадут в выборку.\n\n\n\n\n\n\n\n\n\nОтносительно количества объектов, извлекаемых из каждой страты, существуют разные варианты. Дизайн исследования может предполагать, что количество респондентов из каждой страты должно быть одинаковым — тогда мы будем набирать равное количество респондентов из каждой страты. Или же нам может быть важно обеспечить в выборке такое же соотношение между стратами по количеству респондентов, какое существует в генеральной совокупности — тогда необходимо, зная общий объём выборки, рассчитать количества респондентов из каждой страты, зная пропорции в генеральной совокупности, например, из данных государственной статистики или других источников.\n\n\n1.4.3 Групповая выборка\nВ случае групповой выборки (cluster sample) мы разбиваем генеральную совокупность на несколько обособленных, но одинаковых групп (кластеров). Обособленный в том же смысле, что и в случае стратифицированной выборки — один респондент может принадлежать только к одной группе наблюдений. В каком смысле группы тогда должны быть одинаковыми? Они должны быть одинаковыми с точки зрения дизайна исследования. Пусть мы изучаем удовлетворенность городскими благами жителей некоторого города. Группой (cluster) в этом случае может выступить район города, в котором проживает респондент, если у нас нет оснований предполагать, что районы города различаются по характеристике «городские блага». Зачем нам такое разделение может пригодится? Возможно, у нас доступ к организациям городского района, которые могут помочь нам распространить опрос, что снизит затраты на проведение исследования.\nПусть мы разделили нашу генеральную совокупность на шесть кластеров:\n\n\n\n\n\n\n\n\n\nКластеры мы считаем примерно одинаковыми по характеристикам между собой — по крайне мере, мы так предполагаем с точки зрения дизайна исследования. Выберем случайно три кластера, которые примут участие в исследовании:\n\n\n\n\n\n\n\n\n\nТеперь из этих кластеров наберем выборку случайным образом:\n\n\n\n\n\n\n\n\n\nХотя такой подход к формированию выборки позволяет экономить драгоценные временные и денежные ресурсы, он имеет свои недостатки. В частности, мы должны быть уверенны, что выделенные нами группы действительно одинаковы с точки зрения исследования — это можно утверждать далеко не всегда.\n\nПока что остановимся на этом — для первого знакомства со статистикой будет достаточно. Мы еще не раз будем возвращаться к этим вопросам, и на других курсах вы тоже будете говорить о репрезентативности выборки.",
    "crumbs": [
      "Введение в статистику",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Основания статистики</span>"
    ]
  },
  {
    "objectID": "intro-randvals.html",
    "href": "intro-randvals.html",
    "title": "2  Шкалы и случайные величины",
    "section": "",
    "text": "2.1 Измерение в социальных науках\nВспомним, что\nТеперь бы понять, что такое измерение…\nИзмерение мы будем определять так:\nЕще раз:\nТакое определение нам позволяет измерить практически всё, что угодно:\nСейчас нас не интересует, как именно «внутри себя» происходит процесс измерения, какие предположения стоят за различными измерениями и как сделать измерение качественным. Об этом подробно рассказывается в курсах когнитивной и экспериментальной психологии, психодиагностики и психометрики и других. Отметим только, что, конечно же, нам как исследователям надо следить за тем, насколько адекватные измерения мы имеем, насколько приписанные значения отражают выраженность, например, психологических черт, или насколько измеряемые (зависимые) экспериментальные переменные адекватны исследовательским задачам.\nИтак, у нас есть интересующие нас признаки генеральной совокупности выборки, которые мы измерили, то есть приклеили на них некоторые значения из определенных шкал. Успех!\nНо тут, пожалуй, разумно задуматься про шкалы. Ведь очевидно, что возраст и пол будут измеряться по-разному, также как и нарциссизм и время реакции.",
    "crumbs": [
      "Введение в статистику",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Шкалы и случайные величины</span>"
    ]
  },
  {
    "objectID": "intro-randvals.html#randvals-measure",
    "href": "intro-randvals.html#randvals-measure",
    "title": "2  Шкалы и случайные величины",
    "section": "",
    "text": "Определение 2.1 Измерение (measurement) — это приписывание признакам объектов изучаемой совокупности определенных значений на определенной шкале.\n\n\n\nесть совокупность объектов, которые мы изучаем — выборка,\nв ней есть какие-то объекты,\nу объектов есть признаки,\nесли мы приписали признаку какое-то значение на некоторой шкале, значит мы измерили данный признак.\n\n\n\nрост\nвозраст\nпол (шкала из двух значений male и female)\nнациональность\nколичество детей в семье\nрейтинг студентов\nкурс обучения или уровень образования\nгеографические координаты (долгота и широта)\nтемпература\nдата\nIQ\nнарциссизм / макиавеллизм / психопатия\nвремя реакции\nточность ответов испытуемого в эксперименте\nи т. д.",
    "crumbs": [
      "Введение в статистику",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Шкалы и случайные величины</span>"
    ]
  },
  {
    "objectID": "intro-randvals.html#randvals-variables",
    "href": "intro-randvals.html#randvals-variables",
    "title": "2  Шкалы и случайные величины",
    "section": "2.2 Признаки и переменные",
    "text": "2.2 Признаки и переменные\nМы уже упомянули выше, что мы можем измерять различные признаки. Попытаемся как-то эту кучу систематизировать. В терминах данных признаки — это переменные, поэтому далее мы будем чаще употребляться именно этот термин — переменная — имея в виду то, что мы намерили, изучая признак. Во многом признак и переменная — это синонимы, только первый термин больше из теории измерений, а второй — из статистики и анализа данных. Измерение же от отдельного человека (объекта выборки) называется наблюдение.\n\n\n\n\n\n\nТипы переменных\n\n\n\n\nКоличественные переменные — те, которые принимают числовые значения\n\nнепрерывные — принимают любые значения (рост, возраст, время реакции и др.)\nдискретные — могут принимать только определенные значения (количество детей в семье, число отчисленных студентов, количество стаканов кофе, выпитых в ночь перед экзаменом и др.)\n\n\nЧисло, приписываемое количественному признаку (переменной) ведёт себя как привычное нам математическое число в том смысле, что выражает некоторое количество — сантиметров, лет, секунд, детей, студентов, стаканов кофе…\n\nНоминальные (категориальные) переменные — используются для разделения наших наблюдений на группы (пол, национальность, курс обучения, используемая операционная система компьютера и др.).\n\nЗаписаны эти переменные обычно текстом (скажем, как в примерах выше, пол — male и female — или операционная система — Win, macOS, Linux).\nОднако, например, курс обучения можно записать по-разному: текстом — freshman, sophomore, junior, senior — или числом — 1, 2, 3, 4. Однако в данном случае числа не несут никакого математического смысла — это просто лейблы, с помощью которых мы различаем группы наблюдений. Ведь и пол мы можем записать с помощью чисел — пусть male = 0, female = 1. Ведь не будем же мы складывать-вычитать девушек и парней?\n\n\n\n\nВнимательный читатель мог заметить, что курс обучения — это не совсем категориальная переменная, ведь «второкурсник» в каком-то смысле «больше», чем «первокурсник». Но мы не можем сказать «на сколько» или «во сколько» больше! Что же делать?\n\n\n\n\n\n\nРанговые переменные\n\n\n\n\nНельзя сказать, что «второкурсник» выражает бо́льшую выраженность признака «год обучения», чем «первокурсник».\nВместе с тем «второкурсник» дольше учился и освоил больше дисциплин, чем «первокурсник». При этом «третьекурсник» учился дольше «второкурсника» — то есть существует порядок категорий.\nТакая переменная называется ранговой.\n\n\n\nДругой пример ранговой переменной — это студенческий рейтинг. Что делает рейтинг? Упорядочивает студентов. Можно ли сказать, что четвертый в рейтинге студент в два раза менее успешен, чем второй? Нет — тот же GPA может отличаться на десятые или сотые доли.\nИтого, классификацию переменных можно представить так (Рисунок 2.1):\n\n\n\n\n\n\nflowchart TD\n  vars(\"Переменные\")\n  quantitative(\"Количественные\")\n  discrete(\"Дискретные\")\n  continuous(\"Непрерывные\")\n  rank(\"Ранговые\")\n  nominal(\"Номинальные\")\n  \n  vars --&gt; quantitative\n  vars --&gt; rank\n  vars --&gt; nominal\n  quantitative --&gt; discrete\n  quantitative --&gt; continuous\n\n\n\n\nРисунок 2.1: Классификация переменных",
    "crumbs": [
      "Введение в статистику",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Шкалы и случайные величины</span>"
    ]
  },
  {
    "objectID": "intro-randvals.html#randvals-scales",
    "href": "intro-randvals.html#randvals-scales",
    "title": "2  Шкалы и случайные величины",
    "section": "2.3 Шкалы",
    "text": "2.3 Шкалы\n\n2.3.1 Зачем нам знать виды шкал?\nОт того, в какой шкале измерена переменная, которую мы исследуем, будет зависеть:\n\nкакие графики мы сможем нарисовать\nкакие статистики на ней имеют смысл\nкакие статистические модели дадут адекватный результат\n\nВ общем, почти весь анализ определяется1 тем, с какой шкалой мы работаем.\nЧто же такое шкала?\n\nОпределение 2.2 Шкала (scale) — это набор допустимых значений переменной с ограничениями на допустимые операции над этими значениями.\n\nВновь посмотрим на признаки, которые мы можем измерять. Пол имеет два допустимых значения — male и female — и мы можем лишь сравнить значения, проверив, совпадают они или нет. В то же время, рассматривая переменную «время», которая может принимать значения от \\(0\\) до \\(+\\infty\\), мы уверенно можем утверждать, что если одна пара длится 120 минут, то две будут длиться 240 минут — мы можем считать сумму значений по этой переменной.\nМожно ли как-то систематизировать все возможные варианты допустимых значений и операций?\n\n\n2.3.2 Типы и виды шкал\nВсего выделяют четыре вида шкал (Таблица 2.1).\n\n\n\nТаблица 2.1: Виды шкал изменения\n\n\n\n\n\n\n\n\n\n\n\n\n\nШкала\nТип шкалы\nТип данных\nДопустимые операции\nНоль\nДопустимые преобразования\n\n\n\n\nНоминальная (номинативная, nominal scale)\nНеметрическая\nКачественные Категориальные\n\\(=\\), \\(\\neq\\)\nОтсутствует\n—\n\n\nПорядковая (ранговая, ordinal scale)\nНеметрическая\nКачественные Категориальные (?) Ранговые\n\\(=\\), \\(\\neq\\), \\(&gt;\\), \\(&lt;\\)\nОтсутствует\nМонотонное преобразование\n\n\nИнтервальная (шкала разностей, interval scale)\nМетрическая\nКоличественные\n\\(=\\), \\(\\neq\\), \\(&gt;\\), \\(&lt;\\), \\(+\\), \\(-\\)\nОтносительный\nЛинейное преобразование\n\n\nАбсолютная (шкала отношений, ratio scale)\nМетрическая\nКоличественные\n\\(=\\), \\(\\neq\\), \\(&gt;\\), \\(&lt;\\), \\(+\\), \\(-\\), \\(\\times\\), \\(\\div\\)\nАбсолютный\nПреобразование подобия\n\n\n\n\n\n\nПройдёмся по колонкам этой таблицы.\n\nТип шкалы — метрическая или неметрическая — определяется тем, одинаково расстояние между делениями шкалы или же нет. Иначе, есть ли на шкале цена деления.\n\nТак, понятно, что на шкале времени реакции все секунды одинакового размера — метрическая шкала.\nА на шкале «используемая операционная система» вообще нет делений, не то что расстояний.\nОбратите внимание, что на ранговой шкале хотя и есть деления (например, шкала Ликерта), их размер неодинаковый: нельзя сказать2, что \\(6\\) на шкале Ликерта в два раза или на три больше, чем \\(3\\). Поэтому ранговая шкала — неметрическая.\n\nТип данных — количественные или категориальные — определяется тем, какие свойства чисел работают на этой шкале.\n\nЧтобы не утонуть в математической части этого всего, соотнесём это с колонкой допустимые операции.\n\nНа количественных шкалах допустимы операции сложения, вычитания, умножения и деления.\nНа категориальных шкалах шкалах допустимы только операции сравнения.\n\n\nНоль\n\nНа номинальной и порядковой шкалах нуля в математическом смысле нет вовсе.\n\nДля номинальной шкалы это очевидно, потому что там вообще нет «чисел» — там только лейблы.\nДля порядковой шкалы, в определенной мере, тоже, потому что \\(0\\) на ней будет обозначать только то, что ранг у этого наблюдения ниже, чем ранг у наблюдения с \\(1\\). Ничего другого этот ноль не обозначает.\n\nНа интервальной и абсолютной шкалах ноль есть.\n\nКлассический пример интервальной шкалы — это температура в градусах Цельсия. Ноль на этой шкале — температуре замерзания воды — выбран произвольно. Ну, потому что это было достаточно удобно. Больше этот ноль ничем не обоснован.\n\nПоскольку ноль относительный, на такой шкале могут быть отрицательные значения — с температурой по Цельсию нас это совершенно не удивляет.\n\nКлассический пример абсолютной шкалы — это температура по Кельвину. Известно, что на этой шкале не бывает отрицательных значений, так как минимум этой шкалы — это минимально возможная температура во Вселенной. Ниже не бывает. Поэтому это абсолютный ноль.\n\n\nДопустимые операции\n\nНаличие относительного нуля даёт возможность складывать и вычитать.\nНаличие абсолютного нуля даёт возможность складывать, вычитать, делить и умножать.\nНа номинальной и порядковой шкалах нуля нет, поэтому арифметические действия на них невозможны.\nНа номинальной шкале допустимо только сравнение на [не]равенство — мы можем только проверить, одинаковы ли наблюдения [по этой переменной] или не одинаковые.\nНа порядковой шкале, помимо сравнения на [не]равенство, допустимо также сравнение на больше-меньше, так как задан порядок.\n\nДопустимые преобразования\n\nОтсюда нам нужно попытаться понять, что такое монотонное преобразование. Это любое преобразование, сохраняющее порядок элементов.\n\nНапример, у нас есть шкала Ликерта от 1 до 5 — [1, 2, 3, 4, 5]. Шкала Ликерта — порядковая, поэтому мы можем утверждать, что 1 &lt; 2 &lt; 3 &lt; 4 &lt; 5.\nПусть мы психометрик и собираемся вычислять психометрические штуки на таких данных. Для удобства нам надо сделать так, чтобы шкала начиналась с нуля.\n\nКажется, надо просто вычесть единицу из всех наблюдений — но законно ли это? Не сломаются ли закономерности наших данных?\n\nДа, законно, потому что вычитание единицы — это монотонное преобразование. И хотя значения переменной изменятся — [0, 1, 2, 3, 4] — порядок значений сохранится — 0 &lt; 1 &lt; 2 &lt; 3 &lt; 4.\n\n\n\n\n\n\n\n\n\nО термине «качественные данные»\n\n\n\nПочему-то номинальную и ранговую шкалы в литературе часто называют «качественными». Видимо, потому что качественные данные обычно рассматриваются как оппозиция количественным.\nЭто в некоторой мере справедливо, поскольку есть два типа исследований — качественные и количественные. Они различаются методологией и используемыми методиками и, как следствие, собираемыми данными.\nВ рамках качественных исследований чаще всего собираются тексты, поэтому во многом качественные данные обычно текстовые. Количественные данные — это, как правило, таблицы с цифрами из любой из четырёх шкал. Безусловно, анализ качественных и количественных данных также существенно различается.\nИтого, кажется, что называть «качественными» номинальную и ранговые шкалы — странно, потому что качественные данные — это неструктурированный текст. Лучше их именовать категориальными. Правда, например, рейтинг студентов (ранговая шкала) тоже не совсем категориальные данные. Такая переменная, конечно, делит наших респондентов на категории (группы), однако между этими группами определён порядок — больше-меньше — поэтому такие переменные называются ранговыми.\n\n\n\n\n2.3.3 Порядок шкал по мощности\nЕсли взять за основу допустимые операции, можно упорядочить шкалы по мощности — более мощной является та шкала, на которой допустимо больше операций. Тогда шкалы можно упорядочить так:\n\\[\n\\text{номинальная} &lt; \\text{порядковая} &lt; \\text{интервальная} &lt; \\text{абсолютная}\n\\]\nНаименее мощная — номинальная, наиболее мощная — абсолютная. Что нам надо вынести из этой иерархии? То, что мы можем по ней двигаться только влево. Если переменная измерена в абсолютной шкале, то мы можем сделать её порядковой или номинальной. Если же переменная изначально номинальная, то перейти в порядковую или интервальную шкалу невозможно.\nНапример, вот такой нехитрый пример (Таблица 2.2):\n\n\n\nТаблица 2.2: Одна и та же переменная, измеренная в разных шкалах\n\n\n\n\n\nВозраст [абсолютная]\nВозраст [ранговая]\nВозраст [номинальная]\n\n\n\n\n86\nпенсионер\nсовершеннолетний\n\n\n43\nвзрослый\nсовершеннолетний\n\n\n38\nвзрослый\nсовершеннолетний\n\n\n22\nмолодой\nсовершеннолетний\n\n\n16\nподросток\nнесовершеннолетний\n\n\n10\nребёнок\nнесовершеннолетний\n\n\n8\nребёнок\nнесовершеннолетний\n\n\n\n\n\n\nВ психологии чаще всего мы сталкиваемся с порядковыми шкалами. Это просто факт. Надо его принять.",
    "crumbs": [
      "Введение в статистику",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Шкалы и случайные величины</span>"
    ]
  },
  {
    "objectID": "intro-randvals.html#randvals-randvals",
    "href": "intro-randvals.html#randvals-randvals",
    "title": "2  Шкалы и случайные величины",
    "section": "2.4 Случайные величины",
    "text": "2.4 Случайные величины\nЕщё раз:\n\nИзмерение — это приписывание признакам объектов изучаемой совокупности определенных значений на определенной шкале.\n\nСо шкалой разобрались. Теперь надо разобраться с приписыванием. Мы будем рассматривать этот вопрос только с точки зрения статистики — теорию измерений не трогаем.\n\n2.4.1 Случайный эксперимент\nОтвлечемся на любимый объект статистиков — игральный кубик.\n\n\n\n\n\nСкажем просто:\n\nБросание игрального кубика — это случайный эксперимент,\nВыпавшее число — это случайная величина.\n\nТеперь более строго.\n\nОпределение 2.3 Случайный эксперимент (random experiment) — это математическая модель некоторого реального эксперимента, результат которого невозможно точно предсказать.\n\nВ каком смысле то, что мы называем сейчас экспериментом, случайно? В том, что результат такого эксперимента точно неизвестен. В частности, заранее неизвестно, какой стороной упадёт кубик при отдельном броске.\n\nОпределение 2.4 Случайная величина (random variable) — это некоторая переменная, значения которой представляют собой численные исходы некоторого случайного эксперимента.\n\nИсход бросания кубика — выпавшее число.\nИз психологического поля можно привести следующие примеры:\n\nв опросных (психометрических) исследованиях:\n\nответ респондента на пункт опросника — это случайный эксперимент\nвыбранный им балл на шкале Ликерта — это случайная величина\nв чём случайность? — неизвестно, какой балл выберет респондент\n\nв поведенческих экспериментах:\n\nклик на стимул на экране в эксперименте зрительного поиска — это случайный эксперимент\nвремя реакции, которое фиксирует PsychoPy — случайная величина\nв чём случайность? — неизвестно, когда точно испытуемый кликнет по стимулу\n\nв нейроисследованиях:\n\nзапись ЭЭГ-активности в конкретный момент времени — случайный эксперимент\nамплитуда колебаний ЭЭГ — случайная величина\nв чём случайность? — неизвестно, что мы зафиксируем в конкретный момент (в частности, потому что существуют технические шумы)\n\nи т. д.\n\n\n\n\n\n\n\nСлучайный эксперимент vs эксперимент как метод исследования\n\n\n\nОбратим внимание на то, что случайный эксперимент — это не то же самое, что эксперимент как метод исследования, изучаемый в рамках курса экспериментальной психологии. Случайный эксперимент происходит в момент измерения какой-либо переменной в рамках эксперимента.\nПосмотрим на примеры, приведённые выше. У нас есть поведенческий эксперимент, в котором существуют независимы и зависимые переменные, определённое количество проб на конкретное сочетание экспериментальных условий и другие аспекты дизайна эксперимента. Однако в процессе сбора данных в рамках этого исследования происходит множество случайный экспериментов, когда испытуемые проходят эксперимент. В каждой пробе осуществляется измерение зависимых переменных, и каждое такое измерение является случайным экспериментом, так как ответ испытуемого (координаты клика или время нажатия на клавишу) нельзя однозначно предсказать.\n\n\nИтого, мы постоянно имеем дело со случайными экспериментами в рамках любых исследований, но также, что более важно, по результатам этих случайных экспериментов [в рамках нашего эксперимента или заполнения опросника] мы собираем значения случайных величин. Вся статистика работает со случайными величинами.\n\n\n2.4.2 Случайная величина\nПопробуем ещё такой заход. Вот мы тут говорим об измерениях признаков/переменных. Эти переменные и есть случайные величины, которые мы измеряем. Случайные — потому что мы никогда не знаем, что же мы получим в конкретном измерении.\nПочему не знаем?\nЕсли у нас «хардовое» измерение (типа ЭЭГ или PsychoPy) — всегда есть погрешность измерения и «шум» в данных. Мы не можем предусмотреть всё и сделать так, чтобы нашего испытуемого ничего не отвлекало, он занимался только экспериментальной задачей, не думал о коте, который остался дома, или испытывал блаженство от ЭЭГ-шной шапочки на себе.\nЕсли это опросник — всё, вроде бы, ещё понятнее. Что нам именно сейчас отметит именно этот респондент — известно только одному никому. В каком состоянии он пришёл, какие у него личностные черты и свойства, насколько он нам доверяет, насколько он готов отвечать честно и т. д.\nК вопросу, зачем нам статистика и анализ данных — чтобы отделить случайности от закономерностей, которые нас интересуют как исследователей, и получить ответы на исследовательские вопросы.\nСлучайные величины бывают дискретные и непрерывные:\n\nнепрерывные — принимают любые значения (рост, возраст, время реакции и др.)\nдискретные — могут принимать только определенные значения (пол, город проживания, балл по шкале Ликерта и др.)\n\n\n\n\n\n\n\nПеременные vs Шкалы vs Случайные величины\n\n\n\nМы обозначили три понятия — переменные, шкалы и случайные величины — которые выглядят очень похоже друг на друга. Тем не менее, они не являются синонимами. Давайте разберемся в различиях между ними. Для этого рассмотрим следующие примеры.\n\n\n\n\n\n\n\n\n\nПеременная\nТип переменной\nШкала\nСлучайная величина\n\n\n\n\nПол\nНоминальная\nНоминальная\nДискретная\n\n\nУровень образования\nНоминальная / Ранговая\nНоминальная / Порядковая\nДискретная\n\n\nБалл по шкале Ликерта\nРанговая\nПорядковая\nДискретная\n\n\nКоличество детей в семье\nКоличественная дискретная\nАбсолютная\nДискретная\n\n\nТемпература по Цельсию\nКоличественная непрерывная\nИнтервальная\nНепрерывная\n\n\nТемпература по Кельвину\nКоличественная непрерывная\nАбсолютная\nНепрерывная\n\n\nВремя реакции\nКоличественная непрерывная\nАбсолютная\nНепрерывная\n\n\n\nТаким образом, можно наблюдать, что хотя эти понятия в некоторой мере пересекаются, всё же существуют различия между этими тремя терминами.\n\n\nЗачем нам различать дискретные и непрерывные случайные величины? Это различение оказывается критически важно, когда мы пытаемся математически описать случайные величины. Оказывается, что они по-разному ведут себя в отношении вероятности.\n\n\n2.4.3 Вероятность\nМатематически строгое введение понятия вероятности требует отдельного курса теории вероятности, которого у нас нет. Мы ограничимся во многом интуитивным пониманием вероятности, которого, в целом, для наших задач будет достаточно.\nПод вероятностью (probability, \\(\\mathbb{P}\\)) мы будем понимать меру возможности наступления некоторого события. Событием будем считать наблюдение (измерение) определённого значения случайной величины. Рассмотрим всю эту ситуацию на примерах дискретных и случайных величин.\n\n\n2.4.4 Дискретные случайные величины\nС дискретными случайными величинами все достаточно просто:\n\nесть ограниченный набор значений, которые случайная величина может принимать,\nесть вероятности, с которыми случайная величина принимает эти значения.\n\nДавайте на игральном кубике. Есть кубик — у него шесть граней. Возможные значения случайной величины \\(X\\) — \\(\\{1,2,3,4,5,6\\}\\). Вероятность того, что кубик упадет хотя бы какой-то из шести сторон — \\(1\\). Если кубик «честный», то каждая из граней выпадает равновероятно, то есть вероятность, с которой наша случайная величина принимает каждое из своих значений будет равна\n\\[\n\\mathbb{P}(X=1) = \\mathbb{P}(X=2) = \\mathbb{P}(X=3) = \\mathbb{P}(X=4) = \\mathbb{P}(X=5) = \\mathbb{P}(X=6 ) = \\frac{1}{6} \\approx 0.167\n\\]\nНо это мы рассчитали теоретически. Давайте проверим, будет ли это работать эмпирически. Подбросим кубик (на симуляции) 100 раз и посмотрим, сколько раз выпало та или иная грань (Таблица 2.3).\n\n\n\nТаблица 2.3: Результаты симуляции 100 бросков игрального кубика\n\n\n\n\n\n\n\nЗначение\n1\n2\n3\n4\n5\n6\n\n\n\n\nЧастота\n19\n15\n18\n11\n16\n21\n\n\nВероятность\n0.19\n0.15\n0.18\n0.11\n0.16\n0.21\n\n\n\n\n\n\n\n\nВнимание, мы построили таблицу частот, она же частотная таблица. Это способ описания поведения дискретной случайной величины в эксперименте.\nМожем ли мы это каким-то образом визуализировать? Да.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 2.2: Визуализация частоты выпадения значений при 100 бросках игрального кубика\n\n\n\nВниманием — столбчатая диаграмма (barplot). Как видите, по оси \\(x\\) идут значения нашей случайной величины, по оси \\(y\\) — частота, с которой случайная величина принимает данной значение. Изи.\nНо погодите, кубик должен падать одинаково часто на каждую из граней, а на графике частоты разные. Да, это правда. Как мы уже не раз упоминали, в данных всегда есть шум и ни один эксперимент не может пройти идеально. В том числе и симуляция. Поэтому те отклонения, которые мы видим на графике, это всего лишь шум — то, что нам нерелевантно.\nЧтобы убедиться, что кубик все-таки честный, давайте подкинем его 1000 раз.\n\n\n\nТаблица 2.4: Результаты симуляции 1000 бросков игрального кубика\n\n\n\n\n\n\n\nЗначение\n1\n2\n3\n4\n5\n6\n\n\n\n\nЧастота\n170\n176\n171\n157\n162\n164\n\n\nВероятность\n0.17\n0.176\n0.171\n0.157\n0.162\n0.164\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 2.3: Визуализация частоты выпадения значений при 1000 бросках игрального кубика\n\n\n\nХм… Больше бросков!\n\n\n\nТаблица 2.5: Результаты симуляции 100 000 бросков игрального кубика\n\n\n\n\n\n\n\nЗначение\n1\n2\n3\n4\n5\n6\n\n\n\n\nЧастота\n16685\n16818\n16656\n16536\n16774\n16531\n\n\nВероятность\n0.167\n0.168\n0.167\n0.165\n0.168\n0.165\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 2.4: Визуализация частоты выпадения значений при 100 000 бросках игрального кубика\n\n\n\nНу, почти. Нивелировать шум полностью нам не удастся никогда, поэтому будем считать, что мы достаточно убеждены, что кубик честен.\nТо, что мы сейчас с вами строили — в таблице или на графике — называется распределением случайной величины (distribution of a random variable, probability distribution). Распределение — это некоторый закон, который полностью описывает поведение случайной величины.\nИтак, мы сейчас обсудили как строить эмпирическое распределение нашей дискретной переменной. А как нам построить теоретическое распределение нашей случайной величины? Для этого нам нужно взять две оси — \\(x\\) и \\(y\\). По оси абсцисс расположить значения нашей случайной величины, по оси ординат — вероятности, с которыми наша случайная величина принимает данные значения.\nВыглядит это так:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 2.5: Функция вероятности дискретного равномерного распределения\n\n\n\nТо, что изображено на рисунке, называется функцией вероятности (probability mass function, PMF) дискретного равномерного распределения.\nДля порядка также скажем, что дискретные случайные величины вовсе не обязательно распределены равномерно. Например, есть такое распределение:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 2.6: Функция вероятности биномиального распределения\n\n\n\nВообще распределений существует довольно много. Мы в рамках этого курса познакомимся далеко не со всеми — только с теми, которые нам пригодятся для решения наших задач.\n\n\n2.4.5 Непрерывные случайные величины\nОкей, с дискретными разобрались. С непрерывными же всё то же самое?\nНе совсем. Есть один ключевой момент, который всё портит.\nМы говорили, что дискретные случайные величины могут принимать только некоторые значения, например, целочисленные — \\(1, 2, 3, -5, 0\\)… Их можно посчитать и сопоставить им вероятности, с которыми случайная величина принимает эти значения.\nЧуть выше мы разобрались с дискретным равномерным распределением. Давайте попробуем применить аналогичные размышления для непрерывного равномерного распределения.\nПусть мы случайным образом выбираем 1000 чисел из отрезка \\([0,1]\\), считая что все числа могут попасться равновероятно. Займемся симуляцией и попробуем отобразить частоты, с которыми выпадают числа:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 2.7: Визуализация частоты случайного выбора 100 чисел из отрезка \\([0, 1]\\)\n\n\n\nХм… Обратим внимание на некоторую интересность: частота каждого значения — единица, то есть каждое значение выпало только один раз. Но может это артефакт малого количества случайных экспериментов по выбору чисел? Давайте извлечём 1000.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 2.8: Визуализация частоты случайного выбора 1000 чисел из отрезка \\([0, 1]\\)\n\n\n\nХм… Ну, может 10 000 исправят ситуацию?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 2.9: Визуализация частоты случайного выбора 10 000 чисел из отрезка \\([0, 1]\\)\n\n\n\nОкак… Всё ещё наблюдаем, что каждое число встретилось в выборке всего один раз. Тогда таблица частот оказывается бессмысленной. Как же нам тогда описать распределение непрерывной случайной величины?\nТак, попробуем другой заход. Когда мы считали вероятность того, что на кубике выпадет определенное число, мы взяли все возможные исходы и поделили единицу на их количество — получили вероятность. Раз мы и сейчас предполагаем равную вероятность выпадения каждого из чисел, то попробуем сделаль тут так же.\n\n— Сколько всего чисел на отрезке \\([0, 1]\\)? — Бесконечность.\n\nЭто что же, получается,\n\\[\n\\mathbb{P}(X = a) \\overset{?}{=} \\frac{1}{\\infty}\n\\]\nтак что ли? Но это же какой-то сюр! Не совсем.\nНе вдаваясь в математические детали, перепишем выражение выше в более математически приличном виде:\n\\[\n\\mathbb{P}(X = a) = \\lim_{n \\to \\infty} \\frac{1}{n} = 0\n\\]\nЭта запись означает следующее:\n\n\n\n\n\n\nКлючевое свойство непрерывных случайных величин\n\n\n\nВероятность того, что непрерывная случайная величина принимает конкретное значение, равна нулю.\n\n\nНо как это? Ведь числа-то выпадают! Вероятность не может быть равна нулю!\nЭто справедливо, но чтобы ответить на все вопросы предельно точно, нам придется умереть в математических океанах. Воспользуемся эвристикой. Будем понимать под «вероятность того, что непрерывная случайная величина принимает конкретное значение, равна нулю» следующее:\n\nМы не можем ожидать, что беря числа из отрезка \\([0, 1]\\) мы попадём в какое-то конкретное число, например, \\(0.5\\).\nДаже если попадём во что-то очень похожее, это будет \\(0.50003\\) или \\(0.4999999999\\).\nРовно \\(0.5\\) никогда не выпадет. В этом смысле вероятность, действительно равна нулю.\n\nВот такое странное поведение у этих непрерывных величин. И тем не менее, хочется все-таки как-то с ними работать, описывать их поведение.\n\n— Зачем? Если они такие странные, а самая используемая в психологии шкала — порядковая, то мож не будет возиться с этой ерундой?  — Весь замес в том, что тестирование статистических гипотез, которое есть сердце анализа данных, полностью основано на работе с непрерывными случайными величинами. Всё-таки придётся разбираться.\n\nДа, мы не можем работать с конкретными значениями непрерывных случайных величин — но мы можем работать с интервалами на множестве значений. Так, если нам надо визуализировать распределение непрерывной случайной величины, мы уже не можем использовать barplot — будет результат подобный рисунку 2.9. Вместо этого будем использовать гистограмму (histogram):\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 2.10: Визуализации распределения чисел, сгенерированных из непрерывного равномерного распределения на отрезке \\([0,1]\\).\n\n\n\nХм… В общем, мы получили нечто похожее на Рисунок 2.4. Похоже мы движемся в правильном направлении.\n\n\n\n\n\n\nВ чем отличие гистограммы от столбиковой диаграммы?\n\n\n\n\nНа столбиковой диаграмме по оси \\(x\\) располагается дискретная переменная — каждый столбик соотносится с конкретным значением изучаемой переменной.\nНа гистограмме же ось \\(x\\) поделена на определенное количество отрезков (на рисунке их 30).\n\nВ границы каждого отрезка попадает сколько-то сгенерированных нами чисел — высота столбика отражает количество чисел, попавших в этот отрезок.\nПри этом, в отличие от барплота, количество столбиков не является строго фиксированным (см. 2.11).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 2.11: Визуализации распределения чисел, сгенерированных из непрерывного равномерного распределения на отрезке \\([0,1]\\) (разбиение на 20 столцов).\n\n\n\n\n\nГистограмма обычно используется для отображения эмпирического распределения непрерывной случайной величины. А как же быть с теоретическим?\nВновь мы не можем взять то, что было у дискретных величин — изобразить график функции вероятности невозможно, поскольку это будет прямая, совпадающая с осью \\(x\\). Возникает необходимость ввести какую-то иную характеристику, связанную с вероятностью, которую можно будет использоваться для описания поведения непрерывных случайных величин.\nВспомним, как выглядел график для дискретного равномерного распределения — вот так 2.5. Наверное, по аналогии нам бы хотелось, чтобы для рассматриваемого нами непрерывного равномерного распределения график выглядел как-то так (Рисунок 2.12):\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 2.12: Схема графика непрерывного равномерного распределения на \\([0, 1]\\)\n\n\n\nВизуально действительно выглядит так, что все числа из отрезка \\([0, 1]\\) выпадают равновероятно. Однако нечто, отображённое на оси \\(y\\) не может быть вероятностью, так как для все значений непрерывной случайной величины вероятность равна нулю.\nЕсли же мы сравним рисунки 2.12 и 2.10, то мы можем заметить, что 2.12 — это некий идеал для 2.10. Действительно, если увеличить количество сгенерированных чисел, то гистограмма будет практически идеально ровной.\nГистограмма нам показывает, сколько сгенерированных чисел лежит в определенном диапазоне отрезка, а поскольку мы сказали, что все числа выпадают равновероятно, то и в каждом выделенном диапазоне (столбике гистограммы) должно лежать одинаковое количество чисел. Иначе говоря, числе одинаково плотно распределены на всём отрезке.\n\n\n2.4.6 Плотность вероятности\nИдея плотности была взята на вооружение математиками, и они, сильно не заморачиваясь относительно названия, ввели понятие плотности вероятности. Мы не будем давать ей строгого математического определения, ибо оно довольно зубодробительно. Мы порисуем картинки.\nСобственно, для непрерывного равномерного распределния график плотности вероятности будет выглядеть именно так, как мы нарисовали — разве что надо ось \\(y\\) подписать и значение поставить.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 2.13: График функции плотности вероятности непрерывного равномерного распределения на \\([0, 1]\\)\n\n\n\nПолученный график называется графиком плотности вероятности (probability density function, PDF). Нам надо уметь его читать.\nПо оси \\(x\\) здесь значения нашей случайной величины (как и в случае PMF), а вот по оси \\(y\\) — эта самая загадочная плотность вероятности. А где же сама вероятность? Раз мы решили работать с интервалами значений, то нас будет интересовать вероятность попадания значений случайной величины в определенный интервал.\n\n\n\n\n\n\nВероятность для непрерывных случайных величин\n\n\n\nВероятность того, что значение непрерывной случайной величины попадёт в заданный интервал определяется как площадь под графиком функции плотности вероятности на этом интервале.\n\n\nПосмотрим на примере равномерного распределения. Какова вероятность, что случайно выбранное из отрезка \\([0,1]\\) число попадёт в интервал \\((0.25, 0.75)\\)? Интуитивно кажется, что должно быть \\(0.5\\), так как длина этого интервала — полочина длины отрезка. Нарисуем.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 2.14: Вероятность попадания случайного числа из непрерывного равномерного распределения на \\([0,1]\\) в интервал \\((0.25, 0.75)\\)\n\n\n\nВоистину площадь полученного прямоугольника равна \\(0.5\\). Значит, схема работает.\nРаботать с равномерным распределением довольно скучно. Посмотрим на другой пример, с которым позднее мы будем знакомиться гораздо подробнее. Пусть у нас есть такое распределения, что его функция плотности выглядит так:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 2.15: Функция плотности вероятности стандартного нормального распределения\n\n\n\nЧисто визуально кажется, что значения из «середины» распределения — скажем, от \\(-2\\) до \\(2\\) — будут встречаться с большей вероятностью, чем значения из крайних частей распределения. И действительно, если мы выберем интервал некоторой ширины, то сможем убедиться в этом.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 2.16: Функция плотности вероятности стандартного нормального распределения\n\n\n\nВ данном случае был взят интервал шириной \\(1\\). Вероятность попадания значений случайной величины в диапазон \\((-0.5, 0.5)\\) относительно велика — \\(0.38\\), а для диапазона \\((2, 3)\\) — всего \\(0.02\\). Ровно это и отображает график плотности вероятности — значения в «середине» лежат плотнее, чем по краям.\nТак работают плотность вероятности, случайные величины и шкалы. К случайным величинам мы будем возвращаться далее постоянно — пока же знакомства достаточно.",
    "crumbs": [
      "Введение в статистику",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Шкалы и случайные величины</span>"
    ]
  },
  {
    "objectID": "intro-randvals.html#footnotes",
    "href": "intro-randvals.html#footnotes",
    "title": "2  Шкалы и случайные величины",
    "section": "",
    "text": "Разумеется, с учетом поставленного исследовательского вопроса и выдвинутых гипотез.↩︎\nОтносительно шкалы Ликерта, активнейшим образом используемой в психометрике, делаются некоторые допущения о её квазинепрерывности и псевдоинтервальности. Однако это вопросы курса психометрики, и пока что мы в них погружаться не будем.↩︎",
    "crumbs": [
      "Введение в статистику",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Шкалы и случайные величины</span>"
    ]
  },
  {
    "objectID": "desc-centraltend.html",
    "href": "desc-centraltend.html",
    "title": "3  Меры центральной тенденции",
    "section": "",
    "text": "3.1 Виды статистики\nМы знаем, что наши переменные-признаки могут быть некоторым образом распределены — как в генеральной совокупности, так и в выборке. Как именно они распределены, описывается распределением случайной величины.\nВот мы собрали некоторые данные и получили какое-то эмпирическое распределение наших переменных. Нам бы, конечно, хотелось понять, что там такое за распределение. И первым шагом к пониманию этого будет описание распределения.\nВообще статистика [как набор методов и инструментов] делится на два вида:\nМы начнем знакомиться со статистикой с описательной статистики, а именно с мер центральной тенденции.",
    "crumbs": [
      "Описательная статистика",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Меры центральной тенденции</span>"
    ]
  },
  {
    "objectID": "desc-centraltend.html#centraltend-stats",
    "href": "desc-centraltend.html#centraltend-stats",
    "title": "3  Меры центральной тенденции",
    "section": "",
    "text": "Описательная статистика (descriptive statistics1) занимается обработкой статистических данных, их наглядным представлением, и собственно описанием через некоторые характеристики.\n\nЭти характеристики, количественно описывающие особенности имеющихся данных, называются описательными статистиками (descriptive statistics2).\nЗадача описательной статистики — ёмко описать имеющиеся данные и составить на основе этих описаний общее представление о них, а также обнаружить особенности, которые могут повлиять на дальнейший анализ.\n\nСтатистика вывода (inferential statistics) занимается поиском ответов на содержательные вопросы, которые мы задаем данным в ходе их анализа в рамках научных и практических исследований.\n\nСостоит из двух компонентов — тестирования статистических гипотез и статистических методов.\n\n\n\n\n\n\n\n\nЗамечание о машинном обучении\n\n\n\nВы наверняка не раз слышали словосочетание «машинное обучение». Это что-то, что время от времени становится то менее, то более хайпово. На самом деле, статистические методы лежат где-то между статистикой вывода и машинным обучением.\nПочему?\nДело в том, что на статистические методы можно смотреть по-разному.\n\nЕсли нашей задачей является поиск ответов на исследовательские вопросы о закономерностях, о связи каких-либо факторов или влиянии переменных друг на друга, то мы будем смотреть на статистические модели с точки зрения статистики вывода. Это позволит нам находить ответы на интересующие нас вопросы — причем не важно, говорим мы о научных исследованиях или об исследованиях в индустрии.\nЕсли перед нами стоит задача хорошо предсказывать одни переменные на основании значений других — например, выдавать рекомендации на Яндекс Музыке или в Яндекс Лавке — то мы будем смотреть на те же статистические модели с точки зрения машинного обучения.\n\nТо есть, модели абсолютно одни и те же, но то, какую модель мы назовем хорошей и как мы эту «хорошесть» определим, будет различаться в зависимости от задачи — исследовательская или предиктивная — которая перед нами стоит.",
    "crumbs": [
      "Описательная статистика",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Меры центральной тенденции</span>"
    ]
  },
  {
    "objectID": "desc-centraltend.html#centraltend-centraltend",
    "href": "desc-centraltend.html#centraltend-centraltend",
    "title": "3  Меры центральной тенденции",
    "section": "3.2 Меры центральной тенденции",
    "text": "3.2 Меры центральной тенденции\nИтак, мы хотим описать наши данные. Точнее, распределения переменных, которые у нас в данных есть. Хотим мы сделать это просто и ёмко. Насколько просто и ёмко? Ну, допустим максимально — одним числом. Кажется, значение переменной, которое лежит в центре распределения, неплохо для этого подойдет.\nКак мы будем искать, что там в центре распределения? Зависит от шкалы, в которой измерена конкретная переменная.\n\n\n\nШкала\nМера центральной тенденции\n\n\n\n\nНоминальная\nМода\n\n\nПорядковая\nМедиана\n\n\nИнтервальная\nСреднее арифметическое\n\n\nАбсолютная\nСреднее арифметическое, геометрическое и др.\n\n\n\nОднако есть некоторые нюансы.\n\n3.2.1 Мода\n\nОпределение 3.1 Мода (mode) — наиболее часто встречающееся значение данной переменной.\n\nТут все достаточно просто и интуитивно понятно. Пусть у нас есть следующий ряд наблюдений:\n\n\n [1] 1 3 4 6 4 2 4 3 2 4 1\n\n\nЕсли мы составим таблицу частот, то получим следующее:\n\n\nx\n1 2 3 4 6 \n2 2 2 4 1 \n\n\nОчевидно, что \\(4\\) встречается чаще других значений — это и есть мода.\nПонятно, что если на нашей шкале нет чисел, а есть текстовые лейблы, это ничего не меняет:\n\n\n [1] \"Москва\"                   \"Казань\"                  \n [3] \"Кёнигсберг\"               \"Барнаул (Алтайский край)\"\n [5] \"Москва\"                   \"Санкт-Петербург\"         \n [7] \"Санкт-Петербург\"          \"Москва\"                  \n [9] \"Санкт-Петербург\"          \"Москва\"                  \n[11] \"Кёнигсберг\"               \"Санкт-Петербург\"         \n[13] \"Москва\"                   \"Казань\"                  \n[15] \"Санкт-Петербург\"          \"Санкт-Петербург\"         \n[17] \"Казань\"                   \"Казань\"                  \n[19] \"Санкт-Петербург\"          \"Москва\"                  \n[21] \"Москва\"                   \"Санкт-Петербург\"         \n[23] \"Санкт-Петербург\"          \"Санкт-Петербург\"         \n[25] \"Санкт-Петербург\"          \"Москва\"                  \n[27] \"Кёнигсберг\"               \"Санкт-Петербург\"         \n[29] \"Казань\"                  \n\n\n\n\ny\nБарнаул (Алтайский край)                   Казань               Кёнигсберг \n                       1                        5                        3 \n                  Москва          Санкт-Петербург \n                       8                       12 \n\n\nМода, получается, Санкт-Петербург.\nТак мы поступаем с эмпирическим распределением. Если мы имеем дело с генеральной совокупностью, то можем формально определить моду через функцию вероятности (probability mass function, PMF). Модой будет являться значение случайной величины, при котором PMF принимает своё максимальное значение.\n\\[\n\\text{mode}(X) = \\arg \\max \\big( \\text{PMF}(X) \\big)\n\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 3.1: Определение моды для дискретной случайной величины по функции вероятности\n\n\n\nМода — 7.\n\n\n3.2.2 Медиана\n\nОпределение 3.2 Медиана (median) — значение переменной, которые располагается на середине отсортированного ряда значений.\n\nТо есть, она делит все наблюдения переменной ровно пополам, и половина наблюдений оказывается по одну сторону от медианы, а половина — по другую.\nЕсли у нас нечетное число наблюдений, то всё ясно. Пусть есть такой ряд наблюдений:\n\n\n [1]  2  3 14  9 16 19 28  7 26 18  1\n\n\nОтсортируем его:\n\n\n [1]  1  2  3  7  9 14 16 18 19 26 28\n\n\nПосмотрим в середину — найдем медиану:\n\n\n[1] 14\n\n\nА что делать, если число наблюдений чётное? Ведь тогда середина ряда будет между двух чисел. Ну, возьмем их среднее арифметическое — это и будет медиана.\nВозьмём такой ряд наблюдений:\n\n\n [1] 14 10  9 16 30  3 25  8 18  7\n\n\nОтсортируем:\n\n\n [1]  3  7  8  9 10 14 16 18 25 30\n\n\nНайдём медиану как \\((10 + 14) / 2\\):\n\n\n[1] 12\n\n\nФормально это можно написать так:\n\\[\n\\text{median}(X) = \\cases{\nX_{\\frac{n+1}{2}}, \\quad \\text{if} \\, n \\, \\text{is odd} \\\\\n\\frac{X_{\\frac{n}{2}} + X_{\\frac{n}{2}+1}}{2}, \\quad \\text{otherwise}\n}\n\\]\nгде \\(X\\) — ряд наблюдений данной переменной, \\(n\\) — число наблюдений, \\(X_i\\) — наблюдение с индексом \\(i\\) в сортированном векторе \\(X\\).\n\n\n3.2.3 Среднее арифметическое\nС этим существом все знакомы еще со школы.\n\nОпределение 3.3 Арифметическое среднее (arithmetic mean, mean, average) — сумма всех значений переменной, делёная на их количество.\n\nИначе говоря:\n\\[\nM(X) = \\overline{X} = \\frac{1}{n} \\sum_{i=1}^n x_i\n\\]\nгде \\(\\overline X\\) — среднее арифметическое, \\(x_i\\) — наблюдение в векторе \\(X\\), \\(n\\) — количество наблюдений.\nНу, то есть всё сложить и поделить на количество того, чего сложили. Изи.\nВот, скажем, средние по двум рядам наблюдений, которые мы встречали в разделе про медиану:\n\n\n [1]  2  3 14  9 16 19 28  7 26 18  1\n\n\n[1] 13\n\n\n\n\n [1] 14 10  9 16 30  3 25  8 18  7\n\n\n[1] 14\n\n\n\n\n3.2.4 Среднее взвешенное\nЧасто возникает такая ситуация, когда нам нужно посчитать среднее по каким-либо имеющимся характеристикам, но одни характеристики для нас важнее, чем другие. Например, мы хотим вычислить суммарный балл обучающегося за курс на основе ряда работ, выполненных в течение курса. Мы могли бы взять оценки за все работы и усреднить их. Однако мы понимаем, что, скажем, тест из десяти вопросов с множественным выбором явно менее показателен, чем, например, аналитическое эссе или экзаменационная оценка. Что делать? Взвесить параметры!\nЧто значит взвесить? Умножить на некоторое число. На самом деле, любое. Пусть мы посчитали, что написать эссе в три абстрактных раза тяжелее, чем написать тест, а сдать экзамен в два раза тяжелее, чем написать эссе. Тогда мы можем присвоить баллу за тест вес \\(1\\), баллу за аналитическое эссе вес \\(3\\), а экзамену — вес \\(6\\). Тогда итоговая оценка за курс будет рассчитываться следующим образом:\n\\[\n\\text{final score} = 1 \\cdot \\text{test} + 3 \\cdot \\text{essay} + 6 \\cdot \\text{exam}\n\\]\nСуперкласс. Однако! Весьма вероятно, что в учебном заведении принята единая система оценивания для всех видов работ — ну, скажем, некая абстрактная десятибалльная система в сферическом вакууме. Получается, если и за тест, и за эссе, и за экзамен у студента по 10 баллов, то суммарный балл 100, что, кажется, больше, чем 10. Чтобы вернуться к изначальным границам баллов, нужно поделить суммарный балл на сумму весов параметров:\n\\[\n\\text{final score} =\n\\frac{1 \\cdot \\text{test} + 3 \\cdot \\text{essay} + 6 \\cdot \\text{exam}}\n{1 + 3 + 6}\n\\]\nКайф! Собственно, это и есть взвешенное среднее. Коэффициенты, на которые мы умножаем значения переменных, называются весами. В общем виде формула принимает следующий вид:\n\\[\n\\overline X = \\frac{\\sum_{i=1}^n w_i \\cdot x_i}{\\sum_{i=1}^n w_i},\n\\]\nгде \\(x_i\\) — значения переменной, \\(w_i\\) — веса для этих значений.\nВзвешенное среднее часто применяется именно во всякого рода ассессментах, и не только образовательных. Например, вы HR-аналитик и оцениваете персонал. Вы аналитически вычисляете веса коэффициентов (допустим, с помощью линейной регрессии), а далее на их основе высчитываете интегральный балл, по которому будете оценивать сотрудников. Это как один из индустриальных примеров.\n\n\n3.2.5 Другие средние\nСреднее бывает не только арифметическое. Правда встретятся вам другие его виды примерно нигде — то есть о-о-о-очень редко и, скорее всего, в каких-то узкоспециализированных статьях. Но упомянуть их, пожалуй, стоит как минимум ради того, чтобы вы не перепугались излишне, ежели вдруг с ними столкнётесь.\n\n3.2.5.1 Квадратичное среднее\nЭто весьма полезная вещь.\n\nОпределение 3.4 Квадратичное среднее (quadratic mean, root mean square, RMS) — это квадратный корень из среднего квадрата наблюдений.\n\nНичего не понятно, поэтому по порядку:\n\nесть наблюдение \\(x_i\\)\nзначит есть и его квадрат \\(x_i^2\\)\nмы умеем считать обычно среднее арифметическое\n\nно ведь \\(x_i^2\\) — это тоже наблюдение (число), просто в квадрате\n\nзначит можем посчитать среднее арифметическое квадратов наблюдений — средний квадрат (mean square) — \\(\\displaystyle \\frac{1}{n} \\sum_{i=1}^n x_i^2\\)\nтеперь извлечём из этого дела корень, чтобы вернуться к исходным единицам измерения — получим то, что нам надо\n\n\\[\n\\text{RMS}(X) = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n x_i^2}\n\\]\nPer se3 мы его вряд ли ещё когда-то увидим, но пару раз оно внезапно всплывет.\n\n\n3.2.5.2 Геометрическое среднее\nВ психологии и социальных науках встречается редко. Применяется там, где необходимо изучать средние скорости изменения — например, в экономике и финансах при изучении доходности, прибыли и выручки; в демографии при расчете индекса человеческого потенциала и др.\n\\[\nG(X) = \\sqrt[n]{\\prod_{i=1}^n x_i}\n\\]\n\n\n3.2.5.3 Гармоническое\nВесьма экзотическая конструкция, используемая при работе с величинами, заданными через обратные значения. Встречается в финансах и экономике, страховании, физике.\n\\[\nH(X) = \\frac{n}{\\displaystyle \\sum_{i=1}^n \\frac{1}{x_i}}\n\\]",
    "crumbs": [
      "Описательная статистика",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Меры центральной тенденции</span>"
    ]
  },
  {
    "objectID": "desc-centraltend.html#centraltend-comparison",
    "href": "desc-centraltend.html#centraltend-comparison",
    "title": "3  Меры центральной тенденции",
    "section": "3.3 Сравнение мер центральной тенденции",
    "text": "3.3 Сравнение мер центральной тенденции\nСравнивать будем моду, медиану и среднее [арифметическое].\nВсе три статистики — мода, медиана и среднее — описывают центральную тенденцию — значение изучаемой нами переменной, вокруг которого собираются другие значения. Но если их три и все они используются, значит между ними должны быть какие-то различия. Посмотрим, какие.\n\n3.3.1 Меры центральной тенденции и типы переменных\n\nВо-первых, очевидно, что моду невозможно посчитать для непрерывной переменной.\n\n\n\n\n\n\n\nНет, не очевидно\n\n\n\n\n\nТак как вероятность того, что непрерывная случайная величина принимает своё конкретное значение, равна нулю, каждое наблюдение в нашей выборке будет уникально — встретится ровно один раз. Вспомните пример из предыдущей главы (Рисунок 2.9), где мы набирали числа из отрезка. Получается, что мода теряет свой смысл.\n\n\n\n\nВо-вторых, медиану нельзя посчитать на номинальной шкале. Кстати, почему?\n\n\n\n\n\n\n\nПотому что\n\n\n\n\n\nна номинальной шкале нет отношения порядка между элементами — на ней нельзя сравнивать на больше-меньше. Следовательно, невозможно отсортировать наблюдения, а значит, и найти медиану.\n\n\n\n\nВ-третьих, среднее тоже нельзя посчитать на номинальной шкале.\n\n\n\n\n\n\n\nМожно, но осторожно\n\n\n\n\n\nВообще, конечно, да — нельзя, потому что на номинальной шкале не определена операция сложения, входящая в вычисление среднего. Однако если на номинальной шкале есть только две категории, которые закодированы 0 и 1, то посчитать среднее можно. Но что оно будет значить?\nИсходный математический смысл среднего явно утерян. Посмотрим на это по-другому: посчитать сумму единиц это всё равно, что посчитать количество единиц. То есть, если мы сложим все нули и единицы, то получим количество единиц среди всех наших наблюдений. А разделив количество единиц на количество наблюдений, мы получим долю единиц — то есть долю наблюдений с лейблом 1.\nокак\n\n\n\n\nВ-четвертых, для дискретной переменной значение среднего арифметического будет не особо осмысленно. Ну, скажем, странно сказать, что в аудитории в среднем стоят 15.86 столов или в российских семьях в среднем 1.5 ребенка. Конечно, в ряде случаев можно это как-то более-менее содержательно интерпретировать, но это требует усилий, а мы ленивые, поэтому лучше использовать медиану.\n\n\n\n\n\n\n\nИтого, делаем следующие выводы\n\n\n\n\nдля номинальной шкалы пригодна только мода\nдля дискретных переменных подходят мода и медиана\nмода иногда лучше, так как точно всегда будет целым числом\nдля непрерывных переменных подходят медиана и среднее\n\n\n\n\n\n3.3.2 Меры центральной тенденции и форма распределения\nПомимо того, что среднее, мода и медиана информативны сами по себе, полезно смотреть на их взаимное расположение.\n\nНа симметричном распределении мода, медиана и среднее совпадают [или, по крайней мере, находятся очень близко друг к другу].\n\n\nЗдесь и далее: красная (сплошная) линия — среднее, синяя (короткопунктирная) — медиана, зелёная (длиннопунктирная) — мода.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 3.2: Взаимное расположение моды, медианы и среднего на симметричном распределении\n\n\n\n\nНа асимметричном распределении мода [практически] в пи́ке\n\n.Практически, потому что мода для непрерывной переменной определена по функции плотности вероятности [черная линия на графике], которая не всегда точно аппроксимирует (в данном случае то же, что и сглаживает) эмпирическое распределение. На картинке ниже мы видим, что по гистограмме мода должна была бы быть в районе самого высокго столбика, однако при сглаживании гистограммы пик немного съехал, и мода оказалась в вершине графика функции плотности вероятности.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 3.3: Взаимное расположение моды, медианы и среднего на распределении с правосторонней асимметрией\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 3.4: Взаимное расположение моды, медианы и среднего на распределении с левосторонней асимметрией\n\n\n\n\nНа асимметричном распределении медиана и среднее смещены в сторону хвоста. Среднее смещено сильнее медианы.\n\nЭто связано с тем, что медиана зависит только от количества наблюдений, а среднее — ещё и от самих значений. На картинках выше примеры для распределения с правосторонней асимметрией (потому что хвост справа) — среднее (красная линия) правее медианы (синяя линия) — и левосторонней асимметрией (так как хвост слева) — среднее (красная линия) левее медианы (синяя линия).\nДля того, чтобы лучше разобраться с тем, как экстремальные значения влияют на моду и медиану посмотрим такой пример. Пусть у нас есть оценки за выпускную квалификационную работу. Например, такие:\n\n\n[1] 6 7 7 8 8\n\n\nСреднее — 7.2, медиана — 7. Если округлить среднее, то можно считать, что среднее и медиана совпали. Ну, ок.\nНо в комиссии сидят ещё два требовательных доктора наук, которые поставили оценки, сильно отличающиеся от остальных:\n\n\n[1] 6 7 7 8 8 3 4\n\n\nПосчитаем медиану и среднее теперь. Среднее — 6.1428571, медиана — 7. Медиана осталась на месте, а вот среднее теперь округлится до 6. Казалось бы, это немного, но в смысле оценок — это прилично, и может сильно повлиять на GPA.\nИтого, среднее более чувствительно к нетипичным значениям (очень большим или очень малым).\nЕсть ещё один интересный вариант распределений — бимодальные. Посмотрим пример ниже:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 3.5: Взаимное расположение моды, медианы и среднего на бимодальном распределении\n\n\n\nМы видим, что на графике есть два пика, однако строго математически мода всё же одна (зелёная пунктирная линия) — и она в более высоком пике. Это логично, ибо там самые часто встречающиеся (самые вероятные) значения.\nИ все жё содержательно мы не можем пренебречь вторым пиком (зелёная точечная линия). Почему он нам важен? Обычно бимодальное распределение — это повод задуматься о том, что наша выборка неоднородна. Бимодальное распределение как бы сложено из двух с центрами в двух пиках. Иначе говоря, в нашей выборке как будто бы две подвыборки, которые обладают разными распределениями интересующего нам признака.\nЧто с этим делать? Хорошо всегда иметь в данных какие-либо дополнительные переменные — как минимум соцдем — чтобы мы могли по данным попытаться предположить, какую группировку мы могли забыть учесть при планировании исследования.\nСо средним и медианой в случае бимодального распределения происходит примерно то же, что и в случае асимметричного распределения — второй пик смещает к себе обе меры центральной тенденции, причем среднее вновь сильнее, чем медиану.",
    "crumbs": [
      "Описательная статистика",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Меры центральной тенденции</span>"
    ]
  },
  {
    "objectID": "desc-centraltend.html#centraltend-mean-features",
    "href": "desc-centraltend.html#centraltend-mean-features",
    "title": "3  Меры центральной тенденции",
    "section": "3.4 Свойства среднего арифметического",
    "text": "3.4 Свойства среднего арифметического\nМы упомянем три основных свойства, к которым будем обращаться в последующих темах.\n\nУтверждение 3.1 Если к каждому значению распределения прибавить некоторое число (константу), то среднее изменится на ту же константу.\n\\[\nM_{X+c} = M_X + c\n\\]\n\n\nДоказательство. \\[\n\\begin{split}\nM_{X+c} &= \\frac{\\sum_{i=1}^n (x_i + c)}{n} = \\\\\n&= \\frac{\\sum_{i=1}^n x_i + nc}{n} = \\\\\n&= \\frac{\\sum_{i=1}^n x_i}{n} + c = M_X + c\n\\end{split}\n\\]\n\nИначе говоря, распределение просто сдвинется. Например, если к каждому значению синего распределения прибавить \\(2\\), получится красное:\n\n\n\n\n\n\n\n\n\n\nУтверждение 3.2 Если каждое значение распределения умножить на некоторое число (константу), то среднее изменится во столько же раз.\n\\[\nM_{X \\times c} = M_X \\times c\n\\]\n\n\nДоказательство. \\[\n\\begin{split}\nM_{X \\times c} &= \\frac{\\sum_{i=1}^n (x_i \\times c)}{n} = \\\\\n&= \\frac{c \\times \\sum_{i=1}^n x_i}{n} = \\\\\n&= \\frac{\\sum_{i=1}^n x_i}{n} \\times c = M_X \\times c\n\\end{split}\n\\]\n\nНапример, здесь каждое значение синего распределения умножили на \\(3\\) и получили красное:\n\n\n\n\n\n\n\n\n\nТут, правда, явно что-то ещё произошло, но мы пока этого не знаем.\n\nУтверждение 3.3 Сумма отклонений от среднего значения равна нулю.\n\\[\n\\sum_{i=1}^n(x_i - M_X) = 0\n\\]\n\n\nДоказательство. \\[\n\\begin{split}\n\\sum_{i=1}^n(x_i - M_X) &= \\sum_{i=1}^n x_i - \\sum_{i=1}^n M_X = \\\\\n& = \\sum_{i=1}^n x_i - nM_X = \\\\\n& = \\sum_{i=1}^n x_i - n \\times \\frac{1}{n} \\sum_{i=1}^n x_i = \\\\\n&= \\sum_{i=1}^n x_i - \\sum_{i=1}^n x_i = 0\n\\end{split}\n\\]\n\nНо можно это осмыслить и более просто графически.\n\n\n\n\n\n\n\n\n\n\nОпределение 3.5 Отклонение — это разность между конкретным значением переменной и средним по этой переменной.\n\\[\nd_i = \\overline X - x_i\n\\]\n\nИ, действительно, так как среднее находится в центре распределения, то часть значений лежит справа, а часть слева. Значит, будут как положительные, так и отрицательные отклонения — и их сумма в итоге будет равна нулю.",
    "crumbs": [
      "Описательная статистика",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Меры центральной тенденции</span>"
    ]
  },
  {
    "objectID": "desc-centraltend.html#footnotes",
    "href": "desc-centraltend.html#footnotes",
    "title": "3  Меры центральной тенденции",
    "section": "",
    "text": "Mass (uncountable) noun.↩︎\nCountable noun, plural in this case.↩︎\nPer se (лат.) — в чистом виде.↩︎",
    "crumbs": [
      "Описательная статистика",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Меры центральной тенденции</span>"
    ]
  },
  {
    "objectID": "desc-variation.html",
    "href": "desc-variation.html",
    "title": "4  Меры разброса",
    "section": "",
    "text": "4.1 Зачем нужны меры разброса\nИтак, мы разобрались с мерами центральной тенденции. Однако для описания распределения их оказывается недостаточно. Почему?\nПосмотрим на несколько распределений:\nМетодом пристального взгляда можно установить, что у всех распределений одинаковые средние:\nОднако мы видим, что значения по-разному группируются вокруг среднего. Как они группируются — плотно, как на втором рисунке, или не особо, как на третьем — можно описать с помощью мер разброса, или мер вариативности.",
    "crumbs": [
      "Описательная статистика",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Меры разброса</span>"
    ]
  },
  {
    "objectID": "desc-variation.html#variation-data-features",
    "href": "desc-variation.html#variation-data-features",
    "title": "4  Меры разброса",
    "section": "4.2 Основные характеристики статистических данных",
    "text": "4.2 Основные характеристики статистических данных\nВообще если посмотреть на это более свысока, то необходимость описания разброса определяется тем, что статистические данные обладают двумя ключевыми особенностями — неопределенностью и вариативностью.\n\nНеопределённость нам говорит о том, что мы не знаем, что именно мы получим в результате наших измерений для конкретной выборки. В том числе потому, что мы работаем на просторах случайных величин.\nВариативность означает, что наши данные будут различаться ещё и от респондента к респонденту. И между выборками тоже. Здесь и ошибка измерения, и различные смешения и ещё куча всего.\n\nБолее того, вариативность есть главное условие применения статики, поскольку она входит в расчёт любого статистического критерия. Если у переменной отсутствует вариативность, статистика на ней работать не будет.",
    "crumbs": [
      "Описательная статистика",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Меры разброса</span>"
    ]
  },
  {
    "objectID": "desc-variation.html#variation-min-max",
    "href": "desc-variation.html#variation-min-max",
    "title": "4  Меры разброса",
    "section": "4.3 Минимум, максимум, размах",
    "text": "4.3 Минимум, максимум, размах\nНачнем с самого простого. Как наиболее просто описать вариативность? Мы работаем с выборкой, а в выборке, как известно, ограниченное число наблюдений. А если оно ограниченное, значит среди них точно есть наибольшее — максимум (max) — и наименьшее — минимум (min).\nДопустим, мы открыли ведомость по «Анатомии и физиологии ЦНС» некоторой академической группы и пронаблюдали следующее:\n\n\n [1]  7  4  6  9 10  5  6  9  6  6  3  6  8  8  5 10  7  5  7  3  9  4  8  3  8\n[26]  4  6  8  7  5\n\n\nМы можем посчитать минимальное и максимальное значение по этому ряду наблюдений — они окажутся равны соответственно 3 и 10. То есть оценки по этой дисциплине варьируются от 3 до 10. Ну, чу́дно.\nРазница между максимальным и минимальным значением называется размах (range):\n\\[\n\\text{range}(X) = \\max(X) - \\min(X)\n\\]\nВ примере выше он будет равен 7.\nИ вот мы преисполнившиеся сим знанием идёт описывать вариативность переменной с помощью размаха, но обнаруживаем в другой ведомости этой же группы (по «Введению в психологию») вот что:\n\n\n [1]  6  8  4  6  7  5  7 10  4  6  7  8  7  6  8 10  8  7  7  6  8  7  6  8  6\n[26]  3  8  6  6  4\n\n\nМинимум, максимум и размах вроде как такие же: 3, 10 и 7 соответственно.\nЗначит ли это, что вариативность одинаковая? Нарисуем.\n\n\n\n\n\n\n\n\n\nКажется, что вариативность различна. Распределение оценок по «Анатомии и физиологии ЦНС» более равномерное, в то время как оценки по «Введению в психологию» активнее группируются где-то в середине.\nШтош, размах хоть и дает нам некоторую информацию о вариативности, нам этого маловато. Будем искать другие меры разброса.",
    "crumbs": [
      "Описательная статистика",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Меры разброса</span>"
    ]
  },
  {
    "objectID": "desc-variation.html#variation-quatile",
    "href": "desc-variation.html#variation-quatile",
    "title": "4  Меры разброса",
    "section": "4.4 Квантили",
    "text": "4.4 Квантили\nВозьмем распределение суммарного балла по шкале толерантности к неопределенности. Выглядит оно как-то так:\n\n\n\n\n\n\n\n\n\nТеперь нам понадобится определение квантиля распределения.\n\nОпределение 4.1 Квантиль (quantile) — это значение переменной, которое не превышается с определенной вероятностью.\n\nОбозначим эту вероятность \\(p\\). Тогда можно сказать, что квантиль уровня \\(p\\) — это такое значение переменной, слева от которого лежит \\(p\\%\\) наблюдений.\nПосмотрим на картинки.\nСлева относительно квантиля-0.05 (\\(x_{0.05}\\)) лежит 5% наблюдений:\n\n\n\n\n\n\n\n\n\nСлева относительно квантиля-0.68 (\\(x_{0.68}\\)) лежит 68% наблюдений:\n\n\n\n\n\n\n\n\n\nСлева относительно квантиля-0.99 (\\(x_{0.99}\\)) лежит 99% наблюдений:\n\n\n\n\n\n\n\n\n\nИтак, мы поняли, а также приняли и осознали, что такое квантиль. Неясно только, как он нам поможет описать вариативность данных.\n\n4.4.1 Квартили\nДля этого нам пригодятся специально обученные квантили. Оказалось достаточно удобно поделить все наблюдение на четыре равные части — вот так:\n\n\n\n\n\n\n\n\n\nЗначения переменной, которые делят выборку на четыре равные части называются квартили (quartile). Получается, что\n\nслева от первого (нижнего) квартиля (\\(\\text{Q1}, x_{0.25}\\)) лежит 25% наблюдений\nслева от второго (среднего) квартиля (\\(\\text{Q2}, x_{0.50}\\)) лежит 50% наблюдений\n\nа значит и справа 50%: получается второй квартиль делит выборку пополам — это медиана\n\nслева от третьего (верхнего) квартиля (\\(\\text{Q3}, x_{0.75}\\)) лежит 75% наблюдений\n\nЧетвертый квартиль не используется, потому что является максимальным значением — слева от него лежит 100% наблюдений.\nКстати, можно также отметить, что первый квартиль — это медиана нижней (меньшей) половины наблюдений, а третий — медиана верней (большей) половины наблюдений.\nВот такая вот прикольная история.\n\n\n4.4.2 Децили\nК слову, делить выборку можно не только на четверти — можно поделить, скажем, на 10 частей и получить децили. Так, слева от первого дециля (\\(x_{0.10}\\)) лежит 10% наблюдений, а слева от третьего (\\(x_{0.30}\\)) — 30%.\nДецили встречаются редко (в основном в психометрике), но знать о них полезно.\n\n\n4.4.3 Перцентили\nГораздо чаще встречаются перцентили — значения переменной, которые делят выборку на 100 равных частей. Например, так устроен ваш рейтинг. Только стоит помнить, что в рейтинге отсчет ведется от максимального GPA, поэтому если у вас нулевой перцентиль (\\(x_{0.00}\\)) по программе, значит выше вас в рейтинге никого нет. А если ваш перцентиль, скажем, 36-ой (\\(x_{0.36}\\)), то выше вас в рейтинге 36% ваших однокурсников, то есть вы все ещё в первой половине рейтинга, что очень неплохо!",
    "crumbs": [
      "Описательная статистика",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Меры разброса</span>"
    ]
  },
  {
    "objectID": "desc-variation.html#variation-iqr",
    "href": "desc-variation.html#variation-iqr",
    "title": "4  Меры разброса",
    "section": "4.5 Интерквартильный размах",
    "text": "4.5 Интерквартильный размах\nИ — о, ура! — мы наконец-то добрались до того, ради чего тут собрались! Зная первый и третий квартили распределения, можно рассчитать интерквартильный (межквартильный) размах (interquartile range, IQR) как разницу между третьим и первым квартилями.\n\\[\n\\text{IQR}(X) = \\text{Q3}(X) - \\text{Q1}(X)\n\\]\nЭта величина описывает интервал значений признака, в котором лежит 50% наблюдений. В случае с баллами по шкале толерантности к неопределенности он равен 24, то есть 50% срединных наблюдений лежит в пределах 24 единиц шкалы.\n\n4.5.1 Визуализация квартилей. Боксплот\nОтображать квартили на гистограмме, во-первых, совершенно неудобно, а во-вторых, не то чтобы график получается информативный. Для визуализации квартилей придумали специальный тип графика — ящик с усами, или боксплот (boxplot).\n\n\n\n\n\n\n\n\n\nПрикольная ерунда. Научимся его читать.\n\nЗначения переменной идут по вертикальной оси (оси ординат)1\nПо горизонтальной оси (оси абсцисс) здесь ничего не идёт2\nЖирная линия посередине ящика — медиана (второй квартиль)\nНижняя граница ящика — первый квартиль, верхняя — третий\nГраницы ящика показывают нам межквартильный размах\nНижний ус — первый квартиль минус полтора межквартильных размаха\nВерхний ус — третий квартиль плюс полтора межквартильных размаха\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nКривой ящик\n\n\n\nЯщик может быть асимметричным — то есть верхняя его часть (расстояние между медианой и третьим квартилем) и нижняя его часть (расстояние между медианой и первым квартилем) могут быть разными. Это нам говорит об асимметричности распределения. Усы также могут быть неравными, если один из них упирается в максимум / минимум — тоже по причине асимметричности распределения.\n\n\nНу, допустим. А что тогда точки?\n\n\n4.5.2 Выбросы\nВообще справедливо было бы задаться вопросом, а зачем нам вообще усы на этом графике? И почему мы прибавляем полтора межквартильных размаха?\nЭто один из подходов к определению нехарактерных значений — выбросов (outliers). При исследовании данных мы часто задаемся вопросом, есть ли в наших данных такие значения, которые сильно отличаются от распределения той или иной переменной. Но как определить это самое «сильно»?\nВот один из подходов. Будем считать, что значения, которые укладываются в интервал \\((\\text{Q1} - 1.5 \\times \\text{IQR}, \\text{Q3} + 1.5 \\times \\text{IQR})\\), нас устраивают. Всё что попадает в этот интервал — это «нормальные», типичные значения нашей переменной. Те же, которые будут находиться за пределами этого интервала, мы назовём нетипичными, аномальными значениями, или выбросами. Эти значения и будут отмечены точками на графике.\n\n\n\n\n\n\nЧто делать с выбросами?\n\n\n\nВо-первых, содержательно анализировать. Выбросы могут возникнуть по разным причинам. Может быть испытуемый отвлекся на прилетевшего в окно голубя, и у нас в данных появилось время реакции 200 секунд. Такие выбросы мы можем исключить из данных.\nА возможно в нашу выборку попали какие-то люди, которые, скажем, очень сильно или очень слабо толерантны к неопределенности. Эти наблюдения не являются «ошибками», и их необходимо дополнительно проанализировать — возможно, это представители каких-либо специфических групп нашей генеральной совокупности. Анализ принесет нам дополнительную информацию, которую мы могли не учесть при планировании исследования. Крч, думать надо. И собирать побольше данных, чтобы можно было найти содержательную интерпретацию происходящему.",
    "crumbs": [
      "Описательная статистика",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Меры разброса</span>"
    ]
  },
  {
    "objectID": "desc-variation.html#variation-disp",
    "href": "desc-variation.html#variation-disp",
    "title": "4  Меры разброса",
    "section": "4.6 Дисперсия",
    "text": "4.6 Дисперсия\nХотя описание разброса переменных с помощью квантилей (в частности, квартилей) может дать нам много полезной информации, все же у них есть существенный недостаток: они никак не взаимодействуют с самими значениями нашей переменной.\nДействительно, мы делим нашу отсортированную выборку на равные части, и смотрим, что в эти части попало. Но хотелось бы как-то учесть ещё и сами значения переменной в некоторой числовой мере разброса.\nНу, хорошо. Поступим следующим образом. Мы все ещё хотим узнать, как наши значения группируются вокруг среднего. В предыдущей главе мы уже видели, что наши наблюдения отклоняются от среднего значения — значит мы можем посчитать отклонение для каждого наблюдения (\\(d\\) — от лат. вумшфешщт или англ. deviation):\n\\[\nd_i = \\overline X - x_i\n\\]\nОкей. Если мы сложим все отклонения и поделим получившуюся сумму на их количество, равное количеству наблюдений (\\(n\\)), то получим среднее отклонение, да?\nВ принципе, да:\n\\[\n\\overline d =\n\\frac{1}{n} \\sum_{i=1}^n d_i =\n\\frac{1}{n} \\sum_{i=1}^n (\\overline X - x_i)\n\\]\nОднако есть одна проблема. В прошлой главе мы выяснили, что сумма отклонений от среднего равна нулю (Утверждение 3.3), а значит и cреднее отклонение также будет равно нулю.\nХорошо. Но отрицательные значения ведь можно победить! Есть два пути:\n\nМодуль. Преимущество первого в том, что размерность величины разброса остается той же, что и у измеряемой переменной.\nКвадрат. Преимущество второго в том, что квадрат обладает более хорошими аналитическими свойствами, чем модуль, а ещё сильные отклонения будут оказывать более сильное влияние на окончательное значение статистики (см. заметку ?nte-abs-sq).\n\nВторой путь на практике оказывается полезнее, так как мы хотим, чтобы сильно отличающиеся наблюдения вносили больший вклад в меру разброса.\nВозведя отклонения в квадрат, получим формулу дисперсии (вариации, variation):\n\\[\nD(X) = \\text{var}(X) = \\sigma^2_X =\n\\frac{1}{n} \\sum_{i=1}^n d_i^2 =\n\\frac{1}{n} \\sum_{i=1}^n (\\overline X - x_i)^2\n\\tag{4.1}\\]\nГениально.\n\n\n\n\n\n\nПочему квадрат лучше модуля?\n\n\n\n\n\nРассмотрим два простейших примера. Пусть у нас есть два нехитрых ряда наблюдений:\n\n\n[1] 1 2 3 4 5 6\n\n\n[1]  1  2  3  4  5 20\n\n\nКак несложно заметить, они отличаются друг от друга всего лишь одним наблюдением — в первом случае существенных отклонений нет, а во втором есть одно наблюдений, значительно отклоняющееся от всех остальных.\nПопробуем посчитать разброс, используя модуль — формула будет такова:\n\\[\n\\text{MAD} = \\frac{1}{n} \\sum_{i=1}^n |d| = \\frac{1}{n} \\sum_{i=1}^n |\\overline X - x_i|\n\\]\nЭта статистика называется среднее абсолютное отклонение (mean absolute deviation, MAD).\nДля первого ряда наблюдений получим 1.5, для второго — 4.72.\nЗначения разброса, безусловно, различаются, однако не то чтобы очень значительно.\nТеперь воспользуется формулой дисперсии:\n\\[\n\\text{var}(X) = \\frac{1}{n} \\sum_{i=1}^n d^2 = \\frac{1}{n} \\sum_{i=1}^n (\\overline X - x_i)^2\n\\]\nДля первого ряда наблюдений получим 2.92, для второго — 41.81.\nВ этой случае значения различаются уже гораздо сильнее — на целый порядок.\nОтметим, что и в случае отклонений в меньшую от среднего сторону формулы не перестают работать. Возьмём такие ряды наблюдений:\n\n\n[1] 15 16 17 18 19 20\n\n\n[1]  5 16 17 18 19 20\n\n\nРасчёты мер разброса для них представлены ниже.\n\n\n\n\nMAD (модуль)\nДисперсия (квадрат)\n\n\n\n\nПервый ряд\n1.5\n2.92\n\n\nВторой ряд\n3.61\n25.14\n\n\n\n\n\n\nНо не совсем. Формула, которую мы получили, пригодна для расчета дисперсии генеральной совокупности — на выборке же она будет давать неточную оценку.\nЧтобы получить точную (несмещенную) оценку дисперсии по выборке, нам нужно исправить знаменатель дроби — вместо \\(n\\) использовать \\(n - 1\\):\n\\[\ns^2_X = \\hat \\sigma^2_X =\n\\frac{1}{n-1} \\sum_{i=1}^n d^2 =\n\\frac{1}{n-1} \\sum_{i=1}^n (\\overline X - x_i)^2\n\\tag{4.2}\\]\nНо почему?\n\n\n\n\n\n\nОбозначения параметров и их выборочных оценок\n\n\n\nОбратим внимание на используемые обозначения.\n\nДля обозначения параметров генеральной совокупности используются греческие буквы, поэтому дисперсия генеральной совокупности обозначена как \\(\\sigma^2\\).\nДля обозначения оценок параметров, полученных на выборке используются соответствующие греческим латинские буквы, поэтому выборочная дисперсия обозначена как \\(s^2\\).\n\nТакже для обозначения выборочных оценок может быть использована «шляпка», которая надевается на обозначение параметра — в случае дисперсии это выглядит как \\(\\hat \\sigma^2\\).\n\n\n\n4.6.1 Свойства выборочных оценок\nВо всём виновата выборка. В первой главе мы говорили, что в ходе исследования мы собираем выборку, чтобы по результатам её изучения сделать вывод о генеральной совокупности (см. Рисунок 1.1). Иначе говоря, мы заинтересованы в получение максимально точных выборочных оценок параметров генеральной совокупности.\nОднако ввиду неопределенности и вариативности данных мы неизбежно будем ошибаться, то есть значение любой выборочной оценки будет отличаться от значения параметра генеральной совокупности. Что же делать?\nНеобходимо предъявить определённые требования к оценке параметра, для того чтобы она считалась «хорошей», «правильной», «корректной». Таких требований всего существует три — несмещённость, состоятельность и эффективность — из которых мы познакомимся только с первым, так как оно имеет непосредственное отношение к оценке дисперсии.\nНесмещённость выражает следующую идею:\n\nпусть мы будем ошибаться в оценке параметра на отдельной выборке,  однако мы не должны ошибаться в среднем, постоянно используя один и тот же способ оценки.\n\nИначе говоря, да, мы ошибёмся на конкретной выборке, но если выборок будет много, то, усреднив оценки по всем выборкам, мы будем попадать ровно в значение параметра генеральной совокупности.\nПод эту идею существует математические обоснование, которое мы не будем рассматривать — лучше поглядим на картинки. Начнём с чего-то хорошо нам знакомого — например, среднего. Ведь у среднего была только одна формула, как мы помним. Почему?\nСделаем симуляцию. Пусть известно, что среднее некоторой переменной в генеральной совокупности равно \\(10\\), а дисперсия — \\(25\\). Для определенности можете считать, допустим, что это время реакции на некоторым тип стимулов, хотя это не важно — излагаемая логика будет работать для любых переменных.\nИзвлечём из этой генеральной совокупности 1000 выборок по 50 наблюдений. На каждой из выборок мы посчитаем среднее и получим что-то такое:\n\n\n  [1] 10.172018 10.732041  8.730498 10.194034  9.957397 11.247254 10.010271\n  [8]  9.627500  9.671977 11.386532 10.134469  9.442532  9.185977  9.317582\n [15] 11.061941  9.996794  9.968616 10.967281 10.501165  9.306908 10.856482\n [22] 10.342924  9.923969  9.884275  9.378945 10.595663  9.176307 10.221581\n [29]  9.845554 11.084339 11.081289  9.273581 11.066268  9.824072  9.932142\n [36] 10.378406  9.720336 10.931505 10.204910 10.523979 10.026035  8.789679\n [43]  9.092949  9.578313 10.009071  8.952169  9.915419 10.814884  8.891549\n [50] 10.727858  9.983400 11.077476  9.836667  9.013348  9.554866 10.293186\n [57]  9.965728 10.509745  9.465434 11.490972  9.557135  9.903944  8.850641\n [64]  9.606149 10.591157  9.796804 10.559390  9.952048  9.636643 10.415579\n [71]  9.865853 10.813721  9.592410 10.231220  9.197716  8.303104 10.712915\n [78] 10.012025 11.149892 10.335617  9.631661  9.538324  9.846021  9.732227\n [85]  9.298658 10.578616  9.415370 10.171959 10.417826  9.027612 11.310096\n [92]  9.307295 10.651196  9.946036  9.604827  9.725039  9.605681  9.861112\n [99]  9.588404  9.525222\n\n\nЗдесь представлено только 100 первых значений выборочных средних, так как выводить все довольно громоздко. Наблюдаем, что от выборки к выборки среднее меняется, но все они плюс-минус находятся около 10 — значения параметра генеральной совокупности.\nМы можем усреднить полученные значения, то есть посчитать среднее средних. Отобразим его на распределении выборочных средних, добавив на график значение параметра генеральной совокупности:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 4.1: Несмещённость среднего арифметического как оценки среднего генеральной совокупности\n\n\n\nНа рисунке красная сплошная линия — значение параметра генеральной совокупности, черная пунктирная — среднее выборочных средних. Видно, что линии [практически] совпадают. Значит, при использовании среднего арифметического в качестве выборочной оценки генерального среднего мы в среднем не ошибаемся. Это и есть несмещённость.\nТеперь рассмотрим ситуацию с дисперсией. Итак, у нас есть два способа оценки дисперсии по выборке — Уравнение 4.1 и Уравнение 4.2. Возьмём те же 1000 выборок по 50 наблюдений и посчитаем для каждой выборке её дисперси двумя способами — по формуле выборочной дисперсии и по формуле дисперсии генеральной совокупности. Получим такие значения:\n\n\n         [,1]     [,2]     [,3]     [,4]     [,5]     [,6]     [,7]     [,8]\n[1,] 21.43088 20.49587 24.46954 21.66786 22.43881 22.28620 26.59727 27.83184\n[2,] 21.00226 20.08595 23.98015 21.23450 21.99003 21.84047 26.06533 27.27521\n         [,9]    [,10]    [,11]    [,12]    [,13]    [,14]    [,15]    [,16]\n[1,] 26.37401 21.56579 20.00768 24.25818 26.16181 27.23231 28.71230 22.23534\n[2,] 25.84653 21.13447 19.60752 23.77301 25.63857 26.68766 28.13805 21.79063\n        [,17]    [,18]    [,19]    [,20]    [,21]    [,22]    [,23]    [,24]\n[1,] 26.46129 28.90916 26.89292 24.96440 32.85149 21.96123 26.79094 23.48350\n[2,] 25.93206 28.33098 26.35506 24.46511 32.19446 21.52201 26.25512 23.01383\n        [,25]    [,26]    [,27]    [,28]    [,29]    [,30]    [,31]    [,32]\n[1,] 25.25271 17.49122 27.39924 23.96021 23.82035 24.51674 16.59327 21.68536\n[2,] 24.74766 17.14140 26.85126 23.48100 23.34395 24.02641 16.26140 21.25166\n        [,33]    [,34]    [,35]    [,36]    [,37]    [,38]    [,39]    [,40]\n[1,] 32.32796 27.61211 31.96177 20.94532 22.33992 31.91699 34.97936 24.66116\n[2,] 31.68140 27.05986 31.32254 20.52641 21.89312 31.27865 34.27977 24.16794\n        [,41]    [,42]    [,43]    [,44]    [,45]    [,46]    [,47]    [,48]\n[1,] 20.07405 18.86281 18.75675 19.10307 23.59617 18.90775 21.90138 29.39349\n[2,] 19.67257 18.48555 18.38161 18.72101 23.12425 18.52960 21.46335 28.80562\n        [,49]    [,50]    [,51]    [,52]    [,53]    [,54]    [,55]    [,56]\n[1,] 26.02598 22.21602 26.12363 21.29367 28.51742 25.34852 23.22511 21.56059\n[2,] 25.50546 21.77170 25.60115 20.86779 27.94707 24.84155 22.76061 21.12938\n        [,57]    [,58]    [,59]    [,60]    [,61]    [,62]    [,63]    [,64]\n[1,] 28.56293 23.55512 24.66227 34.95235 28.57192 30.27220 16.84703 21.14235\n[2,] 27.99167 23.08402 24.16903 34.25331 28.00048 29.66675 16.51009 20.71950\n        [,65]    [,66]    [,67]    [,68]    [,69]    [,70]    [,71]    [,72]\n[1,] 29.56573 28.62074 20.61853 15.24286 24.56120 30.57612 29.65539 28.62259\n[2,] 28.97442 28.04833 20.20616 14.93800 24.06997 29.96459 29.06228 28.05014\n       [,73]   [,74]    [,75]    [,76]    [,77]    [,78]    [,79]    [,80]\n[1,] 30.5701 17.0702 16.56888 21.85629 20.59761 21.46445 24.19590 36.10662\n[2,] 29.9587 16.7288 16.23751 21.41917 20.18566 21.03516 23.71199 35.38449\n        [,81]    [,82]    [,83]    [,84]    [,85]    [,86]    [,87]    [,88]\n[1,] 33.96684 27.40384 16.72593 14.25868 20.21827 31.23118 25.26411 33.85720\n[2,] 33.28751 26.85577 16.39141 13.97350 19.81390 30.60655 24.75883 33.18005\n        [,89]    [,90]    [,91]    [,92]    [,93]    [,94]    [,95]    [,96]\n[1,] 29.27159 20.44659 24.65205 24.70663 28.30399 18.50158 25.47180 23.12485\n[2,] 28.68615 20.03766 24.15901 24.21249 27.73791 18.13155 24.96236 22.66235\n        [,97]    [,98]    [,99]   [,100]\n[1,] 15.32872 29.48873 24.24794 38.14298\n[2,] 15.02215 28.89896 23.76298 37.38012\n\n\nВновь взглянем на первую сотню пар значений: в первой строке расчёты по формуле выборочной дисперсии, во второй — по формуле дисперсии генеральной совокупности. Заметим, что значения в первой строке всегда больше, чем значения во второй. Оно и понятно — так устроены формулы. При этом числа в обеих строках вновь плюс-минус собираются около 25 — значения параметра генеральной совокупности.\nИзобразим картину для большей наглядности:\n\n\n\n\n\n\n\n\n\nКрасной сплошной линией здесь вновь отображен параметр генеральной совокупности. Несложно пронаблюдать, что среднее выборочных дисперсий — чёрная пунктирная линия — [практически] совпадает с красной. Следовательно, формула дисперсии для выборки действительно даёт несмещённую оценку. Теперь обратим внимание на синюю пунктирную линию — среднее оценок дисперсии по формуле для генеральной совокупности. Она не совпадает с красной. Более того, если мы посмотрим на распределение — синяя сплошная линия — то заметим, что оно сдвинуто в сторону относительно чёрного распределения. Это нам говорит о том, что формула для генерального среднего систематически промахивается, что и является выражением смещённости оценки.\nТаким образом, при оценке дисперсии по выборке используется Уравнение 4.2, поскольку именно оно даёт несмещённую оценку параметра генеральной совокупности.\n\n\n4.6.2 Степени свободы\nЧисло \\(n-1\\) в 4.2 называется количеством степеней свободы. Это довольно мутное понятие, которое при этом непозволительно часто встречается в статистике. Попытаемся к нему хотя бы интуитивно подойти.\nСразу возникает разумный вопрос: почему \\(n-1\\)? Почему не \\(n-2\\) или \\(n+6\\)?\nЭто число с неизбежностью появляется в расчетах при математическом способе исследования несмещённости оценки дисперсии. Как говорилось выше, в математику мы здесь нырять не будем, однако можно помыслить обоснование следующим образом.\nВзглянем на формулу дисперсии: в неё входит среднее арифметическое. То есть для того, чтобы рассчитать дисперсию на выборке, сначала нам необходимо на этой же выборке рассчитать среднее. Мы получаем часть информации о выборке, тем самым как бы «фиксируя» её этим средним значением.\nВ каком смысле «фиксируя»? Рассчитанное среднее могло получиться многими способами — разные значения наблюдений могли сложиться в одно и то же среднее. До расчета среднего число свободно варьирующихся наблюдений в выборке было \\(n\\), то есть все имеющиеся значения. Однако когда среднее стало известно, возможность варьирования уменьшилась. Теперь свободно варьирующихся наблюдений стало \\(n-1\\), так как при известном среднем произвольно могут измениться все наблюдения, кроме одного — всегда можно будет его вычислить, зная выборочное среднее и все предыдущие.\nИначе говоря, теперь одно из наблюдений не является случайным, а значит не участвует в формировании дисперсии выборки. По этой причине оно исключается из расчетов, и в формуле дисперсии появляется \\(n-1\\).\nО степенях свободы можно думать ещё и так: для расчета дисперсии мы посчитали одну статистику — среднее арифметическое, значит из числа наблюдений надо вычесть единицу. В общем-то это то же, что и излагалось выше, только в предельно укороченном варианте.\nВпрочем, это не так далеко от истины — позже мы стокнемся со случаями, когда для расчета мер изменчивости необходимо будет рассчитывать две, три и более статистик, и тогда количество степеней свободы будет соответственно \\(n-2\\), \\(n-3\\) и \\(n-p\\).",
    "crumbs": [
      "Описательная статистика",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Меры разброса</span>"
    ]
  },
  {
    "objectID": "desc-variation.html#variation-sd",
    "href": "desc-variation.html#variation-sd",
    "title": "4  Меры разброса",
    "section": "4.7 Стандартное отклонение",
    "text": "4.7 Стандартное отклонение\nИ вот мы получили невероятное! У нас есть формула расчета меры разброса, которая позволяет учесть каждое значение переменной! Ну, не чудо ли!\nЧудо, конечно. Однако есть некоторая проблема. Мы возводили отклонения в квадрат. Представим, что мы хотим посчитать дисперсию роста студентов психфака. Пусть мы измеряли рост в метрах. Отклонения тоже будут в метрах, так как среднее — это тоже метры, а если из метров вычитать метры, то мы получим метры. При возведении же метров в квадрат получаются метры в квадрате. Очевидно, что если мы поделим квадратные метры на некоторое число, они все еще останутся метрами в квадрате.\nМы знаем, что в квадратных метрах измеряется, например, площадь, однако едва ли можно говорить о разбросе роста как о площади. Что-то тут нелогичное получается. К тому же, если мы возьмем не рост, а скажем, время реакции, то его дисперсия будет измеряться в квадратных секундах. Это уже вовсе за рамками всевозможных приличий…\nА счастье было так близко, так возможно! Неужели мы не сможем интерпретировать эту меру разброса? Не сможем даже нарисовать?\nДа, но это не очень большая беда. Для того, чтобы вернуться к исходным единицам измерения нашей переменной, нам всего лишь нужно извлечь корень из дисперсии:\n\\[\n\\sigma_X = \\sqrt{\\sigma^2_X} =\n\\sqrt{\\frac{1}{n} \\sum_{i=1}^n d^2} =\n\\sqrt{\\frac{1}{n} \\sum_{i=1}^n (\\overline X - x_i)^2}\n\\]\nМы получили величину, называемую стандартным (средним квадратичным3) отклонением (standard deviation).\nЧем она хороша? Тем, что её размерность совпадает с размерностью нашей переменной. Стандартное отклонение уже может быть достаточно интерпретабельно и хорошо визуализируемо.\nКстати, формула выше — это стандартное отклонение генеральной совокупности, потому что под корнем стоит дисперсия генеральной совокупности.\nЧтобы посчитать стандартное отклонение по выборке, нам надо извлечь корень из выборочной дисперсии:\n\\[\ns_X = \\sqrt{s^2_X} = \\sqrt{\\frac{1}{n-1} \\sum_{i=1}^n d^2} = \\sqrt{\\frac{1}{n-1} \\sum_{i=1}^n(\\overline X - x_i)^2}\n\\]",
    "crumbs": [
      "Описательная статистика",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Меры разброса</span>"
    ]
  },
  {
    "objectID": "desc-variation.html#variation-comparison",
    "href": "desc-variation.html#variation-comparison",
    "title": "4  Меры разброса",
    "section": "4.8 Сравнение мер разброса",
    "text": "4.8 Сравнение мер разброса\nКак и разные меры центральной тенденции, разные меры разброса по-своему хороши. Более того, они «дружат» с мерами центральной тенденции. Так, с медианой обычно используется межквартильный размах, а со средним арифметическим — стандартное отклонение.\nРазмах подходит для всего сразу. Его стоит рассчитать, чтобы составить самое первое представление о разбросе, о границах изменения изучаемого признака [на нашей выборке].\nСтоит также отметить, что все, что мы тут обсуждали, совершенно не годится для номинативных переменных. Однако у них тоже есть вариативность. Согласитесь, что выборка из Питера, Москвы, и Казани более вариативна, чем выборка из Москвы. Аналогом меры разброса для номинальной переменной можно назвать количество уникальных значений этой переменной.",
    "crumbs": [
      "Описательная статистика",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Меры разброса</span>"
    ]
  },
  {
    "objectID": "desc-variation.html#variation-disp-features",
    "href": "desc-variation.html#variation-disp-features",
    "title": "4  Меры разброса",
    "section": "4.9 Свойства дисперсии и стандартного отклонения",
    "text": "4.9 Свойства дисперсии и стандартного отклонения\nМы рассмотрим два свойства дисперсии и два свойства стандартного отклонения, непосредственно следующих из свойств дисперсии.\n\nУтверждение 4.1 Если к каждому значению распределения прибавить некоторое число (константу), то дисперсия распределения не изменится.\n\\[\nD_{X+c} = D_X\n\\]\n\n\nДоказательство. \\[\n\\begin{split}\nD_{X+c} &=\\frac{1}{n} \\sum_{i=1}^n \\big( (\\overline X + c) - (x_i + c) \\big)^2 = \\\\\n&= \\frac{1}{n} \\sum_{i=1}^n (\\overline X + c - x_i - c)^2 = \\\\\n&= \\frac{1}{n} \\sum_{i=1}^n (\\overline X - x_i)^2 = D_X\n\\end{split}\n\\]\n\n\nСледствие 4.1 Если к каждому значению распределения прибавить некоторое число (константу), то стандартное отклонение не изменится.\n\\[\n\\sigma_{X+c} = \\sigma_X\n\\]\n\n\nДоказательство. \\[\n\\sigma_{X+c} = \\sqrt{\\sigma^2_{X+c}} = \\sqrt{D_{X+c}} = \\sqrt{D_X} = \\sqrt{\\sigma^2_X} = \\sigma_X\n\\]\n\n\nУтверждение 4.2 Если каждое значение распределения умножить на некоторое число (константу), то дисперсия изменится в \\(c^2\\) раз.\n\\[\nD_{X \\times c} = D_X \\times c^2\n\\]\n\n\nДоказательство. \\[\n\\begin{split}\nD_{X \\times c} &=\\frac{1}{n} \\sum_{i=1}^n \\big( (\\overline X \\times c) - (x_i \\times c) \\big)^2 = \\\\\n&= \\frac{1}{n} \\sum_{i=1}^n c^2 \\times (\\overline X - x_i)^2 = \\\\\n&= c^2 \\times \\frac{1}{n} \\sum_{i=1}^n (\\overline X - x_i)^2 = \\\\\n&= c^2 \\times D_X\n\\end{split}\n\\]\n\n\nСледствие 4.2 Если каждое значение распределения умножить на некоторое число (константу), то стандартное отклонение изменится во столько же раз.\n\\[\n\\sigma_{X \\times c} = \\sigma_X \\times c\n\\]\n\n\nДоказательство. \\[\n\\sigma_{X \\times c} = \\sqrt{\\sigma^2_{X \\times c}} = \\sqrt{D_{X \\times c}} = \\sqrt{c^2 \\times D_X} = c \\times \\sqrt{D_X} = c \\times \\sqrt{\\sigma^2_X} = c \\times \\sigma_X\n\\]\n\nПроиллюстрировать свойства дисперсии довольно трудно, поскольку на графиках её отобразить весьма проблематично, однако для стандартного отклонения картинки нарисовать можно. Собственно, мы их уже видели, когда обсуждали свойства среднего арифметического (см. Утверждение 3.1 и Утверждение 3.2).\nДля следствия 4.1 визуализация будет такой:\n\n\n\n\n\n\n\n\n\nКак мы уже видели, распределение просто сдвигается на константу. Если к каждому значению синего распределения прибавить \\(2\\), получится красное — разброс у обоих распределений одинаковый.\nДля следствия 4.2 визуализация выглядит так:\n\n\n\n\n\n\n\n\n\nЗдесь каждое значение синего распределения умножили на \\(3\\) и получили красное — разброс также увеличился в три раза, поэтому распределение более плоское.",
    "crumbs": [
      "Описательная статистика",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Меры разброса</span>"
    ]
  },
  {
    "objectID": "desc-variation.html#footnotes",
    "href": "desc-variation.html#footnotes",
    "title": "4  Меры разброса",
    "section": "",
    "text": "Обычно это так, хотя не обязательно — иногда боксплоты рисуют горизонтально, если это лучше отображает закономерности.↩︎\nНо если мы рисуем несколько боксплотов рядом, то на оси \\(x\\) будет категориальная переменная.↩︎\nВзгляните в предыдущую главу. Как и было обещано, мы увиделись с одним из других средних.↩︎",
    "crumbs": [
      "Описательная статистика",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Меры разброса</span>"
    ]
  },
  {
    "objectID": "desc-normdist.html",
    "href": "desc-normdist.html",
    "title": "5  Нормальное распределение",
    "section": "",
    "text": "5.1 Распределение признаков в генеральной совокупности\nМы научились описывать эмпирическое распределение переменных — то есть распределение, которое получено на выборке. Но ведь в генеральной совокупности наши переменные тоже каким-то образом распределены. Уделим внимание и этому вопросу.\nМожем ли мы знать наверняка, как распределен признак в генеральной совокупности?\nНет.\nОднако мы можем предполагать некоторое теоретическое распределение признака. На основе чего мы можем сделать такое предположение? Конечно же, на основе собранных данных, то есть на основании выборки. Большой выборки. Очень большой выборки. Большого количества очень больших выборок.\nТеоретических распределений существует много — и они разные по форме, по параметрам, которыми они задаются, по величинам, которые ими можно описывать и т. д. Однако есть одно распределение, которое стало невероятно популярным и крайне широко используемым — нормальное распределение. Его мы и будем рассматривать.",
    "crumbs": [
      "Описательная статистика",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Нормальное распределение</span>"
    ]
  },
  {
    "objectID": "desc-normdist.html#нормальное-распределение",
    "href": "desc-normdist.html#нормальное-распределение",
    "title": "5  Нормальное распределение",
    "section": "5.2 Нормальное распределение",
    "text": "5.2 Нормальное распределение\nТот факт, что некоторая величина распределена согласно закону нормального распределения (normal distribution), записывается следующим образом:\n\\[\nX \\thicksim \\mathcal{N}(\\mu, \\sigma^2)\n\\]\nЗдесь \\(X\\) — некоторая случайная величина (переменная), \\(\\mathcal{N}\\) — обозначение нормального распределения, \\(\\mu\\) и \\(\\sigma^2\\) — параметры нормального распределения.\n\n5.2.1 Параметры нормального распределения\nИтак, в скобках указаны параметры распределения — как можно видеть, их всего два. На самом деле, мы их уже хорошо знаем:\n\n\\(\\mu\\) — это не что иное, как среднее,\n\\(\\sigma^2\\) — дисперсия.\n\nЭти два параметра входят в формулу, описывающую график функции плотности вероятности нормального распределения:\n\\[\nf(x) = \\frac{1}{\\sigma \\sqrt{2\\pi}} e ^{- \\frac{(x-\\mu)^2}{2 \\sigma^2}}, \\quad x \\in \\mathbb{R}, \\mu \\in \\mathbb{R}, \\sigma \\in \\mathbb{R}_{&gt;0}\n\\]\nА сам график выглядит вот так:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 5.1: Общий вид нормального распределения\n\n\n\nИ мы его уже тоже много раз видели.\n\n\n\n\n\n\nПочему все так любят нормальное распределение?\n\n\n\n\nЕго очень давно знают. Карл Фридрих Гаусс (1777–1855) исчерпывающе его исследовал, и теперь про это распределение известно всё. И ещё чуть более.\nРяд статистических методов, называемых параметрическими, требуют, чтобы распределение изучаемых переменных подчинялось нормальному закону.\n\nСейчас, строго говоря, это уже не совсем так. Появляются новые исследования и симуляции, показывающие, что это далеко не ключевое требование.\n\nС помощью нормального распределения определяют статистические нормы. Например, в образовательном тестировании, психодиагностике и иногда клинической практике.\nНа основании нормального распределения рассчитывается стандартная ошибка среднего — важная оценка в статистике.\nНа основании нормального распределения, а точнее — стандартной ошибки — рассчитываются доверительные интервалы среднего — одна из ключевых оценок в статистике.\n\n\n\n\n\n5.2.2 Форма нормального распределения и параметры\nОчевидно, что раз у распределения есть какие-то параметры, значит они каким-то образом на него влияют. Не менее очевидно, что среднее \\(\\mu\\) будет задавать положение центра колокола на оси \\(x\\), а дисперсия \\(\\sigma^2\\) — ширину колокола. Ниже представлены несколько нормальных распределений c различными параметрами:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 5.2: Вид функции плотности нормального распределения при различных параметрах\n\n\n\n\n\n5.2.3 Стандартные отклонения и вероятности\nКак уже упоминалось выше, нормальное распределение изучено вдоль и поперек. В том числе, посчитаны вероятности попадания значений в определенные интервалы. Вот они:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 5.3: Нормальное распределение и вероятности\n\n\n\nКонкретно с этими вероятностями мы работаем реже — полезнее оказывается знать следующие:\n\\[\n\\begin{split}\n&\\mathbb{P} \\big( X \\in (\\mu - \\sigma, \\mu + \\sigma) \\big) = 68.2\\% \\\\\n&\\mathbb{P} \\big( X \\in (\\mu - 2\\sigma, \\mu + 2\\sigma) \\big) = 95.6\\% \\\\\n&\\mathbb{P} \\big( X \\in (\\mu - 3\\sigma, \\mu + 3\\sigma) \\big) = 99.8\\%\n\\end{split}\n\\tag{5.1}\\]\nТо есть\n\nв пределах одного стандартного отклонения от среднего значения лежит почти 70% значений — это очень частотные значения;\nв пределах двух стандартных отклонений от среднего значения лежит 95% значений — бо́льшая часть выборки;\nв пределах трех стандартных отклонений от среднего значения лежит практически 100% выборки — практически вся выборка.\n\nЧто нам это дает?\n\nВо-первых, еще один способ определения выбросов (нехарактерных значений).\n\nНапример, так как за границы двух стандартных отклонений попадает всего 5% значений, мы можем считать, что эти значения — нехарактерные и назвать их выбросами. - Либо же можем быть более либеральными и сказать, что выбросы для нас — значения, которые выходят за пределы трех стандартных отклонений. Главное обосновать, почему мы так считаем.\n\nВо-вторых, так мы можем определять статистические нормы.\n\nНапример, мы разрабатываем клинический опросник (типа MMPI какого-нибудь), и нам надо выяснить, какие значения на шкалах итогового балла будут являться «нормой», а какие «патологией». Мы собираем большую репрезентативную выборку (скажем, по России или по странам СНГ), строим распределение итогового балла по каждой из шкал опросника, и определяем границы нормы — пусть это будет \\(\\mu \\pm 3\\sigma\\).\nТеперь, когда новый респондент пройдет наш опросник, мы сможем сказать относительно его тестового балла, соответствует ли он нормативным границам или не соответствует.\nОтмечу еще раз: здесь мы говорим только о статистической норме — о таких значениях, которые чаще всего встречаются в выборке. Это только один из возможных вариантов определения нормы.\n\n\nВ целом, это всё, что нам надо знать про нормальное распределение.",
    "crumbs": [
      "Описательная статистика",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Нормальное распределение</span>"
    ]
  },
  {
    "objectID": "desc-normdist.html#стандартизация",
    "href": "desc-normdist.html#стандартизация",
    "title": "5  Нормальное распределение",
    "section": "5.3 Стандартизация",
    "text": "5.3 Стандартизация\nНормальных распределение существует много, и пример тому Рисунок 5.2. Однако среди всех нормальных распределений одно выделяется особо.\n\n5.3.1 Стандартное нормальное распределение\nНормальное распределение со средним \\(0\\) и дисперсией \\(1\\) называется стандартным нормальным распределением (standard normal distribution), или \\(z\\)-распределением. Значения на шкале такого распределения называются \\(z\\)-значениями.\n\\[\nz \\thicksim \\mathcal{N}(0, 1)\n\\]\nВыглядит оно так:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 5.4: Вид стандартного нормального распределения\n\n\n\nРазумеется, так как стандартное нормальное распределение является частным случаем нормального распределения, оно сохраняет все его свойства.\n\n\n5.3.2 Стандартизация\nЧасто возникает следующая задача: нам нужно сравнить, например, баллы по шкалам двух опросников, при этом разброс баллов на шкале различный. Более того, сами распределения баллов по этим шкалам могут быть также различны.\nРассмотрим следующий пример. Мы дали респондентам два опросника на измерение личностных черт — BFI-2 (по модели «Большая пятерка») и SD3 (по модели «Тёмная триада»). Допустим, что мы хотим сравнить баллы некоторого респондента по шкалам Нейротизм из BFI-2 и Нарциссизм из SD3. Вопрос будет простой: по какой из двух шкал респондент набрал больший балл?\nДанные говорят, что этот респондент набрал \\(31\\) балл по обеим шкалам. Собственно, а в чём тогда вопрос? Ясно же, что баллов набрано по обеим шкалам одинаково. Или всё же нет…\nШкалы BFI-2 состоят из двенадцати пунктов, а шкалы SD3 — из девяти. И даже учитывая, что отвечали респонденты в обоих случаях по пятибалльной шкале Ликерта, суммарный балл по шкалам опросника будет иметь разные пределы изменчивости (Рисунок 5.5). Описательные статистики — например, среднее и стандартное отклонение — будут также различны (Таблица 5.1).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 5.5: Распределения баллов по шкалам опросников. BFI2_NEU — шкала Нейротизм опросника BFI-2, SD3_NAR — шкала Нарциссизм опросника SD3.\n\n\n\n\n\n\nТаблица 5.1: Описательные статистики распределений баллов по шкалам опросников. BFI2_NEU — шкала Нейротизм опросника BFI-2, SD3_NAR — шкала Нарциссизм опросника SD3.\n\n\n\n\n\n\n\n\n\n\n\n\nШкала\nКоличество пунктов\nКоличество респондентов\nСреднее\nСтандартное отклонение\n\n\n\n\nBFI2_NEU\n12\n492\n36.34\n9.41\n\n\nSD3_NAR\n9\n492\n26.94\n6.95\n\n\n\n\n\n\nВ силу разного разброса значение одни и те же значения будут находится в разных частях распределений. В частности, внимательно присмотревшись к описательным статистикам (Таблица 5.1) можно заметить, что значение \\(31\\) меньше среднего для шкалы BFI2-NEU и больше среднего для шкалы SD3_NAR. Это, безусловно, полезная информация, однако хотелось бы найти какой-то единый способ для сравнения значений из различных распределений. Такой способ есть — нам необходимо стандартизировать случайный величины.\n\nОпределение 5.1 Стандартизация — преобразование случайной величины, в результате которого среднее её распределения становится равным \\(0\\), а стандартное отклонение — \\(1\\).\n\\[\nz_i = \\frac{x_i - \\overline X}{s_X},\n\\tag{5.2}\\]\nгде \\(z_i\\) — значение стандартизированной случайной величины, \\(x_i\\) — значение исходной случайной величины, \\(\\overline X\\) — среднее исходной случайной величины, \\(s_X\\) — стандартное отклонение исходной случайной величины.\n\nПолученные стандартизированные значения также часто называют \\(z\\)-значениями. В этом есть довольно понятный смысл, ведь если изначально переменная была распределена нормально — \\(X \\thicksim \\mathcal{N}(\\mu, \\sigma^2)\\) — то стандартизированная случайная величина будет подчиняться стандартному нормальному распределению — \\(z \\thicksim \\mathcal{N}(0, 1)\\).\nПосмотрим на процедуру стандартизации детально, благо деталей всего две — числитель и знаменатель (см. Уравнение 5.2). Стандартизация состоит из двух операций:\n\nцентрирование — то, что происходит в числителе — обращает среднее в ноль (см. Утверждение 3.1),\nнормирование — то, что происходит в знаменателе — обращает стандартное отклонение в единицу (см. Следствие 4.2).\n\nПосмотрим на две операции отдельно на примере стандартизации какого-то нормального распределения.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 5.6: Стандартизация, центрирование, нормирование. Пунктирная линия — стандартное нормальное распределение, точечная линия — исходное распределение.\n\n\n\nНа рисунке 5.6 черной линией представлено исходное нормальное распределение \\(\\mathcal{N}(-1,0.25)\\) [слева сверху]. Если его центрировать, то оно подвинется вправо — \\(x_i - \\overline X\\) — и получится синее распределение \\(\\mathcal{N}(0, 0.25)\\) [справа сверху]. Если нормировать исходное распределение, то оно станет несколько шире — \\(\\frac{x_i}{s_X}\\) — как зелёное \\(\\mathcal{N}(-1,1)\\) [слева снизу]. А если осуществить обе операции вместе — \\(\\frac{x_i - \\overline X}{s_X}\\) — это и будет стандартизация, и распределение совпадет сo стандартным нормальным распределением [справа снизу].\n\n\n\n\n\n\nСтандартизация не меняет форму распределения!\n\n\n\nВ реальной ситуации никто не может нам гарантировать, что выборочное распределение обязательно будет нормальным. Вообще-то на выборке может случится всё, что угодно.\nИногда можно услышать такое утверждение: «стандартизация приводит произвольное распределение к стандартному нормальному» — что совершеннейшая неправда. Вернитесь к определению 5.1 и убедить, что там нет ни слова про нормальность распределений.\nРассмотрим пару примеров. Пусть исходное распределение асимметрично (Рисунок 5.7). Стандартизировав его, мы получим распределение со средним \\(0\\) и стандартным отклонением \\(1\\), однако его форма совершенно не изменилась.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 5.7: Стандартизация асимметричного распределения\n\n\n\nТеперь возьмем бимодальное распределение, и пронаблюдаем ровно ту же ситуацию — форма распределения вновь не изменилась (Рисунок 5.8).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 5.8: Стандартизация бимодального распределения\n\n\n\n\n\nВернёмся же, наконец, к нашей исходной задаче: мы собирались ответить на вопрос по какой из двух шкал респондент набрал больший балл, при этом данные нам говорят, что респондент набрал \\(31\\) балл по обеим шкалам. Найдём стандартизированное значение по формуле 5.2 взяв значения среднего и стандартного отклонения из таблицы 5.1. Получим\n\\[\n\\begin{split}\nz_\\text{BFI2_NEU} &= \\frac{31 - 36.34}{9.41} \\approx -0.57 \\\\\nz_\\text{SD3_NAR} &= \\frac{31 - 29.94}{6.95} \\approx 0.58\n\\end{split}\n\\]\nТаким образом, мы можем сказать, что наш респондент набрал более высокий балл по шкале нарциссизма.\n\n\n5.3.3 Интерпретация z-значений\nмогут быть более типичны или же менее типичны.\nНу, хорошо, стандартизацию мы сделали — это не то чтобы очень сложно. Но как с этими числами дальше работать?\nЗдесь надо понять всего одну вещь: единица z-шкалы — это стандартное отклонение исходной переменной.\nКонечно, z-шкала безразмерная, то есть не имеет единиц измерения (метры, секунды, года и др.). Однако единица — в смысле\n1 — на этой шкале небессмысленна. Это мера типичности.\nПосмотрим еще раз на картинку:\nОбратим внимание вот на что:\n1 ,\n2 ,\n3 и\n− 1 ,\n− 2 ,\n− 3 находятся в тех самых точках, где у нас в другом нормальной распределении стандартные отклонения ( σ ,\n2 σ ,\n3 σ ). А мы помним вот что:\nP ( X ∈ ( μ − σ , μ + σ ) ) = 68.2 %\nP ( X ∈ ( μ − 2 σ , μ + 2 σ ) ) = 95.6 %\nP ( X ∈ ( μ − 3 σ , μ + 3 σ ) ) = 99.8 %\nТо есть z-значения в интервале\n( − 1 , 1 ) — очень типичные, в интервалах\n( − 2 , − 1 ) и\n( 1 , 2 ) — тоже достаточно типичные, в интервалах\n( − 3 , − 2 ) и\n( 2 , 3 ) — менее типичные, но еще «нормальные», меньше\n− 3 и больше\n3 — очень нетипичные. Это и есть мера типичности.\nТаким образом, с помощью z-значений мы можем понять, где находится наш испытуемый / респондент на нашем распределении.\nМожно ли это понять без перевода значений в z-шкалу? Можно. Но неудобно. Надо держать в голове среднее, стандартное отклонение конкретного распределения, а если сравниваем респондентов по нескольким шкалам, то по две характеристики для каждой шкалы — в общем, много инфы. Трудно. А по z-значениям все сразу понятно.\nЕсть еще одно применение z-значений. От них можно перейти к значениям любой стандартной шкалы. Стандартных шкал существует много — Sten, Stanine, T-score, IQ-score… С ними вы познакомитесь в курсе психометрики. Они очень удобны для представления результатов тестов конечным пользователям. Однако для того, чтобы перейти к этим шкалам, сначала необходимо будет все равно перейти к z-значениям.",
    "crumbs": [
      "Описательная статистика",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Нормальное распределение</span>"
    ]
  },
  {
    "objectID": "desc-ci.html",
    "href": "desc-ci.html",
    "title": "6  Доверительные интервалы",
    "section": "",
    "text": "6.1 Точечные и интервальные оценки\nДо этого момента мы работали только с точечными оценками — это оценки, представляющие собой одно число. Например, таковы меры центральной тенденции — медиана, среднее арифметическое — или меры разброса — межквартильный размах, дисперсия, стандартное отклонение. Когда мы рассчитываем каждый из этих показателей мы получаем только одно число.\nОднако поскольку мы имеет дело со статистическими данными, основные свойства которых это неопределенность и вариативность, нам необходимы, помимо точечных оценок, ещё и интервальные оценки.\nНапомним кратко себе, что\nТаким образом, мы не можем быть до конца уверены, что мы получили суперточную оценку изучаемых нами параметров. Даже если мы пользуемся достаточно точными измерительными инструментами, собираем большие выборки и вообще делаем всё, чтобы быть максимально точными и объективными. Возникает необходимость найти какие-то способы выражения нашей неуверенности в точечной оценки параметра генеральной совокупности. Это и есть интервальные оценки — по сути, меры нашей неуверенности.\nЧтобы к ним подойти, нам придется познакомиться с одной важной статистической теоремой.",
    "crumbs": [
      "Описательная статистика",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Доверительные интервалы</span>"
    ]
  },
  {
    "objectID": "desc-normdist.html#normdist-normdist",
    "href": "desc-normdist.html#normdist-normdist",
    "title": "5  Нормальное распределение",
    "section": "5.2 Нормальное распределение",
    "text": "5.2 Нормальное распределение\nТот факт, что некоторая величина распределена согласно закону нормального распределения (normal distribution), записывается следующим образом:\n\\[\nX \\thicksim \\mathcal{N}(\\mu, \\sigma^2)\n\\]\nЗдесь \\(X\\) — некоторая случайная величина (переменная), \\(\\mathcal{N}\\) — обозначение нормального распределения, \\(\\mu\\) и \\(\\sigma^2\\) — параметры нормального распределения.\n\n5.2.1 Параметры нормального распределения\nИтак, в скобках указаны параметры распределения — как можно видеть, их всего два. На самом деле, мы их уже хорошо знаем:\n\n\\(\\mu\\) — это не что иное, как среднее,\n\\(\\sigma^2\\) — дисперсия.\n\nЭти два параметра входят в формулу, описывающую график функции плотности вероятности нормального распределения:\n\\[\nf(x) = \\frac{1}{\\sigma \\sqrt{2\\pi}} e ^{- \\frac{(x-\\mu)^2}{2 \\sigma^2}}, \\quad x \\in \\mathbb{R}, \\mu \\in \\mathbb{R}, \\sigma \\in \\mathbb{R}_{&gt;0}\n\\]\nА сам график выглядит вот так:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 5.1: Общий вид нормального распределения\n\n\n\nИ мы его уже тоже много раз видели.\n\n\n\n\n\n\nПочему все так любят нормальное распределение?\n\n\n\n\nЕго очень давно знают. Карл Фридрих Гаусс (1777–1855) исчерпывающе его исследовал, и теперь про это распределение известно всё. И ещё чуть более.\nРяд статистических методов, называемых параметрическими, требуют, чтобы распределение изучаемых переменных подчинялось нормальному закону.\n\nСейчас, строго говоря, это уже не совсем так. Появляются новые исследования и симуляции, показывающие, что это далеко не ключевое требование.\n\nС помощью нормального распределения определяют статистические нормы. Например, в образовательном тестировании, психодиагностике и иногда клинической практике.\nНа основании нормального распределения рассчитывается стандартная ошибка среднего — важная оценка в статистике.\nНа основании нормального распределения, а точнее — стандартной ошибки — рассчитываются доверительные интервалы среднего — одна из ключевых оценок в статистике.\n\n\n\n\n\n5.2.2 Форма нормального распределения и параметры\nОчевидно, что раз у распределения есть какие-то параметры, значит они каким-то образом на него влияют. Не менее очевидно, что среднее \\(\\mu\\) будет задавать положение центра колокола на оси \\(x\\), а дисперсия \\(\\sigma^2\\) — ширину колокола. Ниже представлены несколько нормальных распределений c различными параметрами:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 5.2: Вид функции плотности нормального распределения при различных параметрах\n\n\n\n\n\n5.2.3 Стандартные отклонения и вероятности\nКак уже упоминалось выше, нормальное распределение изучено вдоль и поперек. В том числе, посчитаны вероятности попадания значений в определенные интервалы. Вот они:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 5.3: Нормальное распределение и вероятности\n\n\n\nКонкретно с этими вероятностями мы работаем реже — полезнее оказывается знать следующие:\n\\[\n\\begin{split}\n&\\mathbb{P} \\big( X \\in (\\mu - \\sigma, \\mu + \\sigma) \\big) = 68.2\\% \\\\\n&\\mathbb{P} \\big( X \\in (\\mu - 2\\sigma, \\mu + 2\\sigma) \\big) = 95.6\\% \\\\\n&\\mathbb{P} \\big( X \\in (\\mu - 3\\sigma, \\mu + 3\\sigma) \\big) = 99.8\\%\n\\end{split}\n\\tag{5.1}\\]\nТо есть\n\nв пределах одного стандартного отклонения от среднего значения лежит почти 70% значений — это очень частотные значения;\nв пределах двух стандартных отклонений от среднего значения лежит 95% значений — бо́льшая часть выборки;\nв пределах трех стандартных отклонений от среднего значения лежит практически 100% выборки — практически вся выборка.\n\nЧто нам это дает?\n\nВо-первых, еще один способ определения выбросов (нехарактерных значений).\n\nНапример, так как за границы двух стандартных отклонений попадает всего 5% значений, мы можем считать, что эти значения — нехарактерные и назвать их выбросами. - Либо же можем быть более либеральными и сказать, что выбросы для нас — значения, которые выходят за пределы трех стандартных отклонений. Главное обосновать, почему мы так считаем.\n\nВо-вторых, так мы можем определять статистические нормы.\n\nНапример, мы разрабатываем клинический опросник (типа MMPI какого-нибудь), и нам надо выяснить, какие значения на шкалах итогового балла будут являться «нормой», а какие «патологией». Мы собираем большую репрезентативную выборку (скажем, по России или по странам СНГ), строим распределение итогового балла по каждой из шкал опросника, и определяем границы нормы — пусть это будет \\(\\mu \\pm 3\\sigma\\).\nТеперь, когда новый респондент пройдет наш опросник, мы сможем сказать относительно его тестового балла, соответствует ли он нормативным границам или не соответствует.\nОтмечу еще раз: здесь мы говорим только о статистической норме — о таких значениях, которые чаще всего встречаются в выборке. Это только один из возможных вариантов определения нормы.\n\n\nВ целом, это всё, что нам надо знать про нормальное распределение.",
    "crumbs": [
      "Описательная статистика",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Нормальное распределение</span>"
    ]
  },
  {
    "objectID": "desc-normdist.html#normdist-stand",
    "href": "desc-normdist.html#normdist-stand",
    "title": "5  Нормальное распределение",
    "section": "5.3 Стандартизация",
    "text": "5.3 Стандартизация\nНормальных распределение существует много, и пример тому Рисунок 5.2. Однако среди всех нормальных распределений одно выделяется особо.\n\n5.3.1 Стандартное нормальное распределение\nНормальное распределение со средним \\(0\\) и дисперсией \\(1\\) называется стандартным нормальным распределением (standard normal distribution), или \\(z\\)-распределением. Значения на шкале такого распределения называются \\(z\\)-значениями.\n\\[\nz \\thicksim \\mathcal{N}(0, 1)\n\\]\nВыглядит оно так:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 5.4: Вид стандартного нормального распределения\n\n\n\nРазумеется, так как стандартное нормальное распределение является частным случаем нормального распределения, оно сохраняет все его свойства.\n\n\n5.3.2 Стандартизация\nЧасто возникает следующая задача: нам нужно сравнить, например, баллы по шкалам двух опросников, при этом разброс баллов на шкале различный. Более того, сами распределения баллов по этим шкалам могут быть также различны.\nРассмотрим следующий пример. Мы дали респондентам два опросника на измерение личностных черт — BFI-2 (по модели «Большая пятерка») и SD3 (по модели «Тёмная триада»). Допустим, что мы хотим сравнить баллы некоторого респондента по шкалам Нейротизм из BFI-2 и Нарциссизм из SD3. Вопрос будет простой: по какой из двух шкал респондент набрал больший балл?\nДанные говорят, что этот респондент набрал \\(31\\) балл по обеим шкалам. Собственно, а в чём тогда вопрос? Ясно же, что баллов набрано по обеим шкалам одинаково. Или всё же нет…\nШкалы BFI-2 состоят из двенадцати пунктов, а шкалы SD3 — из девяти. И даже учитывая, что отвечали респонденты в обоих случаях по пятибалльной шкале Ликерта, суммарный балл по шкалам опросника будет иметь разные пределы изменчивости (Рисунок 5.5). Описательные статистики — например, среднее и стандартное отклонение — будут также различны (Таблица 5.1).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 5.5: Распределения баллов по шкалам опросников. BFI2_NEU — шкала Нейротизм опросника BFI-2, SD3_NAR — шкала Нарциссизм опросника SD3.\n\n\n\n\n\n\nТаблица 5.1: Описательные статистики распределений баллов по шкалам опросников. BFI2_NEU — шкала Нейротизм опросника BFI-2, SD3_NAR — шкала Нарциссизм опросника SD3.\n\n\n\n\n\n\n\n\n\n\n\n\nШкала\nКоличество пунктов\nКоличество респондентов\nСреднее\nСтандартное отклонение\n\n\n\n\nBFI2_NEU\n12\n492\n36.34\n9.41\n\n\nSD3_NAR\n9\n492\n26.94\n6.95\n\n\n\n\n\n\nВ силу разного разброса значение одни и те же значения будут находится в разных частях распределений. В частности, внимательно присмотревшись к описательным статистикам (Таблица 5.1) можно заметить, что значение \\(31\\) меньше среднего для шкалы BFI2-NEU и больше среднего для шкалы SD3_NAR. Это, безусловно, полезная информация, однако хотелось бы найти какой-то единый способ для сравнения значений из различных распределений. Такой способ есть — нам необходимо стандартизировать случайный величины.\n\nОпределение 5.1 Стандартизация — преобразование случайной величины, в результате которого среднее её распределения становится равным \\(0\\), а стандартное отклонение — \\(1\\).\n\\[\nz_i = \\frac{x_i - \\overline X}{s_X},\n\\tag{5.2}\\]\nгде \\(z_i\\) — значение стандартизированной случайной величины, \\(x_i\\) — значение исходной случайной величины, \\(\\overline X\\) — среднее исходной случайной величины, \\(s_X\\) — стандартное отклонение исходной случайной величины.\n\nПолученные стандартизированные значения также часто называют \\(z\\)-значениями. В этом есть довольно понятный смысл, ведь если изначально переменная была распределена нормально — \\(X \\thicksim \\mathcal{N}(\\mu, \\sigma^2)\\) — то стандартизированная случайная величина будет подчиняться стандартному нормальному распределению — \\(z \\thicksim \\mathcal{N}(0, 1)\\).\nПосмотрим на процедуру стандартизации детально, благо деталей всего две — числитель и знаменатель (см. Уравнение 5.2). Стандартизация состоит из двух операций:\n\nцентрирование — то, что происходит в числителе — обращает среднее в ноль (см. Утверждение 3.1),\nнормирование — то, что происходит в знаменателе — обращает стандартное отклонение в единицу (см. Следствие 4.2).\n\nПосмотрим на две операции отдельно на примере стандартизации какого-то нормального распределения.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 5.6: Стандартизация, центрирование, нормирование. Пунктирная линия — стандартное нормальное распределение, точечная линия — исходное распределение.\n\n\n\nНа рисунке 5.6 черной линией представлено исходное нормальное распределение \\(\\mathcal{N}(-1,0.25)\\) [слева сверху]. Если его центрировать, то оно подвинется вправо — \\(x_i - \\overline X\\) — и получится синее распределение \\(\\mathcal{N}(0, 0.25)\\) [справа сверху]. Если нормировать исходное распределение, то оно станет несколько шире — \\(\\frac{x_i}{s_X}\\) — как зелёное \\(\\mathcal{N}(-1,1)\\) [слева снизу]. А если осуществить обе операции вместе — \\(\\frac{x_i - \\overline X}{s_X}\\) — это и будет стандартизация, и распределение совпадет сo стандартным нормальным распределением [справа снизу].\n\n\n\n\n\n\nСтандартизация не меняет форму распределения!\n\n\n\nВ реальной ситуации никто не может нам гарантировать, что выборочное распределение обязательно будет нормальным. Вообще-то на выборке может случится всё, что угодно.\nИногда можно услышать такое утверждение: «стандартизация приводит произвольное распределение к стандартному нормальному» — что совершеннейшая неправда. Вернитесь к определению 5.1 и убедить, что там нет ни слова про нормальность распределений.\nРассмотрим пару примеров. Пусть исходное распределение асимметрично (Рисунок 5.7). Стандартизировав его, мы получим распределение со средним \\(0\\) и стандартным отклонением \\(1\\), однако его форма совершенно не изменилась.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 5.7: Стандартизация асимметричного распределения\n\n\n\nТеперь возьмем бимодальное распределение, и пронаблюдаем ровно ту же ситуацию — форма распределения вновь не изменилась (Рисунок 5.8).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 5.8: Стандартизация бимодального распределения\n\n\n\n\n\nВернёмся же, наконец, к нашей исходной задаче: мы собирались ответить на вопрос по какой из двух шкал респондент набрал больший балл, при этом данные нам говорят, что респондент набрал \\(31\\) балл по обеим шкалам. Найдём стандартизированное значение по формуле 5.2 взяв значения среднего и стандартного отклонения из таблицы 5.1. Получим\n\\[\nz_\\mathrm{BFI2.NEU} = \\frac{31 - 36.34}{9.41} \\approx -0.57\n\\] \\[\nz_\\mathrm{SD3.NAR} = \\frac{31 - 29.94}{6.95} \\approx 0.58\n\\]\nТаким образом, мы можем сказать, что наш респондент набрал более высокий балл по шкале нарциссизма.\n\n\n5.3.3 Интерпретация z-значений\nХорошо, мы сделали стандартизацию — довольно простая процедура. Но как с этими числами дальше работать? Можно ли из них выжать больше смысла, чем просто сравнение?\nЗдесь надо понять всего одну вещь:\n\n\n\n\n\n\nединица \\(z\\)-шкалы — это стандартное отклонение исходной переменной\n\n\n\nКонечно, \\(z\\)-шкала безразмерная, то есть не имеет единиц измерения (метры, секунды, года и др.). Однако единица — в смысле \\(1\\) — на этой шкале небессмысленна. Это мера типичности.\nВзглянем ещё раз на рисунок 5.4. Обратим внимание вот на что: \\(1\\), \\(2\\) \\(3\\) и \\(-1\\), \\(-2\\), \\(-3\\) находятся в тех самых точках, где в другом нормальном распределении находятся стандартные отклонения (\\(\\mu \\pm \\sigma\\), \\(\\mu \\pm 2\\sigma\\), \\(\\mu \\pm 3\\sigma\\)). Мы также знаем, что этим диапазонам соответствуют вероятности, с которыми значения случайных величин оказываются в этих диапазонах (Уравнение 5.1).\nТо есть мы можем говорить, что \\(z\\)-значения\n\nв интервале \\((-1,1)\\) — очень типичные, поскольку лежат в пределах одного стандартного отклонения от среднего,\nв интервалах \\((-2, -1)\\) и \\((1,2)\\) — тоже достаточно типичные, поскольку лежат в пределах двух стандартных отклонений от среднего,\nв интервалах \\((-3, -2)\\) и \\((2,3)\\) — менее типичные, но еще «нормальные», так как лежат в пределах трёх стандартных отклонений от среднего,\nменьшие \\(-3\\) и большие \\(3\\) — очень нетипичные, так как выходят за пределы трёх стандартных отклонений от среднего.\n\nЭто и есть мера типичности.\nТаким образом, с помощью \\(z\\)-значений мы можем быстро понять, где находится испытуемый или респондент на имеющемся распределении.\nМожно ли это понять без перевода значений в \\(z\\)-шкалу? Можно. Но неудобно. Надо держать в голове среднее и стандартное отклонение конкретного распределения, а если сравниваем респондентов по нескольким шкалам, то по две характеристики для каждой шкалы, постоянно пересчитывая диапазоны — в общем, слишком много инфы. Трудно.\n\n\n5.3.4 Применение стандартизации\nПомимо обсужденного выше, есть ещё одно применение \\(z\\)-значений. От них можно перейти к значениям любой другой стандартной шкалы, выполнив преобразование, обратное 5.2. Стандартных шкал существует много — Sten, Stanine, T-score, IQ-score… С ними вы познакомитесь в курсе психометрики. Они оказываются очень удобными для представления результатов тестов конечным пользователям. Однако для того, чтобы перейти к этим шкалам, сначала все равно будет необходимо перейти к \\(z\\)-значениям.\nКроме того, стандартизация также используется в некоторых статистических методах, когда нам необходимо уравнять дисперсии переменных. Поскольку после стандартизации дисперсия переменной всегда будет равна единице, такая процедура отлично подходит для этой задачи.",
    "crumbs": [
      "Описательная статистика",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Нормальное распределение</span>"
    ]
  },
  {
    "objectID": "desc-ci.html#центральная-предельная-теорема",
    "href": "desc-ci.html#центральная-предельная-теорема",
    "title": "6  Доверительные интервалы",
    "section": "6.2 Центральная предельная теорема",
    "text": "6.2 Центральная предельная теорема\nПожалуй, сразу бахнем формулировку, а потом будем разбираться, что она означает.\nCумма достаточно большого количества слабо зависимых случайных величин, имеющих примерно одинаковые масштабы (ни одно из слагаемых не доминирует, не вносит в сумму определяющего вклада), имеет распределение, близкое к нормальному.\nИтак, пусть есть некоторый параметр в генеральной совокупности, который асимметрично распределён. Возьмем случай именно асимметричого распределения, чтобы более наглядно увидеть эффект. Допустим, выглядит это как-то так:\nВот такая красивая штука у нас есть в генеральной совокупности. На всякий случай отмечу, то это некоторое теоретическое распределение — вообще-то мы не знаем наверняка, что там в генеральной совокупности творится. Но вот будем думать, что там что-то такое.\nПонятно, что наш параметр, наш параметр, наша случайная величина имеет некоторое среднее и некоторый разброс в генеральной совокупности:\nValue mean 0.4 sd 0.2 Ну, вот какие-то такие.\nЧтобы максимально точно приблизиться к оценке нашего параметра — будем оценивать среднее генеральной совокупности — нам надо извлечь много больших выборок из нашей генеральной совокупности. Ну, допустим мы извлекаем 1000 выборок по 50 наблюдений. Можно и больше, но давайте посмотрим пока, что будет на таких значениях.\nПосмотрим на распределения нашей переменной в нескольких из выборок:\nВот распределения в первых шестнадцати выборках. На что здесь стоит обратить внимание?\nОт выборки к выборки распределения отличаются. Причем достаточно сильно — где-то распределение больше похоже на нормальное, где-то оно более асимметричное, где-то менее, где-то вообще напоминает равномерное. Это мы в живую увидели вариативность и неопределенность. Каждая из выборок характеризуется каким-то своим средним и каким-то своим разбросом. Вот таблица: Sample Mean SD 1 0.4202292 0.2044323 2 0.3892443 0.2037850 3 0.3861993 0.2224778 4 0.3774064 0.1952898 5 0.4172960 0.2081190 6 0.3616459 0.2052460 7 0.4703232 0.2111924 8 0.4075789 0.2011449 9 0.4141822 0.2018535 10 0.4245290 0.2087136 11 0.3893637 0.1911761 12 0.3778744 0.1983516 13 0.4130055 0.2144898 14 0.3661605 0.1807597 15 0.3956731 0.1963239 16 0.3860937 0.2003544\nВидим, что есть некоторая вариативность выборочных средних. Но раз у нас есть 1000 выборок — а значит и 1000 средних — мы можем построить распределение выборочных средних.\nМы получили распределение выборочных средних значений, которое хотя и не очень похоже на нормальное в данном конкретном случае, но как минимум стало почти симметричным! Вот об этом и говорит центральная предельная теорема.\nБолее того, если мы посчитаем среднее и стандартное отклонение данного распределения, мы получим следующее:\nValue mean 0.3995205 sd 0.0285545 Обратите внимание, на сколько точную оценку генерального среднего мы получили! Да еще и такой ничтожный разброс! Ну, красота!\nТакже нужно обратить внимание еще на две важные детали:\nчем большее количество выборок мы наберем, тем ближе распределение будет к нормальном и тем более точную оценку среднего мы получим чем большее количество наблюдений будет в отдельной выборке, тем ближе распределение будет к нормальном и тем более точную оценку среднего мы получим Увидеть, как это работает, можно здесь.\nИтак, независимо от того, какое распределение переменной есть в генеральной совокупности, при извлечении достаточно большого количества выборок достаточно большого объема мы можем получить очень точную оценку среднего генеральной совокупности, а распределение выборочных средних будет стремиться к нормальному.\nС другими параметрами это также работает. Такие вот статистические приколы.",
    "crumbs": [
      "Описательная статистика",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Доверительные интервалы</span>"
    ]
  },
  {
    "objectID": "desc-ci.html#стандартная-ошибка-среднего",
    "href": "desc-ci.html#стандартная-ошибка-среднего",
    "title": "6  Доверительные интервалы",
    "section": "6.3 Стандартная ошибка среднего",
    "text": "6.3 Стандартная ошибка среднего\nПосмотрим на стандартное отклонение выборочных средних (пунктирная линия на графике — среднее выборочных средних, точечные линии — ± одно стандартное отклонение).\nЭто стандартное отклонение имеет собственное название — стандартная ошибка среднего (standard error of mean).\nЭто одна из интервальных оценок для среднего — в пределах\n[ ¯¯¯ ¯ x − s e ( ¯ x ) , ¯¯¯ ¯ x + s e ( ¯ x )] 1 лежит 68.2% выборочных средних.\nЗадумаемся. Это что же, чтобы рассчитать стандартную ошибку среднего нам каждый раз придется собирать 100500 выборок??7? Нет. Рассчитать стандартную ошибку среднего можно и по одной выборке вот так:\n\\[\n\\text{se}_X = \\frac{s_X}{\\sqrt{n}},\n\\]\nгде \\(s_X\\) — это выборочное стандартное отклонение, а \\(n\\) — количество наблюдений в данной выборке.\nФормула, прямо скажем, не то чтобы очень интуитивна, однако вам придется мне поверить, что она верна.\n\n\n\n\n\n\nЯ недоверчив(а)\n\n\n\n\n\nДля того, чтобы доказать формулу, нам понадобятся два утверждения. С одним мы хорошо знакомы (Утверждение 4.2):\n\\[\nD_{X \\times c} = D_X \\times c^2\n\\]\nВторое утверждение говорит нам, чему равна дисперсия суммы случайных величин — тут вам точно придется мне просто поверить, иначе эта глава никогда не закончится:\n\\[\nD_{X + Y} = D_X + D_Y + 2 \\text{cov}_{X,Y},\n\\]\n\\(\\text{cov}_{X,Y}\\) — это ковариация двух случайных величин, мера их взаимной изменчивости. Мы будем обсуждать её в курсе позже, сейчас она для нас не столь существенна.\nТак как мы предполагает, что выборки мы набирали независимо и из одной и той же генеральной совокупности, то величины в каждой из выборок независимы и [теоретически] одинаково распределены (independent identically distributed, i.i.d.) (для упрощения жизни здесь рассмотрено нормальное распределение):\n\\[\nX_i \\overset{\\text{i.i.d.}}{\\thicksim} \\mathcal{N} (\\mu, \\sigma^2)\n\\]\nВ частности, в силу независимости случайный величин их ковариация равна нулю. Поэтому дисперсия распределения выборочных средних — то есть суммы средних наших исходных случайных величин \\(X_i\\) — будет определяться так:\n\\[\n\\begin{split}\nD \\big( \\sum_{i=1}^n \\frac{1}{n} X_i \\big) &=\nD \\big( \\frac{1}{n} \\sum_{i=1}^n X_i \\big) = \\\\\n&= \\frac{1}{n^2} \\sum_{i=1}^n D(X_i) = \\\\\n&= \\frac{1}{n^2} \\sum_{i=1}^n \\sigma^2 = \\frac{1}{n^2} \\cdot n \\sigma^2 = \\\\\n& = \\frac{n}{n^2} \\sigma^2 = \\frac{\\sigma^2}{n}\n\\end{split}\n\\]\nА значит, стандартное отклонение этого распределения — оно же стандартная ошибка среднего — будет таким:\n\\[\n\\text{se}_X = \\sqrt{\\frac{\\sigma^2}{n}} = \\frac{\\sigma}{\\sqrt{n}}\n\\]\nМагия статистических допущений.\n\n\n\nСтандартная ошибка используется и сама по себе как одна из описательных статистик. Однако также на её основе рассчитывается другая интервальная оценка.",
    "crumbs": [
      "Описательная статистика",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Доверительные интервалы</span>"
    ]
  },
  {
    "objectID": "desc-ci.html#доверительные-интервалы",
    "href": "desc-ci.html#доверительные-интервалы",
    "title": "6  Доверительные интервалы",
    "section": "6.4 Доверительные интервалы",
    "text": "6.4 Доверительные интервалы\nЕще раз вспомним о том, что стандартная ошибка — это не что иное как стандартное отклонение [выборочных средних]. Также вспомним, что главой ранее мы определяли, с какой вероятностью лежит значение нашей случайной величины в пределах скольких-либо стандартных отклонений. Это вот эта картинка (здесь z-распределение):\nМожем ли мы через стандартное отклонение выразить такой интервал, в котором будет лежать, скажем, 95% значений величины? Да.\nНа стандартном нормальной распределении это будет интервал\n[ − 1.96 , 1.96] . А чтобы перейти к размерности интересующей нас переменной, надо выполнить преобразование, обратное стандартизации — умножить на стандартное отклонение и прибавить/вычесть среднее. То есть, интервал, в котором с вероятностью 0.95 будут лежать значения распределения выборочных средних будет таков —\n[ ¯ x − 1.96 × s e , ¯ x + 1.96 × s e] .\nЭтот интервал называется 95%-ный доверительный интервал (95% confidence interval, 95% CI). Он является второй интервальной оценкой среднего и мерой нашей неуверенности относительно точности оценки среднего генеральной совокупности.\nВообще можно рассчитать любой доверительный интервал, который вам захочется, однако самые популярные варианты — это 90%, 95% и 99%. Выражаются через стандартную ошибку они так:\n90 % : ¯ x ± 1.645 × s e 95 % : ¯ x ± 1.96 × s e 99 % : ¯ x ± 2.576 × s e\nНаиболее широко в социальных науках используется 95%-ный. Им и будем пользоваться.\n\n6.4.1 Интерпретация границ доверительного интервала\nТеперь еще одна непростая задача — понять, что значит этот интервал.\nГлядя на график распределения выборочных средних, хочется сказать, что генеральное среднее лежит в граница 95%-ного доверительного интервала (вертикальные линии) с вероятностью 0.95.\nНо это не верно!!!\n\n\n\n\n\n\nСтатистика в отдельном исследовании\n\n\n\nОтметим, что та статистика, которую мы изучаем — фреквентистская статистика — рассматривает любые полученные в ходе исследования результаты с точки зрения принципиальной возможности бесконечно повторять проведённое исследование. Значения статистических показателей также интерпретируются с этой позиции.\n\n\nЗдесь мы вплотную подошли к тестированию статистических гипотез. Неприятность в том, что мы живем во фреквентистском подходе. Подробнее мы будем говорить об этом в следующей главе, а пока же попытаемся смириться с тем, что в даннм подходе расчеты, полученные на конкретных данных, позволяют нам говорить только о том, что будет происходит далее, если мы будем извлекать новые выборки и пользоваться теми же расчетами.\nДавайте на примере самого доверительного интервала. Корректная статистическая интерпретация звучит так:\nЕсли мы будет бесконечно извлекать новые выборки из генеральной совокупности, рассчитывать на них средние и 95% доверительные интервалы к ним, то генеральное среднее попадёт в границы 95% таких доверительных интервалов.\nТо есть, если мы извлечем 100 выборок, посчитаем на каждой из них среднее и построим 95% доверительный интервал к каждому из 100 средних, то 95 доверительных интервалов из 100 будут содержать генеральное среднее — а 5 интервалов содержать его не будут.\nВизуализацию этого можно наблюдать здесь.\nКорректная статистическая интерпретация, конечно, корректная, однако трудноусваемая и сложноприменяемая в жизни. Попробуем сделать её более осязаемой. Есть два путя.\nСамый простой, но крайне некорректный. Если, ну, прям ваще никак не получается уложить статистическую интерпретацию, то можно думать о доверительном интервале так: «генеральное среднее, скорее всего, лежит где-то в этих пределах». Однако в приличных местах об этом говорить никому не стоит. И даже когда соберетесь прибегнуть к такой интерпретации, обязательно сначала вспомните, что она некорректная! Более корректный вариант. К подобной интерпретации также есть некоторые вопросы, однако по крайней мере она обоснована симуляциями. Дело в том, что статистики задались вопросом — а какова все же вероятность, что генеральное среднее попадет вот в этот конкретный рассчитанный нами здесь и сейчас доверительный интервал. Насимулировали там всякого и пришли к выводу, что эта вероятность равна 84.3%. Эту величину назвали capture percentage — то есть отдельный 95% доверительный интервал «ловит» генеральной среднее 843 раза из 1000. Конечно, я всячески рекомендую помедитировать над статистически корректной интерпретаций доверительного интервала и попробовать её осознать, позалипав на визуализацию. Если же это пока trudnovato, постарайтесь осмыслить второй вариант с capture percentage.\n\n\n6.4.2 Доверительный интервал и сравнение средних\nЧем нам может помочь интервальная оценка при поиске различий между группами? Посмотрим на возможные ситуации. Пусть у нас есть средние и доверительные интервалы к ним в двух группах наблюдений — например, балл по шкале депрессии HADS у жителей Москвы и Петербурга.\nПервоначально попробуем выяснить, справедливо ли утверждение «у жителей столиц нет клинически выраженной депрессии». Для этого необходимо, чтобы средний балл был меньше 11. Рассмотрим картинки.\nМы наблюдаем, что в случае Москвы интересующее нас значение 11 не попадает в доверительный интервал, в то время как в случае Петербурга — попадает. Поскольку доверительный интервал отображает нашу неуверенность в том, что наше выборочное среднее отражает генеральное среднее, для нас все значения в пределах доверительного интервала статистически равны между собой. Таким образом, так как 11 не попадает в 95%-ный доверительный интервал для Москвы, мы можем на уровне доверия 0.95 сказать, что средний уровень депрессии жителей Москвы ниже порога клинически выраженной депрессии. Про петербуржцев такого сказать не получится, так как 11 попало в доверительный интервал для Петербурга — а значит, средний уровень депресии 8.5 статистически равен 11, хотя по абсолютному значению ниже. Такая вот статистическая магия.\nЕще раз:\nесли некоторое число попадает в доверительный интервал для выборочного среднего, то мы говорим, что среднее статистически не отличается от этого числа — даже если по абсолютным значениям разница существенна; если некоторое число не попадает в доверительный интервал для выборочного среднего, то мы говорим, что среднее статистически отличается от этого числа — и больше или меньше в зависимости от абсолютных значений. Однако сравнивать выборочное среднее с некоторым числом — крайне маргинальная задача. Обычно мы сравниваем две группы между собой. Посмотрим на ситуации, которые принципиально возможны при сравнении средних в двух группах.\nПо оси\nx — группы наблюдений, по оси\ny — значение интересующей нас переменной. Видим четыре возможные ситуации:\nА — каждое среднее попадает в доверительный интервал другого среднего B — одно среднее попадает в доверительный интервал другого среднего, а второе — не попадает в данном случае, среднее второй группы попадо в доверительный интервал среднего первой группы, в то время как среднее первой группы лежит за границами доверительного интервала среднего второй группы С — ни одно из средних не попало в доверительный интервал другого среднего но мы видим пересечение доверительных интервалов D — доверительные интервалы не пересекаются, следовательно, ни одно из средних не попало в доверительный интервал другого среднего Исходя из рассуждений выше, можно отметить, что если хотя бы одно среднее попало в доверительный интервал другого — случаи A и B — то различий между группами нет. А вот если среднии не попадают в доверительные интервал друг друга — случаи C и D — то различия между группами есть.\nТакие дела.\n\n\n6.4.3 Связь доверительного интервала с разбросом и объемом выборки\nТак как доверительный интервал рассчитывается на основе стандартной ошибки, которая в свою очередь рассчитывается на основе стандартного отклонения и числа наблюдений, нетрудно заметить, что:\nЧем выше разброс в данных, тем будет шире доверительный интервал [так как больше стандартная ошибка] Чем больше наблюдений в нашей выборке, тем будет уже доверительный интервал [так как меньше стандартная ошибка] На этом — ура! — мы заканчиваем изучение описательной статистики! Впереди нас ждёт знакомство со статистическим выводом!",
    "crumbs": [
      "Описательная статистика",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Доверительные интервалы</span>"
    ]
  },
  {
    "objectID": "desc-ci.html#точечные-и-интервальные-оценки",
    "href": "desc-ci.html#точечные-и-интервальные-оценки",
    "title": "6  Доверительные интервалы",
    "section": "",
    "text": "Неопределенность статистических данных означает, что мы никогда не знаем, что мы получим в результате данного конкретного измерения.\n\nво-первых, потому что мы работаем со случайными величинами,\nво-вторых, потому что наши измерительные инструменты не идеальны и всегда содержат ошибку измерения.\n\nВариативность статистических данных говорит нам о том, что наши измерения всегда обладают некоторым разбросом.\n\nво-первых, потому что объекты нашего изучения — люди — разные,\nво-вторых, потому наши измерительные инструменты всё ещё не идеальны и всегда содержат ошибку измерения.",
    "crumbs": [
      "Описательная статистика",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Доверительные интервалы</span>"
    ]
  },
  {
    "objectID": "desc-ci.html#ci-clt",
    "href": "desc-ci.html#ci-clt",
    "title": "6  Доверительные интервалы",
    "section": "6.2 Центральная предельная теорема",
    "text": "6.2 Центральная предельная теорема\nДля построения интервальных оценок параметров используют центральную предельную теорему. Сформулировать её можно так.\n\nТеорема 6.1 Центральная предельная теорема (ЦПТ). Cумма достаточно большого количества слабо зависимых одинаково распределенных случайных величин имеет распределение, близкое к нормальному.\n\nОднако нас будет интересовать не столько сама теорема, сколько одно из её следствий.\n\nСледствие 6.1 Если \\(X_1, \\, X_2, \\, \\ldots, X_n\\) — независимые одинаково распределённые случайные величины со средним \\(\\mu\\) и дисперсией \\(\\sigma^2\\), то при увеличении их числа распределение средних этих случайных величин имеет распределение, близкое к нормальному со средним \\(\\mu\\) и дисперсией \\(\\dfrac{\\sigma^2}{n}\\) (стандартным отклонением \\(\\dfrac{\\sigma}{\\sqrt{n}}\\)):\n\\[\nX_i \\overset{\\text{i.i.d}}{\\thicksim} (\\mu, \\sigma^2) \\Rightarrow \\overline X_i \\overset{d}{\\to} \\mathcal{N} \\bigg( \\mu, \\frac{\\sigma^2}{n} \\bigg)\n\\]\n\nФормулировка следствия довольно сложна. Давайте подумаем, чем она соответствует в области исследовательской практики.\n\nКогда мы проводим исследование, мы извлекаем выборку из генеральной совокупности.\nНа этой выборке мы измеряем какую-либо переменную \\(X\\).\nПусть на этой выборке мы получили случайную величину \\(X_1\\), измерив интересующая нас переменную.\nПовторив исследование несколько раз — допустим, \\(n\\) — на других выборках из той же генеральной совокупности, мы получим случайные величины \\(X_2,\\, X_3,\\, \\ldots X_n\\).\nПоскольку все выборки приходили из одной и той же генеральной совокупности, распределения всех случайных величин будут иметь одни и те же параметры — то есть наши случайные величины будут одинаково распределены.\nТак как выборки извлекались отдельно для каждого исследования, получившиеся случайные величины оказываются независимы.\n\nТаким образом, [следствие] ЦПТ рассматривает поведение распределения выборочных средних при многократном повторении исследования. По сути, это та же ситуация, которую мы рассматривали при обсуждении несмещённости точечных оценок.\nИтак, пусть есть некоторая случайная величина \\(X\\), распределение которой в генеральной совокупности асимметрично. Случай асимметричного распределения удобен для рассмотрения, поскольку эффект, описываемый ЦПТ можно увидеть более наглядно. Допустим, выглядит это как-то так:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 6.1: Распределение случайной величины в генеральной совокупности\n\n\n\nОткуда мы знаем, что случайная величина распределена так? Ниоткуда. В рамках симуляции, которой мы сейчас будем заниматься мы просто рассматриваем такой случай. Разумеется, в реальной ситуации мы может сделать только допущение о распределении величины генеральной совокупности — как она распределена на самом деле мы никогда не узнаем.\nПонятно, что это распределение будет обладать неким средним и некоторым стандартным отклонением — в нашем случае значения будут такими:\n\n\n\nТаблица 6.1: Параметры распределения случайной величины в генеральной совокупности\n\n\n\n\n\nПараметр распределения\nЗначение\n\n\n\n\nСреднее\n0.4\n\n\nСтандартное отклонение\n0.2\n\n\n\n\n\n\nЧтобы максимально точно приблизиться к оценке нашего параметра — будем оценивать среднее генеральной совокупности — нам надо извлечь много больших выборок из нашей генеральной совокупности. Ну, допустим мы извлекаем 1000 выборок по 50 наблюдений. Можно и больше, но давайте посмотрим пока, что будет на таких значениях.\nПосмотрим на распределения нашей переменной в нескольких из выборок:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 6.2: Распределения случайной величины в первых двадцати выборках\n\n\n\nВот распределения в первых двадцати выборках. На что здесь стоит обратить внимание?\nОт выборки к выборки распределения, безусловно, отличаются. Причем достаточно сильно — где-то распределение больше похоже на нормальное, где-то оно более асимметричное, где-то менее, где-то вообще напоминает равномерное. Это мы в живую увидели вариативность и неопределенность.\nКаждая из выборок характеризуется каким-то своим средним и каким-то своим разбросом (Таблица 6.2).\n\n\n\nТаблица 6.2: Выборочные средние и стандарные отклонения первых двадцати выборок\n\n\n\n\n\n\n\nSample\nMean\nSD\n\n\n\n\nV1\n0.37\n0.18\n\n\nV2\n0.35\n0.22\n\n\nV3\n0.40\n0.20\n\n\nV4\n0.40\n0.21\n\n\nV5\n0.42\n0.22\n\n\nV6\n0.35\n0.20\n\n\nV7\n0.38\n0.15\n\n\nV8\n0.36\n0.23\n\n\nV9\n0.45\n0.21\n\n\nV10\n0.34\n0.20\n\n\nV11\n0.40\n0.20\n\n\nV12\n0.38\n0.22\n\n\nV13\n0.39\n0.19\n\n\nV14\n0.35\n0.19\n\n\nV15\n0.42\n0.22\n\n\nV16\n0.44\n0.22\n\n\nV17\n0.33\n0.21\n\n\nV18\n0.43\n0.23\n\n\nV19\n0.39\n0.20\n\n\nV20\n0.39\n0.20\n\n\n\n\n\n\n\n\nВидим, что есть некоторая вариативность выборочных средних. Но раз у нас есть 1000 выборок — а значит и 1000 средних — мы можем построить распределение выборочных средних (Рисунок 6.3).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 6.3: Распределение выборочных средних\n\n\n\nМы получили распределение выборочных средних значений, которое очень похоже на нормальное — эмпирическое распределение отображено с помощью гистограммы, а ожидаемое теоретическое с помощью чёрной линии. Вот об этом и говорит центральная предельная теорема.\nБолее того, если мы посчитаем среднее и стандартное отклонение данного распределения, мы получим следующее (Таблица 6.3).\n\n\n\nТаблица 6.3: Параметры распределения выборочных средних\n\n\n\n\n\nПараметры\nЗначение\n\n\n\n\nСреднее (M)\n0.4\n\n\nСтандартное отклонение (SD)\n0.03\n\n\n\n\n\n\nТакже нужно обратить внимание еще на две важные детали:\n\nчем большее количество выборок мы наберем, тем ближе распределение будет к нормальному и тем более точную оценку среднего мы получим\nчем большее количество наблюдений будет в отдельной выборке, тем ближе распределение будет к нормальному и тем более точную оценку среднего мы получим\n\nЗдесь можно посмотреть динамическую симуляцию, изучить роль количества выборок и количества наблюдений в формировании итогового распределения средних.\n\n\n\n\n\n\nИтак, независимо от того, какое распределение переменной есть в генеральной совокупности, при извлечении достаточно большого количества выборок достаточно большого объема мы можем получить очень точную оценку среднего генеральной совокупности, а распределение выборочных средних будет стремиться к нормальному.",
    "crumbs": [
      "Описательная статистика",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Доверительные интервалы</span>"
    ]
  },
  {
    "objectID": "desc-ci.html#ci-se",
    "href": "desc-ci.html#ci-se",
    "title": "6  Доверительные интервалы",
    "section": "6.3 Стандартная ошибка среднего",
    "text": "6.3 Стандартная ошибка среднего\nСобственно, а зачем нам это надо было?\nПосмотрим на стандартное отклонение выборочных средних (Рисунок 6.4).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 6.4: Стандартная ошибка среднего. Точечная линия — среднее выборочных средних, пунктирные линии — плюс-минус одно стандартное отклонение.\n\n\n\nПоскольку ЦПТ обеспечила нам возможность пользоваться свойствами нормального распределения, то в пределах одного стандартного отклонения от среднего средних будет лежать 68.2% выборочных средних (Рисунок 5.3 и Уравнение 5.1). Таким образом, мы получаем диапазон, в пределах которого лежат наиболее часто встречающиеся выборочные средние, а значит это может служить интервальной оценкой нашего параметра — он называется стандартной ошибкой среднего.\n\nОпределение 6.1 Стандартная ошибка среднего (\\(\\text{se}\\)) — стандартное отклонение распределения выборочных средних.\n\nТеперь задумаемся о следующем: чтобы получить стандартную ошибку, мы сгенерировали 1000 выборок, однако в рамках отдельного исследования мы работаем только с одной выборкой — значит ли это, что мы не сможем посчитать стандартную ошибку, чтобы получить интервальную оценку среднего?\nНет. Рассчитать стандартную ошибку среднего можно и по одной выборке вот так:\n\\[\n\\text{se}_X = \\frac{s_X}{\\sqrt{n}},\n\\tag{6.1}\\]\nгде \\(s_X\\) — это выборочное стандартное отклонение, а \\(n\\) — количество наблюдений в данной выборке.\nФормула, прямо скажем, не то чтобы очень интуитивна, однако вам придется мне поверить, что она верна.\n\n\n\n\n\n\nЯ недоверчив(а)\n\n\n\n\n\nДля того, чтобы доказать формулу, нам понадобятся два утверждения. С одним мы хорошо знакомы (Утверждение 4.2):\n\\[\nD_{X \\times c} = D_X \\times c^2\n\\]\nВторое утверждение говорит нам, чему равна дисперсия суммы случайных величин — тут вам точно придется мне просто поверить, иначе эта глава никогда не закончится:\n\\[\nD_{X + Y} = D_X + D_Y + 2 \\text{cov}_{X,Y},\n\\]\n\\(\\text{cov}_{X,Y}\\) — это ковариация двух случайных величин, мера их взаимной изменчивости. Мы будем обсуждать её в курсе позже, сейчас она для нас не столь существенна.\nТак как мы предполагает, что выборки мы набирали независимо и из одной и той же генеральной совокупности, то величины в каждой из выборок независимы и [теоретически] одинаково распределены (independent identically distributed, i.i.d.) (для упрощения жизни здесь рассмотрено нормальное распределение):\n\\[\nX_i \\overset{\\text{i.i.d.}}{\\thicksim} \\mathcal{N} (\\mu, \\sigma^2)\n\\]\nВ частности, в силу независимости случайный величин их ковариация равна нулю. Поэтому дисперсия распределения выборочных средних — то есть суммы средних наших исходных случайных величин \\(X_i\\) — будет определяться так:\n\\[\n\\begin{split}\nD \\big( \\sum_{i=1}^n \\frac{1}{n} X_i \\big) &=\nD \\big( \\frac{1}{n} \\sum_{i=1}^n X_i \\big) = \\\\\n&= \\frac{1}{n^2} \\sum_{i=1}^n D(X_i) = \\\\\n&= \\frac{1}{n^2} \\sum_{i=1}^n \\sigma^2 = \\frac{1}{n^2} \\cdot n \\sigma^2 = \\\\\n& = \\frac{n}{n^2} \\sigma^2 = \\frac{\\sigma^2}{n}\n\\end{split}\n\\]\nА значит, стандартное отклонение этого распределения — оно же стандартная ошибка среднего — будет таким:\n\\[\n\\text{se}_X = \\sqrt{\\frac{\\sigma^2}{n}} = \\frac{\\sigma}{\\sqrt{n}}\n\\]\nМагия статистических допущений.\n\n\n\nСтандартная ошибка используется и сама по себе как одна из описательных статистик. Однако также на её основе рассчитывается другая интервальная оценка.",
    "crumbs": [
      "Описательная статистика",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Доверительные интервалы</span>"
    ]
  },
  {
    "objectID": "desc-ci.html#ci-ci",
    "href": "desc-ci.html#ci-ci",
    "title": "6  Доверительные интервалы",
    "section": "6.4 Доверительные интервалы",
    "text": "6.4 Доверительные интервалы\nЕще раз вспомним о том, что стандартная ошибка — это не что иное как стандартное отклонение [выборочных средних]. Также вспомним, что главой ранее мы определяли, с какой вероятностью лежит значение нашей случайной величины в пределах скольких-либо стандартных отклонений (Рисунок 5.3).\nМожем ли мы через стандартное отклонение выразить такой интервал, в котором будет лежать, скажем, 95% значений величины? Для определенности возьмем стандартное нормальное распределение, и выделим на нём диапазон, в пределах которого лежит 95% значений.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 6.5: Стандартное нормальное распределение. Диапазон, в пределах которого лежит 95% значений.\n\n\n\nМатематически вычислимо, что границы этого интервала будут такими — \\([-1.96, 1.96]\\).\nОкей, но это не совсем то, что нас интересовало. Мы хотели узнать, в каких пределах лежит 95% выборочных средних, если мы знаем их распределение. Воспользуемся известной нам стандартизацией (Уравнение 5.2) — вернее, её обратным преобразованием — и перейдем от z-значений к значениям произвольного распределения:\n\\[\nx_i = z_i \\cdot s_x + \\overline X,\n\\]\nгде \\(z_i\\) — значения стандартного нормального распределения, \\(x_i\\) — значение нового распределения, \\(\\overline X\\) — среднее нового распределения, \\(s_x\\) — стандартное отклонение нового распределения.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 6.6: Доверительный интервал. Точечная линия — среднее выборочных средних, пунктирные линии — доверительный интервал для среднего.\n\n\n\nТаким образом, мы можем перевести границы \\([-1.96, 1.96]\\) в границы на распределении выборочных средних следующим образом:\n\\[\n[\\overline X - 1.96 \\cdot \\text{se}_x, \\, \\overline X + 1.96 \\cdot \\text{se}_x]\n\\tag{6.2}\\]\nВ пределах такого интервала будет лежать 95% выборочных средних.\nОднако на практике мы имеет дело только с одной выборкой, поэтому и интервал будет рассчитываться на основании одного выборочного среднего и стандартного отклонения по выборке. Например, если мы возьмем первую выборку из сгенерированных (Таблица 6.2) и рассчитаем такой интервал для её среднего, получится:\n\\[\n\\begin{split}\n&[\\overline X - 1.96 \\cdot \\text{se}_X, \\, \\overline X + 1.96 \\cdot \\text{se}_X] = \\Big[ \\overline X - 1.96 \\cdot \\frac{s_X}{\\sqrt{n}}, \\, \\overline X + 1.96 \\cdot \\frac{s_X}{\\sqrt{n}} \\Big] = \\\\\n&= \\Big[0.37 - 1.96 \\cdot \\frac{0.18}{\\sqrt{50}}, \\, 0.37 + 1.96 \\cdot \\frac{0.18}{\\sqrt{50}} \\Big] =\n[0.32, \\, 0.42]\n\\end{split}\n\\]\nЭтот интервал называется 95%-ным доверительным интервалом (95% confidence interval, 95% CI). Он является второй интервальной оценкой среднего и мерой нашей неуверенности относительно точности оценки среднего генеральной совокупности.\nВообще можно рассчитать любой доверительный интервал, который вам захочется, однако самые популярные варианты — это 90%, 95% и 99%. Выражаются через стандартную ошибку они так:\n\\[\n\\begin{split}\n90\\%: &\\quad \\overline X \\pm 1.645 \\cdot \\text{se}_x \\\\\n95\\%: &\\quad \\overline X \\pm 1.96 \\cdot \\text{se}_x \\\\\n99\\%: &\\quad \\overline X \\pm 2.576 \\cdot \\text{se}_x\n\\end{split}\n\\]\nНаиболее широко в социальных науках используется 95%-ный. С ним и будем работать.\n\n6.4.1 Интерпретация границ доверительного интервала\nТеперь еще одна непростая задача — понять, что значит этот интервал.\nГлядя на график распределения выборочных средних (Рисунок 6.6) и исходя из того, как интервал был получен, хочется сказать, что генеральное среднее лежит в границах 95%-ного доверительного интервала с вероятностью 0.95.\nНо это не верно!!! Вновь необходимо вспомнить, что в рамках отдельного исследования мы имеем дело только с одной выборкой, и доверительный интервал, рассчитанный на одной выборке, это совершенно не то, что отображает вышеупомянутый график (Рисунок 6.6). Он показывает логику, положенную в механизм расчёта интервала, однако не пригоден для его интерпретации.\n\n\n\n\n\n\nСтатистика в отдельном исследовании\n\n\n\nОтметим, что та статистика, которую мы изучаем — фреквентистская статистика — рассматривает любые результаты с точки зрения принципиальной возможности бесконечно повторять проведённое исследование. Соответственно, корректная интерпретация получаемых статистических штук будет строиться в долгосрочной перспективе повторения исследований.\nТакое положение дел затрудняет интерпретацию результатов отдельного исследования и часто приводит к некорректным выводам, поэтому необходимо уделить вопросу интерпретации отдельное серьезное внимание.\n\n\nДавайте на примере самого доверительного интервала. Корректная статистическая интерпретация звучит так:\n\n\n\n\n\n\nЕсли мы будет бесконечно извлекать новые выборки из генеральной совокупности, рассчитывать на них средние и 95% доверительные интервалы к ним, то генеральное среднее попадёт в границы 95% таких доверительных интервалов.\n\n\n\nТо есть, если мы извлечем 100 выборок, посчитаем на каждой из них среднее и построим 95% доверительный интервал к каждому из 100 средних, то 95 доверительных интервалов из 100 будут содержать генеральное среднее, а 5 интервалов содержать его не будут.\nВ частности, если мы посмотрим, что происходит на сгенерированных ранее выборках (Рисунок 6.2), мы получим следующую картину (Рисунок 6.7).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 6.7: Покрытие генерального среднего доверительными интервалами. Из 1000 доверительных интервалов 966 содержат генеральной среднее, 34 — не содержат.\n\n\n\nДинамическую визуализацию этого можно наблюдать здесь.\nКорректная статистическая интерпретация, конечно, корректная, однако трудноусваемая и сложноприменяемая в практике Попробуем сделать её более осязаемой. Есть три путя.\n\n\n\n\n\n\nСамый простой, но крайне некорректный\n\n\n\nЕсли, ну, прям ваще никак не получается уложить статистическую интерпретацию, то можно думать о доверительном интервале так: «генеральное среднее, скорее всего, лежит где-то в этих пределах».\nОднако в приличных местах об этом говорить никому не стоит. И даже когда соберетесь прибегнуть к такой интерпретации, обязательно сначала вспомните, что она некорректная!\n\n\n\n\n\n\n\n\nСкорректированный вариант\n\n\n\nК подобной интерпретации также есть некоторые вопросы, однако, по крайней мере, она обоснована симуляциями. Задаваться вопросом о вероятности попадания генерального среднего в конкретный рассчитанный нами здесь и сейчас доверительный интервал всё же можно. Симуляции показывают, что эта вероятность приблизительно равна 84.3%. Эту величину назвали capture percentage — то есть отдельный 95% доверительный интервал «ловит» генеральное среднее 843 раза из 1000.\n\n\n\n\n\n\n\n\nПрактически применимый вариант\n\n\n\nЕжели мы всё же посмотрим на Рисунок 6.6 и попробуем вытащить практически пригодную интерпретацию, то мы можем заметить, что в границы доверительного интервала попадают наиболее частотные, типичные значения среднего. Также необходимо вспомнить, что мы работаем с конкретными данными в рамках одного исследования. Исходя из этих двух пунктов, можно сказать, что границы доверительного интервала задают диапазон значений, которые не противоречат имеющимся у нас данным.\nЭта интерпретация хорошо согласуется с NHST-подходом к тестированию статистических гипотез, о котором мы будем говорить далее.\n\n\n\n\n6.4.2 Доверительный интервал и сравнение средних\nЧем нам может помочь интервальная оценка при поиске различий между группами? Посмотрим на возможные ситуации. Пусть у нас есть средние и доверительные интервалы к ним в двух группах наблюдений — например, балл по шкале депрессии HADS у жителей Москвы и Петербурга.\nПервоначально попробуем выяснить, справедливо ли утверждение «у жителей столиц нет клинически выраженной депрессии». Для этого необходимо, чтобы средний балл был меньше 11. Рассмотрим картину.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 6.8: Сравнение выборочного среднего с данным значением через доверительный интервал\n\n\n\nМы наблюдаем, что в случае Москвы интересующее нас значение 11 не попадает в доверительный интервал, в то время как в случае Петербурга — попадает. Поскольку доверительный интервал отображает нашу неуверенность в том, что наше выборочное среднее отражает генеральное среднее, для нас все значения в пределах доверительного интервала статистически равны между собой. Или же можем сказать, что границы доверительного интервала обозначают значения, не противоречащие данным. Таким образом, так как 11 не попадает в 95%-ный доверительный интервал для Москвы, мы можем сказать, что средний уровень депрессии жителей Москвы ниже порога клинически выраженной депрессии. Про петербуржцев такого сказать не получится, так как 11 попало в доверительный интервал для Петербурга — а значит, средний уровень депрессии 8.5 статистически равен 11, хотя по абсолютному значению ниже. Иначе говоря, значение 11 не противоречит имеющимся данным, хотя выборочное среднее и не совпадает с ним.\n\n\n\n\n\n\n\nесли некоторое число попадает в доверительный интервал для выборочного среднего, то мы говорим, что среднее статистически не отличается от этого числа — даже если по абсолютным значениям разница существенна\nесли некоторое число не попадает в доверительный интервал для выборочного среднего, то мы говорим, что среднее статистически отличается от этого числа — и больше или меньше в зависимости от абсолютных значений\n\n\n\n\nОднако чаще мы сравниваем две группы между собой. Посмотрим на ситуации, которые принципиально возможны при сравнении средних в двух группах.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 6.9: Сравнение выборочных средних в двух группах\n\n\n\nПо оси \\(x\\) — группы наблюдений, по оси \\(y\\) — значение интересующей нас переменной. Видим четыре возможные ситуации:\n\nА — каждое среднее попадает в доверительный интервал другого среднего\nB — одно среднее попадает в доверительный интервал другого среднего, а второе — не попадает\n\nв данном случае, среднее второй группы попало в доверительный интервал среднего первой группы, в то время как среднее первой группы лежит за границами доверительного интервала среднего второй группы\n\nС — ни одно из средних не попало в доверительный интервал другого среднего\n\nно есть пересечение доверительных интервалов\n\nD — доверительные интервалы не пересекаются, следовательно, ни одно из средних не попало в доверительный интервал другого среднего\n\nИсходя из рассуждений выше, можно отметить, что если хотя бы одно среднее попало в доверительный интервал другого — случаи A и B — то различий между группами нет. А вот если средние не попадают в доверительные интервалы друг друга — случаи C и D — то различия между группами есть.\n\n\n6.4.3 Связь доверительного интервала с разбросом и объемом выборки\nТак как доверительный интервал рассчитывается на основе стандартной ошибки (Уравнение 6.2), которая в свою очередь рассчитывается на основе стандартного отклонения и числа наблюдений (Уравнение 6.1), нетрудно заметить, что:\n\n\n\n\n\n\n\nчем выше разброс в данных, тем будет шире доверительный интервал, так как больше стандартная ошибка\nчем больше наблюдений в нашей выборке, тем будет у́же доверительный интервал,[так как меньше стандартная ошибка",
    "crumbs": [
      "Описательная статистика",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Доверительные интервалы</span>"
    ]
  },
  {
    "objectID": "infer-stattesting.html",
    "href": "infer-stattesting.html",
    "title": "7  Тестирование статистических гипотез",
    "section": "",
    "text": "7.1 Базовые понятия\nМы затеваем исследование, чтобы проверить какие-либо гипотезы. Поэтому в ходе статистического анализа мы, главным образом, заняты тем, что тестируем статистические гипотезы. Ведь на какого рода вопросы мы отвечаем с помощью анализа?\nИ так далее. Так или иначе, всё сводится к тому, что мы ищем какие-то различия. Но силу того, что у нас неопределённость и вариативность в данных, мы просто так «в лоб» сказать о различиях по оценкам параметров не можем. Приходится тестировать статистические гипотезы.\nГипотезы, как мы знаем, бывают трех видов:\nСтатистические гипотезы бывают простыми и сложными.\nНапример, истинная величина параметра соответствует некоторому строго заданному значению: \\(H: \\theta = \\theta_0\\). Другой вариант — две генеральные совокупности имеют одно и то же значение одной и той же характеристики: \\(H: \\theta_1 = \\theta_2\\).\nВ рамках самого хода тестирования гипотез существует проверяемая (нулевая) гипотеза (\\(H_0\\)). Её обычно стараются предельно упростить, поэтому она чаще всего формулируется как простая гипотеза. В противовес ей выдвигается альтернативная гипотеза (\\(H_1\\)), которая будет иметь, как следствие, вид сложной гипотезы.\nЧто же может случиться в ходе проверки статистической гипотезы?",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Тестирование статистических гипотез</span>"
    ]
  },
  {
    "objectID": "infer-stattesting.html#базовые-понятия",
    "href": "infer-stattesting.html#базовые-понятия",
    "title": "7  Тестирование статистических гипотез",
    "section": "",
    "text": "Определение 7.1 Гипотеза (\\(H\\)) — это предположение, которое подлежит проверке на основе результатов наблюдений.\n\n\n\nТеоретическая — про конструкты\nЭмпирическая — про переменные (зависимые и независимые)\nСтатистическая\n\nс одной стороны, про данные — что мы получили в данный конкретный момент, собрав вот эти конкретные данные\nс другой стороны, про параметры генеральной совокупности — так как мы стремимся всё же изучать их, работая с выборкой\n\n\n\n\nПростая гипотеза — это такое предположение, которое включает в себя какое-либо однозначно определяемое утверждение.\n\n\n\nСложная гипотеза предполагает множественность вариантов для параметра, которые укладываются в рамки проверяемого предположения. Например, \\(H: \\theta &gt; \\theta_0\\) или \\(H: \\theta_1 \\neq \\theta_2\\).",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Тестирование статистических гипотез</span>"
    ]
  },
  {
    "objectID": "infer-stattesting.html#возможные-результаты-проверки-гипотез",
    "href": "infer-stattesting.html#возможные-результаты-проверки-гипотез",
    "title": "7  Тестирование статистических гипотез",
    "section": "7.2 Возможные результаты проверки гипотез",
    "text": "7.2 Возможные результаты проверки гипотез\nМы изучаем в исследовании какую-либо закономерность, которая в реальном мире может существовать, а может и не существовать. В силу неопределённости и вариативности наших данных мы может либо обнаружить интересующую нас закономерность, либо не обнаружить её.\nВ качестве нулевой гипотезы мы выдвигаем предположение о том, что закономерность отсутствует — так мы упрощаем нашу нулевую гипотезу. Пусть \\(H_0\\) обозначает, что предположение об отсутствии закономерности, которое мы проверяем справедливо, а \\(H_1\\) — не справедливо. На основании данных мы можем либо не отклонить наше предположение (\\(\\hat H_0\\)), либо отклонить (\\(\\hat H_1\\)).\nТогда имеем следующую ситуацию (Таблица 7.1).\n\n\n\nТаблица 7.1: Возможные результаты проверки статистических гипотез\n\n\n\n\n\n\n\\(H_0\\)\n\\(H_1\\)\n\n\n\n\n\\(\\hat H_0\\)\n✓\nОшибка II рода\n\n\n\\(\\hat H_1\\)\nОшибка I рода\n✓\n\n\n\n\n\n\nМы видим, что из четырёх возможных ситуаций две нас устраивают — там мы делаем корректный вывод об отсутствии или наличии закономерности. Две другие нас не устраивают, так как мы в этих случаях совершаем ошибки.\n\nОшибка I рода возникает, когда в генеральной совокупности искомой закономерности нет, но мы в силу случайных флуктуаций в данных её нашли.\nОшибка II рода возникает, когда в генеральной совокупности искомая закономерность есть, но мы в силу каких-либо причин её не нашли.\n\nОшибки — это нехорошо, они нас не устраивают. Надо каким-то образом их контролировать.\n\nОшибка I рода контролируется достаточно просто. Так как в ситуации ошибки I рода мы получили некий результат — нашли закономерность, которую искали — мы можем посчитать вероятность, с которой потенциально ошиблись. А собственно контролировать ошибку мы будем с помощью уровня значимости \\(\\alpha\\).\n\nУровень значимости \\(\\alpha\\) выбирается до начала процедуры тестирования гипотезы и задает вероятность, с который мы позволяем себе ошибиться — отклонить нулевую гипотезу, при условии, что она верна.\n\nОшибку II рода контролировать сложнее, так как мы не получили результата — не нашли закономерность, которую искали. Но ситуации ошибки II рода — ложноотрицательного вывода — «противоположна» ситуация истинно положительного вывода — когда мы обнаружили закономерность, при условии, что она есть. Соответственно, нам будет полезна какая-то метрика, которая позволит сказать, что мы сделали всё возможное для того, чтобы обнаружить искомую закономерность.\n\nВероятность ошибки II рода обозначается \\(β\\) — тогда вероятность того, что мы не совершили ошибку II рода будет \\(1-\\beta\\). Эта величина называется статистической мощностью — она связана с размером эффекта и объемом выборки. На основании статистической мощности и ожидаемого размера эффекта можно рассчитать требуемый объем выборки.\n\n\nРазмер эффекта — это оценка величины, или силы, закономерности в генеральной совокупности. О нём мы будем говорить подробнее в последующих главах, так как на примере конкретных статистических методов этот концепт будет более осязаем.\nСоберем все обозначения в единую табличку (Таблица 7.2)1.\n\n\n\nТаблица 7.2: Вероятности ошибок I и  II рода\n\n\n\n\n\n\n\n\n\n\n\n\\(H_0\\)\n\\(H_1\\)\n\n\n\n\n\\(\\hat H_0\\)\n\\(\\mathbb P (\\hat H_0 | H_0)\\)\n\\(\\mathbb P (\\hat H_0 | H_1) = \\beta\\)\n\n\n\\(\\hat H_1\\)\n\\(\\mathbb P (\\hat H_0 | H_0) = \\alpha\\)\n\\(\\mathbb P (\\hat H_1 | H_1) = 1 - \\beta\\)\n\n\n\n\n\n\nУровень значимости \\(\\alpha\\) выбирается близким к нулю — конвенциональным значением для социальных наук считается \\(0.05\\). Вообще \\(\\alpha\\) можно выбрать сколь угодно малым, однако при выборе уровня значимости руководствуются принципом разумной достаточности, так как если устремить \\(\\alpha\\) к нулю, то устремится к нулю и вероятность отклонения нулевой гипотезы.\n\n\n\n\n\n\nМатематические руны\n\n\n\n\n\n\\[\n\\mathbb P (\\hat H_1) = \\mathbb P (\\hat H_1|H_0) \\cdot \\mathbb P(H_0) = \\alpha \\cdot \\mathbb P (H_0)\n\\]\n\n\n\nДостаточной статистической мощностью (\\(1-\\beta\\)) считается \\(0.8\\). Аналогично, устремляя мощность к единице (\\((1-\\beta) \\to 1 \\Rightarrow \\beta \\to 0\\)), мы устремляем вероятность не отклонения нулевой гипотезы к нулю.\n\n\n\n\n\n\nЕщё математические руны\n\n\n\n\n\n\\[\n\\mathbb P (\\hat H_0) = \\mathbb P (\\hat H_0|H_1) \\cdot \\mathbb P(H_1) = \\beta \\cdot \\mathbb P (H_1)\n\\]\n\n\n\nНеобходимо также помнить, что ошибки первого и второго рода связаны между собой так, что\n\\[\n\\alpha \\to 0 \\Rightarrow \\beta \\to 1\n\\]\n\n\n\n\n\n\nОпять математические руны\n\n\n\n\n\n\\[\n\\begin{split}\n\\beta \\cdot \\mathbb P(H_1) &= \\mathbb P (\\hat H_0) \\\\\n\\beta \\cdot \\mathbb P(H_1) &= \\mathbb P (\\hat H_0 | H_0) \\cdot \\mathbb P(H_0) \\\\\n\\beta &= \\frac{1}{\\mathbb P(H_1)} \\cdot \\mathbb P(H_0) \\cdot \\mathbb P (\\hat H_0 | H_0) \\\\\n\\beta &= \\frac{1}{\\mathbb P(H_1)} \\cdot \\mathbb P(H_0) \\cdot \\big( 1 - \\mathbb P (\\hat H_1 | H_0) \\big) \\\\\n\\beta &= \\frac{1}{\\mathbb P(H_1)} \\cdot \\mathbb P(H_0) \\cdot ( 1 - \\alpha) \\\\\n\\overset{\\mathbb P(H_1) \\approx \\mathbb P(H_0)}{\\Longrightarrow}\n\\beta &\\approx 1-\\alpha\n\\end{split}\n\\]",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Тестирование статистических гипотез</span>"
    ]
  },
  {
    "objectID": "infer-stattesting.html#асимметрия-статистического-вывода",
    "href": "infer-stattesting.html#асимметрия-статистического-вывода",
    "title": "7  Тестирование статистических гипотез",
    "section": "7.3 Асимметрия статистического вывода",
    "text": "7.3 Асимметрия статистического вывода\nВыше мы сказали, что для проверки гипотезы нужны две вещи:\nрезультаты наблюдений и критерий. С результатами наблюдений более-менее очевидно.\nКритерий — это правило, согласно которому гипотезу либо принимают, либо отклоняют. Однако перед тем как проверять гипотезу, её так-то нужно сформулировать, и сделать это правильно, поскольку от формулировки гипотезы зависит интерпретация результатов проверки и дальнейшее использование полученной информации.\nИспользуемая статистика сама по себе является [непрерывной] случайной величиной, а значит может быть построено её распределение. Критерий будет разделять это распределение на непересекающиеся области. В результате чего возникает критическая область — область отклонения гипотезы. Дополнением к ней является область неотклонения гипотезы.\nКритическая область может быть односторонней (при\nH 1 : θ &gt; θ 0 или\nH 1 : θ &lt; θ 0 ) и двусторонней (при\nH 1 : θ ≠ θ 0 ). «Размер» критической области определяется уровнем значимости.\nСтатистический вывод — заключение о том, получили ли мы подтверждение альтернативной гипотезы — по структуре представляет собой импликацию. Если вам не знаком этот термин из логики, то вот:\nЕсли значение нашей статистики, которое мы рассчитали на выборке, попало в критическую область, то мы говорим о том, что нулевая гипотеза отклоняется. Если значение нашей статистики, которое мы рассчитали на выборке, не попало в критическую область, то мы не получаем оснований для того, чтобы отклонить нулевую гипотезу. Однако мы также не получаем оснований, чтобы её «принять». Мы остаёмся в некотором неведении: мы не нашли различий, а есть они там или нет — хто ж их знает… Итого, мы не можем сделать никакого вывода. В этом и заключается асимметрия статистического вывода. Как раз для того, чтобы с ней как-то жить, мы работаем со статистической мощностью.\nПосмотреть, как все эти штуки друг с другом соотносятся можно тут.",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Тестирование статистических гипотез</span>"
    ]
  },
  {
    "objectID": "infer-stattesting.html#алгоритм-тестирования-статистических-гипотез",
    "href": "infer-stattesting.html#алгоритм-тестирования-статистических-гипотез",
    "title": "7  Тестирование статистических гипотез",
    "section": "7.3 Алгоритм тестирования статистических гипотез",
    "text": "7.3 Алгоритм тестирования статистических гипотез\nДля тестирования гипотез есть два сценария: первый и тот, которым мы будем пользоваться. Первый вариант чуть более классический, второй — более гибкий.\n\n\n\n\n\n\nСценарий номер раз\n\n\n\n\nФормулировка гипотезы\nВыбор статистического критерия\nВыбор уровня значимости \\(\\alpha\\)\nПостроение закона распределения статистики критерия при условии, что нулевая гипотеза верна\nОпределение границ критической области\nРасчёт выборочной статистики\nОпределение, попадает ли наблюдаемое значение статистики в критическую область и статистический вывод\n\n\n\n\n\n\n\n\n\nСценарий номер два\n\n\n\n\nФормулировка гипотезы\nВыбор статистического критерия\nВыбор уровня значимости \\(\\alpha\\)\nПостроение закона распредлеения статистики критерия при условии, что нулевая гипотеза верна\nРасчёт выборочной статистики\nРасчёт достигнутого уровня значимости p-value\nСопоставление \\(\\alpha\\) и p-value и статистический вывод\n\n\n\nПочему второй вариант более гибкий? Представим, что мы захотели понизить уровень значимости с \\(0.05\\) до \\(0.01\\) — такие уровни значимости всречаются, например, в медицине. Если мы идем по первому сценарию, то нам надо заново пересчитать критические значения и вновь проанализировать, попадает ли наблюдаемое значение в критическую область. Если мы адепты второго сценария, то нам надо только выполнить одно новое сравнение нашего p-value с новым уровнем значимости.\nВероятно, пока мало что понятно. Поэтому в следующей главе разберем все это безобразие на примере.",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Тестирование статистических гипотез</span>"
    ]
  },
  {
    "objectID": "infer-stattesting.html#footnotes",
    "href": "infer-stattesting.html#footnotes",
    "title": "7  Тестирование статистических гипотез",
    "section": "",
    "text": "Здесь использовано обозначение условной вероятности \\(\\mathbb P (A|B)\\), то есть это вероятность того, что случилось событие \\(A\\) при условии, что случилось событие \\(B\\).↩︎",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Тестирование статистических гипотез</span>"
    ]
  },
  {
    "objectID": "infer-correlation.html",
    "href": "infer-correlation.html",
    "title": "8  Корреляционный анализ",
    "section": "",
    "text": "8.1 Ковариация\nИтак, мы переходим к рассмотрению конкретных статистических методов. Начнём, пожалуй, с наиболее интуитивного — тестируем гипотезу о связи между двумя количественными переменными.\nМы хотим описать имеющиеся взаимосвязи как можно проще и опираясь на то, что у нас уже есть. Мы знаем, что дисперсия, или вариация (variance), заключает в себе информацию об изменчивости признака. Если мы хотим исследовать взаимосвязь между признаками, то логично будет посмотреть, как изменяется один из признаков при изменении другого — иначе говоря, рассчитать совместную изменчивость признаков, или ко-вариацию (co-variance).\nКак мы её будем считать? Подумаем графически. Расположим две переменные на осях и сопоставим каждому имеющемуся наблюдению точку на плоскости.\nОтметим средние значения по обеим переменным.\nРазумеется, что у нас наблюдаются отклонения наблюдений от среднего. Заметим, что отклонения могут быть сонаправленными — одновременно по обеим переменным\nx и\ny в положительную или отрицательную сторону (зеленые стрелки) — или разнонаправленными — в положительную сторону по одной из переменных и в отрицательную по другой, и наоборот (рыжие стрелки).\nПри этом обратим внимание, что точки на графике, отображающие наши наблюдения, как бы идут более-менее в направлении какой-то прямой — серой, как на картинке:\nИ чем отклонения от средних по обеим переменным будут более согласованы, тем точнее они будут идти по этой прямой.\nПолучается, мы можем на основании согласованности отклонений уже следать заключение о направлении связи, ведь произведение отклонений по обеим величинам будет положительно, если отклонения сонаправленны, и отрицательно, если они разнонаправленны. Остается только понять, как совместные отклонения организованы «в среднем» — это и будет ковариацией двух величин:\ncov ( x , y ) = 1 n − 1 n ∑ i = 1\n( ¯ x − x i ) ( ¯ y − y i )\nКстати, а что такое ковариация переменной с самой собой?\nВот что Это все, конечно, кул, однако важно отметить, что ковариация улавливает только линейную составляющую взаимосвязи между признаками — мы говорили выше, что точки идут как бы по некоторой прямой — поэтому если\ncov ( x , y ) = 0 , то мы можем сказать, что между переменными нет линейной взаимосвязи, однако это не значит, что между этими переменными нет никакой другой зависимости.\nЕсли же ковариация отлична от нуля, то\nесли её значение положительно, то мы можем заподозрить прямую связь между переменными, если же её значение отрицательно, то мы можем предположить обратную связь между переменными. У ковариации есть два важных недостатка:\nэто размерная величина, поэтому её значение зависит от единиц измерения признаков, она зависит от дисперсий признаков, поэтому по её значению можно определить только направление связи (прямая или обратная), однако ничего нельзая сказать о силе связи. Поэтому нам нужно как-то модицифировать эту статистику, чтобы мы могли больше вытащить из её значения.",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Корреляционный анализ</span>"
    ]
  },
  {
    "objectID": "infer-correlation.html#корреляция",
    "href": "infer-correlation.html#корреляция",
    "title": "8  Корреляционный анализ",
    "section": "8.2 Корреляция",
    "text": "8.2 Корреляция\nРаз ковариация зависит от дисперсии, то можно сделать некоторые математические преобразования, чтобы привести эмпирические распределения к какому-то одному виду — сделать так, чтобы они имели одинакое математическое ожидание (среднее) и одинаковую дисперсию. С этой задачей прекрасно справляется стандартизация. Напоминаю формулу:\nz i = x i − ¯ x s\nПосле такого преобразования математическое ожидание нашего распределения будет равно нулю, а стандартное отклонение — единице. Это избавит нас от влияния дисперсии на значение ковариации. Ковариация двух стандартно нормально распределенных величин называется корреляцией (correlation).\ncov ( z ( x ) , z ( y ) ) = 1 n − 1 n ∑ i = 1\nz ( x ) z ( y ) = corr ( x , y ) ,\nгде\nz ( x ) и\nz ( y ) — стандартизированные величины\nx и\ny соответственно.\nКорреляцию можно выразить через ковариацию:\ncorr ( x , y ) = 1 n − 1 n ∑ i = 1\n( ¯ x − x i s x ) ( ¯ y − y i s y ) = 1 s x s y ( 1 n − 1 n ∑ i = 1\n( ¯ x − x i ) ( ¯ y − y i ) ) = cov(x, y) s x s y\nЕсли внимательно всмотреться в формулу, то можно обнаружить, что корреляция это не что иное, как стандартизированное значение ковариации.\nКоэффициент корреляции имеет четкие пределы изменения:\n[ − 1 ; 1] . Крайнее левое значение говорит о том, что присутствует полная обратная линейная взаимосвязь, крайнее правое — что присутствует полная прямая линейная взаимосвязь. Как и ковариация, корреляция ловит только линейную составляющую связи, поэтому нулевое значение корреляци показывает, что между переменными отсутствует линейная взаимосвязь. Это всё еще не значит, что связи нет вовсе.\nПреимущество корреляции над ковариацией в том, что она отражает не только направление, но и силу связи:\nЗначение коэффициента Интерпретация − 1.0 – − 0.9 очень сильная обратная связь − 0.9 – − 0.7 сильная обратная связь − 0.7 – − 0.5 средняя обратная связь − 0.5 – − 0.3 слабая обратная связь − 0.3 – 0.0 очень слабая обратная связь 0.0 – 0.3 очень слабая прямая связь 0.3 – 0.5 слабая прямая связь 0.5 – 0.7 средняя прямая связь 0.7 – 0.9 сильная прямая связь 0.9 – 1.0 очень сильная прямая связь Пронаблюдать можно тут.",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Корреляционный анализ</span>"
    ]
  },
  {
    "objectID": "infer-correlation.html#корреляция-пирсона",
    "href": "infer-correlation.html#корреляция-пирсона",
    "title": "8  Корреляционный анализ",
    "section": "8.3 Корреляция Пирсона",
    "text": "8.3 Корреляция Пирсона\nТо, что мы только что обсудили, называется коэффициентом корреляции Пирсона. Пирсон, как вы могли обратить внимание, много чего успел наделать на благо статистики — вот ещё и корреляцию нам придумал. Этот коэффициент применим, когда мы работаем с двумя нормально распределенными величинами или хотя бы двумя величинами, измеренями в метрических шкалах. Еще раз напомним чере его формулу:\nr x 1 x 2 = ∑ n i = 1 ( ¯ x 1 − x i 1 ) ( ¯ x 2 − x i 2 ) √ ∑ n i = 1 ( ¯ x 1 − x i 1 ) 2 ⋅ ∑ n i = 1 ( ¯ x 2 − x i 2 ) 2\nТеперь задумаемся — хоть это и неприятно — можем ли мы сказать по значению коэффициента корреляции, отличается ли он от нуля? Вспомнив, что мы занимаемся статистикой, сразу ответим — нет. Поскольку мы рассчитываем коэффициент корреляции на данных, а они содержат всякую вариативность и неопределенность, нам придется предпринять дополнительные усилия, чтобы заявить, что обнаруженная нами связь статистически значима.\n\n8.3.1 Тестирование статистической значимости коэффициента корреляции\nИтак, мы, как обычно, хотим ответить на вопрос, есть ли в генеральной совокупности связь между двумя изучаемыми переменными. Если в генеральной совокупности связь между признаками отсутствует, то есть\nρ x 1 x 2 = 0 , будет ли равен нулю\nr x 1 x 2 ? Можно с уверенностью сказать, что не будет, так как выборочный коэффициент корреляции — случайная величина. А мы помним, что вероятность принятия случайной величиной своего конкретного значения равна нулю.\nТогда необходимо протестировать статистическую гипотезу:\nH 0 : ρ x 1 x 2 = 0 H 1 : ρ x 1 x 2 ≠ 0\nНулевая гипотеза гласит, что между признаками нет линейной взаимосвязи, альтернативная говорит — что есть. Обычно мы не закладываем в гипотезу направление связи, потому что и положительная, и отрицательная нас устроит — это мы будем потом уже содержательно интерпретировать.\nГипотезу сформулировали, теперь надо подобрать статистический критерий. Он вот:",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Корреляционный анализ</span>"
    ]
  },
  {
    "objectID": "infer-correlation.html#коэффициенты-корреляции-для-разных-шкал",
    "href": "infer-correlation.html#коэффициенты-корреляции-для-разных-шкал",
    "title": "8  Корреляционный анализ",
    "section": "9.1 Коэффициенты корреляции для разных шкал",
    "text": "9.1 Коэффициенты корреляции для разных шкал\nВыше мы подробно обсудили корреляцию Пирсона и отметили, что этот коэффициент применяется для метрических шкал да ещё и нормально распределенных величин. А что же делать, если в наших данных не так?\n\n9.1.1 Параметрические и непараметрические критерии\nВсе статистические методы деляться на два типа: параметрические и непараметрические.\nПараметрические методы работают с непосредственно с параметрами распределения исследуемых переменных. Так, для вычисления корреляции Пирсона мы используем среднее и стандартное отклонение. Как следствие, одно из условий применимести таких методов — нормальное распределение изучаемых переменных. Если это требование не выполнено, мы не можем быть достаточно уверены в том, что статистический метод дает надежные результаты — как минимум, потому что сами среднее и стандартное отклонение в случае скошенных распределения не особо хорошо описывают данные. Непараметрические методы не используют в вычислениях собственных статистик параметры распределений. Например, изученный нам хи-квадрат относится к непараметрическим критериям. Они работают либо с частотами, либо в рангами — в зависимости от того, какие переменные мы анализируем. Поэтому если требования нормальности распределения не выполнено, используют методы этой группы. Практически каждый параметрический критерий имеет своего непараметрического собрата. Отметим, что сам статистический вывод в случае непараметрических критериев осуществляется точно так же, как и в случае параметрических.\n\n\n9.1.2 Непараметрические коэффициенты корреляции\nДля разных шкал разработаны разные коэффициенты корреляции. Оценки коэффициентов будут рассчитываться по-разному, но логика тестирования статистических гипотез остаётся одинаковой.\nПеременная\nX Переменная\nY Мера связи Интервальная или отношений Интервальная или отношений Корреляция Пирсона Ранговая, интервальная или отношений Ранговая, интервальная или отношений Корреляция Спирмена Ранговая Ранговая Корреляция Кенделла У непараметрических критериев формулы несколько зубодробительны, поэтому оставим их покоиться с миром. В статистическом ПО нужно будет просто выбрать подходящий критерий из предложенных.",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Корреляционный анализ</span>"
    ]
  },
  {
    "objectID": "infer-correlation.html#другие-корреляции",
    "href": "infer-correlation.html#другие-корреляции",
    "title": "8  Корреляционный анализ",
    "section": "9.2 Другие корреляции",
    "text": "9.2 Другие корреляции\nЭтот раздел для отчаянных. Вас никто об это ни на экзамене, ни, возможно, в жизни не спросит.\nМожно коррелировать не только количественные и ранговые шкалы между собой, но и качественные тоже:\nПеременная\nX Переменная\nY Мера связи Дихотомическая Дихотомическая\nϕ -коэффициент Дихотомическая Ранговая Рангово-бисериальный коэффициент Дихотомическая Интервальная или отношений Бисериальный коэффициент 10.5.1\nϕ -коэффициент Этот коэффициент позволяет рассчитать корреляцию между двумы дихотомическими шкалами. Он основан на расчёте статистики\nχ 2 . По двум дихотомическим переменным строится, как мы знаем, таблицу сопряженности и рассчитывается\nχ 2 . Далее он нормируется следующим образом, чтобы получить значения от 0 до 1, которые можно интерпретироват аналогично коэффициенту корреляции:",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Корреляционный анализ</span>"
    ]
  }
]