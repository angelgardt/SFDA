[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "SFDA | PSY HSE",
    "section": "",
    "text": "Начало",
    "crumbs": [
      "Начало"
    ]
  },
  {
    "objectID": "index.html#врубаем-тэхно-для-рабочего-настроения",
    "href": "index.html#врубаем-тэхно-для-рабочего-настроения",
    "title": "SFDA | PSY HSE",
    "section": "Врубаем тэхно для рабочего настроения",
    "text": "Врубаем тэхно для рабочего настроения\n\nПрежде всего, разумно будет попытаться разобраться в том, заради чего мы тут собрались. Ну, попробуем…\n\nВот, скажем, решили мы замерить уровень счастья российского населения — задача, прямо скажем, не суперпростая. Дать опросник 144 миллионам людей весьма энергозатратно, и хотелось бы как-то упростить себе задачу. Сколько нам надо опросить людей, чтобы наш замер отражал реальность? Как нам их выбрать? Как потом обсчитать цифры, которые мы получим? И вообще, наш опросник — он точный? Надежный? Им вообще законно что-либо измерять?\nИли вот мы — учёный. Решили провести некоторый суровый когнитивный эксперимент, чтобы узнать, как пользователи Android и iOS ищут иконки разных приложений. Скачали статей, выдвинули гипотезы, придумали дизайн, запрогали эксп, нашли несчастных, которые прошли этот эксп — по итогу получили какие-то цифири. Возникает справедливый вопрос: и чё? Как нам сказать, что данные подтвердили или опровергли наши гипотезы? Можем ли мы вообще по этим данным что-то сказать? Ну, допустим, мы ленивые и вообще программировать это для умных — отдадим специально обученным аналитикам посчитать это всё. И получим цифири. О, нет — опять! Возникает ещё один справедливый вопрос: и чё? Как нам сказать, что эти цифры подтверждают или опровергают наши гипотезы? Можем ли мы вообще по этим цифрам что-либо сказать осмысленное? А содержательно как это интерпретировать? Иконки-то как пользователи ищут?\nНу, или мы — HR в компании на 100500 тыщ человек сотрудников. Пришел гендир, сказал «уволить нельзя премировать, только непонятно кого». Дал нам экселевскую таблицу со всякими показателями эффективности и сказал «завтра к вечеру должна быть система грейдов, по которой будем оценить сотрудников». И что делать? Придется всю ночь ворочать цифры и статистически моделировать.\nА вот, скажем, залезли мы в ковидные новости очередной волны — там что-то страшное, да в графиках, да снова цифры какие-то ужасные. Хлебнули чаю, включили статистический взгляд — а, ну так все норм же. Оценили риски для себя, друзей, родных, убедились в том, что журналисты снова навели излишней суеты, восхитились собой, пошли инвестировать в крипту.\nОпять какие-то графики увидели, тренды, прогнозы и всё такое. Как понять? Как прочитать это всё? Как оценить, куда надо стипуху вкласть? Вспомнили статистику, навели шороху, собрали достойный инвестиционный портфельчик — хлебнули кофе, пошли покупать билеты на Бали.\nДальше можно расписывать огромное количество подобных случаев. Приходится признать, что сегодня мы живем в окружении огромного количества алгоритмов, основанных на статистическом анализе. Всё то, что называется модным словосочетанием «машинное обучение» базируется на тех статистических методах, которые мы будем с вами изучать.\nМожно ли жить без этого знания? В принципе, да. Однако\n\nкогнитивщикам и нейроисследователям необходимо анализировать свои данные своих экспериментов и — что значительное более важно — корректно интерпретировать результаты статистического анализа, что невозможно без понимания того, как используемые статистические методы работают\nсоциальщикам и личностникам-исследователям также необходимо анализировать данные своих исследований — и используемые ими модели даже сложнее, чем у когнитивщиков и нейроученых\nорганизационщикам придется также работать с данными, потому что HR-аналитика на хайпе и экспертный подход к оценке персонала постепенно теряет актуальность [а ещё айтишников нанимать придётся]\nличностникам-консультантам надо быть в теме того, что творят личностники-исследователи, а значит придется читать статьи и оценивать их адекватность, в том числе, в аспекте анализа данных\nвсем [даже некоторым когнитивщикам] придется работать с опросниками — а вся психометрика строится на статистике\nвсем придется в жизни анализировать потоки информации, возрастающие с невероятной скоростью, данные и графики, критически и оценивать, выявлять неочевидные закономерности, чтобы понимать, что происходит — и статистика в этом сильно поможет\nвсе мы продолжаем жить в мире гаджетов и технологий, и понимание того, какие модели лежат в их основе, очень прилично апгрейдит наше понимание того, что восстание машин будет о-о-о-очень не скоро.\n\nКонечно, мы не можем обсудить всё. Мы находимся в рамках суровых институциональных ограничений. Но мы постараемся заложить достаточно прочный фундамент, который при правильном применении и должном уходе поможет вам преуспеть и в жизни, и в работе и вообще.",
    "crumbs": [
      "Начало"
    ]
  },
  {
    "objectID": "index.html#зачем-изучать-анализ-данных-в-эпоху-нейросетей",
    "href": "index.html#зачем-изучать-анализ-данных-в-эпоху-нейросетей",
    "title": "SFDA | PSY HSE",
    "section": "Зачем изучать анализ данных в эпоху нейросетей?",
    "text": "Зачем изучать анализ данных в эпоху нейросетей?\nА действительно? Можно же просто закинуть промпт, и всё готово…\nНу, закинем промпт.\n\nЗачем изучать анализ данных, если существуют нейросети, которые могут проанализировать данные за меня?\n\n\n\n\n\n\n\nОтвет ChatGPT-4 (30 мая 2024)\n\n\n\nЭто отличный вопрос! Действительно, нейросети и другие методы машинного обучения становятся все более мощными инструментами для анализа данных. Однако есть несколько причин, почему важно изучать анализ данных, даже если существуют такие технологии:\n\nПонимание процесса: Понимание основ анализа данных позволяет лучше понять, как работают нейросети и другие алгоритмы машинного обучения. Это помогает в настройке, интерпретации и улучшении моделей.\nВыбор методов: Анализ данных помогает выбирать подходящие методы и инструменты для конкретной задачи. Нейросети — не всегда лучший выбор, особенно для небольших наборов данных или когда требуется интерпретируемость результатов.\nКачество данных: Анализ данных включает в себя предварительную обработку данных — очистку, нормализацию, выявление и исправление ошибок. Без этого этапа нейросеть может обучиться на “грязных” данных и выдавать неправильные результаты.\nИнтерпретируемость моделей: Многие модели машинного обучения (включая нейросети) сложны для интерпретации. Традиционные методы анализа данных, такие как регрессия или дерево решений, могут предложить более простые и интерпретируемые модели, что важно в некоторых приложениях, например, в медицине или финансах.\nОбоснование результатов: В некоторых ситуациях требуется не только предсказать результат, но и объяснить, почему модель приняла то или иное решение. Это особенно важно в регулируемых отраслях, таких как банковское дело или страхование.\nКомбинаторика методов: Возможно объединение различных методов анализа данных и машинного обучения для достижения лучших результатов. Глубокое понимание как статистических методов, так и нейросетей позволяет строить гибридные модели.\nИнновации и новые подходы: Знания в области анализа данных способствуют разработке новых алгоритмов и подходов, что может привести к появлению более эффективных способов решения задач.\n\nВ целом, изучение анализа данных дает фундаментальные знания, которые помогут лучше использовать и усовершенствовать нейросетевые модели и другие инструменты машинного обучения.\n\n\n\nЗачем мне как аналитику уметь писать код, если можно попросить нейросеть написать код под конкретную задачу по анализу данных?\n\n\n\n\n\n\n\nОтвет ChatGPT-4 (30 мая 2024)\n\n\n\nИспользование нейросетей для генерации кода под задачи анализа данных может быть полезным, но есть несколько причин, по которым важно уметь писать код самостоятельно, даже если вы аналитик:\n\nПонимание данных и процессов: Знание программирования помогает лучше понять структуру данных и методы, которые вы используете для их анализа. Это особенно важно для интерпретации результатов и их корректного применения.\nОтладка и валидность результатов: Автоматически сгенерированный код может привести к ошибкам или неправильным выводам. Умение самостоятельно писать и проверять код позволяет убедиться, что все работает корректно.\nГибкость и адаптация: Ваши задачи могут изменяться, требуя новой логики анализа или дополнительных шагов обработки данных. Умение писать код позволяет легче адаптироваться к новым требованиям и быстро вносить изменения.\nКачество данных: Предварительная обработка данных — ключевой этап анализа. Знание программирования помогает эффективно очистить, нормализовать и обработать данные перед анализом.\nОптимизация: Автоматически сгенерированный код может быть неоптимальным. Умение писать собственный код позволяет вам сделать анализ данных более эффективным и производительным.\nИнтерпретируемость: Полное понимание кода делает результаты вашего анализа более понятными и объяснимыми для заинтересованных сторон.\nКомандная работа и документация: В команде аналитиков важно уметь читать и писать структурированный код, чтобы эффективно сотрудничать с коллегами и поддерживать документацию проекта.\nНавык решения уникальных задач: Задачи анализа данных могут быть очень разнообразными и требовать индивидуального подхода. Нейросеть может не всегда справиться с уникальными или нестандартными задачами без надлежащего контекста.\nПрофессиональный рост: Знание программирования является важным навыком для роста и развития в карьере аналитика. Это открывает двери к более сложным и интересным проектам.\nБезопасность и конфиденциальность: Используя нейросеть, вы можете столкнуться с проблемами, связанными с конфиденциальностью данных. Самостоятельная работа с кодом помогает лучше контролировать безопасность и защиту данных.\n\nХотя нейросети могут быть полезным инструментом, знание программирования остается важным навыком для аналитиков, обеспечивая гибкость, контроль и качество работы.\n\n\nВ общем-то, автор согласен с мнением большой языковой модели. Пусть и не все обозначенные ею пункты в полной мере актуальны для психологов, так или иначе каждый тезис находит своё отражение в исследовательской работе психолога.\nКроме того, если мы уж и решили использовать нейросеть для генерации кода или подбора статистического метода под имеющуюся у вас задачу, надо каким-то образом надо сформулировать промпт. А как его сформулировать, если не знать хотя бы на концептуальном уровне, что должно получиться в результате анализа данных?\nПолучается, что всё-таки имеет смысл разобраться в статистике и анализе данных хотя бы на некотором базовом уровне, чтобы использоваться нейросетки с умом.",
    "crumbs": [
      "Начало"
    ]
  },
  {
    "objectID": "intro-intro.html",
    "href": "intro-intro.html",
    "title": "1  Основания статистики",
    "section": "",
    "text": "1.1 Выборка и генеральная совокупность\nСтатистика (statistics) — это междисциплинарная область знаний, а также практической деятельности, изучающая массовые явления, а также принципы и методы работы с данными, характеризующими эти явления.\nЗвучит красиво. Осталось понять, что это значит.\nМассовые явления затрагивают огромные массы людей. Огромность масс, конечно, различна. Скажем, базовые перцептивные закономерности, связанные с тем, как устроена зрительная система, охватывают всех людей. Уровень удовлетворенности жизнью россиян охватывает только население России. Городские блага москвичей — только для жителей Москвы. Учебная мотивация студентов департамента психологии НИУ ВШЭ — это только про людей с психологических бакалавриата и магистратур НИУ ВШЭ.\nГенеральная совокупность (population) — множество всех [существующих] исследуемых объектов, а также сведения о них.\nОбъем совокупности (\\(N\\)) — число единиц, образующих совокупность.\nКороче, надо исследовать много людей, а времени и денег нет. Приходится из генеральной совокупности извлекать выборку (sample) — некоторую часть нашей генеральной совокупности (объемом \\(n\\)). При этом \\(n \\ll N\\) (много меньше).\nНас, конечно же, интересуют какие-то признаки, которыми обладают объекты нашей генеральной совокупности. Эти признаки могут быть выражены количественно в определенных показателях (Таблица 1.1).\nПризнаки могут быть очень разными, как и показатели, которыми мы их пытаемся измерить. Не будем сильно в это углубляться, ибо этим занимается теория измерений, а мы тут статистикой пришли заниматься.\nЧто нам важно сейчас: генеральная совокупность характеризуется параметром.\nПараметр (\\(\\theta\\)) — относительно постоянная [от одной совокупности к другой] величина, характеризующая генеральную совокупность по некоторому показателю.\nНу, то есть в принципе существует средний уровень нейротизма по BFI студента-психолога или индекс индивидуализма/коллективизма для конкретной культуры. Проблема в том, что величина параметра, который мы изучаем, неизвестна. И никогда не будет известна.\nНо почему?\nПоэтому величину параметра мы можем только предсказать с определённой статистической точностью. Измеряя что-либо на выборке, мы получаем выборочную характеристику (оценку, estimation) (\\(\\hat \\theta\\)) — эмпирический (измеримый) аналог параметра.",
    "crumbs": [
      "Введение в статистику",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Основания статистики</span>"
    ]
  },
  {
    "objectID": "intro-intro.html#выборка-и-генеральная-совокупность",
    "href": "intro-intro.html#выборка-и-генеральная-совокупность",
    "title": "1  Основания статистики",
    "section": "",
    "text": "Таблица 1.1: Примеры признаков и показателей\n\n\n\n\n\n\n\n\n\nПризнак\nПоказатель\n\n\n\n\nРабочая память\nОбъем рабочей памяти\n\n\nНейротизм\nУровень нейротизма по BFI\n\n\nЗаработная плата\nСредняя заработная плата\n\n\nКогнитивная нагрузка\nУровень когнитивной нагрузки по ЭЭГ-коррелятам\n\n\nДоверие к ИИ\nУровень доверия к ИИ по опроснику TAIA\n\n\nИндивидуализм/коллективизм\nИндекс индивидуализма/коллективизма по модели Хофстеде\n\n\n\n\n\n\n\n\n\n\n\n\nМы не можем изучить всю генеральную совокупность — в ней слишком много объектов\nНаши измерения всегда содержат ошибку — мы даже длину линейкой точно не можем измерить, что уж о психологических измерениях говорить",
    "crumbs": [
      "Введение в статистику",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Основания статистики</span>"
    ]
  },
  {
    "objectID": "intro-intro.html#основная-задача-статистики",
    "href": "intro-intro.html#основная-задача-статистики",
    "title": "1  Основания статистики",
    "section": "1.2 Основная задача статистики",
    "text": "1.2 Основная задача статистики\nМы в какой-то малоприятной ситуации… Мы пытаемся измерить то, что в определенном смысле невозможно измерить, при этом достаточно точно, чтобы потом это можно было сравнивать или строить какие-то модели. Задача выглядит заведомо провальной…\nОднако именно в этот момент на помощь нам приходит статистика. Не в гордом одиночестве, конечно. Она приводит с собой теорию измерений, психометрику, теорию обнаружения сигнала и др. Всё это работает в нашей психологической науке в комплексе. Мы же в данном курсе сосредотачиваемся на статистической части этого салата.\nСтатистика даёт нам теоретический и математический инструментарий, чтобы мы могли делать какие-либо выводы о генеральной совокупности по  собранным на выборке данным. К сожалению, как бы нам не хотелось, мы не можем делать выводы по сырым данным, потому что измерения по выборке не отражают вот прям ровно то, что есть в генеральной совокупности. Нам их надо определенным образом обсчитать, чтобы наши выводы были корректными. Этим и занимается статистика.\nЕсли мы попытаемся нарисовать какую-то концептуальную схему работы с выборкой в ходе исследования, то получится нечто такое (Рисунок 1.1).\n\n\n\n\n\n\nРисунок 1.1: Схема работы с выборкой в ходе исследования\n\n\n\nМы желаем изучить некую генеральную совокупность (population), которая недоступна нам в полном объёме. По этой причине мы извлекаем (sampling) из неё выборку (sample). На выборке мы собираем данные (data), по которым хотим делать вывод (inference) о генеральной совокупности. Как именно нам сделать такой вывод и рассказывает статистика.\nВероятно, сейчас это звучит достаточно абстрактно, но на данном этапе будет достаточно некоторого интуитивного понимания того, зачем нужна статистика. Далее интуиция обрастёт содержанием и уложится, хотелось бы надеяться, в достаточно стройную систему.\nИтог — статистика помогает нам делать выводы об изучаемой генеральной совокупности по выборке.",
    "crumbs": [
      "Введение в статистику",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Основания статистики</span>"
    ]
  },
  {
    "objectID": "intro-intro.html#основная-характеристика-выборки",
    "href": "intro-intro.html#основная-характеристика-выборки",
    "title": "1  Основания статистики",
    "section": "1.3 Основная характеристика выборки",
    "text": "1.3 Основная характеристика выборки\nОкей, статистика даёт нам теоретический и математический аппарат, который позволяет делать выводы о генеральной совокупности по выборке. Однако если мы криво собрали данные, то никакая математика нас не спасет от некорректных выводов.\n\nОдин из принципов машинного обучения гласит: garbage in, garbage out, Это значит «плохие данные на входе — бессмысленные результаты на выходе».\n\nТогда возникает вопрос: как собрать хорошие данные? Аспектов в этом вопросе много, и все они решаются при разработке дизайна исследования. Мы не будем здесь подробно разбирать, как корректно разрабатывать дизайн исследования, ибо это не является задачей курса статистики. Однако одни из ключевых элементов дизайна любого исследования — его выборка и способ её формирования.\nСреди характеристик выборки можно назвать много чего — например, объём и сбалансированность — но в целом все отдельные характеристики обобщаются в понятие репрезентативности.\nРепрезентативность выборки — это степень соответствия характеристик выборки характеристикам генеральной совокупности.\nНапример, мы хотим исследовать связь учебной мотивации и академической успеваемости бакалавров психологии. Если мы соберем данные только со своих однокурсников, будет нехорошо, так как в нашу выборку не попали (1) другие курсы психологического бакалавриата нашего вуза, (2) бакалавры-психологи других вузов Москвы и (3) бакалавры-психологи вузов других городов России.\nИ так работает всегда.\n\nНу, почти. Есть соблазн проводить исследования на студентах-психологах, потому что они достаточно близко и их можно загнать на эксперименты за баллы. Более-менее сносно это может работать на каких-то базовых когнитивных феноменах из восприятия и памяти. Обычно у нас нет оснований предполагать, что восприятие и память работают принципиально по-разному у людей разного возраста и разных социальных страт. Хотя, например, относительно памяти уже надо разбираться в том, что мы конкретно хотим про память изучать. Всё становится сложнее, если мы собираемся изучать что-то более высокоуровневое — например, мышление — или феномены личностной или социальной психологии.\n\nПочему выборка должна быть репрезентативной?\nПотому что если мы делаем нормально, то хотим обобщать результаты нашего исследования, полученные на выборке, на генеральную совокупность. Если выборка нерепрезентативна, то мы не можем этого сделать. Зачем в таком случае проводить исследование — решительно неясно.\nТогда возникает вопрос: как собрать респрезентативную выборку? Можно предложить следующий общий алгоритм.\n\nОсознать, кто наша генеральная совокупность.\n\nВ самом начале этой страницы приводились примеры разных генеральных совокупностей, и для каждой генеральной совокупности репрезентативная выборка будет своя.\n\nПонять, есть ли какая-то группировка, важная для нашего исследования, в нашей генеральной совокупности.\n\nСоциальная страта, специальность образования, сфера работы, пол или гендер, возрастные группы, регион проживания, семейное положение, что-либо ещё.\n\nРассчитать достаточный объём выборки\n\nэто не самая простая задача, и о ней мы будем говорить отдельно\nпока отметим в назывном порядке, что на объем выборки будут влиять дизайн исследования, изменчивость признака, уровень значимости и размер эффекта [что бы это ни значило]\n\nОбеспечить случайное попадание респондентов в выборку.\n\nНа последнем пункте стоит остановиться подробнее. Если у нас есть ресурсы набрать много людей в выборку — скажем, раза в 2–3 больше, чем достаточный объем выборки — то можно просто случайным образом откуда-то доставать людей, и всё будет хорошо. Некоторые статистические теоремы говорят, что такой вариант вполне пригоден для обеспечения репрезентативности выборки.\nЕсли мы всё же не можем набрать много людей, то надо набрать выборку достаточного объема и проверить репрезентативна ли она — отражает ли выборка те группировки изучаемых объектов, которые есть в генеральной совокупности.\nИдеальная выборка — это когда каждый человек имеет равную вероятность попасть в число респондентов (или испытуемых). Такая выборка называется вероятностной (probability sampling). Полностью случайный отбор трудно достижим — это очень дорого — но к нему нужно стремиться. Сам метод сбора данных может деформировать выборку (например, онлайн-опросы отсекают пенсионеров), поэтому думать о сборе данных необходимо уже на этапе планирования исследования.",
    "crumbs": [
      "Введение в статистику",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Основания статистики</span>"
    ]
  },
  {
    "objectID": "intro-intro.html#способы-формирования-выборки",
    "href": "intro-intro.html#способы-формирования-выборки",
    "title": "1  Основания статистики",
    "section": "1.4 Способы формирования выборки",
    "text": "1.4 Способы формирования выборки\nСпособов формирования выборки существует много. Для каждого отдельного исследования существующие способы можно модифицировать, что даст нам ещё кучу новых способов. Однако в рамках курса мы рассмотрим три основные способа формирования вероятностной выборки.\n\n1.4.1 Простая случайная выборка\nВ случае простой случайной выборки (simple random sample) элементы генеральной совокупности случайным образом попадают в выборку. Представим, что на этой картинке изображена вся генеральная совокупность:\n\n\n\n\n\n\n\n\n\nЕсли мы наберем простую случайную выборку из этой генеральной совокупности, она будет выглядеть так:\n\n\n\n\n\n\n\n\n\nКак можно заметить, в выборку попали объекты из всех частей нашей генеральной совокупности — это говорит о том, что выборка репрезентативна.\nПростая случайная выборка, конечно, хороша своей простотой, однако у неё есть два существенных недостатка. Во-первых, действительно случайное попадание респондентов (или испытуемых) в выборку обеспечить практически невозможно — всегда будут ограничение на доступ к каким-либо частям генеральной совокупности. Во-вторых, простая случайная выборка будет респрезентативной только при большом объёме. Так, если мы посмотрим на простую случайную выборку малого объёма для той жё генеральной совокупности, что была выше, то получим следующее:\n\n\n\n\n\n\n\n\n\nНа рисунке видно, что многие части генеральной совокупности не представлены в выборке, что свидетельсвует о нерепрезентативности выборки.\n\n\n1.4.2 Стратифицированная выборка\nВ случае стратифицированной выборки (stratified sample) генеральная совокупность разбивается на несколько обособленных и различных по своей природе групп (страт). В каком смысле обособленных? В том, что каждый объект (респондент, испытуемый) может принадлежать только к одной страте. Например, возрастная группа (дети, подростки, молодежь, взрослые, пожилые), пол, среднемесячный доход семьи и др. Важно отметить, что страта — это характеристика изучаемых объектов, важная с точки зрения дизайна исследования. Ровно поэтому мы хотим учесть её при формировании выборки, обеспечив её репрезентативность по данной характеристике.\nПусть наша генеральная совокупность выглядит как-то так и состоит из четырёх страт:\n\n\n\n\n\n\n\n\n\nЕсли мы поделим это месиво точек по стратам, то получим следующее:\n\n\n\n\n\n\n\n\n\nТеперь из каждой страты случайным образом выберем несколько объектов, которые и попадут в выборку.\n\n\n\n\n\n\n\n\n\nОтносительно количества объектов, извлекаемых из каждой страты, существуют разные варианты. Дизайн исследования может предполагать, что количество респондентов из каждой страты должно быть одинаковым — тогда мы будем набирать равное количество респондентов из каждой страты. Или же нам может быть важно обеспечить в выборке такое же соотношение между стратами по количеству респондентов, какое существует в генеральной совокупности — тогда необходимо, зная общий объём выборки, рассчитать количества респондентов из каждой страты, зная пропорции в генеральной совокупности, например, из данных государственной статистики или других источников.\n\n\n1.4.3 Групповая выборка\nВ случае групповой выборки (cluster sample) мы разбиваем генеральную совокупность на несколько обособленных, но одинаковых групп (кластеров). Обособленный в том же смысле, что и в случае стратифицированной выборки — один респондент может принадлежать только к одной группе наблюдений. В каком смысле группы тогда должны быть одинаковыми? Они должны быть одинаковыми с точки зрения дизайна исследования. Пусть мы изучаем удовлетворенность городскими благами жителей некоторого города. Группой (cluster) в этом случае может выступить район города, в котором проживает респондент, если у нас нет оснований предполагать, что районы города различаются по характеристике «городские блага». Зачем нам такое разделение может пригодится? Возможно, у нас доступ к организациям городского района, которые могут помочь нам распространить опрос, что снизит затраты на проведение исследования.\nПусть мы разделили нашу генеральную совокупность на шесть кластеров:\n\n\n\n\n\n\n\n\n\nКластеры мы считаем примерно одинаковыми по характеристикам между собой — по крайне мере, мы так предполагаем с точки зрения дизайна исследования. Выберем случайно три кластера, которые примут участие в исследовании:\n\n\n\n\n\n\n\n\n\nТеперь из этих кластеров наберем выборку случайным образом:\n\n\n\n\n\n\n\n\n\nХотя такой подход к формированию выборки позволяет экономить драгоценные временные и денежные ресурсы, он имеет свои недостатки. В частности, мы должны быть уверенны, что выделенные нами группы действительно одинаковы с точки зрения исследования — это можно утверждать далеко не всегда.\n\nПока что остановимся на этом — для первого знакомства со статистикой будет достаточно. Мы еще не раз будем возвращаться к этим вопросам, и на других курсах вы тоже будете говорить о репрезентативности выборки.",
    "crumbs": [
      "Введение в статистику",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Основания статистики</span>"
    ]
  },
  {
    "objectID": "part-r.html",
    "href": "part-r.html",
    "title": "Анализ данных в R",
    "section": "",
    "text": "Вырубаем тэхно — врубаем дипхаус",
    "crumbs": [
      "Анализ данных в R"
    ]
  },
  {
    "objectID": "intro-randvals.html",
    "href": "intro-randvals.html",
    "title": "2  Шкалы и случайные величины",
    "section": "",
    "text": "2.1 Измерение в социальных науках\nВспомним, что\nТеперь бы понять, что такое измерение…\nПод измерением (measurement) мы будем понимать приписывание признакам объектов изучаемой совокупности определенных значений на определенной шкале.\nЕще раз:\nТакое определение нам позволяет измерить практически всё, что угодно:\nСейчас нас не интересует, как именно «внутри себя» происходит процесс измерения, какие предположения стоят за различными измерениями и как сделать измерение качественным. Об этом подробно рассказывается в курса когнитивной и экспериментальной психологии, психодиагностики и психометрики и других. Отметим только, что, конечно же, нам как исследователям надо следить за тем, насколько адекватные измерения мы имеем, насколько приписанные измерения отражают выраженность, например, психологических черт, или насколько измеряемые (зависимые) экспериментальные переменные адекватны исследовательским задачам.\nИтак, у нас есть интересующие нас признаки генеральной совокупности выборки, которые мы измерили, то есть приклеили на них некоторые значения из определенных шкал. Успех!\nНо тут, пожалуй, разумно задуматься про шкалы. Ведь очевидно, что возраст и пол будут измеряться по-разному, также как и нарциссизм и время реакции.",
    "crumbs": [
      "Введение в статистику",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Шкалы и случайные величины</span>"
    ]
  },
  {
    "objectID": "intro-randvals.html#признаки-и-переменные",
    "href": "intro-randvals.html#признаки-и-переменные",
    "title": "2  Шкалы и случайные величины",
    "section": "2.2 Признаки и переменные",
    "text": "2.2 Признаки и переменные\nМы уже упомянули выше, что мы можем измерять различные признаки. Попытаемся как-то эту кучу систематизировать. В терминах данных признаки — это переменные, поэтому далее мы будем чаще употребляться именно этот термин — переменная — имея в виду то, что мы намерили, изучая признак. Во многом признак и переменная — это синонимы, только первый термин больше из теории измерений, а второй — из статистики и анализа данных. Измерение же от отдельного человека (объекта выборки) называется наблюдение.\nИтак, типы переменных:\n\nКоличественные переменные — те, которые принимают числовые значения\n\nнепрерывные — принимают любые значения (рост, возраст, время реакции и др.)\nдискретные — могут принимать только определенные значения (количество детей в семье, число отчисленных студентов, количество стаканов кофе, выпитых в ночь перед экзаменом и др.)\n\n\nЧисло, приписываемое количественному признаку (переменной) ведёт себя как привычное нам математическое число в том смысле, что выражает некоторое количество — сантиметров, лет, секунд, детей, студентов, стаканов кофе…\n\nНоминальные (категориальные) переменные — используются для разделения наших наблюдений на группы (пол, национальность, курс обучения, используемая операционная система компьютера и др.).\n\nЗаписаны эти переменные обычно текстом (скажем, как в примерах выше, пол — male и female — или операционная система — Win, macOS, Linux).\nОднако, например, курс обучения можно записать по-разному: текстом — freshman, sophomore, junior, senior — или числом — 1, 2, 3, 4. Однако в данном случае числа не несут никакого математического смысла — это просто лейблы, с помощью которых мы различаем группы наблюдений. Ведь и пол мы можем записать с помощью чисел — пусть male = 0, female = 1. Ведь не будем же мы складывать-вычитать девушек и парней?\n\n\nВнимательный читатель мог заметить, что курс обучения — это не совсем категориальная переменная, ведь «второкурсник» в каком-то смысле «больше», чем «первокурсник». Но мы не можем сказать «на сколько» или «во сколько» больше! Что же делать?\n\nНельзя сказать, что «второкурсник» выражает бо́льшую выраженность признака «год обучения», чем «первокурсник».\nВместе с тем «второкурсник» дольше учился и освоил больше дисциплин, чем «первокурсник». При этом «третьекурсник» учился дольше «второкурсника» — то есть существует порядок категорий.\nТакая переменная называется ранговой.\n\nДругой пример ранговой переменной — это студенческий рейтинг. Что делает рейтинг? Упорядочивает студентов. Можно ли сказать, что четвертый в рейтинге студент в два раза менее успешен, чем второй? Нет — тот же GPA может отличаться на десятые или сотые доли.\nИтого, классификацию переменных можно представить так (Рисунок 2.1):\n\n\n\n\n\n\nflowchart TD\n  vars(\"Переменные\")\n  quantitative(\"Количественные\")\n  discrete(\"Дискретные\")\n  continuous(\"Непрерывные\")\n  rank(\"Ранговые\")\n  nominal(\"Номинальные\")\n  \n  vars --&gt; quantitative\n  vars --&gt; rank\n  vars --&gt; nominal\n  quantitative --&gt; discrete\n  quantitative --&gt; continuous\n\n\n\n\nРисунок 2.1: Классификация переменных",
    "crumbs": [
      "Введение в статистику",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Шкалы и случайные величины</span>"
    ]
  },
  {
    "objectID": "intro-randvals.html#шкалы",
    "href": "intro-randvals.html#шкалы",
    "title": "2  Шкалы и случайные величины",
    "section": "2.3 Шкалы",
    "text": "2.3 Шкалы\nЗачем нам знать виды шкал?\nОт того, в какой шкале измерена переменная, которую мы исследуем, будет зависеть:\n\nкакие графики мы сможем нарисовать\nкакие статистики на ней имеют смысл\nкакие статистические модели дадут адекватный результат\n\nВ общем, почти весь анализ определяется тем, с какой шкалой мы работаем.\nПод шкалой (scale) мы будем понимать набор допустимых значений с ограничениями на допустимые операции над ними. Вновь посмотрим на признаки, которые мы можем измерять. Пол имеет два допустимых значения — male и female — и мы можем лишь сравнить значения, проверив, совпадают они или нет. В то же время, рассматривая переменную «время», которая может принимать значения от \\(0\\) до \\(+\\infty\\), мы уверенно можем утверждать, что если одна пара длится 120 минут, то две будут длиться 240 минут — мы можем считать сумму значений по этой переменной.\nМожно ли как-то систематизировать все возможные варианты допустимых значений и операций?\n\n2.3.1 Типы и виды шкал\nВсего выделяют четыре вида шкал (Таблица 2.1).\n\n\n\nТаблица 2.1: Виды шкал изменения\n\n\n\n\n\n\n\n\n\n\n\n\n\nШкала\nТип шкалы\nТип данных\nДопустимые операции\nНоль\nДопустимые преобразования\n\n\n\n\nНоминальная (номинативная, nominal scale)\nНеметрическая\nКачественные Категориальные\n\\(=\\), \\(\\neq\\)\nОтсутствует\n—\n\n\nПорядковая (ранговая, ordinal scale)\nНеметрическая\nКачественные Категориальные (?) Ранговые\n\\(=\\), \\(\\neq\\), \\(&gt;\\), \\(&lt;\\)\nОтсутствует\nМонотонное преобразование\n\n\nИнтервальная (шкала разностей, internal scale)\nМетрическая\nКоличественные\n\\(=\\), \\(\\neq\\), \\(&gt;\\), \\(&lt;\\), \\(+\\), \\(-\\)\nОтносительный\nЛинейное преобразование\n\n\nАбсолютная (шкала отношений, ratio scale)\nМетрическая\nКоличественные\n\\(=\\), \\(\\neq\\), \\(&gt;\\), \\(&lt;\\), \\(+\\), \\(-\\), \\(\\times\\), \\(\\div\\)\nАбсолютный\nПреобразование подобия\n\n\n\n\n\n\nПройдёмся по колонкам этой таблицы.\n\nТип шкалы — метрическая или неметрическая — определяется тем, одинаково расстояние между делениями шкалы или же нет. Иначе, есть ли на шкале цена деления.\n\nТак, понятно, что на шкале времени реакции все секунды одинакового размера — метрическая шкала.\nА на шкале «используемая операционная система» вообще нет делений, не то что расстояний.\nОбратите внимание, что на ранговой шкале хотя и есть деления (например, шкала Ликерта), их размер неодинаковый: нельзя сказать, что \\(6\\) на шкале Ликерта в два раза или на три больше, чем \\(3\\). Поэтому ранговая шкала — неметрическая.\n\nТип данных — количественные или категориальные — определяется тем, какие свойства чисел работают на этой шкале.\n\nЧтобы не утонуть в математической части этого всего, соотнесём это с колонкой допустимые операции.\n\nНа количественных шкалах допустимы операции сложения, вычитания, умножения и деления.\nНа категориальных шкалах шкалах допустимы только операции сравнения.\n\n\nНоль\n\nНа номинальной и порядковой шкалах нуля в математическом смысле нет вовсе.\n\nДля номинальной шкалы это очевидно, потому что там вообще нет «чисел» — там только лейблы.\nДля порядковой шкалы, в определенной мере, тоже, потому что \\(0\\) на ней будет обозначать только то, что ранг у этого наблюдения ниже, чем ранг у наблюдения с \\(1\\). Ничего другого этот ноль не обозначает.\n\nНа интервальной и абсолютной шкалах ноль есть.\n\nКлассический пример интервальной шкалы — это температура в градусах Цельсия. Ноль на этой шкале — температуре замерзания воды — выбран произвольно. Ну, потому что это было достаточно удобно. Больше этот ноль ничем не обоснован.\n\nПоскольку ноль относительный, на такой шкале могут быть отрицательные значения — с температурой по Цельсию нас это совершенно не удивляет.\n\nКлассический пример абсолютной шкалы — это температура по Кельвину. Известно, что на этой шкале не бывает отрицательных значений, так как минимум этой шкалы — это минимально возможная температура во Вселенной. Ниже не бывает. Поэтому это абсолютный ноль.\n\n\nДопустимые операции\n\nНаличие относительного нуля даёт возможность складывать и вычитать.\nНаличие абсолютного нуля даёт возможность складывать, вычитать, делить и умножать.\nНа номинальной и порядковой шкалах нуля нет, поэтому арифметические действия на них невозможны.\nНа номинальной шкале допустимо только сравнение на [не]равенство — мы можем только проверить, одинаковы ли наблюдения [по этой переменной] или не одинаковые.\nНа порядковой шкале, помимо сравнения на [не]равенство, допустимо также сравнение на больше-меньше, так как задан порядок.\n\nДопустимые преобразования\n\nОтсюда нам нужно попытаться понять, что такое монотонное преобразование. Это любое преобразование, сохраняющее порядок элементов.\n\nНапример, у нас есть шкала Ликерта от 1 до 5 — [1, 2, 3, 4, 5]. Шкала Ликерта — порядковая, поэтому мы можем утверждать, что 1 &lt; 2 &lt; 3 &lt; 4 &lt; 5.\nПусть мы психометрик и собираемся вычислять психометрические штуки на таких данных. Для удобства нам надо сделать так, чтобы шкала начиналась с нуля.\n\nКажется, надо просто вычесть единицу из всех наблюдений — но законно ли это? Не сломаются ли закономерности наших данных?\n\nДа, законно, потому что вычитание единицы — это монотонное преобразование. И хотя значения переменной изменятся — [0, 1, 2, 3, 4] — порядок значений сохранится — 0 &lt; 1 &lt; 2 &lt; 3 &lt; 4.\n\n\n\n\n\n\n\n\n\nО термине «качественные данные»\n\n\n\nПочему-то номинальную и ранговую шкалы в литературе часто называют «качественными». Видимо, потому что качественные данные обычно рассматриваются как оппозиция количественным.\nЭто в некоторой мере справедливо, поскольку есть два типа исследований — качественные и количественные. Они различаются методологией и используемыми методиками и, как следствие, собираемыми данными.\nВ рамках качественных исследований чаще всего собираются тексты, поэтому во многом качественные данные обычно текстовые. Количественные данные — это, как правило, таблицы с цифрами из любой из четырёх шкал. Безусловно, анализ качественных и количественных данных также существенно различается.\nИтого, кажется, что называть «качественными» номинальную и ранговые шкалы — странно, потому что качественные данные — это неструктурированный текст. Лучше их именовать категориальными. Правда, например, рейтинг студентов (ранговая шкала) тоже не совсем категориальные данные. Такая переменная, конечно, делит наших респонгдентов на категории (группы), однако между этими группами определён порядок — больше-меньше — поэтому такие переменные называются ранговыми.\n\n\n\n\n2.3.2 Порядок шкал по мощности\nЕсли взять за основу допустимые операции, можно упорядочить шкалы по мощности — более мощной является та шкала, на которой допустимо больше операций. Тогда шкалы можно упорядочить так:\n\nноминальная &lt; порядковая &lt; интервальная &lt; абсолютная\n\nНаименее мощная — номинальная, наиболее мощная — абсолютная. Что нам надо вынести из этой иерархии? То, что мы можем по ней двигаться только влево. Если переменная измерена в абсолютной шкале, то мы можем сделать её порядковой или номинальной. Если же переменная изначально номинальная, то перейти в порядковую или интервальную шкалу невозможно.\nНапример, вот такой нехитрый пример (Таблица 2.2):\n\n\n\nТаблица 2.2: Одна и та же переменная, измеренная в разных шкалах\n\n\n\n\n\nВозраст [абсолютная]\nВозраст [ранговая]\nВозраст [номинальная]\n\n\n\n\n86\nпенсионер\nсовершеннолетний\n\n\n43\nвзрослый\nсовершеннолетний\n\n\n38\nвзрослый\nсовершеннолетний\n\n\n22\nмолодой\nсовершеннолетний\n\n\n16\nподросток\nнесовершеннолетний\n\n\n10\nребёнок\nнесовершеннолетний\n\n\n8\nребёнок\nнесовершеннолетний\n\n\n\n\n\n\nВ психологии чаще всего мы сталкиваемся с порядковыми шкалами. Это просто факт. Надо его принять.",
    "crumbs": [
      "Введение в статистику",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Шкалы и случайные величины</span>"
    ]
  },
  {
    "objectID": "intro-randvals.html#случайные-величины",
    "href": "intro-randvals.html#случайные-величины",
    "title": "2  Шкалы и случайные величины",
    "section": "2.4 Случайные величины",
    "text": "2.4 Случайные величины\nЕщё раз:\n\nИзмерение — это приписывание признакам объектов изучаемой совокупности определенных значений на определенной шкале.\n\nСо шкалой разобрались. Теперь надо разобраться с приписыванием. Будем рассматривать этот вопрос только с точки зрения статистики — теорию измерений не трогаем.\n\n2.4.1 Случайный эксперимент\nОтвлечемся на любимый объект статистиков — игральный кубик.\n\n\n\n\n\nСкажем просто:\n\nБросание игрального кубика — это случайный эксперимент,\nВыпавшее число — это случайная величина.\n\nТеперь более строго.\n\nСлучайный эксперимент — это математическая модель некоторого реального эксперимента. В каком смысле то, что мы называем сейчас экспериментом, случайно? В том, что результат такого эксперимента точно неизвестен. В частности, заранее неизвестно, какой стороной упадёт кубик при отдельном броске.\nСлучайная величина — это некоторая переменная, значения которой представляют собой численные исходы некоторого случайного эксперимента. Исход бросания кубика — выпавшее число.\n\nИз психологического поля можно привести следующие примеры:\n\nв опросных (психометрических) исследованиях:\n\nответ респондента на пункт опросника — это случайный эксперимент\nвыбранный им балл на шкале Ликерта — это случайная величина\nв чём случайность? — неизвестно, какой балл выберет респондент\n\nв поведенческих экспериментах:\n\nклик на стимул на экране в эксперименте зрительного поиска — это случайный эксперимент\nвремя реакции, которое фиксирует PsychoPy — случайная величина\nв чём случайность? — неизвестно, когда точно испытуемый кликнет по стимулу\n\nв нейроисследованиях:\n\nзапись ЭЭГ-активности в конкретный момент времени — случайный эксперимент\nамплитуда колебаний ЭЭГ — случайная величина\nв чём случайность? — неизвестно, что мы зафиксируем в конкретный момент (в частности, потому что существуют технические шумы)\n\nи т. д.\n\n\n\n\n\n\n\nСлучайный эксперимент vs эксперимент как метод исследования\n\n\n\nОбратим внимание на то, что случайный эксперимент — это не то же самое, что эксперимент как метод исследования, изучаемый в рамках курса экспериментальной психологии. Случайный эксперимент происходит в момент измерения какой-либо переменной в рамках эксперимента.\nОбратим внимание на примеры, приведённые выше. У нас есть поведенческий эксперимент, в котором существуют независимы и зависимые переменные, определённое количество проб на конкретное сочетание экспериментальных условий и другие аспекты дизайна эксперимента. Однако в процессе сбора данных в рамках этого исследования происходит множество случайный экспериментов, когда испытуемые проходят эксперимент. В каждой пробе осуществляется измерение зависимых переменных, и каждое такое измерение является случайным экспериментом, так как ответ испытуемого (клик или нажатие на клавишу) нельзя однозначно предсказать.\n\n\nИтого, мы постоянно имеем дело со случайными экспериментами в рамках любых исследований, но также, что более важно, по результатам этих случайных экспериментов [в рамках нашего эксперимента или заполнения опросника] мы собираем значения случайных величин. Вся статистика работает со случайными величинами.\n\n\n2.4.2 Случайная величина\nПопробуем ещё такой заход. Вот мы тут говорим об измерениях признаков/переменных. Эти переменные и есть случайные величины, которые мы измеряем. Случайные — потому что мы никогда не знаем, что же мы получим в конкретном измерении. Почему не знаем? Если у нас «хардовое» измерение (типа ЭЭГ или PsychoPy) — всегда есть погрешность измерения и «шум» в данных. Мы не можем предусмотреть всё, чтобы нашего испытуемого ничего не отвлекало, он занимался только экспериментальной задачей, не думал о коте, который остался дома или испытывал блаженство от ЭЭГшной шапочки на себе. Если это опросник — всё, вроде бы, ещё понятнее. Что нам именно сейчас отметит именно этот респондент — известно только одному никому. В каком состоянии он пришёл, какие у него личностные черты и свойства, насколько от нам доверяет, насколько он готов отвечать честно и т.д.\nК вопросу, зачем нам статистика и анализ данных — чтобы среди всех этих факторов выделить то, что нас интересует как исследователей, и получить ответы на исследовательские вопросы.\nСлучайные величины бывают дискретные и непрерывные:\n\nнепрерывные — принимают любые значения (рост, возраст, время реакции и др.)\nдискретные — могут принимать только определенные значения (пол, город проживания, балл по шкале Ликерта и др.)\n\n\n\n\n\n\n\nПеременные vs Шкалы vs Случайные величины\n\n\n\nМы обозначили три понятия — переменные, шкалы и случайные величины — которые выглядят очень похоже друг на друга. Тем не менее, они не являются синонимами. Давайте разберемся в различиях между ними. Для этого рассмотрим следующие примеры.\n\n\n\n\n\n\n\n\n\nПеременная\nТип переменной\nШкала\nСлучайная величина\n\n\n\n\nПол\nНоминальная\nНоминальная\nДискретная\n\n\nУровень образования\nНоминальная / Ранговая\nНоминальная / Порядковая\nДискретная\n\n\nБалл по шкале Ликерта\nРанговая\nПорядковая\nДискретная\n\n\nКоличество детей в семье\nКоличественная дискретная\nАбсолютная\nДискретная\n\n\nТемпература по Цельсию\nКоличественная непрерывная\nИнтервальная\nНепрерывная\n\n\nТемпература по Кельвину\nКоличественная непрерывная\nАбсолютная\nНепрерывная\n\n\nВремя реакции\nКоличественная непрерывная\nАбсолютная\nНепрерывная\n\n\n\nТаким образом, можно наблюдать, что хотя эти понятия в некоторой мере пересекаются, всё же существуют различия между этими тремя терминами.\n\n\nЗачем нам различать дискретные и непрерывные случайные величины? Это различение оказывается критически важно, когда мы пытаемся математически описать случайные величины. Оказывается, что они по-разному ведут себя в отношении вероятности.\n\n\n2.4.3 Вероятность\nМатематически строгое введение понятия вероятности требует отдельного курса теории вероятности, которого у нас нет. Мы ограничимся во многом интуитивным пониманием вероятности, которого, в целом, для наших задач будет достаточно.\nПод вероятностью (probability, \\(\\mathbb{P}\\)) мы будем понимать меру возможности наступления некоторого события. Событием будем считать наблюдение (измерение) определённого значения случайной величины. Рассмотрим всю эту ситуацию на примерах дискретных и случайных величин.\n\n\n2.4.4 Дискретные случайные величины\nС дискретными случайными величинами все достаточно просто:\n\nесть ограниченный набор значений, которые случайная величина может принимать,\nесть вероятности, с которыми случайная величина принимает эти значения.\n\nДавайте на игральном кубике. Есть кубик — у него шесть граней. Возможные значения случайной величины \\(X\\) — \\(\\{1,2,3,4,5,6\\}\\). Вероятность того, что кубик упадет хотя бы какой-то из шести сторон — \\(1\\). Если кубик «честный», то каждая из граней выпадает равновероятно, то есть вероятность, с которой наша случайная величина принимает каждое из своих значений будет равна\n\\[\\mathbb{P}(X=1) = \\mathbb{P}(X=2) = \\mathbb{P}(X=3) = \\mathbb{P}(X=4) = \\mathbb{P}(X=5) = \\mathbb{P}(X=6 ) = \\frac{1}{6} \\approx 0.167\n\\]\nНо это мы рассчитали теоретически. Давайте проверим, будет ли это работать эмпирически. Подбросим кубик (на симуляции) 100 раз и посмотрим, сколько раз выпало та или иная грань (Таблица 2.3).\n\n\n\nТаблица 2.3: Результаты симуляции 100 бросков игрального кубика\n\n\n\n\n\n\n\nЗначение\n1\n2\n3\n4\n5\n6\n\n\n\n\nЧастота\n19\n15\n18\n11\n16\n21\n\n\nВероятность\n0.19\n0.15\n0.18\n0.11\n0.16\n0.21\n\n\n\n\n\n\n\n\nВнимание, мы построили таблицу частот, она же частотная таблица. Это способ описания поведения дискретной случайной величины в эксперименте.\nМожем ли мы это каким-то образом визуализировать? Да.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 2.2: Визуализация частоты выпадения значений при 100 бросках игрального кубика\n\n\n\nВнимание, столбчатая диаграмма (barplot). Как видите, по оси x идут значения нашей случайной величины, по оси y частота, с которой случайная величина принимает данной значение. Изи.\nНо погодите, кубик должен падать одинаково часто на каждую из граней, а на графике частоты разные. Да, это правда. Как мы уже не раз упоминали, в данных всегда есть шум и ни один эксперимент не может пройти идеально. В том числе и симуляция. Поэтому те отклонения, которые мы видим на графике, это всего лишь шум — то, что нам нерелевантно.\nЧтобы убедиться, что кубик все-таки верный, давайте подкинем его 1000 раз.\n\n\n\nТаблица 2.4: Результаты симуляции 1000 бросков игрального кубика\n\n\n\n\n\n\n\nЗначение\n1\n2\n3\n4\n5\n6\n\n\n\n\nЧастота\n170\n176\n171\n157\n162\n164\n\n\nВероятность\n0.17\n0.176\n0.171\n0.157\n0.162\n0.164\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 2.3: Визуализация частоты выпадения значений при 1000 бросках игрального кубика\n\n\n\n\n\n\nТаблица 2.5: Результаты симуляции 100 000 бросков игрального кубика\n\n\n\n\n\n\n\nЗначение\n1\n2\n3\n4\n5\n6\n\n\n\n\nЧастота\n16685\n16818\n16656\n16536\n16774\n16531\n\n\nВероятность\n0.167\n0.168\n0.167\n0.165\n0.168\n0.165\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 2.4: Визуализация частоты выпадения значений при 100 000 бросках игрального кубика\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 2.5: Функция вероятности дискретного равномерного распределения\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 2.6: Функция вероятности биномиального распределения\n\n\n\nНу, почти. Нивелировать шум полностью нам не удастся никогда, поэтому будем считать, что мы достаточно убеждены, что кубик честен.\nТо, что мы сейчас с вами строили — в таблице или на графике — называется распределением случайной величины. Распределение — это некоторый закон, который полностью описывает поведение случайной величины.\nИтак, мы сейчас обсудили как строить эмпирическое распределение нашей дискретной переменной. А как нам построить теоретическое распределение нашей случайной величины? Для этого нам нужно взять две оси — x и y. По оси абсцисс расположить значения нашей случайной величины, по оси ординат — вероятности, с которыми наша случайная величина принимает данные значения. Выглядит это так:\nТо, что изображено на рисунке, называется функцией вероятности (probability mass function, PMF) дискретного равномерного распределения.\n\n\n2.4.5 Непрерывные случайные величины\nОкей, с дискретными разобрались. С непрерывными же всё то же самое?\nНе совсем. Есть один ключевой момент, который всё портит.\nМы говорили, что дискретные случайные величины могут принимать только некоторые значения, например, целочисленные —\n1 ,\n2 ,\n3 ,\n− 5 ,\n0 … Их можно посчитать, и сопоставить им вероятности, с которыми случайная величина принимает эти значения.\nЧуть выше мы разобрались с дискретным равномерным распределением. Давайте попробуем применить аналогичные размышления для непрерывного равномерного распределения. Пусть мы случайным образом выбираем 1000 чисел из отрезка\n[ 0 , 1] 1. Займемся симуляцией и построим частотную таблицу:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 2.7: Визуализация частоты случайного выбора 100 чисел из отрезка \\([0, 1]\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 2.8: Визуализация частоты случайного выбора 1000 чисел из отрезка \\([0, 1]\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 2.9: Визуализация частоты случайного выбора 10 000 чисел из отрезка \\([0, 1]\\)\n\n\n\nОй… Эт чё, каждое число встретилось в выборке всего один раз? Тогда таблица частот бессмысленна.\nТак, попробуем другой заход. Когда мы считали вероятность того, что на кубике выпадет определенное число, мы взяли все возможные исходы и поделили единицу на их количество — получили вероятность. Попробуем тут так же.\nСколько всего чисел на отрезке\n[ 0 , 1] ? Бесконечность.\nЭто что, получается,\n\\[\n\\mathbb{P}(X = a) \\overset{?}{=} \\frac{1}{\\infty}\n\\]\nтак что ли? Но это же какой-то сюр! Не совсем.\nЕсли не вдаваться в детали, то\n\\[\n\\mathbb{P}(X = a) = \\lim_{n \\to \\infty} \\frac{1}{n} = 0\n\\]\nчто означает\nвероятность того, что непрерывная случайная величина принимает конкретное значение, равна нулю.\nЕсли вдаваясь в детали, то вот Но как это? Ведь числа-то выпадают! Вероятность не может быть равна нулю!\nЭто справедливо, но чтобы ответить на все вопросы точно, нам придется умереть в математических океанах. Воспользуемся эвристикой. Будем понимать под «вероятность того, что непрерывная случайная величина принимает конкретное значение, равна нулю» следующее:\nМы не можем ожидать, что беря числа их отрезка\n[ 0 , 1] мы попадём в какое-то конкретное число, например,\n0.5 . Даже если попадём во что-то очень похожее, это будет\n0.50003 или\n0.4999999999 . Ровно\n0.5 никогда не выпадет. В этом смысле вероятность, действительно равна нулю.\nВот такое странное поведение у этих непрерывных величин. И тем не менее, хочется все-таки как-то с ними работать, описывать из поведение.\nДа, мы не можем работать с конкретными значениями непрерывных случайных величин — но мы можем работать с интервалами на множестве значений. Так, если нам надо визуализировать распределение непрерывной случайной величины, мы уже не можем использовать barplot — будет результат как с таблицей чатот. Вместо этого будем использовать гистограмму (histogram):\nggplot(NULL, aes(random1000)) +\n  geom_histogram(color=\"black\")\nВ чем отличие гистограммы от столбиковой диаграммы?\nНа столбиковой диаграмме по оси x располагается дискретная переменная — каждый столбик соотносится с конкретным значением изучаемой переменной. На гистограмме же ось x поделена на определенное количество отрезков (на рисунке их 30). В границе каждого отрезка попадает сколько-то сгенерировааных нами чисел — высота столбика отражает количество чисел, попавших в этот отрезок. При этом количество столбиков не является строго фиксированным (в отличие от барплота).\nggplot(NULL, aes(random1000)) +\n  geom_histogram(bins = 20, color = \"black\")\nГистограмма обычно используется для отображения эмпирического распределения непрерывной случайной величины.\nА как же быть с теоретическим?\nВновь мы не можем взять то, что было у дискретных величин — изобразить график функции вероятности невозможно, посколько это будет прямая, совпадающая с осью x. Математики выкрутились хитро — они ввели понятие плотности вероятности. Что это такое мы разбирать не будем, потому что кроме математических формальностей за этим ничего не стоит, а для жизни нам это не особо нужно. Но что нам обязательно надо сделать — научиться читать график плотности вероятности (probability density function, PDF).\nПо оси x здесь значения нашей случайной величины (как и в случае PMF), а вот по оси y — эта самая загадочная плотность вероятности. А где же сама вероятность? Как рам узнать, какова вероятность попадания значений случайной величины в некоторый интервал?\nДля этого надо выделить этот интервал, провести через границы этого интервала прямые, параллельные оси y, и найти площадь под графиком функции на этом интервале:",
    "crumbs": [
      "Введение в статистику",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Шкалы и случайные величины</span>"
    ]
  },
  {
    "objectID": "intro-randvals.html#измерение-в-социальных-науках",
    "href": "intro-randvals.html#измерение-в-социальных-науках",
    "title": "2  Шкалы и случайные величины",
    "section": "",
    "text": "есть совокупность объектов, которые мы изучаем — выборка,\nв ней есть какие-то объекты,\nу объектов есть признаки,\nесли мы приписали признаку какое-то значение на некоторой шкале, значит мы измерили данный признак.\n\n\n\nрост\nвозраст\nпол (шкала из двух значений male и female)\nнациональность\nколичество детей в семье\nрейтинг студентов\nкурс обучения или уровень образования\nгеографические координаты (долгота и широта)\nтемпература\nдата\nIQ\nнарциссизм / макиавеллизм / психопатия\nвремя реакции\nточность ответов испытуемого в эксперименте\nи т. д.",
    "crumbs": [
      "Введение в статистику",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Шкалы и случайные величины</span>"
    ]
  },
  {
    "objectID": "desc-centraltend.html",
    "href": "desc-centraltend.html",
    "title": "3  Меры центральной тенденции",
    "section": "",
    "text": "Мы знаем, что наши переменные-признаки могут быть некоторым образом распределены — как в генеральной совокупности, так и в выборке. Как именно они распределены, описывается распределением случайной величины.\nВот мы собрали некоторые данные и получили какое-то эмпирическое распределение наших переменных. Нам бы, конечно, хотелось понять, что там такое за распределение. И первым шагом к пониманию этого будет описание распределения.\n3.1 Виды статистики Вообще статистика [как набор методов и инструментов] делится на два вида:\nОписательная статистика (descriptive statistics1) занимается обработкой статистических данных, их наглядным представлением, и собственно описанием через некоторые характеристики. Эти характеристики, количественно описывающие особенности имеющихся данных, называются описательными статистиками (descriptive statistics2). Задача описательной статистики — ёмко описать имеющиеся данные и составить на основе этих описаний общее представление о них, а также обнаружить особенности, которые могут повлиять на дальнейший анализ. Статистика вывода (inferential statistics) занимается поиском ответов на содержательные вопросы, которые мы задаем данным в ходе их анализа в рамках научных и практических исследований. Состоит из двух компонентов — тестирования статистических гипотез и статистических методов. Замечание о машинном обучении\nВы наверняка не раз слышали словосочетание «машинное обучение». Это что-то, что время от времени становится то менее, то более хайпово. На самом деле, статистические методы лежат где-то между статистикой вывода и машинным обучением.\nПочему?\nДело в том, что на статистические методы можно смотреть по-разному.\nЕсли нашей задачей является поиск ответов на исследовательские вопросы о закономерностях, о связи каких-либо факторов или влиянии переменных друг на друга, то мы будем смотреть на статистические модели с точки зрения статистики вывода. Это позволит нас находить ответы на интересующие нас вопросы — причем не важно, говорим мы о научных исследованиях или об исследованиях в индустрии. Если перед нами стоит задача хорошо предсказывать одни переменные на основании значений других — например, выдавать рекомендации на Яндекс.Музыке или в Яндекс.Лавке — то мы будем смотреть на те же статистические модели с точки зрения машинного обучения. То есть, модели абсолютно одни и те же, но то, какую модель мы назовем хорошей и как мы эту «хорошесть» определим, будет отличаться в зависимости от задачи — исследовательская или предиктивная — которая перед нами стоит.\nМы начнем знакомиться со статистикой с описательной статистики, а именно с мер центральной тенденции.\n3.2 Меры центральной тенденции Итак, мы хотим описать наши данные. Точнее, распределения переменных, которые у нас в данных есть. Хотим сделать это просто и ёмко. Насколько просто и ёмко? Ну, допустим максимально — одним числом. Кажется, значение переменной, которое лежит в центре распределения, неплохо для этого подойдет.\nКак мы будем искать, что там в центре распределения? Зависит от шкалы, в которой измерена конкретная переменная.\nШкала Мера центральная тенденции Номинальная Мода Порядковая Медиана Интервальная Среднее арифметическое Абсолютная Среднее арифметическое, геометрическое и др. Однако есть неоторые нюансы.\n3.2.1 Мода Мода (mode) — наиболее часто встречающееся значение данной переменной.\nТут все достаточно просто и интуитивно понятно. Пусть у нас есть следующий ряд наблюдений:\nx ## [1] 1 3 4 6 4 2 4 3 2 4 1 Если мы составим таблицу частот, то получим следующее:\ntable(x) ## x ## 1 2 3 4 6 ## 2 2 2 4 1 Очевидно, что\n4 встречается чаще других значений — это и есть мода.\nПонятно, что если на нашей шкале нет чисел, а есть текстовые лейблы, это ничего не меняет:\ny ## [1] “Москва” “Казань”\n## [3] “Кёнигсберг” “Барнаул (Алтайский край)” ## [5] “Москва” “Санкт-Петербург”\n## [7] “Санкт-Петербург” “Москва”\n## [9] “Санкт-Петербург” “Москва”\n## [11] “Кёнигсберг” “Санкт-Петербург”\n## [13] “Москва” “Казань”\n## [15] “Санкт-Петербург” “Санкт-Петербург”\n## [17] “Казань” “Казань”\n## [19] “Санкт-Петербург” “Москва”\n## [21] “Москва” “Санкт-Петербург”\n## [23] “Санкт-Петербург” “Санкт-Петербург”\n## [25] “Санкт-Петербург” “Москва”\n## [27] “Кёнигсберг” “Санкт-Петербург”\n## [29] “Казань” table(y) ## y ## Барнаул (Алтайский край) Казань Кёнигсберг ## 1 5 3 ## Москва Санкт-Петербург ## 8 12 Мода, получается, Санкт-Петербург.\nТак мы поступаем с эмпирическим распределением. Если мы имеем дело с генеральной совокупностью, то можем формально определить моду через фунцию вероятности (probability mass function, PMF). Это будет её максимальное значение:\nm o d e ( X ) = max ( P M F ( X ) )\nМода — 7.\n3.2.2 Медиана Медиана (median) — это значение, которые располагается на середине отсортированного ряда значений переменной. То есть, она делит все наблюдения переменной ровно пополам и половина наблюдений оказывается по одну сторону от медианы, а половина — по другую.\nЕсли у нас нечетное число наблюдений, то всё ясно:\nv1 ## [1] 2 3 14 9 16 19 28 7 26 18 1 sort(v1) ## [1] 1 2 3 7 9 14 16 18 19 26 28 median(v1) ## [1] 14 А что делать, если число наблюдений чётное? Ведь тогда середина ряда будет между двух чисел. Ну, возьмем их среднее арифметическое — это и будет медиана.\nv2 ## [1] 14 10 9 16 30 3 25 8 18 7 sort(v2) ## [1] 3 7 8 9 10 14 16 18 25 30 median(v2) ## [1] 12 Формально это можно написать так:\nm e d i a n = ⎧ ⎪ ⎨ ⎪ ⎩ X ( n + 1 2 ) , if n is odd , X ( n 2 ) + X ( n 2 + 1 ) 2 , otherwise ,\nгде\nX — ряд наблюдений данной переменной,\nn — число наблюдений,\nX ( a ) — наблюдение с индексом\na в сортированном векторе\nX .\n3.2.3 Среднее арифметическое С этим существом все знакомы еще со школы. Арифметическое среднее (arithmetic mean, mean, average) считается так:\nM X = ¯ x = ∑ n i = 1 x i n ,\nгде\n¯ X — среднее арифметическое,\nx i — наблюдение в векторе\nX ,\nn — количество наблюдений.\nНу, то есть всё сложить и поделить на количество того, чего сложили. Изи.\nВот, скажем, средние по v1 и v2:\nmean(v1) ## [1] 13 mean(v2) ## [1] 14 3.2.4 Другие средние Среднее арифметическое не одиноко — есть и другие. Встретяться они вам примерно нигде — то есть о-о-о-очень редко и, скорее всего, в каком-то изощрённом виде. Но упомянуть их, пожалуй, стоит.\n3.2.4.1 Геометрическое среднее Редко встречается в научных работах, но заради общего представления пусть будет.\nG X = n    ⎷ n ∏ i = 1\nx i = ( n ∏ i = 1\nx i ) 1 n\n3.2.4.2 Гармоническое Суперэкзотичный покемон.\nH X = n ∏ n i = 1 x i ∑ n i = 1 ( 1 x ∏ n j = 1 x j ) = n ∑ n i = 1 1 x i\n3.2.4.3 Квадратичное А вот это уже более полезная история. Мы с ним столкнёмся далее, правда под разными масками.\nКвадратичное среднее (quadratic mean, root mean square, RMS) — это квадратный корень из среднего квадрата наблюдений. Ничего не понятно, поэтому по порядку.\nесть наблюдение\nx i\nзначит есть и его квадрат\nx 2 i\nмы умеем считать обычно среднее арифметическое, но ведь\nx 2 i — это тоже наблюдение, просто в квадрате, так? значит можем посчитать среднее арифметическое квадратов наблюдений — средний квадрат ∑ n i = 1 x 2 i n\nнорм, а теперь извлечём из этого дела корень — получим то, что там надо X R M S = √ ∑ n i = 1 x 2 i n\nPer se мы его вряд ли ещё когда-то увидим, но пару раз оно внезапно всплывет.\n3.2.4.4 Взвешенное Полезная вещь.\nЧасто бывает такая ситуация, что нас нужно посчитать среднее по каким-либо имеющимся параметрам, но одни параметры для нас важнее, чем другие. Например, мы хотим вычислить суммарный балл обучающегося за курс на основе ряда работ, выполненных в течение курса, однако мы понимаем, что тест из десяти вопросов с множественном выбором явно менее показателен, чем, например, аналитическое эссе или экзаменационная оценка. Что делать? Взвесить параметры!\nЧто значит взвесить? Умножить на некоторое число. На самом деле, любое. Пусть мы посчитали, что написать эссе в три абстрактных раза тяжелее, чем написать тест, а сдать экзамен в два раза тяжелее, чем написать эссе. Тогда мы можем присвоить баллу за тест вес\n1 , баллу за аналитическое эссе вес\n3 , а экзамену — вес\n6 . Тогда итоговая оценка за курс будет рассчитываться следующим образом:\n\n4 final score\n1 ⋅ test + 3 ⋅ essay + 6 ⋅ exam\nСуперкласс. Однако! Весьма вероятно, что в учебном заведении принята единая система оценки для всех видов работ (ну, скажем, некая абстрактная десятибалльная система в сферическом вакууме). Получается, если и за тест, и за эссе, и за экзамен у студента по 10 баллов, то суммарный балл 100, что, кажется, больше, чем 10. Чтобы вернуться к изначальным границам баллов, нужно моделить суммарный балл на сумму весов параметров:\n\n\n5 final score\n1 ⋅ test + 3 ⋅ essay + 6 ⋅ exam 1 + 3 + 6\nКайф! Собственно, это и есть взвешенное среднее. Коэффициенты, на которые мы умножаем значение парамернов, называются весами параметров. И в общем виде формула принимает следующий вид.\n¯ x = ∑ n i = 1 w i x i ∑ n i = 1 w i = n ∑ i = 1\nw ′ i x i ,\nгде\nx i — значения конкретных параметров,\nw i — веса конкретных параметров,\nw ′ i — нормированные веса параметров.\nВторая часть формулы показывается нам, что можно облегчить себе вычислительную жизнь, если заранее нормировать веса, то есть разделить каждый коэффициент на сумму коэффициентов:\nw ′ i = w i ∑ n i = 1 w i\nТогда сумма коэффициентов будет равна единице. Так чаще всего и поступают, так как тогда коэффициент будет представлять долю, которую весит данный параметр в суммарной оценке. Удобно, практично, красиво.\nВзвещенное среднее часто применяется именно во всякого рода ассессментах, и не только образовательных. Например, вы HR-аналитик и оцениваете персонал. Вы аналитически вычисляете веса коэффициентов (допустим, с помощью линейной регрессии), а далее на их основе высчитаете интегральный балл, по которому будете оценивать сотрудников. Это как один из индустриальных примеров.\n3.3 Сравнение мер центральной тенденции Сравнивать будем моду, медиану и среднее [арифметическое].\nИтак, все три статистики — мода, медиана и среднее — описывают центральную тенденцию — некоторое значение изучаемой нами переменной, вокруг которого собираются другие значения. Но если их три и все они используются, значит между ними должны быть какие-то различия. Посмотрим, какие.\nВо-первых, очевидно, что моду невозможно посчитать для непрерывной переменной.\nНет, не очевидно Во-вторых, медиану нельзя посчитать на номинальной шкале. Кстати, почему?\nПотому что В-третьих, среднее тоже нельзя посчитать на номинальной шкале.\nМожно, но осторожно В-четвертых, для дискретной переменной значение среднего арифметического будет не особо осмысленно. Ну, скажем, странно сказать, что в аудитории в среднем стоят 15.86 столов или в российских семьях в среднем 1.5 ребенка. Конечно, в ряде случаев можно это как-то более-менее содержательно интерпретировать, но это требует усилий, а мы ленивые, поэтому лучше использовать медиану.\nИтого, делаем следующие выводы:\nдля номинальной шкалы пригодна только мода для дискретных переменных подходят мода и медиана мода иногда лучше, так как точно всегда будет целым числом для непрерывных переменных подходят медиана и среднее Теперь нам надо разобраться, как будут себя вести меры центральной тенденции в зависимости от формы распределения.\nНа симметричном распределении мода, медиана и среднее совпадают [или, по крайней мере, находятся очень близко друг к другу]. Здесь и далее: красная линия — среднее, синяя — медиана, зелёная — мода.\nНа асимметричном распределении мода [практически] в пике. Практически, потому что функция плотности вероятности [черная линия на графике] на всегда точно аппроксимирует (в данном случае то же, что и сглаживает) эмпирическое распределение. На картинке ниже мы видим, что на гистограмме мода — самый высокий столбик, что и показывает нам зелёная линия, которой обозначена мода. Однако при сглаживании гистограммы пик немного съехал, и мода оказалась не совсем в вершине графика функции плотности вероятности.\nВообще-то это нормально, потому что мода для непрерывной величины, которую мы и визуализируем с помощью графика плотности, либо не может быть посчитана вовсе, либо — если так получилось, и у нас все же есть повторяющиеся значения — не слишком хорошая мера центральной тенденции. В целом, и на симметричном распределении мода тоже может находиться немного в стороне от пика.\nНа асимметричном распределении медиана и среднее смещены в сторону хвоста. Среднее смещено сильнее медианы. Это связано с тем, что медиана зависит только от количества наблюдений, а среднее ещё и от самих значений. На картинке ниже пример для распределения с правосторонней асимметрии (потому что хвост справа) — среднее (красная линия) правее медианы (синяя линия).\nА это пример для распределения с левосторонней асимметрией (так как хвост слева) — среднее (красная линия) левее медианы (синяя линия).\nДля того, чтобы лучше разобраться с тем, как большие и малые значения влияют на моду и медиану посмотрим такой пример. Пусть у нас есть оценки за выпускную квалификационную работу. Например, такие:\nmarks ## [1] 6 7 7 8 8 Посчитаем медиану и среднее:\nmedian(marks) ## [1] 7 mean(marks) ## [1] 7.2 Среднее\n7.2 округлиться до\n7 , то есть можно считать, что среднее и медиана совпали. Ну, ок.\nНо в комиссии сидят два требовательных доктора наук, которые поставили оценки, сильно отличающиеся от остальных:\nmarks ## [1] 6 7 7 8 8 3 4 Посчитаем медиану и среднее теперь:\nmedian(marks) ## [1] 7 mean(marks) ## [1] 6.142857 Медиана осталась на месте — всё ещё\n7 . А вот среднее\n6.1 округлится до\n6 . Казалось бы, это немного, но в смысле оценок — это прилично, и может сильно повлиять на GPA.\nИтого, среднее более чувствительно к нетипичным значениям (очень большим или очень малым).\nЕсть ещё один интересный вариант распределений — бимодальные. Значит ли, что у этого распределения две моды? Не всегда. Посмотрим пример ниже:\nМы видим, что на графике есть два пика, однако строго математически мода одна (зеленая линия) — и она в более высоком пике. Это логично, ибо там самые часто встречающиеся значения.\nИ все жё содержательно мы не можем пренебречь вторым пиком. Почему нам он важен? Обычно бимодальное распределение — это повод задуматься о том, что наша выборка неоднородна. Бимодальное распределение как бы сложено из двух с центрами в двух пиках. То есть в нашей выборке как будто бы две подвыборки, которые обладают разными распределениями интересующего нам признака.\nЧто с этим делать? Хорошо всегда иметь в данным какие-либо дополнительные переменные — как минимум соцдем — чтобы мы могли по данным попытаться предположить, какую группировку мы могли забыть учесть при планировании исследования.\nСо средним и медианой происходит примерно то же, что и в случае асимметричного распределения. Второй пик смещает к себе обе меры центральной тенденции, причем среднее вновь сильнее, чем медиану.\n3.4 Свойства среднего арифметического Если к каждому значению распределения прибавить некоторое число (константу), то среднее увеличится на это же константу. M x + c = M x + c\nВот почему:\nM x + c = ∑ n i = 1 ( x i + c ) n = ∑ n i = 1 x i + n c n = ∑ n i = 1 x i n + c = M x + c\nИначе говоря, распределение просто сдвинется. Например, если к каждому значению синего распределения прибавить\n2 , получится красное:\nЕсли каждое значение распределение умножить на некоторое число (константу), то среднее увеличится во столько же раз. M x × c = M x × c\nВот почему:\nM x × c = ∑ n i = 1 ( x i × c ) n = c × ∑ n i = 1 x i n = ∑ n i = 1 x i n × c = M x × c\nНапример, здесь каждое значение синего распределения умножили на\n3 и получили красное:\nТут, правда, явно что-то ещё произошло, но мы пока этого не знаем. Однако, отметит этот факт.\nСумма отклонений от среднего значения равна нулю. n ∑ i = 1\n( x i − M x ) = 0\nЭлегантное доказательство:\nn ∑ i = 1\n( x i − M x ) = n ∑ i = 1\nx i − n ∑ i = 1\nM x = n ∑ i = 1\nx i − n M x = = n ∑ i = 1\nx i − n × 1 n n ∑ i = 1\nx i = n ∑ i = 1\nx i − n ∑ i = 1\nx i = 0\nНо можно это осмыслить и более просто графически.\nОтклонение — это разность между средним и конкретным значением переменной. И, действительно, так как среднее находится в центре распределения, то часть значений лежит справа, а часть слева. Значит, будут как положительные, так и отрицательные отклонения — и их сумма в итоге будет равна нулю.",
    "crumbs": [
      "Описательная статистика",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Меры центральной тенденции</span>"
    ]
  },
  {
    "objectID": "r-vis.html",
    "href": "r-vis.html",
    "title": "22  Визуализация данных",
    "section": "",
    "text": "22.1 Что есть ggplot2?\nggplot2 — это внешний пакет языка R, который позволяет строить красивые и сложные визуализации. Как и любой R-пакет, это набор функций, которые позволяют делать те или иные преобразования с графиками. Пакет ggplot2 является частью семейства пакетов tidyverse.\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors",
    "crumbs": [
      "Анализ данных в R",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Визуализация данных</span>"
    ]
  },
  {
    "objectID": "r-vis.html#грузим-данные",
    "href": "r-vis.html#грузим-данные",
    "title": "22  Визуализация данных",
    "section": "22.2 Грузим данные",
    "text": "22.2 Грузим данные\nДатасет номер раз:\n\ndirtDoz &lt;- read_csv(\"https://raw.githubusercontent.com/angelgardt/psy-hse-ggplot2/master/dirtyDozen.csv\")\n\nRows: 22 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): gender\ndbl (5): age, class, mac, nar, psy\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nДатасет номер два:\n\nshare &lt;- read_delim(\"https://raw.githubusercontent.com/angelgardt/psy-hse-ggplot2/master/share.csv\",\n                    delim = \" \", locale = locale(decimal_mark = \",\"))\n\nRows: 16200 Columns: 8\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \" \"\nchr (2): trialtype, platform\ndbl (4): setsize, time1, time2, id\nlgl (2): correct1, correct2\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.",
    "crumbs": [
      "Анализ данных в R",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Визуализация данных</span>"
    ]
  },
  {
    "objectID": "r-vis.html#философия-a-layered-grammar-of-graphics",
    "href": "r-vis.html#философия-a-layered-grammar-of-graphics",
    "title": "22  Визуализация данных",
    "section": "22.3 Философия A Layered Grammar of Graphics",
    "text": "22.3 Философия A Layered Grammar of Graphics\nИдея, воплощенная в ggplot2, восходит к работе L. Wilkinson «The Grammar of Graphics». Базируясь на идеях, изложенных в этой работе, Hadley Wickham разработал концепцию Layered Grammar of Graphics и создал мощный пакет для визуализации, ради которого мы все здесь собрались. Автором по этому пакету написана целая книга, но мы сосредоточимся на основных смысловых и ключевых моментах, которые необходимы, чтобы сделать что-то крутое.\n\nЧасто возникает вопрос: почему 2? Ответ примерно такой: был и первый ggplot, но попытка не задалась от слова совсем, и пришлось все переделать.",
    "crumbs": [
      "Анализ данных в R",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Визуализация данных</span>"
    ]
  },
  {
    "objectID": "r-vis.html#собственно-к-философии-построения-графиков",
    "href": "r-vis.html#собственно-к-философии-построения-графиков",
    "title": "22  Визуализация данных",
    "section": "22.4 Собственно к философии построения графиков",
    "text": "22.4 Собственно к философии построения графиков\nПо своей сути график представляет собой сложную аппликацию из нескольких слоев. На каждом слое располагаются сходные по содержанию элементы. Начиная с самого первого — базового — и постепенно добавляя слой за слоем необходимые элементы, можно создавать сложные визуализации для отображения инетерсных закономерностей в данных.\nПосле создания базового графика осуществляется настройка отдельных элементов по необходимости и в зависимости от требований издательства / преподавателя / научника / комиссии и т.д. И поскольку все элементы в определенной степени изолированы друг от друга, это открывает большие возможности кастомизации. Кроме того, чтобы оформить график в соответствии с конкретными требованиями, нет необходимости перерисовывать его целиком, так как содержательная часть графика независима от настроек внешнего облика. Все, что вам нужно — это добавить/удалить пару строк кода.\nНо — хватит слов! Поехали уже рисовать уже!",
    "crumbs": [
      "Анализ данных в R",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Визуализация данных</span>"
    ]
  },
  {
    "objectID": "r-vis.html#данные",
    "href": "r-vis.html#данные",
    "title": "22  Визуализация данных",
    "section": "22.5 Данные",
    "text": "22.5 Данные\nСегодня у нас есть двое данных. Первые — поведенческие. Это share. Это данные эксперимента, в котором пользователи Android и iOS искали иконки «share» обеих платформ среди универсальных иконок. Короче, зрительный поиск.\nПеременные в датасете следующие:\ntrialtype — тип пробы (tray/dots/both) setsize — количество стимулов в пробе (8/12/16) time1 — время первого клика time2 — время второго клика id — индентификатор испытуемого platform — платформа смартфона (Android/iOS) correct1 — был ли корректным первый клик (найден ли первый целевой стимул) correct2 — был ли корректным второй клик (найден ли второй целевой стимул) Вторые — опросниковые. Это dirtDoz. Это данные прохождения опросника «Темная дюжина» старшеклассниками российских школ.\nПеременные таковы:\nage — возраст респондента gender — гендерная принадлежность респондента (male/female/other) class — класс, в котором обучается респондент mac — балл по шкале макиавеллизма nar — балл по шкале нарциссизма psy — балл по шкале психопатии Ну, вот с данными мы познакомились — теперь можно расчехлять кисти!",
    "crumbs": [
      "Анализ данных в R",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Визуализация данных</span>"
    ]
  },
  {
    "objectID": "r-vis.html#базовая-визуализация",
    "href": "r-vis.html#базовая-визуализация",
    "title": "22  Визуализация данных",
    "section": "22.6 Базовая визуализация",
    "text": "22.6 Базовая визуализация\n\n22.6.1 Базовый слой\nКогда мы собираемся рисовать, мы берем холст. Когда мы начинаем рисовать график в ggplot2, первое, что нам надо ему сказать — «Дай мне холст!». На языке ggplot2 это делается с помощью команды ggplot():\n\nggplot()\n\n\n\n\n\n\n\n\nПолучите — распишитесь. ggplot2 дал нам холст. Иначе говоря, мы построили базовый слой, на котором далее будем располагать элементы нашего графика.\nСледующее, что нам нужно сделать, это указать данные, по которым мы будем строить нашу визуализацию. Это делается с помошью аргумента data:\n\nggplot(data = dirtDoz)\n\n\n\n\n\n\n\n\nВроде бы ничего не изменилось, да и собственно, не должно было, ведь мы никак не указали, что мы хотим отобразить. Давайте укажем.\n\n\n22.6.2 Разметка осей\nВажнейшие элементы любого графика — это оси. Мы строим двумерные графики, поэтому и оси у нас две — как учили в школе, x (горизонтальная ось, ось абсцисс) и y (вертикальная ось, ось ординат).\nЧтобы задать оси графика потребуется отдельная функция. Она называется aes(), и в общем задает эстетики графика.\n\n\n22.6.3 Эстетики (aesthetics)\nИтак, конкретнее об эстетиках. Иначе говоря, это то форматирование, которое связано с данными. Или еще один способ понимания: эстетики — это способы отображения переменных из датасета. У функции aes() есть ряд параметров, они тоже называются эстетики.\nВот список эстетик, которые используются чаще всего: x, y, color, fill, shape, size.\nНесложно догадаться, что переменные по осям задаются параметрами x и y. Что ж, зададим.\nДавайте визуализируем связь между нарциссизмом и макиавеллизмом (ернее, между баллами по этим шкалам):\n\nggplot(data = dirtDoz,\n       aes(nar, mac))\n\n\n\n\n\n\n\n\nТак, ну, допустим… А где картинка?\nКартинки нет, но ggplot2 честно отработал свою работу. Мы задали только оси — и он нам разметил их в соответствии с имеющимися в векторах значениях. Больше мы ему ничего не написали. Чтобы всё-таки получить картинку, необходимо указать, как мы хотим отобразим наши переменные.\n\n\n22.6.4 Геомы\nЗа то, каким образом будут отображены переменными, а конкретно, какими «геометрическими объектами», отвечает семейство функций geom_*. Когда мы переходим к этой функции, мы переходим на новый слой. Чтобы это обозначить используется плюсик +:\n\nggplot(data = dirtDoz,\n       aes(nar, mac)) +\n  geom_point()\n\n\n\n\n\n\n\n\nМы выбрали точки для отображения переменных, потому что это наиболее наглядный вариант отобразить зависимость между двумя переменными. Такой тип графика называется scatterplot, или диаграмма рассеяния.\nНо, вообще-то, можно и получше отобразить закономерность. Как минимум, добавить линию тренда с помощью специального геома:\n\nggplot(data = dirtDoz,\n       aes(nar, mac)) +\n  geom_point() +\n  geom_smooth()\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nКак видите, при добавлении нового «геометрического» способа отображения данных мы добавляем новый слой.\nСейчас мы гораздо отчетливее видим, что есть некоторый тренд — с ростом баллов по одной из шкал растут баллы и по другой. Но мы можем визуализировать закономерность ещё более явно. Так как geom_smooth() подразумевает «сглаживание», оно может происходить с помощью разных методов (используемый метод нам написали в консоль). Мы можем эскплицинто указать, какой метод хотим использовать. Например, линейную регрессию:\n\nggplot(data = dirtDoz,\n       aes(nar, mac)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nВот вам, пожалуйста, красивый линейный тренд.",
    "crumbs": [
      "Анализ данных в R",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Визуализация данных</span>"
    ]
  },
  {
    "objectID": "r-vis.html#больше-информации-на-график",
    "href": "r-vis.html#больше-информации-на-график",
    "title": "22  Визуализация данных",
    "section": "22.7 Больше информации на график",
    "text": "22.7 Больше информации на график\nКак мы помним из структуры данных (и теории), в Тёмную Триаду входят три1 черты. Мы пока отобразили зависимость между двумя. Хотелось бы добавить третью и при этом не выйти в 3D — всё-таки мы собираемся это печатать в статье.\n\n22.7.1 Цвет\nЦвет — удивительная шкала. Она может быть дискретной и непрерывной, порядковой и категориальной. То есть, мы можем сделать вот так:\n\nggplot(data = dirtDoz,\n       aes(nar, mac, color = psy)) +\n  geom_point()\n\n\n\n\n\n\n\n\nМы задачи отображение количественной переменной с помошью цвета и эффектно отобразили связь между тремя количественными переменными на двумерном графике. Ну и кто тебе скажет, что мы не боги визуализации?\n\n\n22.7.2 Фасетирование\nМы уже отобразили приличное количество информации, но недостаточное. Давайте ещё нашу выборку по гендеру разобьем — будет весело! Чтобы на одном субграфике были мальчики, а на другом девочки. Для этого есть семейство функций facet_*():\n\nggplot(data = dirtDoz,\n       aes(nar, mac, color = psy)) +\n  geom_point() +\n  facet_wrap(~ gender)\n\n\n\n\n\n\n\n\nЯ обещал, что будет весело. Давайте исключим из анализа единственную небинарную персону — заодно посмотрим, как филигранно tidyverse сплетается с ggplot2:\n\ndirtDoz %&gt;% \n  filter(gender != \"other\") %&gt;% \n  ggplot(aes(nar, mac, color = psy)) +\n  geom_point() +\n  facet_wrap(~ gender)\n\n\n\n\n\n\n\n\nНу, что-то такое. Вот теперь это окончательный вариант базовой визуализации. Ура!",
    "crumbs": [
      "Анализ данных в R",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Визуализация данных</span>"
    ]
  },
  {
    "objectID": "r-vis.html#настройка-графика",
    "href": "r-vis.html#настройка-графика",
    "title": "22  Визуализация данных",
    "section": "22.8 Настройка графика",
    "text": "22.8 Настройка графика\nНо рано радоваться — время кодить, солнце ещё не взошло!\nСодержание на график мы вывели, однако в таком виде публиковать его категорически нельзя. Необходимо поработать над деталями.\n\n22.8.1 Эстетики, но под другим углом\nОцените размер точек — кажется маловаты, да? Надо нарисовать их побольше. Для этого есть параметр size:\n\ndirtDoz %&gt;% \n  filter(gender != \"other\") %&gt;% \n  ggplot(aes(nar, mac, color = psy)) +\n  geom_point(size = 2) +\n  facet_wrap(~ gender)\n\n\n\n\n\n\n\n\nВот, так стало значительно приятнее и проще смотреть. Обратите внимание, что в этом случае мы задавали значение аргумента size вне функции aes(), так как он не связан с самими данными — значение 2 мы берем извне, задаем произвольно.\n\n\n22.8.2 Подписи осей\nПоддерживаете вы отечественного производителя или стремитесь опубликоваться в журнале «Природа» — переменные на графике должны быть подписаны нормально2. То есть из подписи оси (эстетики) должно быть понятно, какой показатель отображён на графике. Что ж, подпишем.\nДля этого есть функция labs(), которая позволяет подписать [почти] всё и сразу. И это будет новый слой:\n\ndirtDoz %&gt;% \n  filter(gender != \"other\") %&gt;% \n  ggplot(aes(nar, mac, color = psy)) +\n  geom_point(size = 2) +\n  facet_wrap(~ gender) +\n  labs(x = \"Нарциссизм\",\n       y = \"Макиавеллизм\",\n       color = \"Психопатия\",\n       title = \"Связь черт Тёмной Триады у старших школьников\")\n\n\n\n\n\n\n\n\nНу, уже как будто прилично.\n\n\n22.8.3 Тема\nНо серый дефолтный фон до добра ещё никого не доводил. Когда-то стандартная тема ggplot2 была очень популярна, так как позволяла заявить, что ты «могёшь в R» и «как мощны твои количественные методы», но нынче публика уже значительно искушенная в этом вопросе. Да и на самом деле, серый фон снижает контрастность, в результате чего восприятие визуализации затрудняется. Проведем этот день под лозунгом: «Даёшь контрастность каждой визуализации!»\nНам всего лишь надо сменить тему. Я люблю чёрно-белую, другие предпочитают минималистичную. Выбор за вами, но я сделаю вот так:\n\ndirtDoz %&gt;% \n  filter(gender != \"other\") %&gt;% \n  ggplot(aes(nar, mac, color = psy)) +\n  geom_point(size = 2) +\n  facet_wrap(~ gender) +\n  labs(x = \"Нарциссизм\",\n       y = \"Макиавеллизм\",\n       color = \"Психопатия\",\n       title = \"Связь черт Тёмной Триады у старших школьников\") +\n  theme_bw()\n\n\n\n\n\n\n\n\nКрасuво!\n\n\n22.8.4 Подписи фасетов\nО нет! Мы же забыли исправить названия субграфиков — они там всё ещё на латинице висят. Секундочку, щас всё будет!\nДля этого нам надо завести именованный вектор: имена — это исходные названия уровней категориальной переменной, а сами элементы вектора — это лейблы, которые должны отображаться на графике. В нашем случае вот так:\n\nla &lt;- c(male = \"Мальчики\",\n        female = \"Девочки\")\n\nТеперь мы можем сделать вот что:\n\ndirtDoz %&gt;% \n  filter(gender != \"other\") %&gt;% \n  ggplot(aes(nar, mac, color = psy)) +\n  geom_point(size = 2) +\n  facet_wrap(~ gender,\n             labeller = labeller(gender = la)) +\n  labs(x = \"Нарциссизм\",\n       y = \"Макиавеллизм\",\n       color = \"Психопатия\",\n       title = \"Связь черт Тёмной Триады у старших школьников\") +\n  theme_bw()\n\n\n\n\n\n\n\n\nФух, слава Богу… Поправили.\n\n\n22.8.5 Оптимизация\nКажется, что легеда, располагающаяся справа — это невыгодно. Почему? Нам мы хотелось показать взаимоотношения между переменными, растянув точки порише. Мы могли бы переместить легенду вниз, освободив пространство справа. Давайте так и сделаем. Для этого нам надо подправить некоторые элементы темы:\n\ndirtDoz %&gt;% \n  filter(gender != \"other\") %&gt;% \n  ggplot(aes(nar, mac, color = psy)) +\n  geom_point(size = 2) +\n  facet_wrap(~ gender,\n             labeller = labeller(gender = la)) +\n  labs(x = \"Нарциссизм\",\n       y = \"Макиавеллизм\",\n       color = \"Психопатия\",\n       title = \"Связь черт Тёмной Триады у старших школьников\") +\n  theme_bw() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\nТеперь и общая композиция симметричнее стала. Но вот маленькая напасть: подпись «Психопатия» теперь как будто проситься, чтобы её подтянули повыше — выповняли по центру с цветовой шкалой. Штош, это потребует чуть большего количества пальцедвижений, но её прошение мы удовлетворим.\nПод капотом ggplot2 развернута сложная система ООП, в которую мы вникать не будем, иначе нам никакого кофе не хватит. Но сейчас мы подойдём к ней максимально близко.\nПодпись «Психопатия» — это, во-первых, текстовый элемент, а во-вторых, заголовок легенды. Теперь внимательно следите за руками и названиями аргументов и функций:\n\ndirtDoz %&gt;% \n  filter(gender != \"other\") %&gt;% \n  ggplot(aes(nar, mac, color = psy)) +\n  geom_point(size = 2) +\n  facet_wrap(~ gender,\n             labeller = labeller(gender = la)) +\n  labs(x = \"Нарциссизм\",\n       y = \"Макиавеллизм\",\n       color = \"Психопатия\",\n       title = \"Связь черт Тёмной Триады у старших школьников\") +\n  theme_bw() +\n  theme(legend.position = \"bottom\",\n        legend.title = element_text(vjust = .9))\n\n\n\n\n\n\n\n\nМы взяли аргумент legend.title, который управляет заголовком легенды, а так как заголовок — это текстовый элемент, то аргумент ждёт результата работы функции element_text(). Из все возможных опций управления текстом нас сейччас интересует выравнивание по вертикали (vertical justification) (vjust). Число подбираем визуально.\nЭто было непросто, но мы справились. Давайте ещё заголовок графика до кучи по центру поставим — и отправляем в журнал:\n\ndirtDoz %&gt;% \n  filter(gender != \"other\") %&gt;% \n  ggplot(aes(nar, mac, color = psy)) +\n  geom_point(size = 2) +\n  facet_wrap(~ gender,\n             labeller = labeller(gender = la)) +\n  labs(x = \"Нарциссизм\",\n       y = \"Макиавеллизм\",\n       color = \"Психопатия\",\n       title = \"Связь черт Тёмной Триады у старших школьников\") +\n  theme_bw() +\n  theme(legend.position = \"bottom\",\n        legend.title = element_text(vjust = .9),\n        plot.title = element_text(hjust = .5))",
    "crumbs": [
      "Анализ данных в R",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Визуализация данных</span>"
    ]
  },
  {
    "objectID": "r-vis.html#встроенная-статистическая-обработка",
    "href": "r-vis.html#встроенная-статистическая-обработка",
    "title": "22  Визуализация данных",
    "section": "22.9 Встроенная статистическая обработка",
    "text": "22.9 Встроенная статистическая обработка\nХорошо. На простеньком мы размялись — теперь надо сделать что-то посерьёзнее.\nЧасто бывает так, что мы хотим отобразить на графике не сырые данные, а какие-либо посчитанные статистики. Получается, сначала надо предобработать данные, получить необходимые значения, а затем на основе них строить график.\nНо зачем? Если можно сразу в коде построения графика рассчитать все, что нам нужно! В ggplot2 уже встроены инструменты простейшей статистический обработки!\nПосотрим, как влияют на [среднее] время реакции различные экспериментальные условия. Начнём с самого простого — количества стимулов на экране.\n\n22.9.1 Статы\nСтаты — это те самые встроенные инструменты статистической обработки. Они позволяют прямо в коде графика обсчитать данные и сразу визуализировать результаты.\nНа самом деле, мы уже сталкивались со встроенными инструментами статистической обработки, ведь что делает geom_smooth(method = “lm”)? Не что иное, как визуализирует линейную регрессию, построенную на выбранных данных!\nНаиболее популярная функция из семейства stat_*() — это stat_summary(). С помощью неё можно удобно визуализировать средние.\nСразу зададим черно-белую тему на все последующие визуализации. Это делается так:\n\ntheme_set(theme_bw())\n\nИтак, мы хотим понять, как зависит среднее время реакции от количества стимулов. Нас будут интересовать пробы с одним целевым стимулом, поэтому отфильтруем все остальные, а также сразу расчертим базовый слой:\n\nshare %&gt;% \n  filter(trialtype != \"both\") %&gt;% \n  ggplot(aes(setsize, time1))\n\n\n\n\n\n\n\n\nТак, обратим внимание на следующий момент: на оси x обозначились числа 10 и 14, а таких сетсайзов в данных нет. Можем убедиться:\n\nunique(share$setsize)\n\n[1]  8 12 16\n\n\nЭто случилось потому, что переменная setsize записана в датасете как числовая, а для вычисления среднего времени реакции в каждом из условий будет нужна группировка наблюдений. По числовой переменно группировка невозможноЮ, поэтому необходимо прописать, что данную переменную мы будем рассматривать как фактор:\n\nshare %&gt;% \n  filter(trialtype != \"both\") %&gt;% \n  ggplot(aes(as_factor(setsize), time1))\n\n\n\n\n\n\n\n\nВо, теперь как надо.\nТеперь добавляем средние. Как и полагается, на новый слой:\n\nshare %&gt;% \n  filter(trialtype != \"both\") %&gt;% \n  ggplot(aes(as_factor(setsize), time1)) +\n  stat_summary(fun = mean, geom = \"point\")\n\n\n\n\n\n\n\n\nРазберемся, что тут написано. Первый аргумент (fun) принимает функцию, результат которой будет отложен по оси y. В нашем случае это среднее (mean). Она будет применена к переменой time1, причем наблюдения будут автоматически сгруппированы по интересующим нас группам. Второй аргумент — это уже знакомый нам геом, который отвечает за то, как «геометрически» будут отрисованы знаечния на графике. Наш выбор — точки. Как результат мы наблюдаем то, что хотели.\nОднако как мы знаем из статистики, чтобы узнать, есть ли различия между условиями, нам недостаточно только средних значений — необходимы доверительные интервалы. Что ж, отобразим и их.\nДобавим новый слой с помощью всё той же функции stat_summary(), но на этот раз она будет выглядеть немного по-другому:\n\nshare %&gt;% \n  filter(trialtype != \"both\") %&gt;% \n  ggplot(aes(as_factor(setsize), time1)) +\n  stat_summary(fun = mean, geom = \"point\") +\n  stat_summary(fun.data = mean_cl_boot, geom = \"errorbar\")\n\n\n\n\n\n\n\n\nКак мы видим, немного изменился первый аргумент. Это связано с изменением геома. Для отображения доверительных интервалов нам нужен геом errorbar, который требует не одно значение, а два — верхнюю и нижнюю границу доверительного интервала. То есть fun.data принимает как аргумент мини-датафрейм — как раз в таком формате и возвращается результат функции mean_cl_boot(). Можно посмотреть на её работу отдельно:\n\nmean_cl_boot(share$time1)\n\n         y     ymin    ymax\n1 1.599066 1.586527 1.61303\n\n\nСобственно, вот он датафрейм из одной строки. Здесь три значения, но errorbar игронирует первое (оно и есть среднее значение) и использует только второе и третье, строя по ним «усы».\nСобственно, график почти готов, однако добавим линии, которые будут соединять наши средние. Это допустимо в данной визуализации, так как мы отображаем повторные измерения и так более наглядно будет прослеживаться закономерность.\n\nshare %&gt;% \n  filter(trialtype != \"both\") %&gt;% \n  ggplot(aes(as_factor(setsize), time1)) +\n  stat_summary(fun = mean, geom = \"point\") +\n  stat_summary(fun.data = mean_cl_boot, geom = \"errorbar\") +\n  stat_summary(fun = mean, geom = \"line\")\n\n`geom_line()`: Each group consists of only one observation.\nℹ Do you need to adjust the group aesthetic?\n\n\n\n\n\n\n\n\n\nАга, вроде слой добавили, но ничего не изменилось. Еще и warning вылетел. Надо почитать!\nggplot2 нам говорит, что каждая группа у нас содержит одно наблюдение — и он категорически прав, ведь у нас в каждой группе отображается только среднее значение. Из-за этого он не понимает, как ему нужно соединять точки. Надо ему подсказать, что с точки зрения соединения точек у нас всего одна группа, так как мы хотим, чтобы наши средние были последовательно соединены. Так и запишем (используя аргумент group):\n\nshare %&gt;% \n  filter(trialtype != \"both\") %&gt;% \n  ggplot(aes(as_factor(setsize), time1)) +\n  stat_summary(fun = mean, geom = \"point\") +\n  stat_summary(fun.data = mean_cl_boot, geom = \"errorbar\") +\n  stat_summary(fun = mean, geom = \"line\",\n               aes(group = 1))\n\n\n\n\n\n\n\n\nВот такая у нас классная линейная закономерность получилась! Ну, а чего мы ждали — зрительный поиск же…\nДобавляем переменных Окей, как влияет число стимулов мы поняли. Теперь хотим посмотреть, как на этом фоне ведут себя другие факторы. Добавим тип пробы. Обозначим его, например, цветом:\n\nshare %&gt;% \n  filter(trialtype != \"both\") %&gt;% \n  ggplot(aes(as_factor(setsize), time1,\n             color = trialtype)) +\n  stat_summary(fun = mean, geom = \"point\") +\n  stat_summary(fun.data = mean_cl_boot, geom = \"errorbar\") +\n  stat_summary(fun = mean, geom = \"line\",\n               aes(group = 1))\n\n\n\n\n\n\n\n\nО, хорошо. Только с линией теперь надо что-то делать. Пока её уберём. И добавим ещё один фактор — используемая платформа смартфона. Пусть он обозначается формой точек:\n\nshare %&gt;% \n  filter(trialtype != \"both\") %&gt;% \n  ggplot(aes(as_factor(setsize), time1,\n             color = trialtype,\n             shape = platform)) +\n  stat_summary(fun = mean, geom = \"point\") +\n  stat_summary(fun.data = mean_cl_boot, geom = \"errorbar\")\n\n\n\n\n\n\n\n\nУф… Ну, групировка прошла успешно — уже хорошо, однако отображение хромает. Надо немного раздвинуть точки относительно друг друга в отдельных категориях, так как сейчас они явно друг на друга налезают. Для этого есть аргумент position, который принимает результат выполнения функции position_dodge()3.\nЧтобы упростить код, заведем переменную pd, в которую сохраним результаты работы функции position_dodge() и далее будем передавать эту переменную в аргумент position:\n\npd &lt;- position_dodge(.3)\nshare %&gt;% \n  filter(trialtype != \"both\") %&gt;% \n  ggplot(aes(as_factor(setsize), time1,\n             color = trialtype,\n             shape = platform)) +\n  stat_summary(fun = mean, geom = \"point\",\n               position = pd) +\n  stat_summary(fun.data = mean_cl_boot, geom = \"errorbar\",\n               position = pd)\n\n\n\n\n\n\n\n\nАга, ну, норм. Только «усы» доверительных интервалов широки — надо сделать их поуже:\n\nshare %&gt;% \n  filter(trialtype != \"both\") %&gt;% \n  ggplot(aes(as_factor(setsize), time1,\n             color = trialtype,\n             shape = platform)) +\n  stat_summary(fun = mean, geom = \"point\",\n               position = pd) +\n  stat_summary(fun.data = mean_cl_boot, geom = \"errorbar\",\n               position = pd, width = .3)\n\n\n\n\n\n\n\n\nКрасuво!\nОсталось только понять, как бы нам вернуть линии. Осмыслим, что нам надо соединить красные треугольники между собой, зелёные треугольники между собой, красный точки между собой и зелёные точки между собой. То есть группы точек у нас получаются в результате взаимодействия факторов. Так и напишем:\n\nshare %&gt;% \n  filter(trialtype != \"both\") %&gt;% \n  ggplot(aes(as_factor(setsize), time1,\n             color = trialtype,\n             shape = platform,\n             group = interaction(trialtype, platform))) +\n  stat_summary(fun = mean, geom = \"line\",\n               position = pd) +\n  stat_summary(fun.data = mean_cl_boot, geom = \"errorbar\",\n               position = pd, width = .3) +\n  stat_summary(fun = mean, geom = \"point\",\n               position = pd)",
    "crumbs": [
      "Анализ данных в R",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Визуализация данных</span>"
    ]
  },
  {
    "objectID": "r-vis.html#наводим-красоту",
    "href": "r-vis.html#наводим-красоту",
    "title": "22  Визуализация данных",
    "section": "22.10 Наводим красоту",
    "text": "22.10 Наводим красоту\nСделаем то, что мы уже умеем: увеличим размер точек, сдвинем легенду вниз, подпишем переменные. Попутно сделаем линни пунктирными, чтобы не сильно отвлекали внимание:\n\nshare %&gt;% \n  filter(trialtype != \"both\") %&gt;% \n  ggplot(aes(as_factor(setsize), time1,\n             color = trialtype,\n             shape = platform,\n             group = interaction(trialtype, platform))) +\n  stat_summary(fun = mean, geom = \"line\",\n               position = pd, linetype = \"dashed\", alpha = .7) +\n  stat_summary(fun.data = mean_cl_boot, geom = \"errorbar\",\n               position = pd, width = .3) +\n  stat_summary(fun = mean, geom = \"point\",\n               position = pd, size = 3) +\n  labs(x = \"Количество стимулов в пробе\",\n       y = \"Время реакции (первый клик), с\",\n       color = \"Тип пробы\",\n       shape = \"Платформа\",\n       title = \"Время реакции при взаимодействии факторов\",\n       subtitle = \"Тип пробы × Платформа × Количество стимулов в пробе\") +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\nОч. хор. Вот только мы отобразили интервальную оценку на графике, а ведь это может быть не только доверительный интервал — так же выглядит и стандартная ошибка и даже стандартное отклонение. Надо подписать в подписи:\n\nshare %&gt;% \n  filter(trialtype != \"both\") %&gt;% \n  ggplot(aes(as_factor(setsize), time1,\n             color = trialtype,\n             shape = platform,\n             group = interaction(trialtype, platform))) +\n  stat_summary(fun = mean, geom = \"line\",\n               position = pd, linetype = \"dashed\", alpha = .7) +\n  stat_summary(fun.data = mean_cl_boot, geom = \"errorbar\",\n               position = pd, width = .3) +\n  stat_summary(fun = mean, geom = \"point\",\n               position = pd, size = 3) +\n  labs(x = \"Количество стимулов в пробе\",\n       y = \"Время реакции (первый клик), с\",\n       color = \"Тип пробы\",\n       shape = \"Платформа\",\n       title = \"Время реакции при взаимодействии факторов\",\n       subtitle = \"Тип пробы × Платформа × Количество стимулов в пробе\",\n       caption = \"отображен 95% доверительный интервал\") +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\nНу, почти всё. Осталось только красиво подписать платформы и типы проб. Для этого есть функции семейства scale_*(). Работает это так:\n\nshare %&gt;% \n  filter(trialtype != \"both\") %&gt;% \n  ggplot(aes(as_factor(setsize), time1,\n             color = trialtype,\n             shape = platform,\n             group = interaction(trialtype, platform))) +\n  stat_summary(fun = mean, geom = \"line\",\n               position = pd, linetype = \"dashed\", alpha = .7) +\n  stat_summary(fun.data = mean_cl_boot, geom = \"errorbar\",\n               position = pd, width = .3) +\n  stat_summary(fun = mean, geom = \"point\",\n               position = pd, size = 3) +\n  labs(x = \"Количество стимулов в пробе\",\n       y = \"Время реакции (первый клик), с\",\n       color = \"Тип пробы\",\n       shape = \"Платформа\",\n       title = \"Время реакции при взаимодействии факторов\",\n       subtitle = \"Тип пробы × Платформа × Количество стимулов в пробе\",\n       caption = \"отображен 95% доверительный интервал\") +\n  scale_color_discrete(labels = c(\"Three Dots\", \"Outgoing Tray\")) +\n  scale_shape_discrete(labels = c(\"Android\", \"iOS\")) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\nСупер! Отправляем в журнал!",
    "crumbs": [
      "Анализ данных в R",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Визуализация данных</span>"
    ]
  },
  {
    "objectID": "r-vis.html#кастомизация-шкал",
    "href": "r-vis.html#кастомизация-шкал",
    "title": "22  Визуализация данных",
    "section": "22.11 Кастомизация шкал",
    "text": "22.11 Кастомизация шкал\nНо недолго мы радовались: пришло письмо от редактора. Краткое содержание — «очень хороший, отличный, прекрасный график! переделайте, пожалуйста». Редактору не понравилось использование цвета — журнал печатается в черно-белом варианте.\nОк, секудочку.\nМы уже приступили к кастомизации шкал, когда задавали лейблы для уровней наших категориальных переменных. Теперь включим кастом на всю силу — используем функции scale_*_manual():\n\nshare %&gt;% \n  filter(trialtype != \"both\") %&gt;% \n  ggplot(aes(as_factor(setsize), time1,\n             color = trialtype,\n             shape = platform,\n             group = interaction(trialtype, platform))) +\n  stat_summary(fun = mean, geom = \"line\",\n               position = pd, linetype = \"dashed\", alpha = .7) +\n  stat_summary(fun.data = mean_cl_boot, geom = \"errorbar\",\n               position = pd, width = .3) +\n  stat_summary(fun = mean, geom = \"point\",\n               position = pd, size = 3) +\n  labs(x = \"Количество стимулов в пробе\",\n       y = \"Время реакции (первый клик), с\",\n       color = \"Тип пробы\",\n       shape = \"Платформа\",\n       title = \"Время реакции при взаимодействии факторов\",\n       subtitle = \"Тип пробы × Платформа × Количество стимулов в пробе\",\n       caption = \"отображен 95% доверительный интервал\") +\n  scale_color_manual(values = c(\"gray50\", \"black\"),\n                     labels = c(\"Three Dots\", \"Outgoing Tray\")) +\n  scale_shape_discrete(labels = c(\"Android\", \"iOS\")) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\nЗдесь мы задаём цвета через названия. Можно также использовать HEX code.",
    "crumbs": [
      "Анализ данных в R",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Визуализация данных</span>"
    ]
  },
  {
    "objectID": "r-vis.html#шрифт",
    "href": "r-vis.html#шрифт",
    "title": "22  Визуализация данных",
    "section": "22.12 Шрифт",
    "text": "22.12 Шрифт\nЕщё редактору не понравился шрифт без засечек — он хочет Times New Roman.\nОк, секудочку.\n\nshare %&gt;% \n  filter(trialtype != \"both\") %&gt;% \n  ggplot(aes(as_factor(setsize), time1,\n             color = trialtype,\n             shape = platform,\n             group = interaction(trialtype, platform))) +\n  stat_summary(fun = mean, geom = \"line\",\n               position = pd, linetype = \"dashed\", alpha = .7) +\n  stat_summary(fun.data = mean_cl_boot, geom = \"errorbar\",\n               position = pd, width = .3) +\n  stat_summary(fun = mean, geom = \"point\",\n               position = pd, size = 3) +\n  labs(x = \"Количество стимулов в пробе\",\n       y = \"Время реакции (первый клик), с\",\n       color = \"Тип пробы\",\n       shape = \"Платформа\",\n       title = \"Время реакции при взаимодействии факторов\",\n       subtitle = \"Тип пробы × Платформа × Количество стимулов в пробе\",\n       caption = \"отображен 95% доверительный интервал\") +\n  scale_color_manual(values = c(\"gray50\", \"black\"),\n                     labels = c(\"Three Dots\", \"Outgoing Tray\")) +\n  scale_shape_discrete(labels = c(\"Android\", \"iOS\")) +\n  theme(legend.position = \"bottom\",\n        title = element_text(family = \"Times New Roman\"),\n        plot.title = element_text(face = \"bold\"),\n        axis.text = element_text(family = \"Times New Roman\"),\n        legend.text = element_text(family = \"Times New Roman\"))\n\n\n\n\n\n\n\n\nНу, вот теперь редактор доволен.",
    "crumbs": [
      "Анализ данных в R",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Визуализация данных</span>"
    ]
  },
  {
    "objectID": "r-vis.html#сохранение-графиков",
    "href": "r-vis.html#сохранение-графиков",
    "title": "22  Визуализация данных",
    "section": "22.13 Сохранение графиков",
    "text": "22.13 Сохранение графиков\nДля того, чтобы опубликовать график в статье или даже просто вставить в презентацию нужно его как-то выгрузить. Скриншоты нам не подходят, потому что качество их зачастую совершенно никуда не годится. На наше счастье есть функция для выгрузки картинок из R, которая называется ggsave().\nОна принимает следующие аргументы:\n\nfilename — название файла, в который будет сохранен график\nplot — график, который необходимо сохранить (по умолчанию — последний построенный)\nscale — степень масштабирования изображения\nwidth — ширина изображения\nheight — высота изображения\nunits — единицы изменения (дюймы, миллиметры, сантиметры)\ndpi — разрешение изображения (dots per inch, точки на дюйм)\n\nФункция позволяет сохранить изображения большинства форматов (JPEG, PNG, SVG, TIFF, PDF).\n\nggsave('graph1.png', width = 20, height = 20, units = 'cm', dpi = \"print\")\n\nВыполнив эту функцию мы получим в рабочей директории файл с графиком, который мы только что нарисовали.\n\nВот и весь основной флоу, которому можно следовать при создании публикабельных графиков. А если этого уже мало, то вполне можно нырять в невероятное чтиво и бороздить Google вопросами о конкретных вещах — на Stack Overflow найдется ответ практически на любой вопрос.\n\nЛёгкая внезапность.↩︎\nИбо, как гласит одна тибетская мудрость, «нормально делай — нормально будет».↩︎\nЕсть и другие position_*(), но мы их упустим.↩︎",
    "crumbs": [
      "Анализ данных в R",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Визуализация данных</span>"
    ]
  },
  {
    "objectID": "infer-stattesting.html",
    "href": "infer-stattesting.html",
    "title": "7  Тестирование статистических гипотез",
    "section": "",
    "text": "В ходе статистического анализа мы, главным образом, заняты тем, что тестируем статистические гипотезы. Ведь на какого рода вопросы мы отвечаем с помощью анализа?\nРазличаются ли группы между собой? Значимо ли влияние какого-либо фактора? → Различаются ли группы между собой? Хороша ли та модель, которую мы построили? → Отличается ли она от нулевой модели? И так далее. Так или иначе, всё сводится в тому, что мы ищем какие-то различия. Но силу того, что у нас неопределённость и вариация в данных, мы просто так «в лоб» сказать о различиях по оценкам параметров не можем. Приходится тестировать статистические гипотезы.\n8.1 Базовые понятия Гипотеза ( H ) — это предположение, которое подлежит проверке на основе результатов наблюдений.\nГипотезы бывают трех видов:\nТеоретическая — про конструкты. Эмпирическая — про переменные (зависимые и независимые). Статистическая — про данные (что мы получили в данный конкретный момент, собрав вот эти конкретные данные). Статистические гипотезы бывают простыми и сложными.\nПростая гипотеза — это такое предположение, которое включает в себя какое-либо однозначно определеяемое утверждение. Например, истинная величина параметра соответствует некоторому строго заданному значению:\nH : θ = θ 0 . Другой вариант — две генеральные совокупности имеют одно и то же значение одной и той же характеристики:\nH : θ 1 = θ 2 .\nСложная гипотеза предполагает множественность вариантов для параметра, которые укладываются в рамки проверяемого предположения. Например,\nH : θ &gt; θ 0 или\nH : θ 1 ≠ θ 2 .\nВ рамках самого хода тестирования гипотез существует проверяемая (нулевая) гипотеза ( H 0 ). Её обычно стараются предельно упростить, поэтому она формулируется как простая гипотеза. В противовес ей выдвигается альтернативная гипотеза ( H 1 ), которая будет иметь вид сложной гипотезы.\nДля проверки гипотезы нужны две вещи:\nрезультаты наблюдений и критерий. Результаты наблюдений, полученные на выборке, сами по себе, как правило, не используются. Однако на их основе рассчитываются выборочные статистики (показатели), которые непосредственно участвуют в проверке гипотезы.\nВ результате проверки статистических гипотез могут возникнуть четыре ситуации.\n8.2 Возможные результаты проверки гипотез Мы изучаем в исследовании какую-либо закономерность, которая в реальном мире может существовать, а может и не существовать. В силу неопределённости и вариативности наших данных мы может либо обнаружить интересующую нас закономерность, либо не обнаружить.\nВ качестве нулевой гипотезы мы выдвигаем предположение о том, что закономерность отсутствует — так мы упрощаем нашу нулевую гипотезу. Пусть\nH 0 обозначает, что предположение, которое мы проверяем справедливо, а\nH 1 — не справедливо. На основании данных мы можем либо не отклонить наше предположение ( ^ H 0 ), либо отклонить ( ^ H 1 ).\nТогда имеем следующую ситуацию:\nH 0\nH 1\n^ H 0 ✓ Ошибка II рода ^ H 1 Ошибка I рода ✓ Ошибка I рода возникает, когда в генеральной совокупности искомой закономерности нет, но мы в силу случайных флуктуаций в данных её нашли. Ошибка II рода возникает, когда в генеральной совокупности искомая закономерность есть, но мы в силу каких-либо причин её не нашли. Ошибки — это нехорошо, они нас не устраивают. Надо каким-то образом их контролировать.\nОшибка I рода контролируется достаточно просто. Так как мы нашли закономерность, которую искали, мы можем посчитать вероятность, с которой потенциально ошиблись. А собственно контролировать ошибку мы будем с помощью уровня значимости\nα , который выбирается до начала процедуры тестирования гипотезы. Он и задает вероятность, с который мы позволяем себе ошибиться — отклонить нулевую гипотезу, при условии, что она верна.\nОшибку II рода контролировать сложнее, так как мы не нашли закономерность, которую искали. Нам нужна какая-то метрика, которая позволит сказать, что мы сделали всё возможное для того, чтобы обнаружить искомую закономерность. Вероятность ошибки II рода обозначается\nβ — тогда вероятность того, что мы не совершили ошибку II рода будет\n1 − β . Эта величина называется статистической мощностью, и она связана с размером эффекта и объемом выборки. Статистическую мощность можно рассчитать как до проведения статистического анализа — для расчета требуемого объема выборки — так и после — для определения достигнутой статистической мощности.\nСоберем все обозначения в единую табличку1:\nH 0\nH 1\n^ H 0\nP ( ^ H 0 | H 0 )\nP ( ^ H 0 | H 1 ) = β\n^ H 1\nP ( ^ H 1 | H 0 ) = α\nP ( ^ H 1 | H 1 ) = 1 − β\nУровень значимости\nα выбирается близким к нулю — всем знакомо конвенциональное значение\n0.05 . Вообще\nα можно выбрать сколь угодно малым, однако при выборе уровня значимости руководствуются принципом разумной достаточности, так как если устремить\nα к нулю, то устремиться к нулю и вероятность отклонения нулевой гипотезы\nМатематические руны Достаточной статистической мощностью считается\n0.8 . Аналогично, устремляя мощность к единице ( ( 1 − β ) → 1 ⇒ β → 0 ), мы устремляем вероятность не отклонения нулевой гипотезы к нулю:\nЕщё математические руны Необходимо также помнить, что ошибки первого и второго рода связаны между собой так, что\nα → 0 ⇒ β → 1\nОпять математические руны 8.3 Асимметрия статистического вывода Выше мы сказали, что для проверки гипотезы нужны две вещи:\nрезультаты наблюдений и критерий. С результатами наблюдений более-менее очевидно.\nКритерий — это правило, согласно которому гипотезу либо принимают, либо отклоняют. Однако перед тем как проверять гипотезу, её так-то нужно сформулировать, и сделать это правильно, поскольку от формулировки гипотезы зависит интерпретация результатов проверки и дальнейшее использование полученной информации.\nИспользуемая статистика сама по себе является [непрерывной] случайной величиной, а значит может быть построено её распределение. Критерий будет разделять это распределение на непересекающиеся области. В результате чего возникает критическая область — область отклонения гипотезы. Дополнением к ней является область неотклонения гипотезы.\nКритическая область может быть односторонней (при\nH 1 : θ &gt; θ 0 или\nH 1 : θ &lt; θ 0 ) и двусторонней (при\nH 1 : θ ≠ θ 0 ). «Размер» критической области определяется уровнем значимости.\nСтатистический вывод — заключение о том, получили ли мы подтверждение альтернативной гипотезы — по структуре представляет собой импликацию. Если вам не знаком этот термин из логики, то вот:\nЕсли значение нашей статистики, которое мы рассчитали на выборке, попало в критическую область, то мы говорим о том, что нулевая гипотеза отклоняется. Если значение нашей статистики, которое мы рассчитали на выборке, не попало в критическую область, то мы не получаем оснований для того, чтобы отклонить нулевую гипотезу. Однако мы также не получаем оснований, чтобы её «принять». Мы остаёмся в некотором неведении: мы не нашли различий, а есть они там или нет — хто ж их знает… Итого, мы не можем сделать никакого вывода. В этом и заключается асимметрия статистического вывода. Как раз для того, чтобы с ней как-то жить, мы работаем со статистической мощностью.\nПосмотреть, как все эти штуки друг с другом соотносятся можно тут.\n8.4 Алгоритм тестирования статистических гипотез Для тестирования гипотез есть два сценария: первый и тот, которым мы будем пользоваться. Первый вариант чуть более классический, второй — более гибкий.\nСценарий номер раз\nФормулировка гипотезы Выбор статистического критерия Выбор уровня значимости\nα\nПостроение закона распредления статистики критерия при условии, что нулевая гипотеза верна Определение границ критической области Расчёт выборочной статистики Определение, попадает ли наблюдемое значение статистики в критическую область и вынесение решения Сценарий номер два\nФормулировка гипотезы Выбор статистического критерия Выбор уровня значимости\nα\nПостроение закона распредлеения статистики критерия при условии, что нулевая гипотеза верна Расчёт выборочной статистики Расчёт достигнутого уровня значимости p-value Сопоставление\nα и p-value и вынесение решения Почему второй вариант более гибкий? Представим, что мы захотели понизить уровень значимости с\n0.05 до\n0.01 — такие уровни значимости всречаются, например, в медицине. Если мы идем по первому сценарию, то нам надо заново пересчитать критические значения и вновь проанализировать, попадает ли наблюдаемое значение в критическую область. Если мы адепты второго сценария, то нам надо только выполнить одно новое сравнение нашего p-value с новым уровнем значимости.\nВероятно, пока мало что понятно. Поэтому в следующей главе разберем все это безобразие на примере.\nЗдесь использовано обозначение условной вероятности\nP ( A | B ) , то есть это вероятность того, что случилось событие\nA при условии, что случилось событие\nB .↩︎",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Тестирование статистических гипотез</span>"
    ]
  },
  {
    "objectID": "infer-categorical.html",
    "href": "infer-categorical.html",
    "title": "8  Анализ категориальных данных",
    "section": "",
    "text": "8.1\nСегодня мы изучим первый статистический метод, которые применяется при анализе категориальных данных. Напомню, что это категориальные данные — это те, которые измерены в номинальной (реже — порядковой) шкале. А раз они измерены в номинальной шкале, значит наши данные разбиваются на некоторые категории. А раз есть категории, значит можно посчитать их частоты. А раз можно посчитать частоты, значит можно построить таблицу частот.\n9.1 Таблица сопряженности Таблицы частот для одной переменной мы с вами строили — это довольно простая задача. Однако теперь нас интересует не одна переменная, а две — мы будем искать связь между двумя категориальными переменными.\nДавайте на примере. Пусть у нас есть данные о том, как студенты некоторого курса сдали экзамен по анализу данных. Экзамен проходил во вторник. При этом известно, что одна часть студентов усиленно готовилась к экзамену, а другая часть — отмечала понедельник в барах на Китай-городе.\nВ цифрах:\nвсего студентов на курсе 120 человек успешно сдали экзамен 94 студента готовились к экзамену 86 студентов готовились и не сдали экзамен 3 студента По этим данным мы можем построить таблицу сопряженности (contingency table, cross tabulation, crosstab).\nСдали экзамен Не сдали экзамен\nГотовились\n83\n3\n86\nОтмечали понедельник\n11\n23\n34\n94\n26\n120\nТаблица сопряженности отражает совместное распределение двух категориальных (в данном случае — бинарных) переменных. На основе такой таблицы проверяеются гипотезы о связях между двумя категориальными переменными. В общем случае таблица сопряженности будет выглядеть так:\nX 1\nX 2\nY 1\na\nb\na + b\nY 2\nc\nd\nc + d\na + c\nb + d\nN\nЭта таблица отражает эмпирические частоты — то есть те, которые получились из собранных нами данных. Здесь\nX и\nY — наши переменные, индексы\n1 и\n2 показывают категорию, к которой относится то или иное наблюдение. На пересечении столбца и строки — частота совместного появления признаков\nX i и\nY j . Суммы частот по строкам и столбцам — маргинальные частоты [строк и столбцов соответственно].\nИтак, эмпирические частоты у нас в наличии. Теперь вспомним алгоритм тестирования статистических гипотез:\nФормулировка гипотезы Выбор статистического критерия Выбор уровня значимости\nα\nПостроение закона распределения статистики критерия при условии, что нулевая гипотеза верна Расчёт выборочной статистики Расчёт достигнутого уровня значимости p-value Сопоставление\nα и p-value и вынесение решения Нам нужно сформулировать нулевую гипотезу. Как мы помним, нулевая гипотеза всегда об отсутствии каких-либо различий. В нашем случае если нет никакой связи между переменными\nX и\nY — подготовка к экзамену и успешность сдачи — то все частоты в таблице должны быть равны. То есть\nH 0 : a = b = c = d\nАльтернативная гипотеза в этом случае будет гласить, что хотя бы между двумя какими-либо ячейчас отсутствует статистическое равенство. Это сложно записать математически — можно, но будет длинно. Воспользуется логическим отрицанием — неверно, что все частоты равны между собой:\nH 1 : ¬ ( a = b = c = d )\nОкей, формулировка гипотезы — ✓ done!\nТеперь надо понять, как нам эту гипотезу протестировать. Мы бы, конечно, могли просто взять и сравнить наши частоты, но мы так делать не можем, ибо всё ещё вариативность и неопределенность статистических данных. Надо придумать другой ход.\nМы можем взять теоретическую ситуацию, когда между нашими переменными нет связи — а значит нет различия между частотами — и сравнить с тем, что у нас есть в таблице. Так и поступают. Поэтому сначала нам нужно рассчитать теоретические частоты.\n9.2 Расчёт теоретических частот Чтобы построить таблицу теоретического распределения частот, нам нужно понять, как были бы распределены наши данные в случае, если между нашими переменными не было бы связи. Это делается так:\nX ∗ 1\nX ∗ 2\nY ∗ 1\n( a + b ) ⋅ ( a + c ) N\n( a + b ) ⋅ ( b + d ) N\nY ∗ 2\n( c + d ) ⋅ ( a + c ) N\n( c + d ) ⋅ ( a + c ) N\nТо есть для расчета теоретической частоты в конкретной ячейке мы перемножаем соответствующие маргинальные вероятности и делим на число наблюдений. Рассчитаем теоретические частоты для нашего примера:\nСдали экзамен Не сдали экзамен Готовились\n86 ⋅ 94 120 = 67.37\n86 ⋅ 26 120 = 18.63\nОтмечали понедельник\n34 ⋅ 94 120 = 26.63\n34 ⋅ 26 120 = 7.37\nЧтобы понять, какое содержание стоит за расчетом теоретических частот, надо разложить расчет на два действия. Первое — вычисление долей сдавших и не сдавших экзамен:\np готовились = 86 120 ≈ 0.72 p отмечали = 34 120 ≈ 0.28\nВторое — находим части, равные рассчитанным долям, от количества сдавших и не сдавших экзамен:\nn готовились и сдали = 0.72 ⋅ 94 = 67.68 n готовились и не сдали = 0.72 ⋅ 26 = 18.72 n отмечали и сдали = 0.28 ⋅ 94 = 26.32 n отмечали и не сдали = 0.28 ⋅ 26 = 7.28\nНу, вот мы то же самое и получили [с точностью до промежуточного округления].\nИтак, у нас есть всё, что нужно, чтобы перейти к тестированию гипотезы.\n9.3 Критерий независимости Пирсона Переходим ко второму пункту алгоритма — выбор статистического критерия. Для поиска взаимосвязей между категориальными переменными разработан критерий независимости Пирсона ( χ 2 Пирсона). Это первый статистический критерий, с которым мы с вами знакомимся. У каждого статистического критерия есть статистика критерия, которая рассчитывается определенным образом. Для критерия\nχ 2 она рассчитывается так:\nχ 2 = ∑ i\n( O i − E i ) 2 E i ,\nгде\nO i — эмпирические (наблюдаемые, observed) частоты, а\nE i — теоретические (ожидаемые, expected) частоты.\nВнимательно присмотревшись в формуле, можно увидеть, что чем больше отклонения эмпирических частот от теоретических, тем больше числитель дроби, тем больше статистистика критерия. Несложно рассчитать значения статистического критерия для нашего примера:\nχ 2 = ( 83 − 67.37 ) 2 67.37 + ( 3 − 18.63 ) 2 18.63 + ( 11 − 26.63 ) 2 26.63 + ( 23 − 7.37 ) 2 7.37 ≈ 59.06\nДальше мы можем рассчитать критическое значения критерия\nχ 2 — договоримся, что если не оговорено иное, мы берем в качестве уровня значимости конвенциональный 0.05 — и сравнить его с полученным, но в прошлой главе мы договорились, что так делать не будем. Мы будем рассчитывать p-value, или достигнутый уровень значимости. Руками это делать трудно — надо в интегралы уметь и формулы для распределенрий знать — поэтому мы доверим это специально обученному программному обеспечению:",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Анализ категориальных данных</span>"
    ]
  },
  {
    "objectID": "infer-categorical.html#pearsons-chi-squared-test-with-yates-continuity-correction",
    "href": "infer-categorical.html#pearsons-chi-squared-test-with-yates-continuity-correction",
    "title": "8  Анализ категориальных данных",
    "section": "8.2 Pearson’s Chi-squared test with Yates’ continuity correction",
    "text": "8.2 Pearson’s Chi-squared test with Yates’ continuity correction",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Анализ категориальных данных</span>"
    ]
  },
  {
    "objectID": "infer-categorical.html#section-1",
    "href": "infer-categorical.html#section-1",
    "title": "8  Анализ категориальных данных",
    "section": "8.3 ",
    "text": "8.3",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Анализ категориальных данных</span>"
    ]
  },
  {
    "objectID": "infer-categorical.html#data-d",
    "href": "infer-categorical.html#data-d",
    "title": "8  Анализ категориальных данных",
    "section": "8.4 data: d",
    "text": "8.4 data: d",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Анализ категориальных данных</span>"
    ]
  },
  {
    "objectID": "infer-categorical.html#x-squared-55.378-df-1-p-value-9.946e-14",
    "href": "infer-categorical.html#x-squared-55.378-df-1-p-value-9.946e-14",
    "title": "8  Анализ категориальных данных",
    "section": "8.5 X-squared = 55.378, df = 1, p-value = 9.946e-14",
    "text": "8.5 X-squared = 55.378, df = 1, p-value = 9.946e-14\nПолучилось другое значение\nχ 2 , что связано со сделанными нами округлениями в ходе расчета теоретических частот. Но принципиально это ничего не меняет — мы видим p-value много меньше 0.05.\nКак мы говорили в прошлой главе, если p-value меньше выбранного уровня значимости, у нас есть оcнования отклонить нулевую гипотезу об отсутствии различий, и принять альтернативную гипотезу. Итого, связь между подготовкой к экзамену и успешностью его сдачи есть. Ну, ничего себе какой полезный вывод — а мы то и не в курсе были…\nЛадно, это всё хорошо — и даже достаточно для эвристического понимания того, как работает хи-вадрат, однако давайте все же посмотрим чуть глубже в то, что осталось под капотом.\n9.3.1 Распределение\nχ 2\nПочему вообще критерий называется хи-квадрат? Откуда берется p-value? И куда делось «построение закона распределения статистики критерия при условии, что нулевая гипотеза верна»?\nОбо всём по порядку. Еще раз вернемся к алгоритму:\nФормулировка гипотезы Выбор статистического критерия Выбор уровня значимости\nα\nПостроение закона распределения статистики критерия при условии, что нулевая гипотеза верна Расчёт выборочной статистики Расчёт достигнутого уровня значимости p-value Сопоставление\nα и p-value и вынесение решения Первые три пункта вычеркнуты — их мы обсудили. Гипотезу сформулировали, статистический критерий выбрали, уровень значимости оставили конвенциональным. Что дальше?\nСтатистика критерия — любого, не только\nχ 2 — это непрерывная случайная величина. И она подчинается некоторому распределению. В частности, статистика рассматриваемого нами критерия подчинается распределению\nχ 2 , которое выглядит вот так:\nВажно: так выглядит распределение статистики\nχ 2 при условии, что нулевая гипотеза верна! Именно его мы и строим. Ну, как строим: оно уже построено за нас. Нам надо только понять, какое из возможных использовать. Мы видим, что форма распределения зависит от количества степеней свободы. Значит нам надо научиться рассчитывать количество степеней свободы для конкретного случая. Это делается так:",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Анализ категориальных данных</span>"
    ]
  },
  {
    "objectID": "infer-categorical.html#f-m",
    "href": "infer-categorical.html#f-m",
    "title": "8  Анализ категориальных данных",
    "section": "9.1 f m",
    "text": "9.1 f m",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Анализ категориальных данных</span>"
    ]
  },
  {
    "objectID": "infer-categorical.html#section-2",
    "href": "infer-categorical.html#section-2",
    "title": "8  Анализ категориальных данных",
    "section": "9.2 233 262",
    "text": "9.2 233 262\nТеоретические частоты будут таковы — рассчитываются по формуле\np ⋅ N , где\np — теоретическая доля,\nN — количество наблюдений:\nfemale male 0.54 ⋅ 495 = 267.3\n0.46 ⋅ 495 = 227.7\nФормула для расчета статистики критерия вот:\nχ 2 = ∑ i\n( O i − E i ) 2 E i ,\nгде\nO i — эмпирические (наблюдаемые, observed) частоты, а\nE i — теоретические (ожидаемые, expected) частоты.\nНа что-то очень похоже, да?\nСтепени свободы, так как строчка в таблице только одна, рассчитываются следующим образом:",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Анализ категориальных данных</span>"
    ]
  },
  {
    "objectID": "infer-categorical.html#section-3",
    "href": "infer-categorical.html#section-3",
    "title": "8  Анализ категориальных данных",
    "section": "10.1 ",
    "text": "10.1",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Анализ категориальных данных</span>"
    ]
  },
  {
    "objectID": "infer-categorical.html#chi-squared-test-for-given-probabilities",
    "href": "infer-categorical.html#chi-squared-test-for-given-probabilities",
    "title": "8  Анализ категориальных данных",
    "section": "10.2 Chi-squared test for given probabilities",
    "text": "10.2 Chi-squared test for given probabilities",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Анализ категориальных данных</span>"
    ]
  },
  {
    "objectID": "infer-categorical.html#section-4",
    "href": "infer-categorical.html#section-4",
    "title": "8  Анализ категориальных данных",
    "section": "10.3 ",
    "text": "10.3",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Анализ категориальных данных</span>"
    ]
  },
  {
    "objectID": "infer-categorical.html#data-d_gender",
    "href": "infer-categorical.html#data-d_gender",
    "title": "8  Анализ категориальных данных",
    "section": "10.4 data: d_gender",
    "text": "10.4 data: d_gender",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Анализ категориальных данных</span>"
    ]
  },
  {
    "objectID": "infer-categorical.html#x-squared-9.5682-df-1-p-value-0.00198",
    "href": "infer-categorical.html#x-squared-9.5682-df-1-p-value-0.00198",
    "title": "8  Анализ категориальных данных",
    "section": "10.5 X-squared = 9.5682, df = 1, p-value = 0.00198",
    "text": "10.5 X-squared = 9.5682, df = 1, p-value = 0.00198\nСнова видим p-value\n&lt; α , значит мы получили значение статистики, не характерное для ситуации справедливости нулевой гипотезы, и у нас есть основания отклонить нулевую гипотезу и принять альтернативную о том, что эмпирические частоты отличаются от теоретических.\nПолучается, что наша выборка не особо репрезентативна. Грустно… :(\nНапоследок отметим, что если мы используем специально обученное ПО, мы вообще-то мало что делаем руками — только строчку кода пишем. Остальное же — формулирование гипотезы, построение распределения, подсчет статистики и p-value — за нас делает машина. Нам остается включить мозг, когда мы делаем статистический вывод.",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Анализ категориальных данных</span>"
    ]
  },
  {
    "objectID": "infer-correlation.html",
    "href": "infer-correlation.html",
    "title": "9  Корреляционный анализ",
    "section": "",
    "text": "Мы рассмотрели метод, позволяющий тестировать гипотезу об отсутствии связи между категориальными переменными. Теперь посмотрим, что делать, если нас интересуют гипотезы о связи между двумя количественными переменными.\n10.1 Ковариация Мы хотим описать имеющиеся взаимосвязи как можно проще и опираясь на то, что у нас уже есть. Мы знаем, что дисперсия, или вариация (variance), заключает в себе информацию об изменчивости признака. Если мы хотим исследовать взаимосвязь между признаками, то логично будет посмотреть, как изменяется один из признаков при изменении другого — иначе говоря, рассчитать совместную изменчивость признаков, или ко-вариацию (co-variance).\nКак мы её будем считать? Подумаем графически. Расположим две переменные на осях и сопоставим каждому имеющемуся наблюдению точку на плоскости.\nОтметим средние значения по обеим переменным.\nРазумеется, что у нас наблюдаются отклонения наблюдений от среднего. Заметим, что отклонения могут быть сонаправленными — одновременно по обеим переменным\nx и\ny в положительную или отрицательную сторону (зеленые стрелки) — или разнонаправленными — в положительную сторону по одной из переменных и в отрицательную по другой, и наоборот (рыжие стрелки).\nПри этом обратим внимание, что точки на графике, отображающие наши наблюдения, как бы идут более-менее в направлении какой-то прямой — серой, как на картинке:\nИ чем отклонения от средних по обеим переменным будут более согласованы, тем точнее они будут идти по этой прямой.\nПолучается, мы можем на основании согласованности отклонений уже следать заключение о направлении связи, ведь произведение отклонений по обеим величинам будет положительно, если отклонения сонаправленны, и отрицательно, если они разнонаправленны. Остается только понять, как совместные отклонения организованы «в среднем» — это и будет ковариацией двух величин:\ncov ( x , y ) = 1 n − 1 n ∑ i = 1\n( ¯ x − x i ) ( ¯ y − y i )\nКстати, а что такое ковариация переменной с самой собой?\nВот что Это все, конечно, кул, однако важно отметить, что ковариация улавливает только линейную составляющую взаимосвязи между признаками — мы говорили выше, что точки идут как бы по некоторой прямой — поэтому если\ncov ( x , y ) = 0 , то мы можем сказать, что между переменными нет линейной взаимосвязи, однако это не значит, что между этими переменными нет никакой другой зависимости.\nЕсли же ковариация отлична от нуля, то\nесли её значение положительно, то мы можем заподозрить прямую связь между переменными, если же её значение отрицательно, то мы можем предположить обратную связь между переменными. У ковариации есть два важных недостатка:\nэто размерная величина, поэтому её значение зависит от единиц измерения признаков, она зависит от дисперсий признаков, поэтому по её значению можно определить только направление связи (прямая или обратная), однако ничего нельзая сказать о силе связи. Поэтому нам нужно как-то модицифировать эту статистику, чтобы мы могли больше вытащить из её значения.\n10.2 Корреляция Раз ковариация зависит от дисперсии, то можно сделать некоторые математические преобразования, чтобы привести эмпирические распределения к какому-то одному виду — сделать так, чтобы они имели одинакое математическое ожидание (среднее) и одинаковую дисперсию. С этой задачей прекрасно справляется стандартизация. Напоминаю формулу:\nz i = x i − ¯ x s\nПосле такого преобразования математическое ожидание нашего распределения будет равно нулю, а стандартное отклонение — единице. Это избавит нас от влияния дисперсии на значение ковариации. Ковариация двух стандартно нормально распределенных величин называется корреляцией (correlation).\ncov ( z ( x ) , z ( y ) ) = 1 n − 1 n ∑ i = 1\nz ( x ) z ( y ) = corr ( x , y ) ,\nгде\nz ( x ) и\nz ( y ) — стандартизированные величины\nx и\ny соответственно.\nКорреляцию можно выразить через ковариацию:\ncorr ( x , y ) = 1 n − 1 n ∑ i = 1\n( ¯ x − x i s x ) ( ¯ y − y i s y ) = 1 s x s y ( 1 n − 1 n ∑ i = 1\n( ¯ x − x i ) ( ¯ y − y i ) ) = cov(x, y) s x s y\nЕсли внимательно всмотреться в формулу, то можно обнаружить, что корреляция это не что иное, как стандартизированное значение ковариации.\nКоэффициент корреляции имеет четкие пределы изменения:\n[ − 1 ; 1] . Крайнее левое значение говорит о том, что присутствует полная обратная линейная взаимосвязь, крайнее правое — что присутствует полная прямая линейная взаимосвязь. Как и ковариация, корреляция ловит только линейную составляющую связи, поэтому нулевое значение корреляци показывает, что между переменными отсутствует линейная взаимосвязь. Это всё еще не значит, что связи нет вовсе.\nПреимущество корреляции над ковариацией в том, что она отражает не только направление, но и силу связи:\nЗначение коэффициента Интерпретация − 1.0 – − 0.9 очень сильная обратная связь − 0.9 – − 0.7 сильная обратная связь − 0.7 – − 0.5 средняя обратная связь − 0.5 – − 0.3 слабая обратная связь − 0.3 – 0.0 очень слабая обратная связь 0.0 – 0.3 очень слабая прямая связь 0.3 – 0.5 слабая прямая связь 0.5 – 0.7 средняя прямая связь 0.7 – 0.9 сильная прямая связь 0.9 – 1.0 очень сильная прямая связь Пронаблюдать можно тут.\n10.3 Корреляция Пирсона То, что мы только что обсудили, называется коэффициентом корреляции Пирсона. Пирсон, как вы могли обратить внимание, много чего успел наделать на благо статистики — вот ещё и корреляцию нам придумал. Этот коэффициент применим, когда мы работаем с двумя нормально распределенными величинами или хотя бы двумя величинами, измеренями в метрических шкалах. Еще раз напомним чере его формулу:\nr x 1 x 2 = ∑ n i = 1 ( ¯ x 1 − x i 1 ) ( ¯ x 2 − x i 2 ) √ ∑ n i = 1 ( ¯ x 1 − x i 1 ) 2 ⋅ ∑ n i = 1 ( ¯ x 2 − x i 2 ) 2\nТеперь задумаемся — хоть это и неприятно — можем ли мы сказать по значению коэффициента корреляции, отличается ли он от нуля? Вспомнив, что мы занимаемся статистикой, сразу ответим — нет. Поскольку мы рассчитываем коэффициент корреляции на данных, а они содержат всякую вариативность и неопределенность, нам придется предпринять дополнительные усилия, чтобы заявить, что обнаруженная нами связь статистически значима.\n10.3.1 Тестирование статистической значимости коэффициента корреляции Итак, мы, как обычно, хотим ответить на вопрос, есть ли в генеральной совокупности связь между двумя изучаемыми переменными. Если в генеральной совокупности связь между признаками отсутствует, то есть\nρ x 1 x 2 = 0 , будет ли равен нулю\nr x 1 x 2 ? Можно с уверенностью сказать, что не будет, так как выборочный коэффициент корреляции — случайная величина. А мы помним, что вероятность принятия случайной величиной своего конкретного значения равна нулю.\nТогда необходимо протестировать статистическую гипотезу:\nH 0 : ρ x 1 x 2 = 0 H 1 : ρ x 1 x 2 ≠ 0\nНулевая гипотеза гласит, что между признаками нет линейной взаимосвязи, альтернативная говорит — что есть. Обычно мы не закладываем в гипотезу направление связи, потому что и положительная, и отрицательная нас устроит — это мы будем потом уже содержательно интерпретировать.\nГипотезу сформулировали, теперь надо подобрать статистический критерий. Он вот:\n\n10 t\nr x 1 x 2 √ 1 − r x 1 x 2 n − 2 H 0 ∼ t ( df = n − 2 )\nЭто t-критерий, и значение его статистики подчиняется t-распределению, или распределению Стьюдента. Число степеней свободы определяется по формуле в скобках и равно\n( n − 2 ) , где\nn — число наблюдений.\nСамо t-распределение выглядит так:\nМожет показаться, что оно похоже на нормальнгое распределение — и это правда, но только с 30+ степеней свободы. А до этого можно наблюдать высокие хвосты.\nСобственно, далее согласно уже знакомому нам алгоритмы тестирования статистических гипотез мы рассчитываем статистику критерия, p-value для неё и делаем статистический вывод. Все так же, как и в случае с хи-квадратом.\n10.3.2 Доверительный интервал для коэффициента корреляции Помимо того, что мы обязаны оценить статистическую значимость коэффициента корреляции, обычно мы еще строим доверительный интервал для него. С построением интервальной оценки возникают некоторые сложности. Мы не можем использовать рассмотренное выше распределение Стьюдента, так как оно строится для случая, когда верна нулевая гипотеза об отсутствии связи. Если же мы строим интервальную оценку, нас интересует случай наличия связи.\nСтатистики долго думали и придумали\nвот это безобразие Впрочем, не очень важно, что именно они там придумали, потому что всё равно мы доверим построить доверительный интервал машине. Нам важно понять, как интерпретировать получившийся результат.\nЕсли в доверительный интервал коэффициента корреляции попадает\n0 , значит коэффициент статистически равен нулю, то есть между изучаемыми переменными взаимосвязи нет. Если в доверительный интервал коэффициента корреляции не попадает\n0 , значит коэффициент статистически отличен от нуля, то есть между изучаемыми переменными взаимосвязь есть. 10.3.3 Размер эффекта для коэффициента корреляции Еще одна статистика, которая нам необходима — это размер эффекта. На этот моменте мы начинаем беседовать об ошибке второго рода. До этого мы говорили только об ошибке первого рода и начились её контролировать с помощью уровня значимости. Теперь вот повогорим об ошибке второго рода.\nВ целом, размер эффекта — это численное выражение силы взаимосвязи между переменными в генеральной совокупности.\nЗдесь нам необходимо призадуматься, и осознать, что вообще-то корреляция сама по себе выражает силу взаимосвязи между переменными. И, да, это правда — размером эффекта для коэффициента корреляции является сам коэффициент корреляции. Удобненько.\nТак, к сожалению, будет не всегда, но вот с корреляцией это так. Ну, и хорошо.\nРекомендации по интерпретация [абсолютного значения] коэффициента корреляции с точки зрения размера эффекта для социальных наук такие:\nЗначение коэффициента Размер эффекта 0.1 Малый (small) 0.3 Средний (medium) 0.7 Большой (large) 10.3.4 Расчет объема выборки для корреляционного анализа Размер эффекта нам требуется для расчета объема выборки, необходимой для корректного корреляционного анализа. В чем идея?\nМы говорили, что ошибку второго рода мы контролирует в помощью статистической мощности, которая равна\n1 − β , где\nβ — вероятность ошибки второго рода. Конвенционально достаточным уровнем статистической мощности считается\n80 % , то есть нам надо предпринять все усилия, чтобы достичь такого уровня статистической мощности. А что мы можем предпринять? Да, в общем-то только собрать достаточное количество наблюдений. Значит, надо рассчитать, сколько нам надо наблюдений, чтобы зафиксировать эффект, если он есть.\nСобственно, статистическая мощность, размер эффекта и объем выборки связаны вот как:\n↑ объем выборки → ↑ статистическая мощность ↑ размер эффекта → ↓ требуемый объем выборки\nИтого, если у нас есть ожидаемый размер эффекта и требуемый уровень статистической мощности, то мы можем рассчитать необходимый объем выборки. Формул не будет — мы рассчитываем объем выборки в специально обученном ПО.\nЧто надо запомнить?\nУровень статистической мощности (power) по умолчанию выбираем\n80 %\nРазмер эффекта можем взять из предыдущих исследований, на основе которых планируем текущее — это лучше — либо из рекомендаций по интерпретации размеров эффекта Например, в психологии большие корреляции — это вообще большая редкость, поэтому берем значения для малого или среднего размеров эффекта. Вгоняем это в программу, и оно там все само магически считается.\n10.3.5 Визуализация корреляции Как можно отображать взаимосвязи между переменными? Один пример графика мы уже видели в самом начале — это была диаграмма рассеяния (scatterplot). Это достаточно простой и понятный график: по осям идут две количественные переменные, точки отображают наблюдения. В итоге получается облако точек. Чем более они вытянуты в линию, тем больше значение корреляции, чем более облако точек «круглое», тем значение кореляции меньше. Дополнительно обычно на таком графике отображают ещё линию тренда, чтобы более наглядно визуализировать линейный компонент взаимосвязи переменных. Построение такой линии отдельная довольно интересная задача — мы вскоре ею займемся и назовем это регрессионный анализ.\nНиже примеры диаграмм рассения. Это визуализация результатов валидизации психометрической методики: на первом графике корреляция между итоговыми баллами двух опросников, а на втором — баллов по отдельным шкалам валидизируемого опросника и общим баллом другого опросника.\nМожно потренироваться визуально определять корреляцию по скаттерплотам.\nБывает, что нас интересует связь не между двумя какими-либо отдельными переменными, а много попарных корреляций между несколькими переменными. Для этого есть визуализация, называемая корреляционная матрица (corrplot). По «осям» идут переменные, а на пересечении цветом отображается корреляция между переменными. Обычно холодные оттенки используются для положительных значений, а теплые — для отрицательных. Чем интенсивнее оттенок, тем больше значение корреляции. В данном случае на графике отображены корреляции между пунктами отдельной шкалы опросника.\n10.4 Коэффициенты корреляции для разных шкал Выше мы подробно обсудили корреляцию Пирсона и отметили, что этот коэффициент применяется для метрических шкал да ещё и нормально распределенных величин. А что же делать, если в наших данных не так?\n10.4.1 Параметрические и непараметрические критерии Все статистические методы деляться на два типа: параметрические и непараметрические.\nПараметрические методы работают с непосредственно с параметрами распределения исследуемых переменных. Так, для вычисления корреляции Пирсона мы используем среднее и стандартное отклонение. Как следствие, одно из условий применимести таких методов — нормальное распределение изучаемых переменных. Если это требование не выполнено, мы не можем быть достаточно уверены в том, что статистический метод дает надежные результаты — как минимум, потому что сами среднее и стандартное отклонение в случае скошенных распределения не особо хорошо описывают данные. Непараметрические методы не используют в вычислениях собственных статистик параметры распределений. Например, изученный нам хи-квадрат относится к непараметрическим критериям. Они работают либо с частотами, либо в рангами — в зависимости от того, какие переменные мы анализируем. Поэтому если требования нормальности распределения не выполнено, используют методы этой группы. Практически каждый параметрический критерий имеет своего непараметрического собрата. Отметим, что сам статистический вывод в случае непараметрических критериев осуществляется точно так же, как и в случае параметрических.\n10.4.2 Непараметрические коэффициенты корреляции Дла разных шкал разработаны разные коэффициенты корреляции. Оценки коэффициентов будут рассчитываться по-разному, но логика тестирования статистических гипотез остаётся одинаковой.\nПеременная\nX Переменная\nY Мера связи Интервальная или отношений Интервальная или отношений Корреляция Пирсона Ранговая, интервальная или отношений Ранговая, интервальная или отношений Корреляция Спирмена Ранговая Ранговая Корреляция Кенделла У непараметрических критериев формулы несколько зубодробительны, поэтому оставим их покоиться с миром. В статистическом ПО нужно будет просто выбрать подходящий критерий из предложенных.\n10.5 Другие корреляции Этот раздел для отчаянных. Вас никто об это ни на экзамене, ни, возможно, в жизни не спросит.\nМожно коррелировать не только количественные и ранговые шкалы между собой, но и качественные тоже:\nПеременная\nX Переменная\nY Мера связи Дихотомическая Дихотомическая\nϕ -коэффициент Дихотомическая Ранговая Рангово-бисериальный коэффициент Дихотомическая Интервальная или отношений Бисериальный коэффициент 10.5.1\nϕ -коэффициент Этот коэффициент позволяет рассчитать корреляцию между двумы дихотомическими шкалами. Он основан на расчёте статистики\nχ 2 . По двум дихотомическим переменным строится, как мы знаем, таблицу сопряженности и рассчитывается\nχ 2 . Далее он нормируется следующим образом, чтобы получить значения от 0 до 1, которые можно интерпретироват аналогично коэффициенту корреляции:\n\n\n11 ϕ\n√ χ 2 N ,\nN — общее количество наблюдений.\n10.5.2 Бисериальный коэффициент корреляции Этот коэффициент используется для вычисления корреляции между количественной ( y ) и категориальной ( x ) шкалой и рассчитывается следующим образом:\n\n\n12 r\n¯ y x 1 − ¯ y x 2 s y √ n 1 n 2 N ( N − 1 ) ,\nгде\n¯ y x 1 — среднее по переменной\ny по элементам группы\nx 1 ,\n¯ y x 2 — среднее по переменной\ny по элементам группы\nx 2 ,\nn 1 — число элементов в группе\nx 1 ,\nn 2 — число элементов в группе\nx 2 ,\nN — общее число элементов.\nВажно отметить, что несмотря на то, что значение коэффициента может быть как положительным, так и отрицательным, это не влияет на интерпретацию. Это одно из исключений из общего правила.\n10.5.3 Рангово-бисериальный коэффициент корреляции Если у нас не количественная, а ранговая шкала, то применяется рангово-бисериальный коэффициент:\n\n\n13 r\n2 ( ¯ x 1 − ¯ x 2 ) N ,\nгде\n¯ x 1 — средний ранг в группе\nx 1 ,\n¯ x 2 — средний ранг в группе\nx 2 ,\nN — общее количество наблюдений.",
    "crumbs": [
      "Статистика вывода",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Корреляционный анализ</span>"
    ]
  }
]