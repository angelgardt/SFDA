# Post hoc тесты

Что ж, мы попытались разобраться в одном из самых часто используемых и полезных методов статистического анализа — дисперсионном анализе — и сделаем вид, что что-то поняли. Однако задумаемся вот над чем:

дисперсионный анализ позволяет протестировать статистическую значимость связи между фактором и зависимой переменной
технически это выражается в поиске различий между группами, на которые делится категориальной переменной наша выборка [наблюдений]
статистическая значимость фактора говорит нам о том, что между какими-то группами есть различия
но между какими именно???
Этот вопрос остается открытым и на него надо как-то ответить.

13.1 Попарные сравнения
Для того, чтобы ответить на этот вопрос, нам придется сравнивать все группы [наблюдений] друг с другом. Этот процесс называется попарные сравнения (pairwise comparison). Выполняются они довольно просто — с обычно помощью t-теста. Однако здесь есть одна важная деталь, о которой нам необходимо поговорить.

Стоп, а если мы все равно сравниваем все группы друг с другом, зачем нам вообще дисперсионный анализ? Вопрос справелив. Однако обо всем по порядку. Начнем с нашей любимой ошибки первого рода.

13.1.1 Проблема множественных сравнений
Итак, мы сравниваем попарно все группы наблюдений между собой. В каждом сравнении мы фиксируем вероятность ошибки первого рода с помощью уровня значимости на уровне  
0.05
 . А какова будет вероятность ошибки, если мы проводим несколько сравнений?

Считаем, что наши сравнения независимы, поэтому вероятности будут перемножаться1. Если верояность ошибиться в одном сравнении равна  
α
 , то вероятность сделать правильный вывод —  
1
−
α
 . Тогда вероятность сделать правильный вывод в  
m
  сравнения —  
(
1
−
α
)
m
 . Отсюда мы можем вывести вероятность ошибиться хотя бы в одном сравнении:

P
′
=
1
−
(
1
−
α
)
m
 

Пусть у нас есть три группы, которые нам надо сравнить друг с другом — получается необходимо провести три сравнения. Итого вероятность ошибиться получается:

P
′
=
1
−
(
1
−
0.05
)
3
≈
0.143
 

Значительно больше, чем  
0.05
 , что нехорошо. И дальше только хуже. Поэтому нам надо либо корректировать уровень значимости, либо использовать мощные методы типа дисперсионного анализа.

13.1.2 Корректировка уровня значимости
Корректировать уровень значимости можно по-разному. Например, можно разделить  
α
  на количество попарных сравнений — такой способ называется поправкой Бонферрони (Bonferroni):

α
′
=
α
n
,
 

где  
n
  — число попарных сравнений.

Поправка Бонферрони считается самой консервативной поправкой — она достаточно сильно уменьшает уровень значимости, и мы можем не поймать искомую закономерность, то есть совершить ошибку второго рода2. Поэтому придумали более либеральные поправки, например, поправку Холма (Холма–Бонферрони, Holm) или поправку Тьюки (Tukey’s HSD test). Можно посмотреть на их формулы, но в целом, не обяз, потому что их все равно никто не знает, а в статистических пакетах мы либо допишем аргумент в функцию, либо нужную галку поставим.

На практике в силу того, что в статистических пакетах мы работаем с p-value, корректируется именно его значение.

По достаточно незамысловатой логике
Таким образом, мы просто сравниваем уже скорретированное p-value, которое нам считает комплюхтер, с тем же самым  
α
=
0.05
 . Жизнь становится значительно проще и приятнее.

13.1.3 Дисперсионный анализ и проблема множественных сравнений
Использование методов типа дисперсионного анализа, которые позволяют проверить наличие статистическую значимость фактора в целом помогает следующим образом:

если фактор статистически НЕ значим, мы НЕ проводим попарные сравнения по группам, на которые он делит нашу выборку — различий между группами все равно не будет
если фактор статистически значим, мы проводим попарные сравнения по группам, на которые он делит нашу выборку, чтобы узнать, между какими группами есть различия
Особенно сильно это помогает в случае взаимодействия факторов, так как там может быть невероятное количество попарных сравнений3.

13.2 Двухвыборочный t-тест
С уровне значимости разобрались — теперь к самому статистическому тесту. Задача такова: протестировать гипотезу о том, что между двумя группами наблюдений нет различий, то есть:

H
0
:
μ
1
=
μ
2
H
1
:
μ
1
≠
μ
2

Гипотезы сформулировали. Выбираем статистический критерий. Он таков:

t
=
¯
x
1
−
¯
x
2
√
s
2
1
n
1
+
s
2
1
n
2
 

Эта статистистика при справедливости нулевой гипотезы подчиняется t-распределению (распределению Стьюдента) с числом степеней свободы, рассчитывающимся по очень страшной формуле.

Вот такой
Напоминаю, что t-распределение выглядит так:


Далее мы рассчитываем статистику критерия — значение t, потом рассчитываем для него p-value, корректируем сообразно выбранному способу корректировки, и сравниваем с уровнем значимости  
α
 .

И, как обычно, по неизменному ни при каких обстоятельствах алгоритму, делаем вывод:

Если p-value  
<
α
 , то мы получаем значение t-статистики, не характерное для случая, когда нулевая гипотеза верна, что даёт нам основания отклонить нулевую гипотезу об отсутствии различий между группами и принять альтернативную, о том, что хотя бы между двумя какими-либо группами есть различия.
Если p-value  
>
α
 , то мы получаем значение t-статистики, характерное для случая, когда нулевая гипотеза верна, что не даёт нам оснований отклонить нулевую гипотезу об отсутствии различий между группами.
Двухвыборочный t-тест пригоден, если наши выборки независимы. Если же у нас связанные, или зависимые, выборки, то нам необходим t-тест для зависимых выборок.

13.3 Парный t-тест
Он даже попроще. Или нет.

Гипотеза та же:

H
0
:
μ
1
=
μ
2
H
1
:
μ
1
≠
μ
2

Статистика другая:

t
=
M
d
s
d
√
n
,
 

где  
M
d
=
1
n
∑
n
i
=
1
(
x
i
1
−
x
i
2
)
 ,  
s
d
=
√
1
n
−
1
∑
n
i
=
1
(
M
d
−
(
x
i
1
−
x
i
2
)
)
2
 .

Эта статистистика при справедливости нулевой гипотезы подчиняется t-распределению (распределению Стьюдента) с числом степеней свободы  
n
−
1
 .

Статистический вывод идентичен предыдущем случаю.

13.4 Че за post hoc?
Итак, с помощью t-теста мы попарно сравниваем группы по фактору, который в дисперсионном анализе оказался статистически значимым, чтобы узнать, между какими группами есть различия.

Зачем это нужно? Статистическая значимость фактора не обязывает все группы различаться между собой — может случиться так, что разница есть только между двумя из трех, или двумя из четырех групп. Это надо узнать, чтобы мы могли корректно интерпретировать результаты с точки зрения теории, которая стоит за нашим исследованием.

Если в дисперсионном анализе участвуют только две группы — то есть фактор содержит два уровня — ничего дополнительно тестировать не нужно!

Данный анализ незывается post hoc analysis или post hoc tests (от лат. post hoc — ‘after this’, ‘after this event’), так как мы проводим его после того, как провели основной анализ другим методом. Такие дела.

13.5 t-тест — сильный и независимый
Вообще t-тест может быть и самостоятельным методом статистического анализа, если у вас в исследовании только две группы наблюдений. Или вы выборочно сравниваете какие-то условия, которые вас интересуют, при сложном дизайне. Или вы проверяете какие-то группы на эквивалетность по каким либо параметрам. В общем, t-тест молодец-красавчик — и сам по себе тоже существует, но и другим статистическим методам помогает.

Об этом нам рассказала теорема умножения вероятностей, которая гласит, что вероятность пересечения независимых событий равна произведению вероятностей этих событий.↩︎

Помним, что при стремлении вероятности ошибки первого рода к нулю, вероятность ошибки второго рода стремиться к единице.↩︎

Допустим для двух факторов с тремя уровнями количество групп будет  
3
×
3
=
9
 , а количество попарных сравнений —  
n
(
n
−
1
)
2
=
9
⋅
8
2
=
36
 !↩︎
 
 