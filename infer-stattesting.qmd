# Тестирование статистических гипотез

Мы затеваем исследование, чтобы проверить какие-либо гипотезы. Поэтому в ходе статистического анализа мы, главным образом, заняты тем, что тестируем *статистические гипотезы*. Ведь на какого рода вопросы мы отвечаем с помощью анализа?

- Различаются ли группы между собой?
- Значимо ли влияние какого-либо фактора? → Различаются ли группы между собой?
- Хороша ли та модель, которую мы построили? → Отличается ли она от нулевой модели?

И так далее. Так или иначе, всё сводится к тому, что мы ищем какие-то различия. Но силу того, что у нас неопределённость и вариативность в данных, мы просто так «в лоб» сказать о различиях по оценкам параметров не можем. Приходится тестировать статистические гипотезы.

## Базовые понятия

:::{#def-hepothesis}
**Гипотеза** ($H$) --- это предположение, которое подлежит проверке на основе результатов наблюдений.
:::

Гипотезы, как мы знаем, бывают трех видов:

- **Теоретическая** --- про конструкты
- **Эмпирическая** --- про переменные (зависимые и независимые)
- **Статистическая**
    - с одной стороны, про данные --- что мы получили в данный конкретный момент, собрав вот эти конкретные данные
    - с другой стороны, про параметры генеральной совокупности --- так как мы стремимся всё же изучать их, работая с выборкой

Статистические гипотезы бывают *простыми* и *сложными*.

- **Простая гипотеза** --- это такое предположение, которое включает в себя какое-либо однозначно определяемое утверждение.

Например, истинная величина параметра соответствует некоторому строго заданному значению: $H: \theta = \theta_0$. Другой вариант --- две генеральные совокупности имеют одно и то же значение одной и той же характеристики: $H: \theta_1 = \theta_2$.

- **Сложная гипотеза** предполагает множественность вариантов для параметра, которые укладываются в рамки проверяемого предположения. Например, $H: \theta > \theta_0$ или $H: \theta_1 \neq \theta_2$.

В рамках самого хода тестирования гипотез существует **проверяемая (нулевая) гипотеза** ($H_0$). Её обычно стараются предельно упростить, поэтому она чаще всего формулируется как простая гипотеза. В противовес ей выдвигается **альтернативная гипотеза** ($H_1$), которая будет иметь, как следствие, вид сложной гипотезы.

<!---
Для проверки гипотезы нужны три вещи:

- результаты наблюдений
- статистический критерий
- критерий статистического вывода.

*Результаты наблюдений*, очевидно, являются основой проверки гипотезы. Однако как мы отмечали в самом начале, сказать о различии генеральных средних просто сравнив выборочные средние мы не сможем.

Здесь нам на помощь приходит *статистический критерий*. Это некоторый способ протестировать нашу гипотезу.

Результаты наблюдений, полученные на выборке, сами по себе, как правило, не используются. Однако на их основе рассчитываются выборочные статистики (показатели), которые непосредственно участвуют в проверке гипотезы.
--->

Что же может случиться в ходе проверки статистической гипотезы?

## Возможные результаты проверки гипотез

Мы изучаем в исследовании какую-либо закономерность, которая в реальном мире *может существовать*, а может и не существовать. В силу неопределённости и вариативности наших данных мы может либо *обнаружить интересующую нас закономерность*, либо *не обнаружить её*.

В качестве нулевой гипотезы мы выдвигаем предположение о том, что закономерность отсутствует --- так мы упрощаем нашу нулевую гипотезу. Пусть $H_0$ обозначает, что предположение об отсутствии закономерности, которое мы проверяем справедливо, а $H_1$ --- не справедливо. На основании данных мы можем либо не отклонить наше предположение ($\hat H_0$), либо отклонить ($\hat H_1$).

Тогда имеем следующую ситуацию (@tbl-stattesting-results).

:::{#tbl-stattesting-results}
||$H_0$|$H_1$|
|:---:|:---:|:---:|
|$\hat H_0$|✓|Ошибка II рода|
|$\hat H_1$|Ошибка I рода|✓|

Возможные результаты проверки статистических гипотез
:::

Мы видим, что из четырёх возможных ситуаций две нас устраивают --- там мы делаем корректный вывод об отсутствии или наличии закономерности. Две другие нас не устраивают, так как мы в этих случаях совершаем ошибки.

- **Ошибка I рода** возникает, когда *в генеральной совокупности* искомой *закономерности нет*, *но мы* в силу случайных флуктуаций в данных *её нашли*.
- **Ошибка II рода** возникает, когда *в генеральной совокупности* искомая *закономерность есть*, *но мы* в силу каких-либо причин *её не нашли*.

Ошибки --- это нехорошо, они нас не устраивают. Надо каким-то образом их контролировать.

- **Ошибка I рода** контролируется достаточно просто. Так как в ситуации ошибки I рода мы получили некий результат --- нашли закономерность, которую искали --- мы можем посчитать вероятность, с которой *потенциально* ошиблись. А собственно *контролировать* ошибку мы будем с помощью уровня значимости $\alpha$.
    - **Уровень значимости** $\alpha$ выбирается до начала процедуры тестирования гипотезы и задает вероятность, с который мы позволяем себе ошибиться --- отклонить нулевую гипотезу, при условии, что она верна.
- **Ошибку II рода** контролировать сложнее, так как мы не получили результата --- не нашли закономерность, которую искали. Но ситуации ошибки II рода --- ложноотрицательного вывода --- «противоположна» ситуация истинно положительного вывода --- когда мы обнаружили закономерность, при условии, что она есть. Соответственно, нам будет полезна какая-то метрика, которая позволит сказать, что мы сделали всё возможное для того, чтобы обнаружить искомую закономерность.
    - Вероятность ошибки II рода обозначается $β$ --- тогда вероятность того, что мы **не совершили ошибку II рода** будет $1-\beta$. Эта величина называется **статистической мощностью** --- она связана с *размером эффекта* и *объемом выборки*. На основании статистической мощности и ожидаемого размера эффекта можно рассчитать требуемый объем выборки.

Размер эффекта --- это оценка величины, или силы, закономерности в генеральной совокупности. О нём мы будем говорить подробнее в последующих главах, так как на примере конкретных статистических методов этот концепт будет более осязаем.

Соберем все обозначения в единую табличку (@tbl-stattesting-probs)[^stattesting-cond-prob].

:::{#tbl-stattesting-probs}
||$H_0$|$H_1$|
|:---:|:---:|:---:|
|$\hat H_0$|$\mathbb P (\hat H_0 | H_0)$|$\mathbb P (\hat H_0 | H_1) = \beta$|
|$\hat H_1$|$\mathbb P (\hat H_0 | H_0) = \alpha$|$\mathbb P (\hat H_1 | H_1) = 1 - \beta$|

Вероятности ошибок I и  II рода
:::

[^stattesting-cond-prob]: Здесь использовано обозначение условной вероятности $\mathbb P (A|B)$, то есть это вероятность того, что случилось событие $A$ при условии, что случилось событие $B$.

Уровень значимости $\alpha$ выбирается близким к нулю --- конвенциональным значением для социальных наук считается $0.05$. Вообще $\alpha$ можно выбрать сколь угодно малым, однако при выборе уровня значимости руководствуются принципом разумной достаточности, так как если устремить $\alpha$ к нулю, то устремится к нулю и вероятность отклонения нулевой гипотезы.

:::{.callout-note appearance="minimal" collapse="true"}
### Математические руны

$$
\mathbb P (\hat H_1) = \mathbb P (\hat H_1|H_0) \cdot \mathbb P(H_0) = \alpha \cdot \mathbb P (H_0)
$$
:::

Достаточной статистической мощностью ($1-\beta$) считается $0.8$. Аналогично, устремляя мощность к единице ($(1-\beta) \to 1 \Rightarrow \beta \to 0$), мы устремляем вероятность не отклонения нулевой гипотезы к нулю.

:::{.callout-note appearance="minimal" collapse="true"}
### Ещё математические руны

$$
\mathbb P (\hat H_0) = \mathbb P (\hat H_0|H_1) \cdot \mathbb P(H_1) = \beta \cdot \mathbb P (H_1)
$$
:::

Необходимо также помнить, что ошибки первого и второго рода связаны между собой так, что

$$
\alpha \to 0 \Rightarrow \beta \to 1
$$

:::{.callout-note appearance="minimal" collapse="true"}
### Опять математические руны

$$
\begin{split}
\beta \cdot \mathbb P(H_1) &= \mathbb P (\hat H_0) \\
\beta \cdot \mathbb P(H_1) &= \mathbb P (\hat H_0 | H_0) \cdot \mathbb P(H_0) \\
\beta &= \frac{1}{\mathbb P(H_1)} \cdot \mathbb P(H_0) \cdot \mathbb P (\hat H_0 | H_0) \\
\beta &= \frac{1}{\mathbb P(H_1)} \cdot \mathbb P(H_0) \cdot \big( 1 - \mathbb P (\hat H_1 | H_0) \big) \\
\beta &= \frac{1}{\mathbb P(H_1)} \cdot \mathbb P(H_0) \cdot ( 1 - \alpha) \\
\overset{\mathbb P(H_1) \approx \mathbb P(H_0)}{\Longrightarrow}
\beta &\approx 1-\alpha
\end{split}
$$
:::


<!---
## Асимметрия статистического вывода

Выше мы сказали, что для проверки гипотезы нужны две вещи:

результаты наблюдений и
критерий.
С результатами наблюдений более-менее очевидно.

Критерий — это правило, согласно которому гипотезу либо принимают, либо отклоняют. Однако перед тем как проверять гипотезу, её так-то нужно сформулировать, и сделать это правильно, поскольку от формулировки гипотезы зависит интерпретация результатов проверки и дальнейшее использование полученной информации.

Используемая статистика сама по себе является [непрерывной] случайной величиной, а значит может быть построено её распределение. Критерий будет разделять это распределение на непересекающиеся области. В результате чего возникает критическая область — область отклонения гипотезы. Дополнением к ней является область неотклонения гипотезы.

Критическая область может быть односторонней (при  
H
1
:
θ
>
θ
0
  или  
H
1
:
θ
<
θ
0
 ) и двусторонней (при  
H
1
:
θ
≠
θ
0
 ). «Размер» критической области определяется уровнем значимости.

Статистический вывод — заключение о том, получили ли мы подтверждение альтернативной гипотезы — по структуре представляет собой импликацию. Если вам не знаком этот термин из логики, то вот:

Если значение нашей статистики, которое мы рассчитали на выборке, попало в критическую область, то мы говорим о том, что нулевая гипотеза отклоняется.
Если значение нашей статистики, которое мы рассчитали на выборке, не попало в критическую область, то мы не получаем оснований для того, чтобы отклонить нулевую гипотезу. Однако мы также не получаем оснований, чтобы её «принять». Мы остаёмся в некотором неведении: мы не нашли различий, а есть они там или нет — хто ж их знает… Итого, мы не можем сделать никакого вывода.
В этом и заключается асимметрия статистического вывода. Как раз для того, чтобы с ней как-то жить, мы работаем со статистической мощностью.

Посмотреть, как все эти штуки друг с другом соотносятся можно тут.
--->

## Алгоритм тестирования статистических гипотез

Для тестирования гипотез есть два сценария: первый и тот, которым мы будем пользоваться. Первый вариант чуть более классический, второй --- более гибкий.

:::{.callout-tip}
### Сценарий номер раз

1. Формулировка гипотезы
1. Выбор статистического критерия
1. Выбор уровня значимости $\alpha$
1. Построение закона распределения статистики критерия при условии, что нулевая гипотеза верна
1. Определение границ критической области
1. Расчёт выборочной статистики
1. Определение, попадает ли наблюдаемое значение статистики в критическую область и статистический вывод
:::

:::{.callout-tip}
### Сценарий номер два

1. Формулировка гипотезы
1. Выбор статистического критерия
1. Выбор уровня значимости $\alpha$
1. Построение закона распредлеения статистики критерия при условии, что нулевая гипотеза верна
1. Расчёт выборочной статистики
1. Расчёт достигнутого уровня значимости p-value
1. Сопоставление $\alpha$ и p-value и статистический вывод
:::

Почему второй вариант более гибкий? Представим, что мы захотели понизить уровень значимости с $0.05$ до $0.01$ --- такие уровни значимости всречаются, например, в медицине. Если мы идем по первому сценарию, то нам надо заново пересчитать критические значения и вновь проанализировать, попадает ли наблюдаемое значение в критическую область. Если мы адепты второго сценария, то нам надо только выполнить одно новое сравнение нашего p-value с новым уровнем значимости.

Вероятно, пока мало что понятно. Поэтому в следующей главе разберем все это безобразие на примере.
