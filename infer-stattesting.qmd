# Тестирование статистических гипотез

```{r opts, echo=FALSE, eval=TRUE}
knitr::opts_chunk$set(echo = FALSE, eval = TRUE, warning = FALSE, message = FALSE, error = FALSE)
```

```{r}
library(tidyverse)
theme_set(theme_bw())
theme_update(legend.position = "bottom")
```

Мы затеваем исследование, чтобы проверить какие-либо гипотезы. Поэтому в ходе статистического анализа мы, главным образом, заняты тем, что тестируем *статистические гипотезы*. Ведь на какого рода вопросы мы отвечаем с помощью анализа?

- Различаются ли группы между собой?
- Значимо ли влияние какого-либо фактора? → Различаются ли группы между собой?
- Хороша ли та модель, которую мы построили? → Отличается ли она от нулевой модели?

И так далее. Так или иначе, всё сводится к тому, что мы ищем какие-то различия. Но силу того, что у нас неопределённость и вариативность в данных, мы просто так «в лоб» сказать о различиях по оценкам параметров не можем. Приходится тестировать статистические гипотезы.

## Базовые понятия

:::{#def-hepothesis}
**Гипотеза** ($H$) --- это предположение, которое подлежит проверке на основе результатов наблюдений.
:::

Гипотезы, как мы знаем, бывают трех видов:

- **Теоретическая** --- про конструкты
- **Эмпирическая** --- про переменные (зависимые и независимые)
- **Статистическая**
    - с одной стороны, про данные --- что мы получили в данный конкретный момент, собрав вот эти конкретные данные
    - с другой стороны, про параметры генеральной совокупности --- так как мы стремимся всё же изучать их, работая с выборкой

Статистические гипотезы бывают *простыми* и *сложными*.

- **Простая гипотеза** --- это такое предположение, которое включает в себя какое-либо однозначно определяемое утверждение.

Например, истинная величина параметра соответствует некоторому строго заданному значению: $H: \theta = \theta_0$. Другой вариант --- две генеральные совокупности имеют одно и то же значение одной и той же характеристики: $H: \theta_1 = \theta_2$.

- **Сложная гипотеза** предполагает множественность вариантов для параметра, которые укладываются в рамки проверяемого предположения. Например, $H: \theta > \theta_0$ или $H: \theta_1 \neq \theta_2$.

В рамках самого хода тестирования гипотез существует **проверяемая (нулевая) гипотеза** ($H_0$). Её обычно стараются предельно упростить, поэтому она чаще всего формулируется как простая гипотеза. В противовес ей выдвигается **альтернативная гипотеза** ($H_1$), которая будет иметь, как следствие, вид сложной гипотезы.

<!---
Для проверки гипотезы нужны три вещи:

- результаты наблюдений
- статистический критерий
- критерий статистического вывода.

*Результаты наблюдений*, очевидно, являются основой проверки гипотезы. Однако как мы отмечали в самом начале, сказать о различии генеральных средних просто сравнив выборочные средние мы не сможем.

Здесь нам на помощь приходит *статистический критерий*. Это некоторый способ протестировать нашу гипотезу.

Результаты наблюдений, полученные на выборке, сами по себе, как правило, не используются. Однако на их основе рассчитываются выборочные статистики (показатели), которые непосредственно участвуют в проверке гипотезы.
--->

Что же может случиться в ходе проверки статистической гипотезы?

## Возможные результаты проверки гипотез

Мы изучаем в исследовании какую-либо закономерность, которая в реальном мире *может существовать*, а может и не существовать. В силу неопределённости и вариативности наших данных мы может либо *обнаружить интересующую нас закономерность*, либо *не обнаружить её*.

В качестве нулевой гипотезы мы выдвигаем предположение о том, что закономерность отсутствует --- так мы упрощаем нашу нулевую гипотезу. Пусть $H_0$ обозначает, что предположение об отсутствии закономерности, которое мы проверяем справедливо, а $H_1$ --- не справедливо. На основании данных мы можем либо не отклонить наше предположение ($\hat H_0$), либо отклонить ($\hat H_1$).

Тогда имеем следующую ситуацию (@tbl-stattesting-results).

:::{#tbl-stattesting-results}
||$H_0$|$H_1$|
|:---:|:---:|:---:|
|$\hat H_0$|✓|Ошибка II рода|
|$\hat H_1$|Ошибка I рода|✓|

Возможные результаты проверки статистических гипотез
:::

Мы видим, что из четырёх возможных ситуаций две нас устраивают --- там мы делаем корректный вывод об отсутствии или наличии закономерности. Две другие нас не устраивают, так как мы в этих случаях совершаем ошибки.

- **Ошибка I рода** возникает, когда *в генеральной совокупности* искомой *закономерности нет*, *но мы* в силу случайных флуктуаций в данных *её нашли*.
- **Ошибка II рода** возникает, когда *в генеральной совокупности* искомая *закономерность есть*, *но мы* в силу каких-либо причин *её не нашли*.

Ошибки --- это нехорошо, они нас не устраивают. Надо каким-то образом их контролировать.

- **Ошибка I рода** контролируется достаточно просто. Так как в ситуации ошибки I рода мы получили некий результат --- нашли закономерность, которую искали --- мы можем посчитать вероятность, с которой *потенциально* ошиблись. А собственно *контролировать* ошибку мы будем с помощью уровня значимости $\alpha$.
    - **Уровень значимости** $\alpha$ выбирается до начала процедуры тестирования гипотезы и задает вероятность, с который мы позволяем себе ошибиться --- отклонить нулевую гипотезу, при условии, что она верна.
- **Ошибку II рода** контролировать сложнее, так как мы не получили результата --- не нашли закономерность, которую искали. Но ситуации ошибки II рода --- ложноотрицательного вывода --- «противоположна» ситуация истинно положительного вывода --- когда мы обнаружили закономерность, при условии, что она есть. Соответственно, нам будет полезна какая-то метрика, которая позволит сказать, что мы сделали всё возможное для того, чтобы обнаружить искомую закономерность.
    - Вероятность ошибки II рода обозначается $β$ --- тогда вероятность того, что мы **не совершили ошибку II рода** будет $1-\beta$. Эта величина называется **статистической мощностью** --- она связана с *размером эффекта* и *объемом выборки*. На основании статистической мощности и ожидаемого размера эффекта можно рассчитать требуемый объем выборки.

Размер эффекта --- это оценка величины, или силы, закономерности в генеральной совокупности. О нём мы будем говорить подробнее в последующих главах, так как на примере конкретных статистических методов этот концепт будет более осязаем.

Соберем все обозначения в единую табличку (@tbl-stattesting-probs)[^stattesting-cond-prob].

:::{#tbl-stattesting-probs}
||$H_0$|$H_1$|
|:---:|:---:|:---:|
|$\hat H_0$|$\mathbb P (\hat H_0 | H_0)$|$\mathbb P (\hat H_0 | H_1) = \beta$|
|$\hat H_1$|$\mathbb P (\hat H_0 | H_0) = \alpha$|$\mathbb P (\hat H_1 | H_1) = 1 - \beta$|

Вероятности ошибок I и  II рода
:::

[^stattesting-cond-prob]: Здесь использовано обозначение условной вероятности $\mathbb P (A|B)$, то есть это вероятность того, что случилось событие $A$ при условии, что случилось событие $B$.

Уровень значимости $\alpha$ выбирается близким к нулю --- конвенциональным значением для социальных наук считается $0.05$. Вообще $\alpha$ можно выбрать сколь угодно малым, однако при выборе уровня значимости руководствуются принципом разумной достаточности, так как **если устремить $\alpha$ к нулю, то устремится к нулю и вероятность отклонения нулевой гипотезы**.

:::{.callout-note appearance="minimal" collapse="true"}
### Математические руны

$$
\mathbb P (\hat H_1) = \mathbb P (\hat H_1|H_0) \cdot \mathbb P(H_0) = \alpha \cdot \mathbb P (H_0)
$$
:::

Достаточной статистической мощностью ($1-\beta$) считается $0.8$. Аналогично, **устремляя мощность к единице ($(1-\beta) \to 1 \Rightarrow \beta \to 0$), мы устремляем вероятность не отклонения нулевой гипотезы к нулю**.

:::{.callout-note appearance="minimal" collapse="true"}
### Ещё математические руны

$$
\mathbb P (\hat H_0) = \mathbb P (\hat H_0|H_1) \cdot \mathbb P(H_1) = \beta \cdot \mathbb P (H_1)
$$
:::

Необходимо также помнить, что ошибки первого и второго рода связаны между собой так, что

$$
\alpha \to 0 \Rightarrow \beta \to 1
$$

:::{.callout-note appearance="minimal" collapse="true"}
### Опять математические руны

$$
\begin{split}
\beta \cdot \mathbb P(H_1) &= \mathbb P (\hat H_0) \\
\beta \cdot \mathbb P(H_1) &= \mathbb P (\hat H_0 | H_0) \cdot \mathbb P(H_0) \\
\beta &= \frac{1}{\mathbb P(H_1)} \cdot \mathbb P(H_0) \cdot \mathbb P (\hat H_0 | H_0) \\
\beta &= \frac{1}{\mathbb P(H_1)} \cdot \mathbb P(H_0) \cdot \big( 1 - \mathbb P (\hat H_1 | H_0) \big) \\
\beta &= \frac{1}{\mathbb P(H_1)} \cdot \mathbb P(H_0) \cdot ( 1 - \alpha) \\
\overset{\mathbb P(H_1) \approx \mathbb P(H_0)}{\Longrightarrow}
\beta &\approx 1-\alpha
\end{split}
$$
:::


<!---
## Асимметрия статистического вывода

Выше мы сказали, что для проверки гипотезы нужны две вещи:

результаты наблюдений и
критерий.
С результатами наблюдений более-менее очевидно.

Критерий — это правило, согласно которому гипотезу либо принимают, либо отклоняют. Однако перед тем как проверять гипотезу, её так-то нужно сформулировать, и сделать это правильно, поскольку от формулировки гипотезы зависит интерпретация результатов проверки и дальнейшее использование полученной информации.

Используемая статистика сама по себе является [непрерывной] случайной величиной, а значит может быть построено её распределение. Критерий будет разделять это распределение на непересекающиеся области. В результате чего возникает критическая область — область отклонения гипотезы. Дополнением к ней является область неотклонения гипотезы.

Критическая область может быть односторонней (при  
H
1
:
θ
>
θ
0
  или  
H
1
:
θ
<
θ
0
 ) и двусторонней (при  
H
1
:
θ
≠
θ
0
 ). «Размер» критической области определяется уровнем значимости.

Статистический вывод — заключение о том, получили ли мы подтверждение альтернативной гипотезы — по структуре представляет собой импликацию. Если вам не знаком этот термин из логики, то вот:

Если значение нашей статистики, которое мы рассчитали на выборке, попало в критическую область, то мы говорим о том, что нулевая гипотеза отклоняется.
Если значение нашей статистики, которое мы рассчитали на выборке, не попало в критическую область, то мы не получаем оснований для того, чтобы отклонить нулевую гипотезу. Однако мы также не получаем оснований, чтобы её «принять». Мы остаёмся в некотором неведении: мы не нашли различий, а есть они там или нет — хто ж их знает… Итого, мы не можем сделать никакого вывода.
В этом и заключается асимметрия статистического вывода. Как раз для того, чтобы с ней как-то жить, мы работаем со статистической мощностью.

Посмотреть, как все эти штуки друг с другом соотносятся можно тут.
--->

## Алгоритм тестирования статистических гипотез

Для тестирования гипотез есть два сценария: первый и тот, которым мы будем пользоваться. Первый вариант чуть более классический, второй --- более гибкий.

:::{.callout-tip}
### Сценарий номер раз

1. Формулировка гипотезы
1. Выбор статистического критерия
1. Выбор уровня значимости $\alpha$
1. Расчёт выборочной статистики
1. Построение закона распределения статистики критерия при условии, что нулевая гипотеза верна
1. Определение границ критической области
1. Определение, попадает ли наблюдаемое значение статистики в критическую область и статистический вывод
:::

:::{.callout-tip}
### Сценарий номер два

1. Формулировка гипотезы
1. Выбор статистического критерия
1. Выбор уровня значимости $\alpha$
1. Расчёт выборочной статистики
1. Построение закона распределения статистики критерия при условии, что нулевая гипотеза верна
1. Расчёт p-значения (p-value)
1. Сопоставление $\alpha$ и p-value и статистический вывод
:::

Разберёмся на примере, что значит каждый из обозначенных шагов в обоих алгоритмах.

Пусть у нас есть следующая ситуация: мы изучаем студентов трёх неких факультетов психологии и хотим выяснить, каков их уровень открытости к опыту [как личностной черты]. Пусть также у нас есть результаты по опроснику Большой пятерки в T-шкале[^t-score]. Опираясь на теорию черт, мы воспользуемся допущением, что в генеральной совокупности личностные черты распределены нормально, а исходя из устройства T-шкалы, мы можем сказать, что интересующая нас переменная «открытость к опыту» имеет в генеральной совокупности нормальное распределение со средним 50 и стандартным отклонением 10, то есть $X \thicksim \mathcal N (50, 100)$.

[^t-score]: T-шкала (T-score) --- одна из стандартных шкал, для которой среднее равно 50, а стандартное отклонение --- 10.

```{r}
mu0 <- 50
sd0 <- 10
Na <- 50
Nb <- 50
Nc <- 50
Nd <- 30
Xa <- 51
Xb <- 53
Xc <- 47
Xd <- 47
```

```{r}
z_test <- function(x, n, mu = 0, sd = 1, alt = "ts") {
  z <- (x - mu)/(sd/sqrt(n))
  if (alt == "gr") {
    p <- 1 - pnorm(z)
  } else if (alt == "lo") {
    p <- pnorm(z)
  } else {
    if (z >= 0) {
      p <- 2 * (1 - pnorm(z))
    } else {
      p <- 2 * pnorm(z)
    }
  }
  return(
    list(z = z,
         p = p)
  )
}

resA <- z_test(Xa, Na, mu0, sd0)
resB <- z_test(Xb, Nb, mu0, sd0)
resC <- z_test(Xc, Nc, mu0, sd0)
resD <- z_test(Xd, Nd, mu0, sd0)
```

Для проверки гипотезы мы имеем следующие данные:

:::{#tbl-z-means}

|Факультет|Количество респондентов|Средний балл по шкале «Открытость к опыту»|
|:---|:---:|:---:|
|A|`r Na`|`r Xa`|
|B|`r Nb`|`r Xb`|
|C|`r Nc`|`r Xc`|
|D|`r Nd`|`r Xd`|

Количество респондентов и средние баллы по шкале в выборках
:::



Итак, сформулируем гипотезы. Рассмотрим сначала такой случай:

- **Теоретическая**: уровень открытости к опыту у студентов отличается от среднего уровня.
- **Эмпирическая**: балл по шкале «Открытость к опыту» отличается от среднего значения по данной шкале.

Теоретические и эмпирические гипотезы не касаются напрямую статистического анализа, так как мы в рамках него заняты тестированием *статистических* гипотез. Однако поскольку статистические гипотезы должны быть согласованы с эмпирическими, которые, в свою очередь, должны быть согласованы с теоретическими, мы прописали эти весьма незамысловатые гипотезы. Теперь же сформулируем статистические.

### Формулировка гипотезы

Для обозначенной эмпирической гипотезы подойдут следующие статистические:

$$
\begin{aligned}
H_0&: \mu = 50 \\
H_1&: \mu \neq 50
\end{aligned}
$$

В формулировке гипотезы фигурирует $\mu$ --- так обозначается среднее генеральной совокупности. Действительно, как мы отмечали в начале главы, статистические гипотезы формулируются в терминах параметров генеральной совокупности. И действительно, как мы говорили в первой главе, мы хотели бы изучать всех студентов того или иного факультета, но в силу ограниченности ресурсов работаем с выборкой. Может показаться, что проверяя гипотезу «балл по шкале “Открытость к опыту” отличается от среднего значения по данной шкале», мы должны сравнивать балл каждого респондента со средним, но это, конечно же, не так, поскольку нас интересует, отличается ли *в среднем* балл респондентов от среднего по шкале --- в данном случае 50. Балл каждого отдельного респондента отличаться от 50, безусловно, будет[^discrete-score] ввиду неопределенности и вариативности данных.

[^discrete-score]: Совпадение в данном случае всё же возможно ввиду того, что T-шкала дискретная, однако даже это совпадение может быть случайным, так как в тестовый балл входит также ошибка измерения, что подробнее обсуждается в курсе психометрики.


### Выбор статистического критерия

Теперь необходимо подобраться статистический критерий для проверки заявленных статистических гипотез. 

$$
z = \frac{\overline X - \mu_0}{\text{se}_X} 
= \frac{\overline X - \mu_0}{\dfrac{\sigma_X}{\sqrt{n}}}
$$

### Выбор уровня значимости

Здесь мы воспользуемся конвенциональным значением: $\alpha = 0.05$.

### Расчёт выборочной статистики

Вспомним таблицу [-@tbl-z-means]

$$
\begin{aligned}
z_A = \frac{51 - 50}{10/\sqrt{50}} \approx 0.707 \\
z_B = \frac{53 - 50}{10/\sqrt{50}} \approx 2.121 \\
z_C = \frac{47 - 50}{10/\sqrt{50}} \approx -2.121 \\
z_D = \frac{47 - 50}{10/\sqrt{30}} \approx -1.643 \\
\end{aligned}
$$

### Распределение статистики

```{r}
ggplot() +
  geom_function(fun = dnorm) + 
  xlim(-4, 4)
```




### Критическая область vs p-value


```{r}
ggplot() +
  geom_function(fun = dnorm) + 
  stat_function(fun = dnorm, geom = "area", xlim = c(1.96, 4), fill = "red", alpha = .5) +
  stat_function(fun = dnorm, geom = "area", xlim = c(-4, -1.96), fill = "red", alpha = 0.5) +
  xlim(-4, 4)
```


```{r}
ggplot() +
  geom_function(fun = dnorm) + 
  stat_function(fun = dnorm, geom = "area", xlim = c(1.96, 4), fill = "red", alpha = .5) +
  stat_function(fun = dnorm, geom = "area", xlim = c(-4, -1.96), fill = "red", alpha = 0.5) +
  stat_function(fun = dnorm, geom = "area", xlim = c(resA$z, 4), fill = "blue", alpha = 0.5) +
  xlim(-4, 4)
```

```{r}
ggplot() +
  geom_function(fun = dnorm) + 
  stat_function(fun = dnorm, geom = "area", xlim = c(1.96, 4), fill = "red", alpha = .5) +
  stat_function(fun = dnorm, geom = "area", xlim = c(-4, -1.96), fill = "red", alpha = 0.5) +
  stat_function(fun = dnorm, geom = "area", xlim = c(resB$z, 4), fill = "blue", alpha = 0.5) +
  xlim(-4, 4)
```

```{r}
ggplot() +
  geom_function(fun = dnorm) + 
  stat_function(fun = dnorm, geom = "area", xlim = c(1.96, 4), fill = "red", alpha = .5) +
  stat_function(fun = dnorm, geom = "area", xlim = c(-4, -1.96), fill = "red", alpha = 0.5) +
  stat_function(fun = dnorm, geom = "area", xlim = c(-4, resC$z), fill = "blue", alpha = 0.5) +
  xlim(-4, 4)
```

```{r}
ggplot() +
  geom_function(fun = dnorm) + 
  stat_function(fun = dnorm, geom = "area", xlim = c(1.96, 4), fill = "red", alpha = .5) +
  stat_function(fun = dnorm, geom = "area", xlim = c(-4, -1.96), fill = "red", alpha = 0.5) +
  stat_function(fun = dnorm, geom = "area", xlim = c(-4, resD$z), fill = "blue", alpha = 0.5) +
  xlim(-4, 4)
```



### Статистический вывод




<!---
Почему второй вариант более гибкий? Представим, что мы захотели понизить уровень значимости с $0.05$ до $0.01$ --- такие уровни значимости всречаются, например, в медицине. Если мы идем по первому сценарию, то нам надо заново пересчитать критические значения и вновь проанализировать, попадает ли наблюдаемое значение в критическую область. Если мы адепты второго сценария, то нам надо только выполнить одно новое сравнение нашего p-value с новым уровнем значимости.
--->
