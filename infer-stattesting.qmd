# Тестирование статистических гипотез

Мы затеваем исследование, чтобы проверить какие-либо гипотезы. Поэтому в ходе статистического анализа мы, главным образом, заняты тем, что тестируем *статистические гипотезы*. Ведь на какого рода вопросы мы отвечаем с помощью анализа?

- Различаются ли группы между собой?
- Значимо ли влияние какого-либо фактора? → Различаются ли группы между собой?
- Хороша ли та модель, которую мы построили? → Отличается ли она от нулевой модели?

И так далее. Так или иначе, всё сводится к тому, что мы ищем какие-то различия. Но силу того, что у нас неопределённость и вариативность в данных, мы просто так «в лоб» сказать о различиях по оценкам параметров не можем. Приходится тестировать статистические гипотезы.

## Базовые понятия

:::{#def-hepothesis}
**Гипотеза** ($H$) --- это предположение, которое подлежит проверке на основе результатов наблюдений.
:::

Гипотезы, как мы знаем, бывают трех видов:

- **Теоретическая** --- про конструкты
- **Эмпирическая** --- про переменные (зависимые и независимые)
- **Статистическая**
    - с одной стороны, про данные --- что мы получили в данный конкретный момент, собрав вот эти конкретные данные
    - с другой стороны, про параметры генеральной совокупности --- так как мы стремимся всё же изучать их, работая с выборкой

Статистические гипотезы бывают *простыми* и *сложными*.

- **Простая гипотеза** --- это такое предположение, которое включает в себя какое-либо однозначно определяемое утверждение.

Например, истинная величина параметра соответствует некоторому строго заданному значению: $H: \theta = \theta_0$. Другой вариант --- две генеральные совокупности имеют одно и то же значение одной и той же характеристики: $H: \theta_1 = \theta_2$.

- **Сложная гипотеза** предполагает множественность вариантов для параметра, которые укладываются в рамки проверяемого предположения. Например, $H: \theta > \theta_0$ или $H: \theta_1 \neq \theta_2$.

В рамках самого хода тестирования гипотез существует **проверяемая (нулевая) гипотеза** ($H_0$). Её обычно стараются предельно упростить, поэтому она чаще всего формулируется как простая гипотеза. В противовес ей выдвигается **альтернативная гипотеза** ($H_1$), которая будет иметь, как следствие, вид сложной гипотезы.

Для проверки гипотезы нужны три вещи:

- результаты наблюдений
- статистический критерий
- критерий статистического вывода.

*Результаты наблюдений*, очевидно, являются основой проверки гипотезы. Однако как мы отмечали в самом начале, сказать о различии генеральных средних просто сравнив выборочные средние мы не сможем.

Здесь нам на помощь приходит *статистический критерий*. Это некоторый способ протестировать нашу гипотезу.

Результаты наблюдений, полученные на выборке, сами по себе, как правило, не используются. Однако на их основе рассчитываются выборочные статистики (показатели), которые непосредственно участвуют в проверке гипотезы.

В результате проверки статистических гипотез могут возникнуть четыре ситуации.

## Возможные результаты проверки гипотез

Мы изучаем в исследовании какую-либо закономерность, которая в реальном мире может существовать, а может и не существовать. В силу неопределённости и вариативности наших данных мы может либо обнаружить интересующую нас закономерность, либо не обнаружить.

В качестве нулевой гипотезы мы выдвигаем предположение о том, что закономерность отсутствует — так мы упрощаем нашу нулевую гипотезу. Пусть  
H
0
  обозначает, что предположение, которое мы проверяем справедливо, а  
H
1
  — не справедливо. На основании данных мы можем либо не отклонить наше предположение ( 
^
H
0
 ), либо отклонить ( 
^
H
1
 ).

Тогда имеем следующую ситуацию:

H
0
 	 
H
1
 
^
H
0
 	✓	Ошибка II рода
^
H
1
 	Ошибка I рода	✓
Ошибка I рода возникает, когда в генеральной совокупности искомой закономерности нет, но мы в силу случайных флуктуаций в данных её нашли.
Ошибка II рода возникает, когда в генеральной совокупности искомая закономерность есть, но мы в силу каких-либо причин её не нашли.
Ошибки — это нехорошо, они нас не устраивают. Надо каким-то образом их контролировать.

Ошибка I рода контролируется достаточно просто. Так как мы нашли закономерность, которую искали, мы можем посчитать вероятность, с которой потенциально ошиблись. А собственно контролировать ошибку мы будем с помощью уровня значимости  
α
 , который выбирается до начала процедуры тестирования гипотезы. Он и задает вероятность, с который мы позволяем себе ошибиться — отклонить нулевую гипотезу, при условии, что она верна.

Ошибку II рода контролировать сложнее, так как мы не нашли закономерность, которую искали. Нам нужна какая-то метрика, которая позволит сказать, что мы сделали всё возможное для того, чтобы обнаружить искомую закономерность. Вероятность ошибки II рода обозначается  
β
  — тогда вероятность того, что мы не совершили ошибку II рода будет  
1
−
β
 . Эта величина называется статистической мощностью, и она связана с размером эффекта и объемом выборки. Статистическую мощность можно рассчитать как до проведения статистического анализа — для расчета требуемого объема выборки — так и после — для определения достигнутой статистической мощности.

Соберем все обозначения в единую табличку1:

H
0
 	 
H
1
 
^
H
0
 	 
P
(
^
H
0
|
H
0
)
 	 
P
(
^
H
0
|
H
1
)
=
β
 
^
H
1
 	 
P
(
^
H
1
|
H
0
)
=
α
 	 
P
(
^
H
1
|
H
1
)
=
1
−
β
 
Уровень значимости  
α
  выбирается близким к нулю — всем знакомо конвенциональное значение  
0.05
 . Вообще  
α
  можно выбрать сколь угодно малым, однако при выборе уровня значимости руководствуются принципом разумной достаточности, так как если устремить  
α
  к нулю, то устремиться к нулю и вероятность отклонения нулевой гипотезы

Математические руны
Достаточной статистической мощностью считается  
0.8
 . Аналогично, устремляя мощность к единице ( 
(
1
−
β
)
→
1
⇒
β
→
0
 ), мы устремляем вероятность не отклонения нулевой гипотезы к нулю:

Ещё математические руны
Необходимо также помнить, что ошибки первого и второго рода связаны между собой так, что

α
→
0
⇒
β
→
1
 

Опять математические руны


## Асимметрия статистического вывода

Выше мы сказали, что для проверки гипотезы нужны две вещи:

результаты наблюдений и
критерий.
С результатами наблюдений более-менее очевидно.

Критерий — это правило, согласно которому гипотезу либо принимают, либо отклоняют. Однако перед тем как проверять гипотезу, её так-то нужно сформулировать, и сделать это правильно, поскольку от формулировки гипотезы зависит интерпретация результатов проверки и дальнейшее использование полученной информации.

Используемая статистика сама по себе является [непрерывной] случайной величиной, а значит может быть построено её распределение. Критерий будет разделять это распределение на непересекающиеся области. В результате чего возникает критическая область — область отклонения гипотезы. Дополнением к ней является область неотклонения гипотезы.

Критическая область может быть односторонней (при  
H
1
:
θ
>
θ
0
  или  
H
1
:
θ
<
θ
0
 ) и двусторонней (при  
H
1
:
θ
≠
θ
0
 ). «Размер» критической области определяется уровнем значимости.

Статистический вывод — заключение о том, получили ли мы подтверждение альтернативной гипотезы — по структуре представляет собой импликацию. Если вам не знаком этот термин из логики, то вот:

Если значение нашей статистики, которое мы рассчитали на выборке, попало в критическую область, то мы говорим о том, что нулевая гипотеза отклоняется.
Если значение нашей статистики, которое мы рассчитали на выборке, не попало в критическую область, то мы не получаем оснований для того, чтобы отклонить нулевую гипотезу. Однако мы также не получаем оснований, чтобы её «принять». Мы остаёмся в некотором неведении: мы не нашли различий, а есть они там или нет — хто ж их знает… Итого, мы не можем сделать никакого вывода.
В этом и заключается асимметрия статистического вывода. Как раз для того, чтобы с ней как-то жить, мы работаем со статистической мощностью.

Посмотреть, как все эти штуки друг с другом соотносятся можно тут.

## Алгоритм тестирования статистических гипотез

Для тестирования гипотез есть два сценария: первый и тот, которым мы будем пользоваться. Первый вариант чуть более классический, второй — более гибкий.

Сценарий номер раз

Формулировка гипотезы
Выбор статистического критерия
Выбор уровня значимости  
α
 
Построение закона распредления статистики критерия при условии, что нулевая гипотеза верна
Определение границ критической области
Расчёт выборочной статистики
Определение, попадает ли наблюдемое значение статистики в критическую область и вынесение решения
Сценарий номер два

Формулировка гипотезы
Выбор статистического критерия
Выбор уровня значимости  
α
 
Построение закона распредлеения статистики критерия при условии, что нулевая гипотеза верна
Расчёт выборочной статистики
Расчёт достигнутого уровня значимости p-value
Сопоставление  
α
  и p-value и вынесение решения
Почему второй вариант более гибкий? Представим, что мы захотели понизить уровень значимости с  
0.05
  до  
0.01
  — такие уровни значимости всречаются, например, в медицине. Если мы идем по первому сценарию, то нам надо заново пересчитать критические значения и вновь проанализировать, попадает ли наблюдаемое значение в критическую область. Если мы адепты второго сценария, то нам надо только выполнить одно новое сравнение нашего p-value с новым уровнем значимости.

Вероятно, пока мало что понятно. Поэтому в следующей главе разберем все это безобразие на примере.

Здесь использовано обозначение условной вероятности  
P
(
A
|
B
)
 , то есть это вероятность того, что случилось событие  
A
  при условии, что случилось событие  
B
 .↩︎
 